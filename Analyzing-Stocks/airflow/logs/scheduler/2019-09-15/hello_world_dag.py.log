[2019-09-15 13:20:00,114] {scheduler_job.py:146} INFO - Started process (PID=18691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:05,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:05,134] {logging_mixin.py:95} INFO - [2019-09-15 13:20:05,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:05,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:05,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:05,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:05,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-09-15 13:20:05,652] {scheduler_job.py:146} INFO - Started process (PID=18711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:10,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:10,675] {logging_mixin.py:95} INFO - [2019-09-15 13:20:10,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:12,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:12,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:12,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:12,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.545 seconds
[2019-09-15 13:20:12,287] {scheduler_job.py:146} INFO - Started process (PID=18721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:17,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:17,302] {logging_mixin.py:95} INFO - [2019-09-15 13:20:17,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:17,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:17,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:17,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:17,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.690 seconds
[2019-09-15 13:20:18,043] {scheduler_job.py:146} INFO - Started process (PID=18726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:23,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:23,052] {logging_mixin.py:95} INFO - [2019-09-15 13:20:23,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:23,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:23,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:23,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:23,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.659 seconds
[2019-09-15 13:20:23,803] {scheduler_job.py:146} INFO - Started process (PID=18747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:28,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:28,821] {logging_mixin.py:95} INFO - [2019-09-15 13:20:28,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:29,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:29,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:29,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:29,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.611 seconds
[2019-09-15 13:20:29,456] {scheduler_job.py:146} INFO - Started process (PID=18752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:34,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:34,469] {logging_mixin.py:95} INFO - [2019-09-15 13:20:34,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:34,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:34,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:34,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:34,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.528 seconds
[2019-09-15 13:20:35,038] {scheduler_job.py:146} INFO - Started process (PID=18755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:40,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:40,047] {logging_mixin.py:95} INFO - [2019-09-15 13:20:40,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:40,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:40,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:40,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:40,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-15 13:20:40,605] {scheduler_job.py:146} INFO - Started process (PID=18759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:45,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:45,619] {logging_mixin.py:95} INFO - [2019-09-15 13:20:45,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:46,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:46,035] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:46,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:46,052] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-15 13:20:46,071] {scheduler_job.py:146} INFO - Started process (PID=18761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:51,079] {logging_mixin.py:95} INFO - [2019-09-15 13:20:51,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:51,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:51,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 13:20:51,535] {scheduler_job.py:146} INFO - Started process (PID=18772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:51,541] {logging_mixin.py:95} INFO - [2019-09-15 13:20:51,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:51,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:20:51,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:20:51,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.419 seconds
[2019-09-15 13:20:52,042] {scheduler_job.py:146} INFO - Started process (PID=18773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:20:52,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:20:52,048] {logging_mixin.py:95} INFO - [2019-09-15 13:20:52,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:16,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:16,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:16,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:16,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 1824.349 seconds
[2019-09-15 13:51:16,427] {scheduler_job.py:146} INFO - Started process (PID=18775) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:21,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:21,433] {logging_mixin.py:95} INFO - [2019-09-15 13:51:21,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:21,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:21,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:21,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:21,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-15 13:51:21,883] {scheduler_job.py:146} INFO - Started process (PID=18783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:26,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:26,900] {logging_mixin.py:95} INFO - [2019-09-15 13:51:26,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:28,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:28,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:28,435] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:28,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.573 seconds
[2019-09-15 13:51:28,519] {scheduler_job.py:146} INFO - Started process (PID=18787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:33,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:33,538] {logging_mixin.py:95} INFO - [2019-09-15 13:51:33,537] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:34,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:34,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:34,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:34,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.439 seconds
[2019-09-15 13:51:35,020] {scheduler_job.py:146} INFO - Started process (PID=18791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:40,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:40,035] {logging_mixin.py:95} INFO - [2019-09-15 13:51:40,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:40,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:40,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:40,435] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:40,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 13:51:40,481] {scheduler_job.py:146} INFO - Started process (PID=18796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:45,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:45,490] {logging_mixin.py:95} INFO - [2019-09-15 13:51:45,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:45,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:45,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:45,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:45,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 13:51:45,954] {scheduler_job.py:146} INFO - Started process (PID=18797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:50,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:50,968] {logging_mixin.py:95} INFO - [2019-09-15 13:51:50,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:51,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:51,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:51,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:51,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 13:51:51,443] {scheduler_job.py:146} INFO - Started process (PID=18799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:56,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:51:56,454] {logging_mixin.py:95} INFO - [2019-09-15 13:51:56,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:56,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:51:56,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:51:56,822] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:51:56,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 13:51:56,932] {scheduler_job.py:146} INFO - Started process (PID=18801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:01,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:52:01,943] {logging_mixin.py:95} INFO - [2019-09-15 13:52:01,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:02,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:02,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:52:02,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:52:02,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 13:52:02,420] {scheduler_job.py:146} INFO - Started process (PID=18803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:07,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:52:07,432] {logging_mixin.py:95} INFO - [2019-09-15 13:52:07,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:07,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:07,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:52:07,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:52:07,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 13:52:07,900] {scheduler_job.py:146} INFO - Started process (PID=18804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:07,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:52:07,906] {logging_mixin.py:95} INFO - [2019-09-15 13:52:07,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:52:08,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:52:08,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 13:52:08,309] {scheduler_job.py:146} INFO - Started process (PID=18805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:52:08,314] {logging_mixin.py:95} INFO - [2019-09-15 13:52:08,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 13:52:08,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 13:52:08,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.363 seconds
[2019-09-15 13:52:08,717] {scheduler_job.py:146} INFO - Started process (PID=18807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 13:52:08,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 13:52:08,722] {logging_mixin.py:95} INFO - [2019-09-15 13:52:08,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:39,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:39,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:30:39,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:30:39,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2310.764 seconds
[2019-09-15 14:30:39,528] {scheduler_job.py:146} INFO - Started process (PID=18811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:44,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:30:44,534] {logging_mixin.py:95} INFO - [2019-09-15 14:30:44,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:44,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:44,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:30:44,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:30:44,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 14:30:44,972] {scheduler_job.py:146} INFO - Started process (PID=18817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:49,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:30:49,989] {logging_mixin.py:95} INFO - [2019-09-15 14:30:49,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:51,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:51,436] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:30:51,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:30:51,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.521 seconds
[2019-09-15 14:30:51,594] {scheduler_job.py:146} INFO - Started process (PID=18822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:56,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:30:56,614] {logging_mixin.py:95} INFO - [2019-09-15 14:30:56,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:57,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:30:57,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:30:58,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:30:58,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.434 seconds
[2019-09-15 14:30:58,108] {scheduler_job.py:146} INFO - Started process (PID=18824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:03,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:03,118] {logging_mixin.py:95} INFO - [2019-09-15 14:31:03,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:03,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:03,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:03,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:03,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:31:03,577] {scheduler_job.py:146} INFO - Started process (PID=18826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:08,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:08,591] {logging_mixin.py:95} INFO - [2019-09-15 14:31:08,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:08,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:08,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:08,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:08,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:31:08,976] {scheduler_job.py:146} INFO - Started process (PID=18828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:13,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:13,985] {logging_mixin.py:95} INFO - [2019-09-15 14:31:13,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:14,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:14,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:14,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:14,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 14:31:14,469] {scheduler_job.py:146} INFO - Started process (PID=18829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:19,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:19,476] {logging_mixin.py:95} INFO - [2019-09-15 14:31:19,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:19,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:19,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:19,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:19,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 14:31:19,956] {scheduler_job.py:146} INFO - Started process (PID=18830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:24,968] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:24,969] {logging_mixin.py:95} INFO - [2019-09-15 14:31:24,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:25,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:25,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:25,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:25,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:31:25,446] {scheduler_job.py:146} INFO - Started process (PID=18832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:30,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:30,459] {logging_mixin.py:95} INFO - [2019-09-15 14:31:30,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:30,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:30,809] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:30,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:30,823] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:31:30,935] {scheduler_job.py:146} INFO - Started process (PID=18833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:30,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:30,940] {logging_mixin.py:95} INFO - [2019-09-15 14:31:30,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:31,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:31,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-15 14:31:31,341] {scheduler_job.py:146} INFO - Started process (PID=18834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:31,346] {logging_mixin.py:95} INFO - [2019-09-15 14:31:31,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:31:31,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:31:31,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-15 14:31:31,749] {scheduler_job.py:146} INFO - Started process (PID=18835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:31:31,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:31:31,754] {logging_mixin.py:95} INFO - [2019-09-15 14:31:31,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:24,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:24,328] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:24,336] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:24,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 232.592 seconds
[2019-09-15 14:35:24,418] {scheduler_job.py:146} INFO - Started process (PID=18837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:29,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:29,429] {logging_mixin.py:95} INFO - [2019-09-15 14:35:29,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:29,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:29,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:29,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:29,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:35:29,889] {scheduler_job.py:146} INFO - Started process (PID=18842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:34,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:34,907] {logging_mixin.py:95} INFO - [2019-09-15 14:35:34,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:36,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:36,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:36,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:36,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.602 seconds
[2019-09-15 14:35:36,627] {scheduler_job.py:146} INFO - Started process (PID=18845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:36,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:36,644] {logging_mixin.py:95} INFO - [2019-09-15 14:35:36,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:37,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:38,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:46,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:46,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 9.614 seconds
[2019-09-15 14:35:46,339] {scheduler_job.py:146} INFO - Started process (PID=18848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:46,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:46,345] {logging_mixin.py:95} INFO - [2019-09-15 14:35:46,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:46,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:46,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:46,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:46,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.454 seconds
[2019-09-15 14:35:46,846] {scheduler_job.py:146} INFO - Started process (PID=18850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:51,852] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:51,854] {logging_mixin.py:95} INFO - [2019-09-15 14:35:51,853] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:52,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:52,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:52,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:52,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:35:52,303] {scheduler_job.py:146} INFO - Started process (PID=18863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:57,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:35:57,310] {logging_mixin.py:95} INFO - [2019-09-15 14:35:57,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:57,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:35:57,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:35:57,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:35:57,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 14:35:57,753] {scheduler_job.py:146} INFO - Started process (PID=18867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:02,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:02,761] {logging_mixin.py:95} INFO - [2019-09-15 14:36:02,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:03,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:03,263] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:03,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:03,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.531 seconds
[2019-09-15 14:36:03,387] {scheduler_job.py:146} INFO - Started process (PID=18869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:08,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:08,403] {logging_mixin.py:95} INFO - [2019-09-15 14:36:08,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:08,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:08,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:08,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:08,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 14:36:08,936] {scheduler_job.py:146} INFO - Started process (PID=18871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:13,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:13,944] {logging_mixin.py:95} INFO - [2019-09-15 14:36:13,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:14,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:14,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:14,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:14,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.586 seconds
[2019-09-15 14:36:14,583] {scheduler_job.py:146} INFO - Started process (PID=18879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:19,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:19,590] {logging_mixin.py:95} INFO - [2019-09-15 14:36:19,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:19,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:20,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:20,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:20,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 14:36:20,120] {scheduler_job.py:146} INFO - Started process (PID=18883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:25,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:25,126] {logging_mixin.py:95} INFO - [2019-09-15 14:36:25,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:25,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:25,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:25,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:25,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 14:36:25,671] {scheduler_job.py:146} INFO - Started process (PID=18884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:30,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:30,680] {logging_mixin.py:95} INFO - [2019-09-15 14:36:30,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:31,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:31,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:31,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:31,058] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:36:31,124] {scheduler_job.py:146} INFO - Started process (PID=18885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:36,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:36,136] {logging_mixin.py:95} INFO - [2019-09-15 14:36:36,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:36,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:36,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:36,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:36,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 14:36:36,573] {scheduler_job.py:146} INFO - Started process (PID=18887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:41,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:41,580] {logging_mixin.py:95} INFO - [2019-09-15 14:36:41,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:41,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:41,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:41,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:41,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-15 14:36:42,019] {scheduler_job.py:146} INFO - Started process (PID=18888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:47,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:47,026] {logging_mixin.py:95} INFO - [2019-09-15 14:36:47,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:47,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:47,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:47,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:47,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 14:36:47,463] {scheduler_job.py:146} INFO - Started process (PID=18889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:52,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:52,473] {logging_mixin.py:95} INFO - [2019-09-15 14:36:52,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:52,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:52,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:52,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:52,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:36:52,910] {scheduler_job.py:146} INFO - Started process (PID=18891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:57,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:36:57,920] {logging_mixin.py:95} INFO - [2019-09-15 14:36:57,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:58,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:36:58,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:36:58,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:36:58,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 14:36:58,353] {scheduler_job.py:146} INFO - Started process (PID=18893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:03,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:03,363] {logging_mixin.py:95} INFO - [2019-09-15 14:37:03,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:03,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:03,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:03,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:03,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:37:03,799] {scheduler_job.py:146} INFO - Started process (PID=18894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:08,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:08,808] {logging_mixin.py:95} INFO - [2019-09-15 14:37:08,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:09,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:09,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:09,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:09,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:37:09,247] {scheduler_job.py:146} INFO - Started process (PID=18896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:14,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:14,257] {logging_mixin.py:95} INFO - [2019-09-15 14:37:14,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:14,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:14,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:14,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:14,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:37:14,700] {scheduler_job.py:146} INFO - Started process (PID=18897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:19,706] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:19,707] {logging_mixin.py:95} INFO - [2019-09-15 14:37:19,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:20,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:20,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:20,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:20,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:37:20,145] {scheduler_job.py:146} INFO - Started process (PID=18916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:25,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:25,155] {logging_mixin.py:95} INFO - [2019-09-15 14:37:25,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:25,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:25,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:25,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:25,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 14:37:25,598] {scheduler_job.py:146} INFO - Started process (PID=18917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:30,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:30,608] {logging_mixin.py:95} INFO - [2019-09-15 14:37:30,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:30,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:30,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:30,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:30,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:37:31,047] {scheduler_job.py:146} INFO - Started process (PID=18918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:36,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:36,053] {logging_mixin.py:95} INFO - [2019-09-15 14:37:36,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:36,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:36,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:36,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:36,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:37:36,508] {scheduler_job.py:146} INFO - Started process (PID=18920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:41,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:41,520] {logging_mixin.py:95} INFO - [2019-09-15 14:37:41,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:41,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:41,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:41,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:41,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:37:41,970] {scheduler_job.py:146} INFO - Started process (PID=18921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:46,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:46,981] {logging_mixin.py:95} INFO - [2019-09-15 14:37:46,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:47,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:47,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:47,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:47,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 14:37:47,422] {scheduler_job.py:146} INFO - Started process (PID=18922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:52,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:52,427] {logging_mixin.py:95} INFO - [2019-09-15 14:37:52,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:52,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:52,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:52,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:52,805] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:37:52,854] {scheduler_job.py:146} INFO - Started process (PID=18924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:57,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:37:57,864] {logging_mixin.py:95} INFO - [2019-09-15 14:37:57,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:58,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:37:58,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:37:58,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:37:58,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:37:58,292] {scheduler_job.py:146} INFO - Started process (PID=18926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:03,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:03,303] {logging_mixin.py:95} INFO - [2019-09-15 14:38:03,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:03,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:03,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:03,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:03,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 14:38:03,747] {scheduler_job.py:146} INFO - Started process (PID=18927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:08,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:08,758] {logging_mixin.py:95} INFO - [2019-09-15 14:38:08,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:09,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:09,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:09,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:09,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 14:38:09,188] {scheduler_job.py:146} INFO - Started process (PID=18929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:14,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:14,195] {logging_mixin.py:95} INFO - [2019-09-15 14:38:14,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:14,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:14,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:14,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:14,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:38:14,637] {scheduler_job.py:146} INFO - Started process (PID=18930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:19,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:19,649] {logging_mixin.py:95} INFO - [2019-09-15 14:38:19,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:20,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:20,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:20,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:20,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 14:38:20,081] {scheduler_job.py:146} INFO - Started process (PID=18932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:25,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:25,088] {logging_mixin.py:95} INFO - [2019-09-15 14:38:25,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:25,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:25,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:25,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:25,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:38:25,536] {scheduler_job.py:146} INFO - Started process (PID=18933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:30,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:30,548] {logging_mixin.py:95} INFO - [2019-09-15 14:38:30,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:30,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:30,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:30,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:30,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 14:38:30,975] {scheduler_job.py:146} INFO - Started process (PID=18934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:35,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:35,984] {logging_mixin.py:95} INFO - [2019-09-15 14:38:35,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:36,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:36,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:36,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:36,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:38:36,407] {scheduler_job.py:146} INFO - Started process (PID=18936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:41,414] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:41,415] {logging_mixin.py:95} INFO - [2019-09-15 14:38:41,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:41,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:41,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:41,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:41,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 14:38:41,857] {scheduler_job.py:146} INFO - Started process (PID=18937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:46,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:46,864] {logging_mixin.py:95} INFO - [2019-09-15 14:38:46,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:47,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:47,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:47,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:47,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:38:47,302] {scheduler_job.py:146} INFO - Started process (PID=18938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:52,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:52,308] {logging_mixin.py:95} INFO - [2019-09-15 14:38:52,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:52,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:52,690] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:52,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:52,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:38:52,756] {scheduler_job.py:146} INFO - Started process (PID=18940) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:57,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:38:57,764] {logging_mixin.py:95} INFO - [2019-09-15 14:38:57,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:58,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:38:58,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:38:58,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:38:58,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:38:58,195] {scheduler_job.py:146} INFO - Started process (PID=18942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:03,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:03,203] {logging_mixin.py:95} INFO - [2019-09-15 14:39:03,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:03,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:03,599] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:03,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:03,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 14:39:03,733] {scheduler_job.py:146} INFO - Started process (PID=18943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:08,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:08,739] {logging_mixin.py:95} INFO - [2019-09-15 14:39:08,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:09,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:09,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:09,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:09,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:39:09,172] {scheduler_job.py:146} INFO - Started process (PID=18945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:14,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:14,183] {logging_mixin.py:95} INFO - [2019-09-15 14:39:14,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:14,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:14,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:14,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:14,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:39:14,628] {scheduler_job.py:146} INFO - Started process (PID=18946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:19,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:19,636] {logging_mixin.py:95} INFO - [2019-09-15 14:39:19,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:20,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:20,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:20,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:20,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 14:39:20,187] {scheduler_job.py:146} INFO - Started process (PID=18948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:25,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:25,194] {logging_mixin.py:95} INFO - [2019-09-15 14:39:25,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:25,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:25,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:25,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:25,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 14:39:25,731] {scheduler_job.py:146} INFO - Started process (PID=18949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:30,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:30,739] {logging_mixin.py:95} INFO - [2019-09-15 14:39:30,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:31,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:31,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:31,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:31,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 14:39:31,166] {scheduler_job.py:146} INFO - Started process (PID=18950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:36,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:36,174] {logging_mixin.py:95} INFO - [2019-09-15 14:39:36,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:36,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:36,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:36,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:36,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 14:39:36,605] {scheduler_job.py:146} INFO - Started process (PID=18952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:41,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:41,611] {logging_mixin.py:95} INFO - [2019-09-15 14:39:41,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:41,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:41,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:41,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:41,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:39:42,039] {scheduler_job.py:146} INFO - Started process (PID=18953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:47,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:47,046] {logging_mixin.py:95} INFO - [2019-09-15 14:39:47,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:47,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:47,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:47,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:47,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:39:47,489] {scheduler_job.py:146} INFO - Started process (PID=18954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:52,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:52,498] {logging_mixin.py:95} INFO - [2019-09-15 14:39:52,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:52,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:52,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:52,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:52,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:39:52,934] {scheduler_job.py:146} INFO - Started process (PID=18956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:57,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:39:57,942] {logging_mixin.py:95} INFO - [2019-09-15 14:39:57,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:58,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:39:58,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:39:58,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:39:58,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:39:58,387] {scheduler_job.py:146} INFO - Started process (PID=18958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:03,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:03,397] {logging_mixin.py:95} INFO - [2019-09-15 14:40:03,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:03,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:03,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:03,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:03,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.353 seconds
[2019-09-15 14:40:03,838] {scheduler_job.py:146} INFO - Started process (PID=18959) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:08,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:08,844] {logging_mixin.py:95} INFO - [2019-09-15 14:40:08,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:09,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:09,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:09,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:09,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 14:40:09,291] {scheduler_job.py:146} INFO - Started process (PID=18962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:14,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:14,296] {logging_mixin.py:95} INFO - [2019-09-15 14:40:14,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:14,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:14,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:14,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:14,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 14:40:14,747] {scheduler_job.py:146} INFO - Started process (PID=18963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:19,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:19,756] {logging_mixin.py:95} INFO - [2019-09-15 14:40:19,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:20,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:20,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:20,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:20,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:40:20,208] {scheduler_job.py:146} INFO - Started process (PID=18965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:25,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:25,215] {logging_mixin.py:95} INFO - [2019-09-15 14:40:25,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:25,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:25,645] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:25,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:25,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 14:40:25,746] {scheduler_job.py:146} INFO - Started process (PID=18966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:30,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:30,757] {logging_mixin.py:95} INFO - [2019-09-15 14:40:30,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:31,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:31,168] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:31,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:31,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 14:40:31,278] {scheduler_job.py:146} INFO - Started process (PID=18967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:36,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:36,289] {logging_mixin.py:95} INFO - [2019-09-15 14:40:36,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:36,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:36,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:36,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:36,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:40:36,732] {scheduler_job.py:146} INFO - Started process (PID=18969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:41,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:41,741] {logging_mixin.py:95} INFO - [2019-09-15 14:40:41,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:42,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:42,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:42,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:42,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:40:42,188] {scheduler_job.py:146} INFO - Started process (PID=18970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:47,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:47,194] {logging_mixin.py:95} INFO - [2019-09-15 14:40:47,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:47,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:47,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:47,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:47,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 14:40:47,639] {scheduler_job.py:146} INFO - Started process (PID=18971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:52,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:52,651] {logging_mixin.py:95} INFO - [2019-09-15 14:40:52,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:52,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:53,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:53,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:53,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 14:40:53,095] {scheduler_job.py:146} INFO - Started process (PID=18973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:58,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:40:58,104] {logging_mixin.py:95} INFO - [2019-09-15 14:40:58,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:58,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:40:58,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:40:58,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:40:58,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:40:58,551] {scheduler_job.py:146} INFO - Started process (PID=18975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:03,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:03,559] {logging_mixin.py:95} INFO - [2019-09-15 14:41:03,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:03,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:03,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:03,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:03,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:41:04,012] {scheduler_job.py:146} INFO - Started process (PID=18976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:09,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:09,019] {logging_mixin.py:95} INFO - [2019-09-15 14:41:09,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:09,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:09,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:09,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:09,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-15 14:41:09,467] {scheduler_job.py:146} INFO - Started process (PID=18978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:14,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:14,481] {logging_mixin.py:95} INFO - [2019-09-15 14:41:14,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:14,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:14,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:14,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:14,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:41:14,927] {scheduler_job.py:146} INFO - Started process (PID=18979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:19,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:19,935] {logging_mixin.py:95} INFO - [2019-09-15 14:41:19,935] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:20,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:20,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:20,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:20,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:41:20,384] {scheduler_job.py:146} INFO - Started process (PID=18981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:25,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:25,390] {logging_mixin.py:95} INFO - [2019-09-15 14:41:25,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:25,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:25,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:25,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:25,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 14:41:25,849] {scheduler_job.py:146} INFO - Started process (PID=18982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:30,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:30,859] {logging_mixin.py:95} INFO - [2019-09-15 14:41:30,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:31,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:31,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:31,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:31,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:41:31,308] {scheduler_job.py:146} INFO - Started process (PID=18983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:36,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:36,319] {logging_mixin.py:95} INFO - [2019-09-15 14:41:36,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:36,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:36,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:36,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:36,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:41:36,769] {scheduler_job.py:146} INFO - Started process (PID=18986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:41,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:41,781] {logging_mixin.py:95} INFO - [2019-09-15 14:41:41,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:42,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:42,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:42,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:42,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:41:42,226] {scheduler_job.py:146} INFO - Started process (PID=18987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:47,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:47,233] {logging_mixin.py:95} INFO - [2019-09-15 14:41:47,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:47,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:47,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:47,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:47,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 14:41:47,685] {scheduler_job.py:146} INFO - Started process (PID=18988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:52,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:52,692] {logging_mixin.py:95} INFO - [2019-09-15 14:41:52,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:53,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:53,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:53,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:53,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:41:53,141] {scheduler_job.py:146} INFO - Started process (PID=18990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:58,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:41:58,153] {logging_mixin.py:95} INFO - [2019-09-15 14:41:58,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:58,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:41:58,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:41:58,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:41:58,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 14:41:58,602] {scheduler_job.py:146} INFO - Started process (PID=18992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:03,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:03,612] {logging_mixin.py:95} INFO - [2019-09-15 14:42:03,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:03,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:03,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:03,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:04,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 14:42:04,053] {scheduler_job.py:146} INFO - Started process (PID=18993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:09,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:09,062] {logging_mixin.py:95} INFO - [2019-09-15 14:42:09,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:09,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:09,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:09,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:09,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 14:42:09,495] {scheduler_job.py:146} INFO - Started process (PID=18995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:14,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:14,503] {logging_mixin.py:95} INFO - [2019-09-15 14:42:14,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:14,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:14,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:14,882] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:14,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 14:42:14,948] {scheduler_job.py:146} INFO - Started process (PID=18996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:19,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:19,956] {logging_mixin.py:95} INFO - [2019-09-15 14:42:19,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:20,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:20,320] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:20,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:20,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 14:42:20,401] {scheduler_job.py:146} INFO - Started process (PID=18998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:25,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:25,409] {logging_mixin.py:95} INFO - [2019-09-15 14:42:25,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:25,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:25,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:25,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:25,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:42:25,864] {scheduler_job.py:146} INFO - Started process (PID=18999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:30,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:30,872] {logging_mixin.py:95} INFO - [2019-09-15 14:42:30,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:31,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:31,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:31,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:31,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 14:42:31,317] {scheduler_job.py:146} INFO - Started process (PID=19000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:36,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:36,327] {logging_mixin.py:95} INFO - [2019-09-15 14:42:36,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:36,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:36,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:36,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:36,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:42:36,769] {scheduler_job.py:146} INFO - Started process (PID=19002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:41,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:41,781] {logging_mixin.py:95} INFO - [2019-09-15 14:42:41,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:42,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:42,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:42,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:42,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-09-15 14:42:42,227] {scheduler_job.py:146} INFO - Started process (PID=19003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:47,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:47,238] {logging_mixin.py:95} INFO - [2019-09-15 14:42:47,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:47,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:47,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:47,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:47,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-15 14:42:47,686] {scheduler_job.py:146} INFO - Started process (PID=19004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:52,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:52,696] {logging_mixin.py:95} INFO - [2019-09-15 14:42:52,696] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:53,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:53,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:53,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:53,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:42:53,146] {scheduler_job.py:146} INFO - Started process (PID=19006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:58,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:42:58,156] {logging_mixin.py:95} INFO - [2019-09-15 14:42:58,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:58,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:42:58,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:42:58,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:42:58,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:42:58,602] {scheduler_job.py:146} INFO - Started process (PID=19008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:03,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:03,609] {logging_mixin.py:95} INFO - [2019-09-15 14:43:03,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:03,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:03,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:03,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:03,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 14:43:04,063] {scheduler_job.py:146} INFO - Started process (PID=19009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:09,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:09,071] {logging_mixin.py:95} INFO - [2019-09-15 14:43:09,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:09,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:09,432] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:09,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:09,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:43:09,523] {scheduler_job.py:146} INFO - Started process (PID=19011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:14,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:14,532] {logging_mixin.py:95} INFO - [2019-09-15 14:43:14,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:14,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:14,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:14,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:14,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 14:43:14,983] {scheduler_job.py:146} INFO - Started process (PID=19012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:19,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:19,995] {logging_mixin.py:95} INFO - [2019-09-15 14:43:19,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:20,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:20,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:20,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:20,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:43:20,444] {scheduler_job.py:146} INFO - Started process (PID=19014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:25,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:25,455] {logging_mixin.py:95} INFO - [2019-09-15 14:43:25,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:25,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:25,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:25,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:25,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 14:43:25,908] {scheduler_job.py:146} INFO - Started process (PID=19015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:30,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:30,920] {logging_mixin.py:95} INFO - [2019-09-15 14:43:30,919] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:31,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:31,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:31,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:31,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:43:31,366] {scheduler_job.py:146} INFO - Started process (PID=19016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:36,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:36,372] {logging_mixin.py:95} INFO - [2019-09-15 14:43:36,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:36,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:36,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:36,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:36,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 14:43:36,828] {scheduler_job.py:146} INFO - Started process (PID=19018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:41,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:41,837] {logging_mixin.py:95} INFO - [2019-09-15 14:43:41,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:42,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:42,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:42,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:42,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.350 seconds
[2019-09-15 14:43:42,288] {scheduler_job.py:146} INFO - Started process (PID=19019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:47,297] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:47,298] {logging_mixin.py:95} INFO - [2019-09-15 14:43:47,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:47,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:47,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:47,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:47,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:43:47,748] {scheduler_job.py:146} INFO - Started process (PID=19020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:52,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:52,757] {logging_mixin.py:95} INFO - [2019-09-15 14:43:52,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:53,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:53,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:53,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:53,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 14:43:53,207] {scheduler_job.py:146} INFO - Started process (PID=19022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:58,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:43:58,215] {logging_mixin.py:95} INFO - [2019-09-15 14:43:58,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:58,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:43:58,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:43:58,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:43:58,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:43:58,668] {scheduler_job.py:146} INFO - Started process (PID=19024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:03,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:03,678] {logging_mixin.py:95} INFO - [2019-09-15 14:44:03,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:04,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:04,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:04,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:04,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:44:04,131] {scheduler_job.py:146} INFO - Started process (PID=19025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:09,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:09,138] {logging_mixin.py:95} INFO - [2019-09-15 14:44:09,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:09,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:09,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:09,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:09,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:44:09,594] {scheduler_job.py:146} INFO - Started process (PID=19027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:14,604] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:14,605] {logging_mixin.py:95} INFO - [2019-09-15 14:44:14,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:14,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:14,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:14,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:14,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-15 14:44:15,054] {scheduler_job.py:146} INFO - Started process (PID=19028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:20,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:20,065] {logging_mixin.py:95} INFO - [2019-09-15 14:44:20,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:20,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:20,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:20,439] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:20,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 14:44:20,511] {scheduler_job.py:146} INFO - Started process (PID=19030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:25,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:25,522] {logging_mixin.py:95} INFO - [2019-09-15 14:44:25,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:25,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:25,873] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:25,882] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:25,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 14:44:25,966] {scheduler_job.py:146} INFO - Started process (PID=19031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:30,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:30,973] {logging_mixin.py:95} INFO - [2019-09-15 14:44:30,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:31,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:31,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:31,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:31,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:44:31,427] {scheduler_job.py:146} INFO - Started process (PID=19032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:36,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:36,435] {logging_mixin.py:95} INFO - [2019-09-15 14:44:36,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:36,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:36,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:36,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:36,805] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:44:36,885] {scheduler_job.py:146} INFO - Started process (PID=19034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:41,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:41,897] {logging_mixin.py:95} INFO - [2019-09-15 14:44:41,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:42,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:42,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:42,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:42,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:44:42,347] {scheduler_job.py:146} INFO - Started process (PID=19035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:47,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:47,355] {logging_mixin.py:95} INFO - [2019-09-15 14:44:47,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:47,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:47,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:47,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:47,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:44:47,811] {scheduler_job.py:146} INFO - Started process (PID=19036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:52,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:52,820] {logging_mixin.py:95} INFO - [2019-09-15 14:44:52,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:53,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:53,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:53,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:53,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:44:53,266] {scheduler_job.py:146} INFO - Started process (PID=19038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:58,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:44:58,273] {logging_mixin.py:95} INFO - [2019-09-15 14:44:58,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:58,604] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:44:58,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:44:58,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:44:58,640] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 14:44:58,724] {scheduler_job.py:146} INFO - Started process (PID=19040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:03,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:03,731] {logging_mixin.py:95} INFO - [2019-09-15 14:45:03,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:04,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:04,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:04,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:04,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-15 14:45:04,183] {scheduler_job.py:146} INFO - Started process (PID=19041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:09,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:09,190] {logging_mixin.py:95} INFO - [2019-09-15 14:45:09,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:09,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:09,551] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:09,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:09,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:45:09,640] {scheduler_job.py:146} INFO - Started process (PID=19043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:14,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:14,661] {logging_mixin.py:95} INFO - [2019-09-15 14:45:14,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:14,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:15,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:15,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:15,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 14:45:15,103] {scheduler_job.py:146} INFO - Started process (PID=19044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:20,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:20,113] {logging_mixin.py:95} INFO - [2019-09-15 14:45:20,112] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:20,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:20,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:20,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:20,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 14:45:20,667] {scheduler_job.py:146} INFO - Started process (PID=19047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:25,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:25,694] {logging_mixin.py:95} INFO - [2019-09-15 14:45:25,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:26,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:26,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:26,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:26,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 14:45:26,163] {scheduler_job.py:146} INFO - Started process (PID=19048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:31,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:31,170] {logging_mixin.py:95} INFO - [2019-09-15 14:45:31,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:31,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:31,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:31,538] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:31,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:45:31,560] {scheduler_job.py:146} INFO - Started process (PID=19049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:36,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:36,576] {logging_mixin.py:95} INFO - [2019-09-15 14:45:36,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:36,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:36,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:36,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:36,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 14:45:37,048] {scheduler_job.py:146} INFO - Started process (PID=19051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:37,054] {logging_mixin.py:95} INFO - [2019-09-15 14:45:37,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,388] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:37,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:37,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-09-15 14:45:37,458] {scheduler_job.py:146} INFO - Started process (PID=19052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:37,465] {logging_mixin.py:95} INFO - [2019-09-15 14:45:37,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:37,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:37,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 14:45:37,869] {scheduler_job.py:146} INFO - Started process (PID=19053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:37,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:37,874] {logging_mixin.py:95} INFO - [2019-09-15 14:45:37,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:38,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:38,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.368 seconds
[2019-09-15 14:45:38,279] {scheduler_job.py:146} INFO - Started process (PID=19054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:38,283] {logging_mixin.py:95} INFO - [2019-09-15 14:45:38,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:38,652] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:38,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 14:45:38,689] {scheduler_job.py:146} INFO - Started process (PID=19055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:38,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:38,693] {logging_mixin.py:95} INFO - [2019-09-15 14:45:38,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:39,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:39,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.365 seconds
[2019-09-15 14:45:39,097] {scheduler_job.py:146} INFO - Started process (PID=19056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:39,102] {logging_mixin.py:95} INFO - [2019-09-15 14:45:39,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:39,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:39,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-15 14:45:39,508] {scheduler_job.py:146} INFO - Started process (PID=19057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:39,513] {logging_mixin.py:95} INFO - [2019-09-15 14:45:39,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:39,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:39,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-15 14:45:39,916] {scheduler_job.py:146} INFO - Started process (PID=19058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:39,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:39,921] {logging_mixin.py:95} INFO - [2019-09-15 14:45:39,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:40,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:40,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.382 seconds
[2019-09-15 14:45:40,323] {scheduler_job.py:146} INFO - Started process (PID=19059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:40,328] {logging_mixin.py:95} INFO - [2019-09-15 14:45:40,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:40,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:40,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.356 seconds
[2019-09-15 14:45:40,733] {scheduler_job.py:146} INFO - Started process (PID=19060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:40,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:40,737] {logging_mixin.py:95} INFO - [2019-09-15 14:45:40,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,082] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:41,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:41,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.363 seconds
[2019-09-15 14:45:41,147] {scheduler_job.py:146} INFO - Started process (PID=19061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:41,152] {logging_mixin.py:95} INFO - [2019-09-15 14:45:41,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:41,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:41,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 14:45:41,559] {scheduler_job.py:146} INFO - Started process (PID=19062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:41,562] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:41,563] {logging_mixin.py:95} INFO - [2019-09-15 14:45:41,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:46,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:46,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 4.605 seconds
[2019-09-15 14:45:46,216] {scheduler_job.py:146} INFO - Started process (PID=19063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:46,221] {logging_mixin.py:95} INFO - [2019-09-15 14:45:46,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:46,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:46,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 14:45:46,624] {scheduler_job.py:146} INFO - Started process (PID=19065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:46,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:46,628] {logging_mixin.py:95} INFO - [2019-09-15 14:45:46,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:47,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:47,044] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:47,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:47,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.435 seconds
[2019-09-15 14:45:47,128] {scheduler_job.py:146} INFO - Started process (PID=19066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:52,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:52,142] {logging_mixin.py:95} INFO - [2019-09-15 14:45:52,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:52,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:52,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:52,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:52,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 14:45:52,574] {scheduler_job.py:146} INFO - Started process (PID=19067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:57,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:45:57,581] {logging_mixin.py:95} INFO - [2019-09-15 14:45:57,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:57,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:45:57,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:45:57,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:45:57,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 14:45:58,033] {scheduler_job.py:146} INFO - Started process (PID=19069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:03,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:03,040] {logging_mixin.py:95} INFO - [2019-09-15 14:46:03,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:03,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:03,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:03,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:03,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:46:03,492] {scheduler_job.py:146} INFO - Started process (PID=19073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:08,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:08,504] {logging_mixin.py:95} INFO - [2019-09-15 14:46:08,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:08,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:08,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:08,864] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:08,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:46:08,951] {scheduler_job.py:146} INFO - Started process (PID=19075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:13,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:13,962] {logging_mixin.py:95} INFO - [2019-09-15 14:46:13,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:14,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:14,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:14,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:14,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:46:14,415] {scheduler_job.py:146} INFO - Started process (PID=19076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:19,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:19,424] {logging_mixin.py:95} INFO - [2019-09-15 14:46:19,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:19,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:19,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:19,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:19,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:46:19,871] {scheduler_job.py:146} INFO - Started process (PID=19077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:24,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:24,881] {logging_mixin.py:95} INFO - [2019-09-15 14:46:24,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:25,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:25,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:25,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:25,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:46:25,335] {scheduler_job.py:146} INFO - Started process (PID=19079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:30,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:30,345] {logging_mixin.py:95} INFO - [2019-09-15 14:46:30,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:30,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:30,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:30,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:30,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.347 seconds
[2019-09-15 14:46:30,790] {scheduler_job.py:146} INFO - Started process (PID=19080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:35,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:35,797] {logging_mixin.py:95} INFO - [2019-09-15 14:46:35,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:36,135] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:36,159] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:36,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:36,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:46:36,250] {scheduler_job.py:146} INFO - Started process (PID=19081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:41,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:41,260] {logging_mixin.py:95} INFO - [2019-09-15 14:46:41,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:41,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:41,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:41,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:41,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:46:41,708] {scheduler_job.py:146} INFO - Started process (PID=19083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:46,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:46,716] {logging_mixin.py:95} INFO - [2019-09-15 14:46:46,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:47,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:47,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:47,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:47,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:46:47,168] {scheduler_job.py:146} INFO - Started process (PID=19084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:52,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:52,174] {logging_mixin.py:95} INFO - [2019-09-15 14:46:52,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:52,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:52,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:52,512] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:52,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.348 seconds
[2019-09-15 14:46:52,622] {scheduler_job.py:146} INFO - Started process (PID=19085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:57,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:46:57,631] {logging_mixin.py:95} INFO - [2019-09-15 14:46:57,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:57,962] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:46:57,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:46:57,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:46:57,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:46:58,081] {scheduler_job.py:146} INFO - Started process (PID=19087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:03,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:03,088] {logging_mixin.py:95} INFO - [2019-09-15 14:47:03,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:03,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:03,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:03,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:03,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:47:03,539] {scheduler_job.py:146} INFO - Started process (PID=19089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:08,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:08,545] {logging_mixin.py:95} INFO - [2019-09-15 14:47:08,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:08,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:08,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:08,910] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:08,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:47:08,999] {scheduler_job.py:146} INFO - Started process (PID=19091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:14,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:14,009] {logging_mixin.py:95} INFO - [2019-09-15 14:47:14,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:14,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:14,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:14,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:14,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:47:14,460] {scheduler_job.py:146} INFO - Started process (PID=19092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:19,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:19,471] {logging_mixin.py:95} INFO - [2019-09-15 14:47:19,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:19,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:19,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:19,806] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:19,811] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.351 seconds
[2019-09-15 14:47:19,918] {scheduler_job.py:146} INFO - Started process (PID=19093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:24,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:24,929] {logging_mixin.py:95} INFO - [2019-09-15 14:47:24,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:25,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:25,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:25,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:25,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:47:25,381] {scheduler_job.py:146} INFO - Started process (PID=19095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:30,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:30,389] {logging_mixin.py:95} INFO - [2019-09-15 14:47:30,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:30,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:30,745] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:30,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:30,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:47:30,840] {scheduler_job.py:146} INFO - Started process (PID=19096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:35,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:35,847] {logging_mixin.py:95} INFO - [2019-09-15 14:47:35,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:36,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:36,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:36,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:36,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:47:36,298] {scheduler_job.py:146} INFO - Started process (PID=19097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:41,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:41,309] {logging_mixin.py:95} INFO - [2019-09-15 14:47:41,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:41,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:41,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:41,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:41,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:47:41,758] {scheduler_job.py:146} INFO - Started process (PID=19099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:46,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:46,764] {logging_mixin.py:95} INFO - [2019-09-15 14:47:46,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:47,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:47,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:47,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:47,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:47:47,221] {scheduler_job.py:146} INFO - Started process (PID=19100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:52,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:52,230] {logging_mixin.py:95} INFO - [2019-09-15 14:47:52,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:52,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:52,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:52,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:52,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:47:52,681] {scheduler_job.py:146} INFO - Started process (PID=19101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:57,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:47:57,690] {logging_mixin.py:95} INFO - [2019-09-15 14:47:57,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:58,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:47:58,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:47:58,071] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:47:58,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:47:58,143] {scheduler_job.py:146} INFO - Started process (PID=19104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:03,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:03,154] {logging_mixin.py:95} INFO - [2019-09-15 14:48:03,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:03,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:03,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:03,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:03,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 14:48:03,598] {scheduler_job.py:146} INFO - Started process (PID=19106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:08,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:08,610] {logging_mixin.py:95} INFO - [2019-09-15 14:48:08,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:08,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:08,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:08,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:08,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:48:09,054] {scheduler_job.py:146} INFO - Started process (PID=19108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:14,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:14,065] {logging_mixin.py:95} INFO - [2019-09-15 14:48:14,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:14,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:14,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:14,409] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:14,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.360 seconds
[2019-09-15 14:48:14,517] {scheduler_job.py:146} INFO - Started process (PID=19109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:19,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:19,528] {logging_mixin.py:95} INFO - [2019-09-15 14:48:19,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:19,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:19,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:19,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:19,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:48:19,975] {scheduler_job.py:146} INFO - Started process (PID=19110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:24,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:24,983] {logging_mixin.py:95} INFO - [2019-09-15 14:48:24,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:25,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:25,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:25,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:25,370] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:48:25,427] {scheduler_job.py:146} INFO - Started process (PID=19112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:30,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:30,449] {logging_mixin.py:95} INFO - [2019-09-15 14:48:30,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:30,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:30,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:30,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:30,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:48:30,888] {scheduler_job.py:146} INFO - Started process (PID=19113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:35,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:35,895] {logging_mixin.py:95} INFO - [2019-09-15 14:48:35,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:36,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:36,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:36,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:36,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 14:48:36,342] {scheduler_job.py:146} INFO - Started process (PID=19114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:41,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:41,348] {logging_mixin.py:95} INFO - [2019-09-15 14:48:41,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:41,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:41,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:41,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:41,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 14:48:41,789] {scheduler_job.py:146} INFO - Started process (PID=19116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:46,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:46,798] {logging_mixin.py:95} INFO - [2019-09-15 14:48:46,798] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:47,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:47,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:47,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:47,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 14:48:47,240] {scheduler_job.py:146} INFO - Started process (PID=19117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:52,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:52,246] {logging_mixin.py:95} INFO - [2019-09-15 14:48:52,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:52,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:52,623] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:52,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:52,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 14:48:52,691] {scheduler_job.py:146} INFO - Started process (PID=19118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:57,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:48:57,701] {logging_mixin.py:95} INFO - [2019-09-15 14:48:57,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:58,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:48:58,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:48:58,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:48:58,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:48:58,147] {scheduler_job.py:146} INFO - Started process (PID=19120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:03,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:03,154] {logging_mixin.py:95} INFO - [2019-09-15 14:49:03,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:03,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:03,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:03,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:03,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:49:03,609] {scheduler_job.py:146} INFO - Started process (PID=19122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:08,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:08,618] {logging_mixin.py:95} INFO - [2019-09-15 14:49:08,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:08,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:08,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:08,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:08,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:49:09,068] {scheduler_job.py:146} INFO - Started process (PID=19124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:14,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:14,075] {logging_mixin.py:95} INFO - [2019-09-15 14:49:14,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:14,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:14,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:14,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:14,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 14:49:14,512] {scheduler_job.py:146} INFO - Started process (PID=19125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:19,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:19,523] {logging_mixin.py:95} INFO - [2019-09-15 14:49:19,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:19,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:19,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:19,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:19,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 14:49:19,972] {scheduler_job.py:146} INFO - Started process (PID=19126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:24,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:24,981] {logging_mixin.py:95} INFO - [2019-09-15 14:49:24,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:25,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:25,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:25,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:25,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 14:49:25,424] {scheduler_job.py:146} INFO - Started process (PID=19128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:30,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:30,433] {logging_mixin.py:95} INFO - [2019-09-15 14:49:30,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:30,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:30,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:30,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:30,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 14:49:30,879] {scheduler_job.py:146} INFO - Started process (PID=19129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:35,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:35,887] {logging_mixin.py:95} INFO - [2019-09-15 14:49:35,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:36,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:36,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:36,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:36,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:49:36,340] {scheduler_job.py:146} INFO - Started process (PID=19130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:41,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:41,346] {logging_mixin.py:95} INFO - [2019-09-15 14:49:41,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:41,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:41,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:41,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:41,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:49:41,790] {scheduler_job.py:146} INFO - Started process (PID=19132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:46,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:46,798] {logging_mixin.py:95} INFO - [2019-09-15 14:49:46,798] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:47,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:47,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:47,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:47,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-15 14:49:47,248] {scheduler_job.py:146} INFO - Started process (PID=19133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:52,257] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:52,258] {logging_mixin.py:95} INFO - [2019-09-15 14:49:52,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:52,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:52,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:52,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:52,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.353 seconds
[2019-09-15 14:49:52,707] {scheduler_job.py:146} INFO - Started process (PID=19134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:57,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:49:57,715] {logging_mixin.py:95} INFO - [2019-09-15 14:49:57,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:58,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:49:58,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:49:58,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:49:58,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 14:49:58,162] {scheduler_job.py:146} INFO - Started process (PID=19136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:03,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:03,169] {logging_mixin.py:95} INFO - [2019-09-15 14:50:03,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:03,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:03,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:03,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:03,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 14:50:03,614] {scheduler_job.py:146} INFO - Started process (PID=19138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:08,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:08,626] {logging_mixin.py:95} INFO - [2019-09-15 14:50:08,625] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:08,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:08,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:08,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:08,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:50:09,071] {scheduler_job.py:146} INFO - Started process (PID=19140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:14,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:14,081] {logging_mixin.py:95} INFO - [2019-09-15 14:50:14,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:14,417] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:14,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:14,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:14,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:50:14,533] {scheduler_job.py:146} INFO - Started process (PID=19141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:19,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:19,541] {logging_mixin.py:95} INFO - [2019-09-15 14:50:19,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:19,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:19,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:19,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:19,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 14:50:19,989] {scheduler_job.py:146} INFO - Started process (PID=19142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:24,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:24,997] {logging_mixin.py:95} INFO - [2019-09-15 14:50:24,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:25,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:25,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:25,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:25,366] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:50:25,449] {scheduler_job.py:146} INFO - Started process (PID=19144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:30,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:30,461] {logging_mixin.py:95} INFO - [2019-09-15 14:50:30,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:30,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:30,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:30,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:30,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:50:30,909] {scheduler_job.py:146} INFO - Started process (PID=19145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:35,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:35,917] {logging_mixin.py:95} INFO - [2019-09-15 14:50:35,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:36,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:36,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:36,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:36,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:50:36,366] {scheduler_job.py:146} INFO - Started process (PID=19146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:41,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:41,375] {logging_mixin.py:95} INFO - [2019-09-15 14:50:41,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:41,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:41,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:41,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:41,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 14:50:41,832] {scheduler_job.py:146} INFO - Started process (PID=19148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:46,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:46,842] {logging_mixin.py:95} INFO - [2019-09-15 14:50:46,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:47,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:47,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:47,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:47,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:50:47,290] {scheduler_job.py:146} INFO - Started process (PID=19149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:52,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:52,301] {logging_mixin.py:95} INFO - [2019-09-15 14:50:52,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:52,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:52,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:52,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:52,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 14:50:52,755] {scheduler_job.py:146} INFO - Started process (PID=19150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:57,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:50:57,766] {logging_mixin.py:95} INFO - [2019-09-15 14:50:57,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:58,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:50:58,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:50:58,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:50:58,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:50:58,211] {scheduler_job.py:146} INFO - Started process (PID=19152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:03,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:03,218] {logging_mixin.py:95} INFO - [2019-09-15 14:51:03,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:03,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:03,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:03,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:03,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:51:03,668] {scheduler_job.py:146} INFO - Started process (PID=19154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:08,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:08,675] {logging_mixin.py:95} INFO - [2019-09-15 14:51:08,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:09,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:09,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:09,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:09,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:51:09,127] {scheduler_job.py:146} INFO - Started process (PID=19156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:14,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:14,139] {logging_mixin.py:95} INFO - [2019-09-15 14:51:14,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:14,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:14,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:14,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:14,504] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:51:14,591] {scheduler_job.py:146} INFO - Started process (PID=19157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:19,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:19,599] {logging_mixin.py:95} INFO - [2019-09-15 14:51:19,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:19,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:19,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:19,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:19,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:51:20,052] {scheduler_job.py:146} INFO - Started process (PID=19158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:25,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:25,062] {logging_mixin.py:95} INFO - [2019-09-15 14:51:25,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:25,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:25,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:25,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:25,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:51:25,514] {scheduler_job.py:146} INFO - Started process (PID=19160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:30,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:30,534] {logging_mixin.py:95} INFO - [2019-09-15 14:51:30,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:30,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:30,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:30,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:30,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 14:51:30,976] {scheduler_job.py:146} INFO - Started process (PID=19161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:35,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:35,986] {logging_mixin.py:95} INFO - [2019-09-15 14:51:35,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:36,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:36,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:36,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:36,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:51:36,436] {scheduler_job.py:146} INFO - Started process (PID=19163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:41,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:41,445] {logging_mixin.py:95} INFO - [2019-09-15 14:51:41,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:41,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:41,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:41,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:41,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:51:41,893] {scheduler_job.py:146} INFO - Started process (PID=19165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:46,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:46,905] {logging_mixin.py:95} INFO - [2019-09-15 14:51:46,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:47,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:47,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:47,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:47,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 14:51:47,353] {scheduler_job.py:146} INFO - Started process (PID=19166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:52,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:52,361] {logging_mixin.py:95} INFO - [2019-09-15 14:51:52,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:52,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:52,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:52,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:52,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 14:51:52,806] {scheduler_job.py:146} INFO - Started process (PID=19167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:57,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:51:57,815] {logging_mixin.py:95} INFO - [2019-09-15 14:51:57,814] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:58,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:51:58,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:51:58,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:51:58,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 14:51:58,265] {scheduler_job.py:146} INFO - Started process (PID=19169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:03,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:03,274] {logging_mixin.py:95} INFO - [2019-09-15 14:52:03,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:03,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:03,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:03,641] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:03,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:52:03,723] {scheduler_job.py:146} INFO - Started process (PID=19171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:08,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:08,730] {logging_mixin.py:95} INFO - [2019-09-15 14:52:08,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:09,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:09,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:09,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:09,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:52:09,184] {scheduler_job.py:146} INFO - Started process (PID=19173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:14,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:14,194] {logging_mixin.py:95} INFO - [2019-09-15 14:52:14,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:14,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:14,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:14,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:14,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 14:52:14,642] {scheduler_job.py:146} INFO - Started process (PID=19174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:19,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:19,650] {logging_mixin.py:95} INFO - [2019-09-15 14:52:19,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:19,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:20,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:20,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:20,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 14:52:20,102] {scheduler_job.py:146} INFO - Started process (PID=19175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:25,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:25,112] {logging_mixin.py:95} INFO - [2019-09-15 14:52:25,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:25,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:25,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:25,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:25,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 14:52:25,564] {scheduler_job.py:146} INFO - Started process (PID=19177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:30,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:30,572] {logging_mixin.py:95} INFO - [2019-09-15 14:52:30,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:30,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:30,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:30,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:30,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:52:31,024] {scheduler_job.py:146} INFO - Started process (PID=19178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:36,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:36,030] {logging_mixin.py:95} INFO - [2019-09-15 14:52:36,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:36,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:36,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:36,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:36,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:52:36,482] {scheduler_job.py:146} INFO - Started process (PID=19179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:41,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:41,489] {logging_mixin.py:95} INFO - [2019-09-15 14:52:41,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:41,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:41,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:41,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:41,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:52:41,942] {scheduler_job.py:146} INFO - Started process (PID=19181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:46,951] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:46,952] {logging_mixin.py:95} INFO - [2019-09-15 14:52:46,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:47,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:47,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:47,321] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:47,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 14:52:47,401] {scheduler_job.py:146} INFO - Started process (PID=19182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:52,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:52,411] {logging_mixin.py:95} INFO - [2019-09-15 14:52:52,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:52,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:52,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:52,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:52,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:52:52,888] {scheduler_job.py:146} INFO - Started process (PID=19184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:57,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:52:57,897] {logging_mixin.py:95} INFO - [2019-09-15 14:52:57,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:58,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:52:58,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:52:58,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:52:58,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 14:52:58,381] {scheduler_job.py:146} INFO - Started process (PID=19186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:03,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:03,396] {logging_mixin.py:95} INFO - [2019-09-15 14:53:03,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:03,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:03,754] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:03,763] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:03,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:53:03,871] {scheduler_job.py:146} INFO - Started process (PID=19188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:03,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:03,877] {logging_mixin.py:95} INFO - [2019-09-15 14:53:03,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:04,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:04,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-09-15 14:53:04,279] {scheduler_job.py:146} INFO - Started process (PID=19189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:04,284] {logging_mixin.py:95} INFO - [2019-09-15 14:53:04,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:04,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:04,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 14:53:04,688] {scheduler_job.py:146} INFO - Started process (PID=19190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:04,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:04,693] {logging_mixin.py:95} INFO - [2019-09-15 14:53:04,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:05,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:05,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.369 seconds
[2019-09-15 14:53:05,099] {scheduler_job.py:146} INFO - Started process (PID=19191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:05,105] {logging_mixin.py:95} INFO - [2019-09-15 14:53:05,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:05,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:05,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 14:53:05,508] {scheduler_job.py:146} INFO - Started process (PID=19192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:05,513] {logging_mixin.py:95} INFO - [2019-09-15 14:53:05,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:05,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:05,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.364 seconds
[2019-09-15 14:53:05,918] {scheduler_job.py:146} INFO - Started process (PID=19193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:05,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:05,922] {logging_mixin.py:95} INFO - [2019-09-15 14:53:05,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:06,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:06,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-09-15 14:53:06,330] {scheduler_job.py:146} INFO - Started process (PID=19194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:06,335] {logging_mixin.py:95} INFO - [2019-09-15 14:53:06,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:06,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:06,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 14:53:06,740] {scheduler_job.py:146} INFO - Started process (PID=19195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:06,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:06,745] {logging_mixin.py:95} INFO - [2019-09-15 14:53:06,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:07,105] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:07,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 14:53:07,150] {scheduler_job.py:146} INFO - Started process (PID=19196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:07,154] {logging_mixin.py:95} INFO - [2019-09-15 14:53:07,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:07,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:07,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-15 14:53:07,559] {scheduler_job.py:146} INFO - Started process (PID=19197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:07,563] {logging_mixin.py:95} INFO - [2019-09-15 14:53:07,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:07,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:07,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.362 seconds
[2019-09-15 14:53:07,970] {scheduler_job.py:146} INFO - Started process (PID=19198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:07,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:07,975] {logging_mixin.py:95} INFO - [2019-09-15 14:53:07,975] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:08,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:08,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.393 seconds
[2019-09-15 14:53:08,379] {scheduler_job.py:146} INFO - Started process (PID=19199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:08,383] {logging_mixin.py:95} INFO - [2019-09-15 14:53:08,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:08,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:08,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.360 seconds
[2019-09-15 14:53:08,787] {scheduler_job.py:146} INFO - Started process (PID=19201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:08,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:08,791] {logging_mixin.py:95} INFO - [2019-09-15 14:53:08,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:09,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:09,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.372 seconds
[2019-09-15 14:53:09,202] {scheduler_job.py:146} INFO - Started process (PID=19202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:09,206] {logging_mixin.py:95} INFO - [2019-09-15 14:53:09,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:53:09,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:53:09,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.369 seconds
[2019-09-15 14:53:09,614] {scheduler_job.py:146} INFO - Started process (PID=19203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:53:09,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:53:09,619] {logging_mixin.py:95} INFO - [2019-09-15 14:53:09,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:04,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:04,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 114.538 seconds
[2019-09-15 14:55:04,219] {scheduler_job.py:146} INFO - Started process (PID=19204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:04,224] {logging_mixin.py:95} INFO - [2019-09-15 14:55:04,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:04,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:04,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 14:55:04,624] {scheduler_job.py:146} INFO - Started process (PID=19206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:04,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:04,628] {logging_mixin.py:95} INFO - [2019-09-15 14:55:04,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:05,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:05,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:05,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:05,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.491 seconds
[2019-09-15 14:55:05,132] {scheduler_job.py:146} INFO - Started process (PID=19207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:10,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:10,142] {logging_mixin.py:95} INFO - [2019-09-15 14:55:10,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:10,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:10,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:10,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:10,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 14:55:10,580] {scheduler_job.py:146} INFO - Started process (PID=19212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:15,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:15,590] {logging_mixin.py:95} INFO - [2019-09-15 14:55:15,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:15,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:15,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:15,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:15,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 14:55:16,033] {scheduler_job.py:146} INFO - Started process (PID=19220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:21,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:21,041] {logging_mixin.py:95} INFO - [2019-09-15 14:55:21,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:21,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:21,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:21,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:21,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 14:55:21,469] {scheduler_job.py:146} INFO - Started process (PID=19224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:26,474] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:26,475] {logging_mixin.py:95} INFO - [2019-09-15 14:55:26,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:26,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:26,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:26,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:26,871] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 14:55:26,914] {scheduler_job.py:146} INFO - Started process (PID=19225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:31,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:31,924] {logging_mixin.py:95} INFO - [2019-09-15 14:55:31,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:32,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:32,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:32,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:32,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 14:55:32,367] {scheduler_job.py:146} INFO - Started process (PID=19227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:37,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:37,376] {logging_mixin.py:95} INFO - [2019-09-15 14:55:37,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:37,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:37,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:37,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:37,759] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:55:37,817] {scheduler_job.py:146} INFO - Started process (PID=19228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:42,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:42,824] {logging_mixin.py:95} INFO - [2019-09-15 14:55:42,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:43,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:43,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:43,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:43,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 14:55:43,366] {scheduler_job.py:146} INFO - Started process (PID=19229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:48,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:48,374] {logging_mixin.py:95} INFO - [2019-09-15 14:55:48,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:48,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:48,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:48,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:48,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 14:55:48,811] {scheduler_job.py:146} INFO - Started process (PID=19231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:53,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:53,819] {logging_mixin.py:95} INFO - [2019-09-15 14:55:53,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:54,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:54,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:54,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:54,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 14:55:54,357] {scheduler_job.py:146} INFO - Started process (PID=19233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:59,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:55:59,367] {logging_mixin.py:95} INFO - [2019-09-15 14:55:59,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:59,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:55:59,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:55:59,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:55:59,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 14:55:59,801] {scheduler_job.py:146} INFO - Started process (PID=19234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:04,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:04,808] {logging_mixin.py:95} INFO - [2019-09-15 14:56:04,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:05,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:05,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:05,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:05,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 14:56:05,241] {scheduler_job.py:146} INFO - Started process (PID=19236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:10,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:10,252] {logging_mixin.py:95} INFO - [2019-09-15 14:56:10,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:10,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:10,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:10,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:10,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 14:56:10,693] {scheduler_job.py:146} INFO - Started process (PID=19237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:15,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:15,704] {logging_mixin.py:95} INFO - [2019-09-15 14:56:15,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:16,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:16,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:16,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:16,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 14:56:16,143] {scheduler_job.py:146} INFO - Started process (PID=19238) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:21,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:21,154] {logging_mixin.py:95} INFO - [2019-09-15 14:56:21,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:21,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:21,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:21,530] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:21,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 14:56:21,586] {scheduler_job.py:146} INFO - Started process (PID=19240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:26,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:26,598] {logging_mixin.py:95} INFO - [2019-09-15 14:56:26,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:26,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:26,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:26,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:26,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:56:27,041] {scheduler_job.py:146} INFO - Started process (PID=19241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:32,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:32,047] {logging_mixin.py:95} INFO - [2019-09-15 14:56:32,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:32,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:32,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:32,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:32,504] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 14:56:32,582] {scheduler_job.py:146} INFO - Started process (PID=19243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:37,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:37,594] {logging_mixin.py:95} INFO - [2019-09-15 14:56:37,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:37,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:38,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:38,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:38,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 14:56:38,130] {scheduler_job.py:146} INFO - Started process (PID=19244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:43,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:43,139] {logging_mixin.py:95} INFO - [2019-09-15 14:56:43,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:43,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:43,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:43,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:43,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 14:56:43,569] {scheduler_job.py:146} INFO - Started process (PID=19245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:48,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:48,575] {logging_mixin.py:95} INFO - [2019-09-15 14:56:48,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:48,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:48,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:48,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:48,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 14:56:49,011] {scheduler_job.py:146} INFO - Started process (PID=19247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:54,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:54,018] {logging_mixin.py:95} INFO - [2019-09-15 14:56:54,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:54,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:54,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:54,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:54,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 14:56:54,458] {scheduler_job.py:146} INFO - Started process (PID=19249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:59,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:56:59,467] {logging_mixin.py:95} INFO - [2019-09-15 14:56:59,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:59,828] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:56:59,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:56:59,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:56:59,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 14:56:59,903] {scheduler_job.py:146} INFO - Started process (PID=19250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:04,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:04,910] {logging_mixin.py:95} INFO - [2019-09-15 14:57:04,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:05,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:05,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:05,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:05,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 14:57:05,345] {scheduler_job.py:146} INFO - Started process (PID=19252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:10,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:10,357] {logging_mixin.py:95} INFO - [2019-09-15 14:57:10,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:10,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:10,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:10,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:10,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 14:57:10,886] {scheduler_job.py:146} INFO - Started process (PID=19253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:15,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:15,897] {logging_mixin.py:95} INFO - [2019-09-15 14:57:15,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:16,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:16,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:16,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:16,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:57:16,329] {scheduler_job.py:146} INFO - Started process (PID=19260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:21,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:21,339] {logging_mixin.py:95} INFO - [2019-09-15 14:57:21,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:21,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:21,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:21,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:21,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 14:57:21,779] {scheduler_job.py:146} INFO - Started process (PID=19263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:26,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:26,790] {logging_mixin.py:95} INFO - [2019-09-15 14:57:26,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:27,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:27,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:27,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:27,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.726 seconds
[2019-09-15 14:57:27,620] {scheduler_job.py:146} INFO - Started process (PID=19270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:32,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:32,627] {logging_mixin.py:95} INFO - [2019-09-15 14:57:32,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:33,022] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:33,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:33,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:33,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 14:57:33,152] {scheduler_job.py:146} INFO - Started process (PID=19277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:38,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:38,157] {logging_mixin.py:95} INFO - [2019-09-15 14:57:38,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:38,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:38,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:38,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:38,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 14:57:38,694] {scheduler_job.py:146} INFO - Started process (PID=19278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:43,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:43,702] {logging_mixin.py:95} INFO - [2019-09-15 14:57:43,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:44,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:44,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:44,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:44,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 14:57:44,127] {scheduler_job.py:146} INFO - Started process (PID=19279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:49,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:49,135] {logging_mixin.py:95} INFO - [2019-09-15 14:57:49,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:49,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:49,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:49,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:49,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 14:57:49,569] {scheduler_job.py:146} INFO - Started process (PID=19281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:54,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:57:54,581] {logging_mixin.py:95} INFO - [2019-09-15 14:57:54,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:54,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:57:54,991] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:57:55,000] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:57:55,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 14:57:55,110] {scheduler_job.py:146} INFO - Started process (PID=19283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:00,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:00,119] {logging_mixin.py:95} INFO - [2019-09-15 14:58:00,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:00,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:00,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:00,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:00,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 14:58:00,551] {scheduler_job.py:146} INFO - Started process (PID=19284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:05,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:05,561] {logging_mixin.py:95} INFO - [2019-09-15 14:58:05,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:05,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:05,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:05,964] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:05,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 14:58:05,988] {scheduler_job.py:146} INFO - Started process (PID=19286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:10,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:10,999] {logging_mixin.py:95} INFO - [2019-09-15 14:58:10,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:11,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:11,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:11,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:11,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 14:58:11,434] {scheduler_job.py:146} INFO - Started process (PID=19288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:16,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:16,443] {logging_mixin.py:95} INFO - [2019-09-15 14:58:16,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:16,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:16,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:16,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:16,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 14:58:16,973] {scheduler_job.py:146} INFO - Started process (PID=19289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:21,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:21,982] {logging_mixin.py:95} INFO - [2019-09-15 14:58:21,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:22,440] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:22,459] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:22,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:22,476] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-09-15 14:58:22,516] {scheduler_job.py:146} INFO - Started process (PID=19292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:27,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:27,524] {logging_mixin.py:95} INFO - [2019-09-15 14:58:27,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:27,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:27,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:27,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:27,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 14:58:28,052] {scheduler_job.py:146} INFO - Started process (PID=19296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:33,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:33,061] {logging_mixin.py:95} INFO - [2019-09-15 14:58:33,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:33,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:33,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:33,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:33,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.497 seconds
[2019-09-15 14:58:33,579] {scheduler_job.py:146} INFO - Started process (PID=19298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:38,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:38,588] {logging_mixin.py:95} INFO - [2019-09-15 14:58:38,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:39,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:39,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:39,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:39,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-15 14:58:39,117] {scheduler_job.py:146} INFO - Started process (PID=19299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:44,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:44,124] {logging_mixin.py:95} INFO - [2019-09-15 14:58:44,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:44,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:44,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:44,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:44,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-15 14:58:44,652] {scheduler_job.py:146} INFO - Started process (PID=19300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:49,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:49,663] {logging_mixin.py:95} INFO - [2019-09-15 14:58:49,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:50,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:50,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:50,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:50,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 14:58:50,181] {scheduler_job.py:146} INFO - Started process (PID=19302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:55,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:58:55,190] {logging_mixin.py:95} INFO - [2019-09-15 14:58:55,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:55,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:58:55,599] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:58:55,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:58:55,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 14:58:55,713] {scheduler_job.py:146} INFO - Started process (PID=19304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:00,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:00,730] {logging_mixin.py:95} INFO - [2019-09-15 14:59:00,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:01,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:01,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:01,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:01,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:59:01,159] {scheduler_job.py:146} INFO - Started process (PID=19305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:06,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:06,167] {logging_mixin.py:95} INFO - [2019-09-15 14:59:06,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:06,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:06,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:06,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:06,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 14:59:06,606] {scheduler_job.py:146} INFO - Started process (PID=19307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:11,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:11,615] {logging_mixin.py:95} INFO - [2019-09-15 14:59:11,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:11,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:12,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:12,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:12,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 14:59:12,152] {scheduler_job.py:146} INFO - Started process (PID=19308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:17,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:17,157] {logging_mixin.py:95} INFO - [2019-09-15 14:59:17,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:17,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:17,535] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:17,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:17,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 14:59:17,604] {scheduler_job.py:146} INFO - Started process (PID=19310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:22,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:22,612] {logging_mixin.py:95} INFO - [2019-09-15 14:59:22,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:22,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:23,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:23,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:23,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 14:59:23,057] {scheduler_job.py:146} INFO - Started process (PID=19311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:28,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:28,067] {logging_mixin.py:95} INFO - [2019-09-15 14:59:28,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:28,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:28,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:28,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:28,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 14:59:28,497] {scheduler_job.py:146} INFO - Started process (PID=19312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:33,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:33,502] {logging_mixin.py:95} INFO - [2019-09-15 14:59:33,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:33,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:33,860] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:33,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:33,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 14:59:33,950] {scheduler_job.py:146} INFO - Started process (PID=19314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:38,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:38,959] {logging_mixin.py:95} INFO - [2019-09-15 14:59:38,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:39,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:39,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:39,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:39,350] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 14:59:39,400] {scheduler_job.py:146} INFO - Started process (PID=19315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:44,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:44,406] {logging_mixin.py:95} INFO - [2019-09-15 14:59:44,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:44,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:44,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:44,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:44,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 14:59:44,848] {scheduler_job.py:146} INFO - Started process (PID=19316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:49,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:49,867] {logging_mixin.py:95} INFO - [2019-09-15 14:59:49,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:50,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:50,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:50,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:50,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 14:59:50,298] {scheduler_job.py:146} INFO - Started process (PID=19318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:55,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 14:59:55,306] {logging_mixin.py:95} INFO - [2019-09-15 14:59:55,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:55,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 14:59:55,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 14:59:55,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 14:59:55,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 14:59:55,750] {scheduler_job.py:146} INFO - Started process (PID=19320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:00,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:00,772] {logging_mixin.py:95} INFO - [2019-09-15 15:00:00,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:01,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:01,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:01,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:01,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:00:01,192] {scheduler_job.py:146} INFO - Started process (PID=19321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:06,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:06,203] {logging_mixin.py:95} INFO - [2019-09-15 15:00:06,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:06,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:06,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:06,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:06,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:00:06,647] {scheduler_job.py:146} INFO - Started process (PID=19323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:11,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:11,653] {logging_mixin.py:95} INFO - [2019-09-15 15:00:11,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:12,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:12,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:12,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:12,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:00:12,098] {scheduler_job.py:146} INFO - Started process (PID=19324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:17,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:17,106] {logging_mixin.py:95} INFO - [2019-09-15 15:00:17,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:17,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:17,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:17,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:17,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:00:17,547] {scheduler_job.py:146} INFO - Started process (PID=19326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:22,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:22,555] {logging_mixin.py:95} INFO - [2019-09-15 15:00:22,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:22,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:22,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:22,953] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:22,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:00:23,000] {scheduler_job.py:146} INFO - Started process (PID=19327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:28,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:28,023] {logging_mixin.py:95} INFO - [2019-09-15 15:00:28,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:28,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:28,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:28,413] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:28,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:00:28,450] {scheduler_job.py:146} INFO - Started process (PID=19328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:33,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:33,468] {logging_mixin.py:95} INFO - [2019-09-15 15:00:33,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:33,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:33,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:33,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:33,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:00:33,900] {scheduler_job.py:146} INFO - Started process (PID=19330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:38,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:38,906] {logging_mixin.py:95} INFO - [2019-09-15 15:00:38,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:39,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:39,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:39,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:39,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:00:39,350] {scheduler_job.py:146} INFO - Started process (PID=19331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:44,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:44,366] {logging_mixin.py:95} INFO - [2019-09-15 15:00:44,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:44,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:44,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:44,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:44,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:00:44,802] {scheduler_job.py:146} INFO - Started process (PID=19332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:49,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:49,818] {logging_mixin.py:95} INFO - [2019-09-15 15:00:49,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:50,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:50,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:50,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:50,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:00:50,248] {scheduler_job.py:146} INFO - Started process (PID=19334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:55,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:00:55,255] {logging_mixin.py:95} INFO - [2019-09-15 15:00:55,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:55,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:00:55,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:00:55,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:00:55,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:00:55,705] {scheduler_job.py:146} INFO - Started process (PID=19336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:00,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:00,721] {logging_mixin.py:95} INFO - [2019-09-15 15:01:00,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:01,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:01,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:01,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:01,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:01:01,156] {scheduler_job.py:146} INFO - Started process (PID=19337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:06,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:06,167] {logging_mixin.py:95} INFO - [2019-09-15 15:01:06,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:06,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:06,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:06,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:06,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:01:06,601] {scheduler_job.py:146} INFO - Started process (PID=19339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:11,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:11,607] {logging_mixin.py:95} INFO - [2019-09-15 15:01:11,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:11,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:11,992] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:12,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:12,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:01:12,052] {scheduler_job.py:146} INFO - Started process (PID=19340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:17,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:17,060] {logging_mixin.py:95} INFO - [2019-09-15 15:01:17,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:17,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:17,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:17,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:17,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:01:17,504] {scheduler_job.py:146} INFO - Started process (PID=19342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:22,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:22,509] {logging_mixin.py:95} INFO - [2019-09-15 15:01:22,509] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:22,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:22,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:22,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:22,909] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:01:22,949] {scheduler_job.py:146} INFO - Started process (PID=19343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:27,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:27,964] {logging_mixin.py:95} INFO - [2019-09-15 15:01:27,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:28,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:28,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:28,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:28,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:01:28,399] {scheduler_job.py:146} INFO - Started process (PID=19344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:33,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:33,407] {logging_mixin.py:95} INFO - [2019-09-15 15:01:33,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:33,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:33,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:33,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:33,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:01:33,847] {scheduler_job.py:146} INFO - Started process (PID=19346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:38,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:38,855] {logging_mixin.py:95} INFO - [2019-09-15 15:01:38,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:39,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:39,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:39,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:39,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:01:39,296] {scheduler_job.py:146} INFO - Started process (PID=19347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:44,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:44,309] {logging_mixin.py:95} INFO - [2019-09-15 15:01:44,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:44,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:44,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:44,700] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:44,705] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:01:44,751] {scheduler_job.py:146} INFO - Started process (PID=19348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:49,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:49,758] {logging_mixin.py:95} INFO - [2019-09-15 15:01:49,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:50,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:50,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:50,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:50,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:01:50,197] {scheduler_job.py:146} INFO - Started process (PID=19350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:55,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:01:55,205] {logging_mixin.py:95} INFO - [2019-09-15 15:01:55,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:55,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:01:55,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:01:55,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:01:55,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:01:55,642] {scheduler_job.py:146} INFO - Started process (PID=19352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:00,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:00,654] {logging_mixin.py:95} INFO - [2019-09-15 15:02:00,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:01,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:01,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:01,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:01,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:02:01,094] {scheduler_job.py:146} INFO - Started process (PID=19353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:06,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:06,101] {logging_mixin.py:95} INFO - [2019-09-15 15:02:06,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:06,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:06,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:06,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:06,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:02:06,549] {scheduler_job.py:146} INFO - Started process (PID=19355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:11,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:11,558] {logging_mixin.py:95} INFO - [2019-09-15 15:02:11,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:11,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:11,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:11,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:11,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:02:11,994] {scheduler_job.py:146} INFO - Started process (PID=19356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:17,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:17,002] {logging_mixin.py:95} INFO - [2019-09-15 15:02:17,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:17,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:17,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:17,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:17,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 15:02:17,447] {scheduler_job.py:146} INFO - Started process (PID=19357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:22,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:22,454] {logging_mixin.py:95} INFO - [2019-09-15 15:02:22,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:22,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:22,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:22,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:22,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:02:22,898] {scheduler_job.py:146} INFO - Started process (PID=19359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:27,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:27,914] {logging_mixin.py:95} INFO - [2019-09-15 15:02:27,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:28,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:28,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:28,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:28,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:02:28,341] {scheduler_job.py:146} INFO - Started process (PID=19360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:33,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:33,352] {logging_mixin.py:95} INFO - [2019-09-15 15:02:33,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:33,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:33,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:33,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:33,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 15:02:33,787] {scheduler_job.py:146} INFO - Started process (PID=19362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:38,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:38,797] {logging_mixin.py:95} INFO - [2019-09-15 15:02:38,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:39,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:39,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:39,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:39,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 15:02:39,240] {scheduler_job.py:146} INFO - Started process (PID=19363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:44,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:44,259] {logging_mixin.py:95} INFO - [2019-09-15 15:02:44,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:44,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:44,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:44,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:44,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-09-15 15:02:44,785] {scheduler_job.py:146} INFO - Started process (PID=19364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:49,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:49,805] {logging_mixin.py:95} INFO - [2019-09-15 15:02:49,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:50,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:50,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:50,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:50,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-15 15:02:50,322] {scheduler_job.py:146} INFO - Started process (PID=19366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:55,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:02:55,331] {logging_mixin.py:95} INFO - [2019-09-15 15:02:55,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:55,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:02:55,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:02:55,754] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:02:55,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 15:02:55,863] {scheduler_job.py:146} INFO - Started process (PID=19368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:00,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:00,882] {logging_mixin.py:95} INFO - [2019-09-15 15:03:00,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:01,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:01,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:01,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:01,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 15:03:01,309] {scheduler_job.py:146} INFO - Started process (PID=19369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:06,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:06,318] {logging_mixin.py:95} INFO - [2019-09-15 15:03:06,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:06,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:06,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:06,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:06,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:03:06,759] {scheduler_job.py:146} INFO - Started process (PID=19371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:11,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:11,766] {logging_mixin.py:95} INFO - [2019-09-15 15:03:11,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:12,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:12,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:12,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:12,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:03:12,198] {scheduler_job.py:146} INFO - Started process (PID=19372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:17,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:17,206] {logging_mixin.py:95} INFO - [2019-09-15 15:03:17,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:17,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:17,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:17,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:17,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:03:17,647] {scheduler_job.py:146} INFO - Started process (PID=19374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:22,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:22,656] {logging_mixin.py:95} INFO - [2019-09-15 15:03:22,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:23,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:23,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:23,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:23,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 15:03:23,196] {scheduler_job.py:146} INFO - Started process (PID=19375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:28,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:28,211] {logging_mixin.py:95} INFO - [2019-09-15 15:03:28,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:28,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:28,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:28,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:28,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:03:28,639] {scheduler_job.py:146} INFO - Started process (PID=19376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:33,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:33,645] {logging_mixin.py:95} INFO - [2019-09-15 15:03:33,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:33,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:34,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:34,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:34,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:03:34,089] {scheduler_job.py:146} INFO - Started process (PID=19378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:39,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:39,100] {logging_mixin.py:95} INFO - [2019-09-15 15:03:39,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:39,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:39,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:39,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:39,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:03:39,541] {scheduler_job.py:146} INFO - Started process (PID=19379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:44,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:44,557] {logging_mixin.py:95} INFO - [2019-09-15 15:03:44,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:44,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:44,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:44,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:44,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:03:44,981] {scheduler_job.py:146} INFO - Started process (PID=19380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:49,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:49,991] {logging_mixin.py:95} INFO - [2019-09-15 15:03:49,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:50,348] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:50,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:50,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:50,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:03:50,439] {scheduler_job.py:146} INFO - Started process (PID=19382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:55,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:03:55,448] {logging_mixin.py:95} INFO - [2019-09-15 15:03:55,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:55,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:03:55,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:03:55,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:03:55,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:03:55,884] {scheduler_job.py:146} INFO - Started process (PID=19384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:00,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:00,902] {logging_mixin.py:95} INFO - [2019-09-15 15:04:00,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:01,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:01,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:01,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:01,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:04:01,330] {scheduler_job.py:146} INFO - Started process (PID=19385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:06,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:06,339] {logging_mixin.py:95} INFO - [2019-09-15 15:04:06,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:06,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:06,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:06,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:06,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:04:06,780] {scheduler_job.py:146} INFO - Started process (PID=19387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:11,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:11,791] {logging_mixin.py:95} INFO - [2019-09-15 15:04:11,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:12,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:12,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:12,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:12,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:04:12,234] {scheduler_job.py:146} INFO - Started process (PID=19388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:17,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:17,241] {logging_mixin.py:95} INFO - [2019-09-15 15:04:17,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:17,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:17,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:17,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:17,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:04:17,680] {scheduler_job.py:146} INFO - Started process (PID=19390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:22,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:22,687] {logging_mixin.py:95} INFO - [2019-09-15 15:04:22,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:23,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:23,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:23,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:23,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 15:04:23,229] {scheduler_job.py:146} INFO - Started process (PID=19391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:28,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:28,247] {logging_mixin.py:95} INFO - [2019-09-15 15:04:28,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:28,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:28,628] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:28,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:28,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:04:28,684] {scheduler_job.py:146} INFO - Started process (PID=19392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:33,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:33,693] {logging_mixin.py:95} INFO - [2019-09-15 15:04:33,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:34,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:34,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:34,079] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:34,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:04:34,134] {scheduler_job.py:146} INFO - Started process (PID=19394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:39,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:39,142] {logging_mixin.py:95} INFO - [2019-09-15 15:04:39,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:39,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:39,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:39,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:39,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:04:39,585] {scheduler_job.py:146} INFO - Started process (PID=19395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:44,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:44,595] {logging_mixin.py:95} INFO - [2019-09-15 15:04:44,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:44,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:44,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:44,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:44,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:04:45,033] {scheduler_job.py:146} INFO - Started process (PID=19396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:50,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:50,045] {logging_mixin.py:95} INFO - [2019-09-15 15:04:50,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:50,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:50,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:50,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:50,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:04:50,476] {scheduler_job.py:146} INFO - Started process (PID=19398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:55,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:04:55,485] {logging_mixin.py:95} INFO - [2019-09-15 15:04:55,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:55,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:04:55,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:04:55,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:04:55,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:04:55,923] {scheduler_job.py:146} INFO - Started process (PID=19400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:00,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:00,937] {logging_mixin.py:95} INFO - [2019-09-15 15:05:00,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:01,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:01,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:01,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:01,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:05:01,373] {scheduler_job.py:146} INFO - Started process (PID=19401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:06,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:06,383] {logging_mixin.py:95} INFO - [2019-09-15 15:05:06,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:06,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:06,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:06,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:06,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:05:06,814] {scheduler_job.py:146} INFO - Started process (PID=19403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:11,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:11,826] {logging_mixin.py:95} INFO - [2019-09-15 15:05:11,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:12,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:12,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:12,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:12,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:05:12,266] {scheduler_job.py:146} INFO - Started process (PID=19405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:17,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:17,275] {logging_mixin.py:95} INFO - [2019-09-15 15:05:17,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:17,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:17,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:17,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:17,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:05:17,718] {scheduler_job.py:146} INFO - Started process (PID=19407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:22,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:22,725] {logging_mixin.py:95} INFO - [2019-09-15 15:05:22,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:23,118] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:23,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:23,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:23,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 15:05:23,264] {scheduler_job.py:146} INFO - Started process (PID=19408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:28,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:28,278] {logging_mixin.py:95} INFO - [2019-09-15 15:05:28,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:28,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:28,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:28,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:28,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:05:28,715] {scheduler_job.py:146} INFO - Started process (PID=19409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:33,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:33,727] {logging_mixin.py:95} INFO - [2019-09-15 15:05:33,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:34,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:34,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:34,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:34,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:05:34,170] {scheduler_job.py:146} INFO - Started process (PID=19411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:39,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:39,179] {logging_mixin.py:95} INFO - [2019-09-15 15:05:39,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:39,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:39,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:39,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:39,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:05:39,612] {scheduler_job.py:146} INFO - Started process (PID=19412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:44,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:44,618] {logging_mixin.py:95} INFO - [2019-09-15 15:05:44,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:44,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:44,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:45,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:45,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:05:45,060] {scheduler_job.py:146} INFO - Started process (PID=19413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:50,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:50,071] {logging_mixin.py:95} INFO - [2019-09-15 15:05:50,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:50,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:50,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:50,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:50,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:05:50,510] {scheduler_job.py:146} INFO - Started process (PID=19415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:55,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:05:55,518] {logging_mixin.py:95} INFO - [2019-09-15 15:05:55,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:55,872] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:05:55,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:05:55,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:05:55,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:05:55,970] {scheduler_job.py:146} INFO - Started process (PID=19417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:00,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:00,985] {logging_mixin.py:95} INFO - [2019-09-15 15:06:00,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:01,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:01,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:01,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:01,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:06:01,426] {scheduler_job.py:146} INFO - Started process (PID=19418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:06,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:06,433] {logging_mixin.py:95} INFO - [2019-09-15 15:06:06,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:06,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:06,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:06,822] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:06,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:06:06,873] {scheduler_job.py:146} INFO - Started process (PID=19421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:11,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:11,893] {logging_mixin.py:95} INFO - [2019-09-15 15:06:11,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:12,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:12,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:12,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:12,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:06:12,317] {scheduler_job.py:146} INFO - Started process (PID=19422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:17,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:17,322] {logging_mixin.py:95} INFO - [2019-09-15 15:06:17,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:17,675] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:17,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:17,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:17,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:06:17,764] {scheduler_job.py:146} INFO - Started process (PID=19424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:22,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:22,771] {logging_mixin.py:95} INFO - [2019-09-15 15:06:22,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:23,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:23,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:23,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:23,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 15:06:23,311] {scheduler_job.py:146} INFO - Started process (PID=19425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:28,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:28,331] {logging_mixin.py:95} INFO - [2019-09-15 15:06:28,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:28,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:28,711] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:28,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:28,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:06:28,759] {scheduler_job.py:146} INFO - Started process (PID=19426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:33,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:33,768] {logging_mixin.py:95} INFO - [2019-09-15 15:06:33,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:34,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:34,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:34,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:34,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:06:34,216] {scheduler_job.py:146} INFO - Started process (PID=19428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:39,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:39,225] {logging_mixin.py:95} INFO - [2019-09-15 15:06:39,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:39,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:39,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:39,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:39,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:06:39,662] {scheduler_job.py:146} INFO - Started process (PID=19429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:44,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:44,670] {logging_mixin.py:95} INFO - [2019-09-15 15:06:44,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:45,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:45,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:45,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:45,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:06:45,110] {scheduler_job.py:146} INFO - Started process (PID=19430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:50,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:50,121] {logging_mixin.py:95} INFO - [2019-09-15 15:06:50,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:50,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:50,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:50,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:50,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:06:50,561] {scheduler_job.py:146} INFO - Started process (PID=19432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:55,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:06:55,568] {logging_mixin.py:95} INFO - [2019-09-15 15:06:55,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:55,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:06:55,953] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:06:55,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:06:55,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:06:56,012] {scheduler_job.py:146} INFO - Started process (PID=19434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:01,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:01,030] {logging_mixin.py:95} INFO - [2019-09-15 15:07:01,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:01,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:01,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:01,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:01,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:07:01,450] {scheduler_job.py:146} INFO - Started process (PID=19435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:06,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:06,457] {logging_mixin.py:95} INFO - [2019-09-15 15:07:06,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:06,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:06,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:06,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:06,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:07:06,902] {scheduler_job.py:146} INFO - Started process (PID=19437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:11,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:11,914] {logging_mixin.py:95} INFO - [2019-09-15 15:07:11,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:12,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:12,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:12,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:12,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 15:07:12,447] {scheduler_job.py:146} INFO - Started process (PID=19438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:17,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:17,456] {logging_mixin.py:95} INFO - [2019-09-15 15:07:17,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:17,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:17,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:17,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:17,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:07:17,896] {scheduler_job.py:146} INFO - Started process (PID=19440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:22,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:22,906] {logging_mixin.py:95} INFO - [2019-09-15 15:07:22,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:23,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:23,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:23,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:23,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 15:07:23,350] {scheduler_job.py:146} INFO - Started process (PID=19441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:28,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:28,359] {logging_mixin.py:95} INFO - [2019-09-15 15:07:28,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:28,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:28,750] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:28,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:28,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:07:28,795] {scheduler_job.py:146} INFO - Started process (PID=19442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:33,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:33,803] {logging_mixin.py:95} INFO - [2019-09-15 15:07:33,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:34,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:34,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:34,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:34,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:07:34,243] {scheduler_job.py:146} INFO - Started process (PID=19444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:39,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:39,252] {logging_mixin.py:95} INFO - [2019-09-15 15:07:39,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:39,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:39,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:39,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:39,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:07:39,698] {scheduler_job.py:146} INFO - Started process (PID=19445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:44,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:44,711] {logging_mixin.py:95} INFO - [2019-09-15 15:07:44,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:45,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:45,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:45,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:45,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:07:45,144] {scheduler_job.py:146} INFO - Started process (PID=19446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:50,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:50,155] {logging_mixin.py:95} INFO - [2019-09-15 15:07:50,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:50,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:50,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:50,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:50,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:07:50,589] {scheduler_job.py:146} INFO - Started process (PID=19448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:55,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:07:55,603] {logging_mixin.py:95} INFO - [2019-09-15 15:07:55,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:55,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:07:55,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:07:55,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:07:55,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:07:56,043] {scheduler_job.py:146} INFO - Started process (PID=19450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:01,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:01,062] {logging_mixin.py:95} INFO - [2019-09-15 15:08:01,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:01,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:01,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:01,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:01,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:08:01,508] {scheduler_job.py:146} INFO - Started process (PID=19451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:06,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:06,525] {logging_mixin.py:95} INFO - [2019-09-15 15:08:06,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:06,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:06,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:06,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:06,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:08:06,976] {scheduler_job.py:146} INFO - Started process (PID=19453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:11,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:11,995] {logging_mixin.py:95} INFO - [2019-09-15 15:08:11,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:12,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:12,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:12,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:12,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:08:12,457] {scheduler_job.py:146} INFO - Started process (PID=19454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:17,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:17,471] {logging_mixin.py:95} INFO - [2019-09-15 15:08:17,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:17,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:17,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:17,860] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:17,866] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:08:17,924] {scheduler_job.py:146} INFO - Started process (PID=19456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:22,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:22,939] {logging_mixin.py:95} INFO - [2019-09-15 15:08:22,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:23,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:23,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:23,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:23,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 15:08:23,403] {scheduler_job.py:146} INFO - Started process (PID=19457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:28,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:28,425] {logging_mixin.py:95} INFO - [2019-09-15 15:08:28,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:28,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:28,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:28,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:28,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:08:28,876] {scheduler_job.py:146} INFO - Started process (PID=19458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:33,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:33,886] {logging_mixin.py:95} INFO - [2019-09-15 15:08:33,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:34,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:34,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:34,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:34,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:08:34,348] {scheduler_job.py:146} INFO - Started process (PID=19460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:39,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:39,362] {logging_mixin.py:95} INFO - [2019-09-15 15:08:39,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:39,718] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:39,746] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:39,755] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:39,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:08:39,821] {scheduler_job.py:146} INFO - Started process (PID=19461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:44,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:44,831] {logging_mixin.py:95} INFO - [2019-09-15 15:08:44,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:45,182] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:45,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:45,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:45,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:08:45,285] {scheduler_job.py:146} INFO - Started process (PID=19462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:50,297] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:50,299] {logging_mixin.py:95} INFO - [2019-09-15 15:08:50,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:50,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:50,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:50,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:50,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 15:08:50,746] {scheduler_job.py:146} INFO - Started process (PID=19464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:55,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:08:55,764] {logging_mixin.py:95} INFO - [2019-09-15 15:08:55,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:56,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:08:56,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:08:56,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:08:56,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:08:56,208] {scheduler_job.py:146} INFO - Started process (PID=19466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:01,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:01,224] {logging_mixin.py:95} INFO - [2019-09-15 15:09:01,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:01,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:01,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:01,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:01,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:09:01,675] {scheduler_job.py:146} INFO - Started process (PID=19467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:06,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:06,691] {logging_mixin.py:95} INFO - [2019-09-15 15:09:06,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:07,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:07,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:07,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:07,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:09:07,137] {scheduler_job.py:146} INFO - Started process (PID=19469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:12,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:12,161] {logging_mixin.py:95} INFO - [2019-09-15 15:09:12,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:12,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:12,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:12,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:12,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:09:12,607] {scheduler_job.py:146} INFO - Started process (PID=19470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:17,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:17,619] {logging_mixin.py:95} INFO - [2019-09-15 15:09:17,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:17,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:18,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:18,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:18,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:09:18,081] {scheduler_job.py:146} INFO - Started process (PID=19473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:23,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:23,097] {logging_mixin.py:95} INFO - [2019-09-15 15:09:23,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:23,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:23,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:23,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:23,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:09:23,552] {scheduler_job.py:146} INFO - Started process (PID=19474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:28,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:28,577] {logging_mixin.py:95} INFO - [2019-09-15 15:09:28,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:28,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:28,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:28,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:28,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:09:29,011] {scheduler_job.py:146} INFO - Started process (PID=19475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:34,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:34,021] {logging_mixin.py:95} INFO - [2019-09-15 15:09:34,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:34,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:34,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:34,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:34,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:09:34,491] {scheduler_job.py:146} INFO - Started process (PID=19477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:39,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:39,509] {logging_mixin.py:95} INFO - [2019-09-15 15:09:39,509] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:39,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:39,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:39,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:39,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:09:39,953] {scheduler_job.py:146} INFO - Started process (PID=19478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:44,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:44,967] {logging_mixin.py:95} INFO - [2019-09-15 15:09:44,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:45,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:45,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:45,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:45,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:09:45,427] {scheduler_job.py:146} INFO - Started process (PID=19479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:50,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:50,443] {logging_mixin.py:95} INFO - [2019-09-15 15:09:50,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:50,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:50,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:50,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:50,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:09:50,895] {scheduler_job.py:146} INFO - Started process (PID=19481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:55,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:09:55,912] {logging_mixin.py:95} INFO - [2019-09-15 15:09:55,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:56,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:09:56,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:09:56,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:09:56,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:09:56,360] {scheduler_job.py:146} INFO - Started process (PID=19483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:01,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:01,385] {logging_mixin.py:95} INFO - [2019-09-15 15:10:01,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:01,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:01,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:01,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:01,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 15:10:01,833] {scheduler_job.py:146} INFO - Started process (PID=19484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:06,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:06,843] {logging_mixin.py:95} INFO - [2019-09-15 15:10:06,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:07,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:07,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:07,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:07,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:10:07,295] {scheduler_job.py:146} INFO - Started process (PID=19486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:12,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:12,321] {logging_mixin.py:95} INFO - [2019-09-15 15:10:12,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:12,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:12,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:12,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:12,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:10:12,760] {scheduler_job.py:146} INFO - Started process (PID=19487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:17,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:17,774] {logging_mixin.py:95} INFO - [2019-09-15 15:10:17,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:18,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:18,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:18,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:18,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:10:18,235] {scheduler_job.py:146} INFO - Started process (PID=19489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:23,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:23,243] {logging_mixin.py:95} INFO - [2019-09-15 15:10:23,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:23,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:23,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:23,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:23,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:10:23,694] {scheduler_job.py:146} INFO - Started process (PID=19490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:28,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:28,723] {logging_mixin.py:95} INFO - [2019-09-15 15:10:28,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:29,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:29,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:29,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:29,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 15:10:29,157] {scheduler_job.py:146} INFO - Started process (PID=19491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:34,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:34,167] {logging_mixin.py:95} INFO - [2019-09-15 15:10:34,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:34,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:34,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:34,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:34,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:10:34,629] {scheduler_job.py:146} INFO - Started process (PID=19493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:39,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:39,639] {logging_mixin.py:95} INFO - [2019-09-15 15:10:39,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:40,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:40,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:40,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:40,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:10:40,088] {scheduler_job.py:146} INFO - Started process (PID=19494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:45,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:45,103] {logging_mixin.py:95} INFO - [2019-09-15 15:10:45,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:45,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:45,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:45,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:45,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:10:45,556] {scheduler_job.py:146} INFO - Started process (PID=19495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:50,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:50,573] {logging_mixin.py:95} INFO - [2019-09-15 15:10:50,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:50,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:50,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:50,962] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:50,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:10:51,039] {scheduler_job.py:146} INFO - Started process (PID=19497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:56,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:10:56,056] {logging_mixin.py:95} INFO - [2019-09-15 15:10:56,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:56,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:10:56,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:10:56,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:10:56,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 15:10:56,504] {scheduler_job.py:146} INFO - Started process (PID=19499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:01,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:01,515] {logging_mixin.py:95} INFO - [2019-09-15 15:11:01,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:01,870] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:01,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:01,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:01,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:11:01,971] {scheduler_job.py:146} INFO - Started process (PID=19500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:06,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:06,988] {logging_mixin.py:95} INFO - [2019-09-15 15:11:06,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:07,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:07,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:07,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:07,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:11:07,444] {scheduler_job.py:146} INFO - Started process (PID=19502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:12,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:12,456] {logging_mixin.py:95} INFO - [2019-09-15 15:11:12,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:12,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:12,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:12,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:12,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:11:12,908] {scheduler_job.py:146} INFO - Started process (PID=19503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:17,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:17,915] {logging_mixin.py:95} INFO - [2019-09-15 15:11:17,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:18,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:18,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:18,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:18,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:11:18,384] {scheduler_job.py:146} INFO - Started process (PID=19505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:23,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:23,408] {logging_mixin.py:95} INFO - [2019-09-15 15:11:23,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:23,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:23,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:23,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:23,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:11:23,858] {scheduler_job.py:146} INFO - Started process (PID=19506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:28,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:28,884] {logging_mixin.py:95} INFO - [2019-09-15 15:11:28,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:29,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:29,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:29,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:29,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:11:29,327] {scheduler_job.py:146} INFO - Started process (PID=19507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:34,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:34,335] {logging_mixin.py:95} INFO - [2019-09-15 15:11:34,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:34,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:34,715] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:34,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:34,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 15:11:34,811] {scheduler_job.py:146} INFO - Started process (PID=19509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:39,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:39,824] {logging_mixin.py:95} INFO - [2019-09-15 15:11:39,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:40,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:40,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:40,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:40,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:11:40,277] {scheduler_job.py:146} INFO - Started process (PID=19510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:45,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:45,295] {logging_mixin.py:95} INFO - [2019-09-15 15:11:45,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:45,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:45,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:45,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:45,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:11:45,756] {scheduler_job.py:146} INFO - Started process (PID=19511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:50,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:50,764] {logging_mixin.py:95} INFO - [2019-09-15 15:11:50,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:51,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:51,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:51,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:51,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:11:51,222] {scheduler_job.py:146} INFO - Started process (PID=19513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:56,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:11:56,235] {logging_mixin.py:95} INFO - [2019-09-15 15:11:56,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:56,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:11:56,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:11:56,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:11:56,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:11:56,699] {scheduler_job.py:146} INFO - Started process (PID=19515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:01,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:01,724] {logging_mixin.py:95} INFO - [2019-09-15 15:12:01,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:02,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:02,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:02,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:02,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:12:02,164] {scheduler_job.py:146} INFO - Started process (PID=19516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:07,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:07,177] {logging_mixin.py:95} INFO - [2019-09-15 15:12:07,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:07,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:07,556] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:07,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:07,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:12:07,640] {scheduler_job.py:146} INFO - Started process (PID=19518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:12,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:12,659] {logging_mixin.py:95} INFO - [2019-09-15 15:12:12,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:13,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:13,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:13,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:13,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 15:12:13,110] {scheduler_job.py:146} INFO - Started process (PID=19519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:18,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:18,119] {logging_mixin.py:95} INFO - [2019-09-15 15:12:18,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:18,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:18,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:18,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:18,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:12:18,574] {scheduler_job.py:146} INFO - Started process (PID=19521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:23,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:23,593] {logging_mixin.py:95} INFO - [2019-09-15 15:12:23,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:23,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:23,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:23,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:23,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:12:24,043] {scheduler_job.py:146} INFO - Started process (PID=19522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:29,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:29,057] {logging_mixin.py:95} INFO - [2019-09-15 15:12:29,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:29,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:29,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:29,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:29,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:12:29,518] {scheduler_job.py:146} INFO - Started process (PID=19523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:34,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:34,533] {logging_mixin.py:95} INFO - [2019-09-15 15:12:34,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:34,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:34,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:34,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:34,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:12:34,977] {scheduler_job.py:146} INFO - Started process (PID=19525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:39,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:39,991] {logging_mixin.py:95} INFO - [2019-09-15 15:12:39,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:40,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:40,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:40,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:40,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:12:40,441] {scheduler_job.py:146} INFO - Started process (PID=19526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:45,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:45,449] {logging_mixin.py:95} INFO - [2019-09-15 15:12:45,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:45,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:45,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:45,830] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:45,835] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:12:45,916] {scheduler_job.py:146} INFO - Started process (PID=19527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:50,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:50,930] {logging_mixin.py:95} INFO - [2019-09-15 15:12:50,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:51,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:51,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:51,317] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:51,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:12:51,385] {scheduler_job.py:146} INFO - Started process (PID=19529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:56,401] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:12:56,402] {logging_mixin.py:95} INFO - [2019-09-15 15:12:56,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:56,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:12:56,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:12:56,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:12:56,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:12:56,857] {scheduler_job.py:146} INFO - Started process (PID=19531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:01,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:01,884] {logging_mixin.py:95} INFO - [2019-09-15 15:13:01,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:02,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:02,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:02,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:02,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 15:13:02,341] {scheduler_job.py:146} INFO - Started process (PID=19532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:07,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:07,356] {logging_mixin.py:95} INFO - [2019-09-15 15:13:07,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:07,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:07,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:07,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:07,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:13:07,812] {scheduler_job.py:146} INFO - Started process (PID=19534) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:12,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:12,834] {logging_mixin.py:95} INFO - [2019-09-15 15:13:12,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:13,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:13,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:13,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:13,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:13:13,288] {scheduler_job.py:146} INFO - Started process (PID=19535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:18,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:18,303] {logging_mixin.py:95} INFO - [2019-09-15 15:13:18,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:18,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:18,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:18,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:18,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:13:18,765] {scheduler_job.py:146} INFO - Started process (PID=19537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:23,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:23,785] {logging_mixin.py:95} INFO - [2019-09-15 15:13:23,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:24,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:24,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:24,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:24,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:13:24,228] {scheduler_job.py:146} INFO - Started process (PID=19538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:29,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:29,253] {logging_mixin.py:95} INFO - [2019-09-15 15:13:29,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:29,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:29,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:29,641] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:29,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:13:29,706] {scheduler_job.py:146} INFO - Started process (PID=19539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:34,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:34,719] {logging_mixin.py:95} INFO - [2019-09-15 15:13:34,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:35,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:35,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:35,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:35,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:13:35,173] {scheduler_job.py:146} INFO - Started process (PID=19542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:40,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:40,187] {logging_mixin.py:95} INFO - [2019-09-15 15:13:40,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:40,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:40,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:40,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:40,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:13:40,644] {scheduler_job.py:146} INFO - Started process (PID=19543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:45,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:45,656] {logging_mixin.py:95} INFO - [2019-09-15 15:13:45,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:46,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:46,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:46,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:46,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:13:46,118] {scheduler_job.py:146} INFO - Started process (PID=19545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:51,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:51,128] {logging_mixin.py:95} INFO - [2019-09-15 15:13:51,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:51,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:51,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:51,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:51,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:13:51,584] {scheduler_job.py:146} INFO - Started process (PID=19547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:56,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:13:56,597] {logging_mixin.py:95} INFO - [2019-09-15 15:13:56,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:56,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:13:56,979] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:13:56,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:13:56,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:13:57,044] {scheduler_job.py:146} INFO - Started process (PID=19549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:02,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:02,067] {logging_mixin.py:95} INFO - [2019-09-15 15:14:02,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:02,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:02,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:02,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:02,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:14:02,524] {scheduler_job.py:146} INFO - Started process (PID=19550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:07,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:07,538] {logging_mixin.py:95} INFO - [2019-09-15 15:14:07,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:07,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:07,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:07,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:07,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 15:14:07,995] {scheduler_job.py:146} INFO - Started process (PID=19552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:13,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:13,010] {logging_mixin.py:95} INFO - [2019-09-15 15:14:13,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:13,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:13,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:13,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:13,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:14:13,463] {scheduler_job.py:146} INFO - Started process (PID=19553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:18,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:18,471] {logging_mixin.py:95} INFO - [2019-09-15 15:14:18,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:18,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:18,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:18,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:18,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:14:18,937] {scheduler_job.py:146} INFO - Started process (PID=19555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:23,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:23,946] {logging_mixin.py:95} INFO - [2019-09-15 15:14:23,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:24,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:24,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:24,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:24,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:14:24,403] {scheduler_job.py:146} INFO - Started process (PID=19556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:29,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:29,423] {logging_mixin.py:95} INFO - [2019-09-15 15:14:29,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:29,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:29,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:29,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:29,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:14:29,878] {scheduler_job.py:146} INFO - Started process (PID=19557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:34,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:34,893] {logging_mixin.py:95} INFO - [2019-09-15 15:14:34,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:35,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:35,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:35,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:35,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 15:14:35,356] {scheduler_job.py:146} INFO - Started process (PID=19559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:40,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:40,364] {logging_mixin.py:95} INFO - [2019-09-15 15:14:40,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:40,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:40,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:40,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:40,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:14:40,826] {scheduler_job.py:146} INFO - Started process (PID=19560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:45,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:45,836] {logging_mixin.py:95} INFO - [2019-09-15 15:14:45,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:46,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:46,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:46,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:46,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:14:46,291] {scheduler_job.py:146} INFO - Started process (PID=19561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:51,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:51,299] {logging_mixin.py:95} INFO - [2019-09-15 15:14:51,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:51,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:51,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:51,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:51,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:14:51,762] {scheduler_job.py:146} INFO - Started process (PID=19563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:56,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:14:56,781] {logging_mixin.py:95} INFO - [2019-09-15 15:14:56,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:57,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:14:57,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:14:57,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:14:57,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:14:57,222] {scheduler_job.py:146} INFO - Started process (PID=19565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:02,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:02,240] {logging_mixin.py:95} INFO - [2019-09-15 15:15:02,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:02,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:02,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:02,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:02,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:15:02,705] {scheduler_job.py:146} INFO - Started process (PID=19566) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:07,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:07,722] {logging_mixin.py:95} INFO - [2019-09-15 15:15:07,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:08,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:08,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:08,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:08,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:15:08,173] {scheduler_job.py:146} INFO - Started process (PID=19568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:13,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:13,181] {logging_mixin.py:95} INFO - [2019-09-15 15:15:13,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:13,535] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:13,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:13,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:13,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:15:13,642] {scheduler_job.py:146} INFO - Started process (PID=19569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:18,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:18,651] {logging_mixin.py:95} INFO - [2019-09-15 15:15:18,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:19,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:19,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:19,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:19,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:15:19,121] {scheduler_job.py:146} INFO - Started process (PID=19571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:24,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:24,136] {logging_mixin.py:95} INFO - [2019-09-15 15:15:24,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:24,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:24,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:24,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:24,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:15:24,588] {scheduler_job.py:146} INFO - Started process (PID=19572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:29,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:29,604] {logging_mixin.py:95} INFO - [2019-09-15 15:15:29,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:29,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:29,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:29,998] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:30,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:15:30,060] {scheduler_job.py:146} INFO - Started process (PID=19573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:35,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:35,074] {logging_mixin.py:95} INFO - [2019-09-15 15:15:35,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:35,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:35,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:35,465] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:35,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 15:15:35,540] {scheduler_job.py:146} INFO - Started process (PID=19575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:40,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:40,548] {logging_mixin.py:95} INFO - [2019-09-15 15:15:40,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:40,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:40,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:40,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:40,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:15:41,010] {scheduler_job.py:146} INFO - Started process (PID=19576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:46,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:46,023] {logging_mixin.py:95} INFO - [2019-09-15 15:15:46,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:46,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:46,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:46,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:46,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:15:46,473] {scheduler_job.py:146} INFO - Started process (PID=19577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:51,485] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:51,486] {logging_mixin.py:95} INFO - [2019-09-15 15:15:51,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:51,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:51,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:51,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:51,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:15:51,944] {scheduler_job.py:146} INFO - Started process (PID=19579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:56,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:15:56,951] {logging_mixin.py:95} INFO - [2019-09-15 15:15:56,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:57,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:15:57,320] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:15:57,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:15:57,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:15:57,431] {scheduler_job.py:146} INFO - Started process (PID=19581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:02,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:02,453] {logging_mixin.py:95} INFO - [2019-09-15 15:16:02,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:02,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:02,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:02,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:02,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 15:16:02,897] {scheduler_job.py:146} INFO - Started process (PID=19582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:07,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:07,915] {logging_mixin.py:95} INFO - [2019-09-15 15:16:07,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:08,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:08,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:08,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:08,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:16:08,368] {scheduler_job.py:146} INFO - Started process (PID=19584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:13,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:13,378] {logging_mixin.py:95} INFO - [2019-09-15 15:16:13,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:13,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:13,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:13,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:13,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:16:13,834] {scheduler_job.py:146} INFO - Started process (PID=19585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:18,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:18,844] {logging_mixin.py:95} INFO - [2019-09-15 15:16:18,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:19,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:19,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:19,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:19,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:16:19,301] {scheduler_job.py:146} INFO - Started process (PID=19587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:24,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:24,313] {logging_mixin.py:95} INFO - [2019-09-15 15:16:24,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:24,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:24,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:24,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:24,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:16:24,773] {scheduler_job.py:146} INFO - Started process (PID=19588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:29,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:29,779] {logging_mixin.py:95} INFO - [2019-09-15 15:16:29,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:30,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:30,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:30,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:30,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:16:30,245] {scheduler_job.py:146} INFO - Started process (PID=19589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:35,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:35,257] {logging_mixin.py:95} INFO - [2019-09-15 15:16:35,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:35,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:35,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:35,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:35,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:16:35,717] {scheduler_job.py:146} INFO - Started process (PID=19591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:40,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:40,728] {logging_mixin.py:95} INFO - [2019-09-15 15:16:40,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:41,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:41,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:41,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:41,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:16:41,174] {scheduler_job.py:146} INFO - Started process (PID=19592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:46,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:46,182] {logging_mixin.py:95} INFO - [2019-09-15 15:16:46,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:46,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:46,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:46,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:46,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:16:46,648] {scheduler_job.py:146} INFO - Started process (PID=19593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:51,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:51,662] {logging_mixin.py:95} INFO - [2019-09-15 15:16:51,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:52,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:52,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:52,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:52,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:16:52,107] {scheduler_job.py:146} INFO - Started process (PID=19595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:57,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:16:57,120] {logging_mixin.py:95} INFO - [2019-09-15 15:16:57,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:57,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:16:57,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:16:57,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:16:57,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:16:57,588] {scheduler_job.py:146} INFO - Started process (PID=19597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:02,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:02,603] {logging_mixin.py:95} INFO - [2019-09-15 15:17:02,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:02,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:02,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:03,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:03,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 15:17:03,056] {scheduler_job.py:146} INFO - Started process (PID=19598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:08,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:08,076] {logging_mixin.py:95} INFO - [2019-09-15 15:17:08,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:08,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:08,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:08,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:08,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:17:08,514] {scheduler_job.py:146} INFO - Started process (PID=19600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:13,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:13,536] {logging_mixin.py:95} INFO - [2019-09-15 15:17:13,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:13,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:13,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:13,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:13,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:17:13,984] {scheduler_job.py:146} INFO - Started process (PID=19601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:18,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:18,990] {logging_mixin.py:95} INFO - [2019-09-15 15:17:18,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:19,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:19,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:19,379] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:19,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:17:19,456] {scheduler_job.py:146} INFO - Started process (PID=19603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:24,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:24,464] {logging_mixin.py:95} INFO - [2019-09-15 15:17:24,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:24,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:24,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:24,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:24,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:17:24,917] {scheduler_job.py:146} INFO - Started process (PID=19604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:29,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:29,938] {logging_mixin.py:95} INFO - [2019-09-15 15:17:29,937] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:30,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:30,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:30,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:30,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:17:30,392] {scheduler_job.py:146} INFO - Started process (PID=19605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:35,401] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:35,402] {logging_mixin.py:95} INFO - [2019-09-15 15:17:35,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:35,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:35,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:35,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:35,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:17:35,869] {scheduler_job.py:146} INFO - Started process (PID=19607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:40,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:40,878] {logging_mixin.py:95} INFO - [2019-09-15 15:17:40,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:41,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:41,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:41,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:41,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:17:41,347] {scheduler_job.py:146} INFO - Started process (PID=19608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:46,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:46,361] {logging_mixin.py:95} INFO - [2019-09-15 15:17:46,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:46,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:46,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:46,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:46,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:17:46,811] {scheduler_job.py:146} INFO - Started process (PID=19609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:51,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:51,830] {logging_mixin.py:95} INFO - [2019-09-15 15:17:51,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:52,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:52,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:52,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:52,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 15:17:52,278] {scheduler_job.py:146} INFO - Started process (PID=19611) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:57,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:17:57,292] {logging_mixin.py:95} INFO - [2019-09-15 15:17:57,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:57,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:17:57,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:17:57,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:17:57,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:17:57,755] {scheduler_job.py:146} INFO - Started process (PID=19613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:02,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:02,774] {logging_mixin.py:95} INFO - [2019-09-15 15:18:02,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:03,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:03,148] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:03,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:03,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:18:03,227] {scheduler_job.py:146} INFO - Started process (PID=19614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:08,233] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:08,234] {logging_mixin.py:95} INFO - [2019-09-15 15:18:08,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:08,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:08,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:08,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:08,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:18:08,696] {scheduler_job.py:146} INFO - Started process (PID=19616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:13,708] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:13,717] {logging_mixin.py:95} INFO - [2019-09-15 15:18:13,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:14,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:14,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:14,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:14,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 15:18:14,167] {scheduler_job.py:146} INFO - Started process (PID=19617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:19,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:19,179] {logging_mixin.py:95} INFO - [2019-09-15 15:18:19,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:19,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:19,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:19,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:19,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 15:18:19,645] {scheduler_job.py:146} INFO - Started process (PID=19619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:24,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:24,659] {logging_mixin.py:95} INFO - [2019-09-15 15:18:24,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:25,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:25,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:25,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:25,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:18:25,112] {scheduler_job.py:146} INFO - Started process (PID=19620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:30,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:30,126] {logging_mixin.py:95} INFO - [2019-09-15 15:18:30,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:30,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:30,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:30,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:30,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:18:30,588] {scheduler_job.py:146} INFO - Started process (PID=19621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:35,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:35,603] {logging_mixin.py:95} INFO - [2019-09-15 15:18:35,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:35,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:35,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:35,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:36,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:18:36,059] {scheduler_job.py:146} INFO - Started process (PID=19623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:41,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:41,075] {logging_mixin.py:95} INFO - [2019-09-15 15:18:41,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:41,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:41,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:41,465] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:41,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 15:18:41,537] {scheduler_job.py:146} INFO - Started process (PID=19624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:46,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:46,544] {logging_mixin.py:95} INFO - [2019-09-15 15:18:46,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:46,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:46,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:46,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:46,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:18:47,012] {scheduler_job.py:146} INFO - Started process (PID=19625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:52,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:52,034] {logging_mixin.py:95} INFO - [2019-09-15 15:18:52,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:52,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:52,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:52,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:52,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:18:52,486] {scheduler_job.py:146} INFO - Started process (PID=19627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:57,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:18:57,500] {logging_mixin.py:95} INFO - [2019-09-15 15:18:57,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:57,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:18:57,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:18:57,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:18:57,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:18:57,936] {scheduler_job.py:146} INFO - Started process (PID=19629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:02,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:02,943] {logging_mixin.py:95} INFO - [2019-09-15 15:19:02,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:03,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:03,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:03,526] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:03,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.597 seconds
[2019-09-15 15:19:03,580] {scheduler_job.py:146} INFO - Started process (PID=19631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:08,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:08,587] {logging_mixin.py:95} INFO - [2019-09-15 15:19:08,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:09,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:09,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:09,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:09,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.589 seconds
[2019-09-15 15:19:09,210] {scheduler_job.py:146} INFO - Started process (PID=19641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:14,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:14,216] {logging_mixin.py:95} INFO - [2019-09-15 15:19:14,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:14,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:14,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:14,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:14,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 15:19:14,646] {scheduler_job.py:146} INFO - Started process (PID=19642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:19,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:19,652] {logging_mixin.py:95} INFO - [2019-09-15 15:19:19,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:20,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:20,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:20,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:20,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 15:19:20,185] {scheduler_job.py:146} INFO - Started process (PID=19644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:25,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:25,195] {logging_mixin.py:95} INFO - [2019-09-15 15:19:25,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:25,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:25,600] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:25,608] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:25,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 15:19:25,731] {scheduler_job.py:146} INFO - Started process (PID=19645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:30,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:30,738] {logging_mixin.py:95} INFO - [2019-09-15 15:19:30,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:31,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:31,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:31,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:31,211] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-15 15:19:31,269] {scheduler_job.py:146} INFO - Started process (PID=19646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:36,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:36,281] {logging_mixin.py:95} INFO - [2019-09-15 15:19:36,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:36,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:36,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:36,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:36,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:19:36,720] {scheduler_job.py:146} INFO - Started process (PID=19648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:41,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:41,728] {logging_mixin.py:95} INFO - [2019-09-15 15:19:41,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:42,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:42,110] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:42,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:42,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:19:42,177] {scheduler_job.py:146} INFO - Started process (PID=19649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:47,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:47,182] {logging_mixin.py:95} INFO - [2019-09-15 15:19:47,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:47,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:47,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:47,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:47,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 15:19:47,729] {scheduler_job.py:146} INFO - Started process (PID=19650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:52,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:52,738] {logging_mixin.py:95} INFO - [2019-09-15 15:19:52,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:53,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:53,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:53,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:53,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 15:19:53,177] {scheduler_job.py:146} INFO - Started process (PID=19652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:58,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:19:58,188] {logging_mixin.py:95} INFO - [2019-09-15 15:19:58,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:58,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:19:58,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:19:58,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:19:58,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:19:58,619] {scheduler_job.py:146} INFO - Started process (PID=19654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:03,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:03,627] {logging_mixin.py:95} INFO - [2019-09-15 15:20:03,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:03,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:03,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:04,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:04,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:20:04,063] {scheduler_job.py:146} INFO - Started process (PID=19656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:09,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:09,084] {logging_mixin.py:95} INFO - [2019-09-15 15:20:09,083] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:09,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:09,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:09,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:09,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:20:09,509] {scheduler_job.py:146} INFO - Started process (PID=19657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:14,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:14,519] {logging_mixin.py:95} INFO - [2019-09-15 15:20:14,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:14,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:14,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:14,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:14,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 15:20:15,056] {scheduler_job.py:146} INFO - Started process (PID=19658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:20,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:20,067] {logging_mixin.py:95} INFO - [2019-09-15 15:20:20,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:20,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:20,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:20,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:20,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:20:20,504] {scheduler_job.py:146} INFO - Started process (PID=19660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:25,509] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:25,511] {logging_mixin.py:95} INFO - [2019-09-15 15:20:25,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:25,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:25,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:25,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:25,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 15:20:25,952] {scheduler_job.py:146} INFO - Started process (PID=19661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:30,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:30,959] {logging_mixin.py:95} INFO - [2019-09-15 15:20:30,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:31,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:31,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:31,366] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:31,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 15:20:31,396] {scheduler_job.py:146} INFO - Started process (PID=19662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:36,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:36,408] {logging_mixin.py:95} INFO - [2019-09-15 15:20:36,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:36,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:36,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:36,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:36,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:20:36,841] {scheduler_job.py:146} INFO - Started process (PID=19664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:41,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:41,850] {logging_mixin.py:95} INFO - [2019-09-15 15:20:41,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:42,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:42,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:42,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:42,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:20:42,294] {scheduler_job.py:146} INFO - Started process (PID=19665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:47,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:47,301] {logging_mixin.py:95} INFO - [2019-09-15 15:20:47,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:47,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:47,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:47,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:47,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 15:20:47,751] {scheduler_job.py:146} INFO - Started process (PID=19666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:52,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:52,765] {logging_mixin.py:95} INFO - [2019-09-15 15:20:52,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:53,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:53,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:53,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:53,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:20:53,202] {scheduler_job.py:146} INFO - Started process (PID=19668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:58,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:20:58,209] {logging_mixin.py:95} INFO - [2019-09-15 15:20:58,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:58,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:20:58,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:20:58,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:20:58,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:20:58,665] {scheduler_job.py:146} INFO - Started process (PID=19670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:03,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:03,676] {logging_mixin.py:95} INFO - [2019-09-15 15:21:03,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:04,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:04,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:04,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:04,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 15:21:04,116] {scheduler_job.py:146} INFO - Started process (PID=19672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:09,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:09,123] {logging_mixin.py:95} INFO - [2019-09-15 15:21:09,123] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:09,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:09,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:09,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:09,504] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:21:09,573] {scheduler_job.py:146} INFO - Started process (PID=19673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:14,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:14,588] {logging_mixin.py:95} INFO - [2019-09-15 15:21:14,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:14,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:14,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:14,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:14,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:21:15,024] {scheduler_job.py:146} INFO - Started process (PID=19674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:20,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:20,034] {logging_mixin.py:95} INFO - [2019-09-15 15:21:20,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:20,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:20,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:20,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:20,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:21:20,469] {scheduler_job.py:146} INFO - Started process (PID=19676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:25,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:25,476] {logging_mixin.py:95} INFO - [2019-09-15 15:21:25,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:25,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:25,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:25,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:25,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:21:25,913] {scheduler_job.py:146} INFO - Started process (PID=19677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:30,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:30,931] {logging_mixin.py:95} INFO - [2019-09-15 15:21:30,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:31,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:31,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:31,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:31,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 15:21:31,364] {scheduler_job.py:146} INFO - Started process (PID=19678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:36,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:36,371] {logging_mixin.py:95} INFO - [2019-09-15 15:21:36,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:36,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:36,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:36,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:36,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 15:21:36,815] {scheduler_job.py:146} INFO - Started process (PID=19680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:41,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:41,824] {logging_mixin.py:95} INFO - [2019-09-15 15:21:41,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:42,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:42,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:42,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:42,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:21:42,265] {scheduler_job.py:146} INFO - Started process (PID=19681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:47,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:47,284] {logging_mixin.py:95} INFO - [2019-09-15 15:21:47,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:47,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:47,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:47,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:47,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:21:47,718] {scheduler_job.py:146} INFO - Started process (PID=19682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:52,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:52,725] {logging_mixin.py:95} INFO - [2019-09-15 15:21:52,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:53,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:53,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:53,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:53,196] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-15 15:21:53,253] {scheduler_job.py:146} INFO - Started process (PID=19684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:58,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:21:58,263] {logging_mixin.py:95} INFO - [2019-09-15 15:21:58,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:58,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:21:58,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:21:58,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:21:58,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 15:21:58,794] {scheduler_job.py:146} INFO - Started process (PID=19686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:03,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:03,804] {logging_mixin.py:95} INFO - [2019-09-15 15:22:03,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:04,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:04,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:04,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:04,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:22:04,236] {scheduler_job.py:146} INFO - Started process (PID=19688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:09,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:09,247] {logging_mixin.py:95} INFO - [2019-09-15 15:22:09,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:09,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:09,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:09,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:09,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:22:09,684] {scheduler_job.py:146} INFO - Started process (PID=19689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:14,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:14,691] {logging_mixin.py:95} INFO - [2019-09-15 15:22:14,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:15,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:15,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:15,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:15,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-15 15:22:15,234] {scheduler_job.py:146} INFO - Started process (PID=19690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:20,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:20,249] {logging_mixin.py:95} INFO - [2019-09-15 15:22:20,249] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:20,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:20,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:20,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:20,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:22:20,682] {scheduler_job.py:146} INFO - Started process (PID=19692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:25,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:25,689] {logging_mixin.py:95} INFO - [2019-09-15 15:22:25,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:26,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:26,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:26,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:26,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:22:26,128] {scheduler_job.py:146} INFO - Started process (PID=19693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:31,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:31,134] {logging_mixin.py:95} INFO - [2019-09-15 15:22:31,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:31,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:31,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:31,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:31,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:22:31,568] {scheduler_job.py:146} INFO - Started process (PID=19694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:36,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:36,574] {logging_mixin.py:95} INFO - [2019-09-15 15:22:36,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:36,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:36,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:36,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:36,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:22:37,017] {scheduler_job.py:146} INFO - Started process (PID=19696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:42,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:42,024] {logging_mixin.py:95} INFO - [2019-09-15 15:22:42,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:42,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:42,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:42,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:42,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:22:42,464] {scheduler_job.py:146} INFO - Started process (PID=19697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:47,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:47,474] {logging_mixin.py:95} INFO - [2019-09-15 15:22:47,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:47,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:47,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:47,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:47,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:22:47,907] {scheduler_job.py:146} INFO - Started process (PID=19699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:52,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:52,915] {logging_mixin.py:95} INFO - [2019-09-15 15:22:52,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:53,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:53,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:53,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:53,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:22:53,367] {scheduler_job.py:146} INFO - Started process (PID=19701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:58,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:22:58,377] {logging_mixin.py:95} INFO - [2019-09-15 15:22:58,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:58,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:22:58,750] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:22:58,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:22:58,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:22:58,824] {scheduler_job.py:146} INFO - Started process (PID=19703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:03,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:03,833] {logging_mixin.py:95} INFO - [2019-09-15 15:23:03,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:04,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:04,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:04,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:04,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:23:04,276] {scheduler_job.py:146} INFO - Started process (PID=19705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:09,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:09,283] {logging_mixin.py:95} INFO - [2019-09-15 15:23:09,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:09,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:09,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:09,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:09,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:23:09,733] {scheduler_job.py:146} INFO - Started process (PID=19706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:14,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:14,741] {logging_mixin.py:95} INFO - [2019-09-15 15:23:14,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:15,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:15,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:15,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:15,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:23:15,195] {scheduler_job.py:146} INFO - Started process (PID=19707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:20,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:20,203] {logging_mixin.py:95} INFO - [2019-09-15 15:23:20,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:20,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:20,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:20,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:20,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:23:20,650] {scheduler_job.py:146} INFO - Started process (PID=19709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:25,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:25,662] {logging_mixin.py:95} INFO - [2019-09-15 15:23:25,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:26,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:26,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:26,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:26,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:23:26,102] {scheduler_job.py:146} INFO - Started process (PID=19710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:31,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:31,120] {logging_mixin.py:95} INFO - [2019-09-15 15:23:31,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:31,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:31,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:31,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:31,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:23:31,563] {scheduler_job.py:146} INFO - Started process (PID=19711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:36,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:36,573] {logging_mixin.py:95} INFO - [2019-09-15 15:23:36,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:36,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:36,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:36,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:36,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:23:37,025] {scheduler_job.py:146} INFO - Started process (PID=19713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:42,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:42,033] {logging_mixin.py:95} INFO - [2019-09-15 15:23:42,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:42,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:42,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:42,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:42,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:23:42,478] {scheduler_job.py:146} INFO - Started process (PID=19714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:47,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:47,489] {logging_mixin.py:95} INFO - [2019-09-15 15:23:47,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:47,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:47,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:47,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:47,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:23:47,932] {scheduler_job.py:146} INFO - Started process (PID=19715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:52,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:52,939] {logging_mixin.py:95} INFO - [2019-09-15 15:23:52,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:53,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:53,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:53,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:53,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:23:53,388] {scheduler_job.py:146} INFO - Started process (PID=19717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:58,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:23:58,395] {logging_mixin.py:95} INFO - [2019-09-15 15:23:58,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:58,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:23:58,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:23:58,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:23:58,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:23:58,849] {scheduler_job.py:146} INFO - Started process (PID=19719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:03,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:03,855] {logging_mixin.py:95} INFO - [2019-09-15 15:24:03,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:04,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:04,227] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:04,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:04,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:24:04,307] {scheduler_job.py:146} INFO - Started process (PID=19721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:09,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:09,316] {logging_mixin.py:95} INFO - [2019-09-15 15:24:09,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:09,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:09,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:09,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:09,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:24:09,760] {scheduler_job.py:146} INFO - Started process (PID=19722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:14,766] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:14,767] {logging_mixin.py:95} INFO - [2019-09-15 15:24:14,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:15,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:15,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:15,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:15,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:24:15,218] {scheduler_job.py:146} INFO - Started process (PID=19723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:20,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:20,225] {logging_mixin.py:95} INFO - [2019-09-15 15:24:20,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:20,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:20,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:20,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:20,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:24:20,677] {scheduler_job.py:146} INFO - Started process (PID=19725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:25,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:25,688] {logging_mixin.py:95} INFO - [2019-09-15 15:24:25,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:26,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:26,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:26,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:26,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:24:26,133] {scheduler_job.py:146} INFO - Started process (PID=19726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:31,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:31,139] {logging_mixin.py:95} INFO - [2019-09-15 15:24:31,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:31,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:31,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:31,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:31,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:24:31,593] {scheduler_job.py:146} INFO - Started process (PID=19727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:36,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:36,601] {logging_mixin.py:95} INFO - [2019-09-15 15:24:36,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:36,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:36,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:36,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:36,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:24:37,052] {scheduler_job.py:146} INFO - Started process (PID=19729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:42,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:42,060] {logging_mixin.py:95} INFO - [2019-09-15 15:24:42,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:42,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:42,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:42,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:42,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:24:42,509] {scheduler_job.py:146} INFO - Started process (PID=19730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:47,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:47,520] {logging_mixin.py:95} INFO - [2019-09-15 15:24:47,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:47,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:47,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:47,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:47,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:24:47,969] {scheduler_job.py:146} INFO - Started process (PID=19731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:52,979] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:52,980] {logging_mixin.py:95} INFO - [2019-09-15 15:24:52,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:53,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:53,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:53,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:53,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:24:53,421] {scheduler_job.py:146} INFO - Started process (PID=19733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:58,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:24:58,429] {logging_mixin.py:95} INFO - [2019-09-15 15:24:58,429] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:58,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:24:58,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:24:58,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:24:58,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:24:58,882] {scheduler_job.py:146} INFO - Started process (PID=19735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:03,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:03,889] {logging_mixin.py:95} INFO - [2019-09-15 15:25:03,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:04,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:04,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:04,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:04,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:25:04,345] {scheduler_job.py:146} INFO - Started process (PID=19737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:09,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:09,353] {logging_mixin.py:95} INFO - [2019-09-15 15:25:09,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:09,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:09,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:09,728] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:09,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:25:09,800] {scheduler_job.py:146} INFO - Started process (PID=19738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:14,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:14,816] {logging_mixin.py:95} INFO - [2019-09-15 15:25:14,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:15,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:15,178] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:15,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:15,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:25:15,259] {scheduler_job.py:146} INFO - Started process (PID=19739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:20,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:20,268] {logging_mixin.py:95} INFO - [2019-09-15 15:25:20,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:20,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:20,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:20,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:20,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:25:20,718] {scheduler_job.py:146} INFO - Started process (PID=19741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:25,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:25,730] {logging_mixin.py:95} INFO - [2019-09-15 15:25:25,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:26,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:26,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:26,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:26,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:25:26,173] {scheduler_job.py:146} INFO - Started process (PID=19742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:31,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:31,189] {logging_mixin.py:95} INFO - [2019-09-15 15:25:31,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:31,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:31,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:31,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:31,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:25:31,629] {scheduler_job.py:146} INFO - Started process (PID=19743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:36,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:36,642] {logging_mixin.py:95} INFO - [2019-09-15 15:25:36,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:36,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:36,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:37,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:37,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:25:37,112] {scheduler_job.py:146} INFO - Started process (PID=19746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:42,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:42,120] {logging_mixin.py:95} INFO - [2019-09-15 15:25:42,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:42,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:42,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:42,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:42,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:25:42,597] {scheduler_job.py:146} INFO - Started process (PID=19747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:47,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:47,610] {logging_mixin.py:95} INFO - [2019-09-15 15:25:47,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:47,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:47,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:47,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:47,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:25:48,064] {scheduler_job.py:146} INFO - Started process (PID=19750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:48,068] {logging_mixin.py:95} INFO - [2019-09-15 15:25:48,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:48,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:48,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.357 seconds
[2019-09-15 15:25:48,477] {scheduler_job.py:146} INFO - Started process (PID=19751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:48,482] {logging_mixin.py:95} INFO - [2019-09-15 15:25:48,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:48,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:48,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.382 seconds
[2019-09-15 15:25:48,887] {scheduler_job.py:146} INFO - Started process (PID=19753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:48,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:48,892] {logging_mixin.py:95} INFO - [2019-09-15 15:25:48,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:49,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:49,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-09-15 15:25:49,297] {scheduler_job.py:146} INFO - Started process (PID=19754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:49,301] {logging_mixin.py:95} INFO - [2019-09-15 15:25:49,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:49,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:49,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.353 seconds
[2019-09-15 15:25:49,707] {scheduler_job.py:146} INFO - Started process (PID=19755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:49,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:49,711] {logging_mixin.py:95} INFO - [2019-09-15 15:25:49,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:50,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:50,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.350 seconds
[2019-09-15 15:25:50,116] {scheduler_job.py:146} INFO - Started process (PID=19756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:50,120] {logging_mixin.py:95} INFO - [2019-09-15 15:25:50,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:50,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:50,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.348 seconds
[2019-09-15 15:25:50,528] {scheduler_job.py:146} INFO - Started process (PID=19757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:50,532] {logging_mixin.py:95} INFO - [2019-09-15 15:25:50,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:50,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:50,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.356 seconds
[2019-09-15 15:25:50,935] {scheduler_job.py:146} INFO - Started process (PID=19758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:50,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:50,939] {logging_mixin.py:95} INFO - [2019-09-15 15:25:50,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:51,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:51,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.352 seconds
[2019-09-15 15:25:51,345] {scheduler_job.py:146} INFO - Started process (PID=19759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:51,350] {logging_mixin.py:95} INFO - [2019-09-15 15:25:51,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:51,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:51,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.340 seconds
[2019-09-15 15:25:51,755] {scheduler_job.py:146} INFO - Started process (PID=19760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:51,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:51,760] {logging_mixin.py:95} INFO - [2019-09-15 15:25:51,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:52,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:52,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.348 seconds
[2019-09-15 15:25:52,163] {scheduler_job.py:146} INFO - Started process (PID=19761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:52,168] {logging_mixin.py:95} INFO - [2019-09-15 15:25:52,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,531] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:52,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:52,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.382 seconds
[2019-09-15 15:25:52,574] {scheduler_job.py:146} INFO - Started process (PID=19762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:52,579] {logging_mixin.py:95} INFO - [2019-09-15 15:25:52,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:52,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:52,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-15 15:25:52,985] {scheduler_job.py:146} INFO - Started process (PID=19763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:52,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:52,990] {logging_mixin.py:95} INFO - [2019-09-15 15:25:52,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:53,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:53,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.349 seconds
[2019-09-15 15:25:53,392] {scheduler_job.py:146} INFO - Started process (PID=19764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:53,396] {logging_mixin.py:95} INFO - [2019-09-15 15:25:53,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:25:53,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:25:53,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.349 seconds
[2019-09-15 15:25:53,799] {scheduler_job.py:146} INFO - Started process (PID=19765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:25:53,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:25:53,804] {logging_mixin.py:95} INFO - [2019-09-15 15:25:53,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:11,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:11,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:11,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:11,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 437.681 seconds
[2019-09-15 15:33:11,554] {scheduler_job.py:146} INFO - Started process (PID=19767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:11,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:11,565] {logging_mixin.py:95} INFO - [2019-09-15 15:33:11,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:12,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:12,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:12,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:12,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.707 seconds
[2019-09-15 15:33:12,350] {scheduler_job.py:146} INFO - Started process (PID=19772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:17,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:17,358] {logging_mixin.py:95} INFO - [2019-09-15 15:33:17,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:17,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:17,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:17,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:17,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.539 seconds
[2019-09-15 15:33:18,003] {scheduler_job.py:146} INFO - Started process (PID=19789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:23,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:23,010] {logging_mixin.py:95} INFO - [2019-09-15 15:33:23,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:23,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:23,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:23,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:23,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 15:33:23,538] {scheduler_job.py:146} INFO - Started process (PID=19795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:28,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:28,549] {logging_mixin.py:95} INFO - [2019-09-15 15:33:28,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:28,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:28,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:28,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:28,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 15:33:29,080] {scheduler_job.py:146} INFO - Started process (PID=19796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:34,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:34,087] {logging_mixin.py:95} INFO - [2019-09-15 15:33:34,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:34,441] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:34,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:34,471] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:34,476] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:33:34,523] {scheduler_job.py:146} INFO - Started process (PID=19797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:39,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:39,529] {logging_mixin.py:95} INFO - [2019-09-15 15:33:39,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:39,901] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:39,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:39,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:39,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 15:33:39,971] {scheduler_job.py:146} INFO - Started process (PID=19799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:44,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:44,981] {logging_mixin.py:95} INFO - [2019-09-15 15:33:44,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:45,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:45,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:45,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:45,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 15:33:45,421] {scheduler_job.py:146} INFO - Started process (PID=19800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:50,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:50,431] {logging_mixin.py:95} INFO - [2019-09-15 15:33:50,430] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:50,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:50,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:50,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:50,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:33:50,867] {scheduler_job.py:146} INFO - Started process (PID=19802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:55,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:33:55,875] {logging_mixin.py:95} INFO - [2019-09-15 15:33:55,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:56,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:33:56,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:33:56,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:33:56,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 15:33:56,327] {scheduler_job.py:146} INFO - Started process (PID=19803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:01,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:01,335] {logging_mixin.py:95} INFO - [2019-09-15 15:34:01,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:01,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:01,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:01,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:01,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:34:01,782] {scheduler_job.py:146} INFO - Started process (PID=19804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:06,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:06,788] {logging_mixin.py:95} INFO - [2019-09-15 15:34:06,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:07,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:07,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:07,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:07,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:34:07,238] {scheduler_job.py:146} INFO - Started process (PID=19806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:12,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:12,258] {logging_mixin.py:95} INFO - [2019-09-15 15:34:12,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:12,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:12,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:12,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:12,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:34:12,684] {scheduler_job.py:146} INFO - Started process (PID=19807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:17,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:17,692] {logging_mixin.py:95} INFO - [2019-09-15 15:34:17,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:18,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:18,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:18,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:18,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:34:18,137] {scheduler_job.py:146} INFO - Started process (PID=19809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:23,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:23,143] {logging_mixin.py:95} INFO - [2019-09-15 15:34:23,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:23,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:23,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:23,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:23,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 15:34:23,683] {scheduler_job.py:146} INFO - Started process (PID=19811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:28,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:28,691] {logging_mixin.py:95} INFO - [2019-09-15 15:34:28,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:29,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:29,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:29,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:29,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 15:34:29,132] {scheduler_job.py:146} INFO - Started process (PID=19812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:34,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:34,139] {logging_mixin.py:95} INFO - [2019-09-15 15:34:34,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:34,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:34,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:34,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:34,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:34:34,578] {scheduler_job.py:146} INFO - Started process (PID=19813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:39,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:39,588] {logging_mixin.py:95} INFO - [2019-09-15 15:34:39,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:40,022] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:40,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:40,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:40,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 15:34:40,130] {scheduler_job.py:146} INFO - Started process (PID=19815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:45,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:45,138] {logging_mixin.py:95} INFO - [2019-09-15 15:34:45,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:45,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:45,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:45,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:45,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 15:34:45,574] {scheduler_job.py:146} INFO - Started process (PID=19816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:50,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:50,584] {logging_mixin.py:95} INFO - [2019-09-15 15:34:50,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:50,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:50,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:50,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:51,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 15:34:51,119] {scheduler_job.py:146} INFO - Started process (PID=19818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:56,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:34:56,130] {logging_mixin.py:95} INFO - [2019-09-15 15:34:56,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:56,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:34:56,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:34:56,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:34:56,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:34:56,573] {scheduler_job.py:146} INFO - Started process (PID=19819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:01,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:01,580] {logging_mixin.py:95} INFO - [2019-09-15 15:35:01,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:01,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:01,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:01,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:01,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:35:02,032] {scheduler_job.py:146} INFO - Started process (PID=19820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:07,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:07,040] {logging_mixin.py:95} INFO - [2019-09-15 15:35:07,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:07,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:07,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:07,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:07,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:35:07,480] {scheduler_job.py:146} INFO - Started process (PID=19822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:12,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:12,487] {logging_mixin.py:95} INFO - [2019-09-15 15:35:12,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:12,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:12,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:12,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:12,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:35:12,922] {scheduler_job.py:146} INFO - Started process (PID=19823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:17,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:17,933] {logging_mixin.py:95} INFO - [2019-09-15 15:35:17,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:18,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:18,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:18,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:18,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:35:18,376] {scheduler_job.py:146} INFO - Started process (PID=19825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:23,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:23,384] {logging_mixin.py:95} INFO - [2019-09-15 15:35:23,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:23,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:23,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:23,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:23,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 15:35:23,828] {scheduler_job.py:146} INFO - Started process (PID=19827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:28,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:28,839] {logging_mixin.py:95} INFO - [2019-09-15 15:35:28,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:29,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:29,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:29,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:29,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:35:29,283] {scheduler_job.py:146} INFO - Started process (PID=19828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:34,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:34,290] {logging_mixin.py:95} INFO - [2019-09-15 15:35:34,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:34,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:34,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:34,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:34,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 15:35:34,739] {scheduler_job.py:146} INFO - Started process (PID=19829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:39,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:39,746] {logging_mixin.py:95} INFO - [2019-09-15 15:35:39,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:40,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:40,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:40,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:40,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 15:35:40,192] {scheduler_job.py:146} INFO - Started process (PID=19831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:45,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:45,211] {logging_mixin.py:95} INFO - [2019-09-15 15:35:45,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:45,578] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:45,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:45,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:45,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 15:35:45,738] {scheduler_job.py:146} INFO - Started process (PID=19832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:50,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:50,747] {logging_mixin.py:95} INFO - [2019-09-15 15:35:50,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:51,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:51,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:51,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:51,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:35:51,179] {scheduler_job.py:146} INFO - Started process (PID=19834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:56,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:35:56,191] {logging_mixin.py:95} INFO - [2019-09-15 15:35:56,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:56,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:35:56,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:35:56,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:35:56,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:35:56,633] {scheduler_job.py:146} INFO - Started process (PID=19835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:01,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:01,641] {logging_mixin.py:95} INFO - [2019-09-15 15:36:01,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:01,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:01,995] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:02,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:02,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 15:36:02,085] {scheduler_job.py:146} INFO - Started process (PID=19837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:07,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:07,091] {logging_mixin.py:95} INFO - [2019-09-15 15:36:07,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:07,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:07,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:07,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:07,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 15:36:07,541] {scheduler_job.py:146} INFO - Started process (PID=19839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:12,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:12,550] {logging_mixin.py:95} INFO - [2019-09-15 15:36:12,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:12,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:12,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:12,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:12,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 15:36:13,084] {scheduler_job.py:146} INFO - Started process (PID=19840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:18,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:18,090] {logging_mixin.py:95} INFO - [2019-09-15 15:36:18,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:18,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:18,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:18,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:18,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 15:36:18,524] {scheduler_job.py:146} INFO - Started process (PID=19842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:23,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:23,531] {logging_mixin.py:95} INFO - [2019-09-15 15:36:23,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:23,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:23,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:23,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:23,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:36:23,976] {scheduler_job.py:146} INFO - Started process (PID=19844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:28,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:28,982] {logging_mixin.py:95} INFO - [2019-09-15 15:36:28,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:29,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:29,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:29,353] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:29,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:36:29,437] {scheduler_job.py:146} INFO - Started process (PID=19845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:34,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:34,444] {logging_mixin.py:95} INFO - [2019-09-15 15:36:34,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:34,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:34,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:34,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:34,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:36:34,886] {scheduler_job.py:146} INFO - Started process (PID=19846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:39,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:39,897] {logging_mixin.py:95} INFO - [2019-09-15 15:36:39,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:40,239] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:40,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:40,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:40,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:36:40,334] {scheduler_job.py:146} INFO - Started process (PID=19848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:45,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:45,350] {logging_mixin.py:95} INFO - [2019-09-15 15:36:45,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:45,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:45,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:45,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:45,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 15:36:45,782] {scheduler_job.py:146} INFO - Started process (PID=19849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:50,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:50,793] {logging_mixin.py:95} INFO - [2019-09-15 15:36:50,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:51,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:51,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:51,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:51,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 15:36:51,232] {scheduler_job.py:146} INFO - Started process (PID=19851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:56,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:36:56,240] {logging_mixin.py:95} INFO - [2019-09-15 15:36:56,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:56,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:36:56,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:36:56,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:36:56,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-09-15 15:36:56,775] {scheduler_job.py:146} INFO - Started process (PID=19854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:01,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:01,783] {logging_mixin.py:95} INFO - [2019-09-15 15:37:01,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:02,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:02,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:02,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:02,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:37:02,219] {scheduler_job.py:146} INFO - Started process (PID=19855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:07,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:07,227] {logging_mixin.py:95} INFO - [2019-09-15 15:37:07,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:07,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:07,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:07,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:07,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 15:37:07,762] {scheduler_job.py:146} INFO - Started process (PID=19857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:12,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:12,770] {logging_mixin.py:95} INFO - [2019-09-15 15:37:12,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:13,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:13,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:13,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:13,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 15:37:13,214] {scheduler_job.py:146} INFO - Started process (PID=19858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:18,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:18,222] {logging_mixin.py:95} INFO - [2019-09-15 15:37:18,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:18,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:18,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:18,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:18,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:37:18,659] {scheduler_job.py:146} INFO - Started process (PID=19860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:23,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:23,671] {logging_mixin.py:95} INFO - [2019-09-15 15:37:23,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:24,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:24,038] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:24,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:24,052] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:37:24,111] {scheduler_job.py:146} INFO - Started process (PID=19862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:29,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:29,128] {logging_mixin.py:95} INFO - [2019-09-15 15:37:29,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:29,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:29,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:29,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:29,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 15:37:29,558] {scheduler_job.py:146} INFO - Started process (PID=19863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:34,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:34,567] {logging_mixin.py:95} INFO - [2019-09-15 15:37:34,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:34,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:34,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:34,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:34,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:37:35,008] {scheduler_job.py:146} INFO - Started process (PID=19864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:40,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:40,024] {logging_mixin.py:95} INFO - [2019-09-15 15:37:40,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:40,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:40,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:40,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:40,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:37:40,467] {scheduler_job.py:146} INFO - Started process (PID=19866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:45,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:45,474] {logging_mixin.py:95} INFO - [2019-09-15 15:37:45,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:45,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:45,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:45,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:45,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:37:45,917] {scheduler_job.py:146} INFO - Started process (PID=19868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:50,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:50,928] {logging_mixin.py:95} INFO - [2019-09-15 15:37:50,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:51,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:51,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:51,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:51,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.354 seconds
[2019-09-15 15:37:51,374] {scheduler_job.py:146} INFO - Started process (PID=19870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:56,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:37:56,390] {logging_mixin.py:95} INFO - [2019-09-15 15:37:56,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:56,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:37:56,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:37:56,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:37:56,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-15 15:37:56,828] {scheduler_job.py:146} INFO - Started process (PID=19871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:01,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:01,840] {logging_mixin.py:95} INFO - [2019-09-15 15:38:01,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:02,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:02,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:02,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:02,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:38:02,279] {scheduler_job.py:146} INFO - Started process (PID=19872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:07,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:07,286] {logging_mixin.py:95} INFO - [2019-09-15 15:38:07,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:07,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:07,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:07,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:07,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:38:07,738] {scheduler_job.py:146} INFO - Started process (PID=19874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:12,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:12,748] {logging_mixin.py:95} INFO - [2019-09-15 15:38:12,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:13,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:13,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:13,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:13,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:38:13,206] {scheduler_job.py:146} INFO - Started process (PID=19875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:18,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:18,214] {logging_mixin.py:95} INFO - [2019-09-15 15:38:18,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:18,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:18,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:18,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:18,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:38:18,668] {scheduler_job.py:146} INFO - Started process (PID=19877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:23,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:23,687] {logging_mixin.py:95} INFO - [2019-09-15 15:38:23,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:24,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:24,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:24,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:24,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:38:24,126] {scheduler_job.py:146} INFO - Started process (PID=19879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:29,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:29,145] {logging_mixin.py:95} INFO - [2019-09-15 15:38:29,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:29,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:29,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:29,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:29,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:38:29,588] {scheduler_job.py:146} INFO - Started process (PID=19880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:34,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:34,598] {logging_mixin.py:95} INFO - [2019-09-15 15:38:34,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:34,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:34,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:34,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:34,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:38:35,041] {scheduler_job.py:146} INFO - Started process (PID=19881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:40,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:40,060] {logging_mixin.py:95} INFO - [2019-09-15 15:38:40,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:40,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:40,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:40,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:40,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:38:40,505] {scheduler_job.py:146} INFO - Started process (PID=19883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:45,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:45,513] {logging_mixin.py:95} INFO - [2019-09-15 15:38:45,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:45,901] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:45,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:45,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:45,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 15:38:45,955] {scheduler_job.py:146} INFO - Started process (PID=19885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:50,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:50,964] {logging_mixin.py:95} INFO - [2019-09-15 15:38:50,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:51,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:51,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:51,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:51,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:38:51,413] {scheduler_job.py:146} INFO - Started process (PID=19887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:56,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:38:56,424] {logging_mixin.py:95} INFO - [2019-09-15 15:38:56,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:56,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:38:56,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:38:56,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:38:56,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:38:56,870] {scheduler_job.py:146} INFO - Started process (PID=19888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:01,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:01,877] {logging_mixin.py:95} INFO - [2019-09-15 15:39:01,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:02,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:02,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:02,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:02,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:39:02,329] {scheduler_job.py:146} INFO - Started process (PID=19889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:07,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:07,337] {logging_mixin.py:95} INFO - [2019-09-15 15:39:07,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:07,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:07,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:07,713] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:07,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:39:07,790] {scheduler_job.py:146} INFO - Started process (PID=19891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:12,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:12,801] {logging_mixin.py:95} INFO - [2019-09-15 15:39:12,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:13,155] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:13,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:13,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:13,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:39:13,240] {scheduler_job.py:146} INFO - Started process (PID=19893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:18,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:18,251] {logging_mixin.py:95} INFO - [2019-09-15 15:39:18,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:18,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:18,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:18,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:18,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:39:18,695] {scheduler_job.py:146} INFO - Started process (PID=19895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:23,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:23,706] {logging_mixin.py:95} INFO - [2019-09-15 15:39:23,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:24,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:24,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:24,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:24,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 15:39:24,151] {scheduler_job.py:146} INFO - Started process (PID=19897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:29,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:29,160] {logging_mixin.py:95} INFO - [2019-09-15 15:39:29,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:29,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:29,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:29,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:29,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:39:29,611] {scheduler_job.py:146} INFO - Started process (PID=19898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:34,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:34,622] {logging_mixin.py:95} INFO - [2019-09-15 15:39:34,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:34,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:34,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:34,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:34,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:39:35,069] {scheduler_job.py:146} INFO - Started process (PID=19899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:40,079] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:40,090] {logging_mixin.py:95} INFO - [2019-09-15 15:39:40,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:40,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:40,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:40,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:40,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:39:40,529] {scheduler_job.py:146} INFO - Started process (PID=19901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:45,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:45,535] {logging_mixin.py:95} INFO - [2019-09-15 15:39:45,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:45,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:45,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:45,914] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:45,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:39:45,992] {scheduler_job.py:146} INFO - Started process (PID=19902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:51,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:51,003] {logging_mixin.py:95} INFO - [2019-09-15 15:39:51,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:51,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:51,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:51,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:51,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:39:51,455] {scheduler_job.py:146} INFO - Started process (PID=19904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:56,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:39:56,463] {logging_mixin.py:95} INFO - [2019-09-15 15:39:56,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:56,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:39:56,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:39:56,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:39:56,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:39:56,915] {scheduler_job.py:146} INFO - Started process (PID=19905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:01,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:01,927] {logging_mixin.py:95} INFO - [2019-09-15 15:40:01,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:02,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:02,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:02,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:02,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:40:02,374] {scheduler_job.py:146} INFO - Started process (PID=19906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:07,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:07,384] {logging_mixin.py:95} INFO - [2019-09-15 15:40:07,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:07,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:07,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:07,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:07,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:40:07,837] {scheduler_job.py:146} INFO - Started process (PID=19908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:12,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:12,847] {logging_mixin.py:95} INFO - [2019-09-15 15:40:12,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:13,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:13,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:13,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:13,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:40:13,296] {scheduler_job.py:146} INFO - Started process (PID=19909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:18,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:18,303] {logging_mixin.py:95} INFO - [2019-09-15 15:40:18,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:18,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:18,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:18,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:18,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:40:18,751] {scheduler_job.py:146} INFO - Started process (PID=19911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:23,758] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:23,759] {logging_mixin.py:95} INFO - [2019-09-15 15:40:23,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:24,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:24,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:24,124] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:24,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:40:24,212] {scheduler_job.py:146} INFO - Started process (PID=19913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:29,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:29,220] {logging_mixin.py:95} INFO - [2019-09-15 15:40:29,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:29,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:29,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:29,589] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:29,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:40:29,671] {scheduler_job.py:146} INFO - Started process (PID=19914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:34,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:34,678] {logging_mixin.py:95} INFO - [2019-09-15 15:40:34,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:35,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:35,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:35,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:35,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:40:35,135] {scheduler_job.py:146} INFO - Started process (PID=19915) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:40,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:40,156] {logging_mixin.py:95} INFO - [2019-09-15 15:40:40,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:40,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:40,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:40,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:40,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:40:40,591] {scheduler_job.py:146} INFO - Started process (PID=19917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:45,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:45,598] {logging_mixin.py:95} INFO - [2019-09-15 15:40:45,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:45,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:45,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:45,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:45,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:40:46,050] {scheduler_job.py:146} INFO - Started process (PID=19918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:51,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:51,057] {logging_mixin.py:95} INFO - [2019-09-15 15:40:51,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:51,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:51,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:51,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:51,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:40:51,509] {scheduler_job.py:146} INFO - Started process (PID=19920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:56,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:40:56,517] {logging_mixin.py:95} INFO - [2019-09-15 15:40:56,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:56,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:40:56,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:40:56,882] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:40:56,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:40:56,969] {scheduler_job.py:146} INFO - Started process (PID=19921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:01,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:01,977] {logging_mixin.py:95} INFO - [2019-09-15 15:41:01,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:02,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:02,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:02,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:02,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:41:02,424] {scheduler_job.py:146} INFO - Started process (PID=19923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:07,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:07,434] {logging_mixin.py:95} INFO - [2019-09-15 15:41:07,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:07,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:07,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:07,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:07,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.359 seconds
[2019-09-15 15:41:07,885] {scheduler_job.py:146} INFO - Started process (PID=19925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:12,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:12,892] {logging_mixin.py:95} INFO - [2019-09-15 15:41:12,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:13,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:13,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:13,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:13,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:41:13,345] {scheduler_job.py:146} INFO - Started process (PID=19926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:18,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:18,354] {logging_mixin.py:95} INFO - [2019-09-15 15:41:18,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:18,698] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:18,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:18,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:18,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:41:18,805] {scheduler_job.py:146} INFO - Started process (PID=19928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:23,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:23,812] {logging_mixin.py:95} INFO - [2019-09-15 15:41:23,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:24,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:24,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:24,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:24,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:41:24,264] {scheduler_job.py:146} INFO - Started process (PID=19930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:29,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:29,270] {logging_mixin.py:95} INFO - [2019-09-15 15:41:29,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:29,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:29,628] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:29,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:29,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 15:41:29,727] {scheduler_job.py:146} INFO - Started process (PID=19931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:34,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:34,736] {logging_mixin.py:95} INFO - [2019-09-15 15:41:34,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:35,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:35,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:35,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:35,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:41:35,184] {scheduler_job.py:146} INFO - Started process (PID=19932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:40,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:40,193] {logging_mixin.py:95} INFO - [2019-09-15 15:41:40,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:40,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:40,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:40,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:40,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.359 seconds
[2019-09-15 15:41:40,643] {scheduler_job.py:146} INFO - Started process (PID=19934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:45,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:45,647] {logging_mixin.py:95} INFO - [2019-09-15 15:41:45,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:45,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:45,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:45,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:45,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.356 seconds
[2019-09-15 15:41:46,104] {scheduler_job.py:146} INFO - Started process (PID=19935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:51,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:51,110] {logging_mixin.py:95} INFO - [2019-09-15 15:41:51,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:51,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:51,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:51,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:51,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.352 seconds
[2019-09-15 15:41:51,559] {scheduler_job.py:146} INFO - Started process (PID=19937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:56,568] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:41:56,569] {logging_mixin.py:95} INFO - [2019-09-15 15:41:56,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:56,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:41:56,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:41:56,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:41:56,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.362 seconds
[2019-09-15 15:41:57,021] {scheduler_job.py:146} INFO - Started process (PID=19938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:02,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:02,032] {logging_mixin.py:95} INFO - [2019-09-15 15:42:02,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:02,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:02,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:02,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:02,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:42:02,490] {scheduler_job.py:146} INFO - Started process (PID=19939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:07,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:07,496] {logging_mixin.py:95} INFO - [2019-09-15 15:42:07,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:07,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:07,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:07,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:07,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:42:07,950] {scheduler_job.py:146} INFO - Started process (PID=19941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:12,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:12,957] {logging_mixin.py:95} INFO - [2019-09-15 15:42:12,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:13,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:13,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:13,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:13,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:42:13,406] {scheduler_job.py:146} INFO - Started process (PID=19942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:18,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:18,418] {logging_mixin.py:95} INFO - [2019-09-15 15:42:18,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:18,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:18,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:18,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:18,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:42:18,863] {scheduler_job.py:146} INFO - Started process (PID=19944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:23,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:23,875] {logging_mixin.py:95} INFO - [2019-09-15 15:42:23,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:24,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:24,240] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:24,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:24,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:42:24,322] {scheduler_job.py:146} INFO - Started process (PID=19946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:29,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:29,329] {logging_mixin.py:95} INFO - [2019-09-15 15:42:29,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:29,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:29,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:29,700] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:29,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 15:42:29,780] {scheduler_job.py:146} INFO - Started process (PID=19947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:34,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:34,791] {logging_mixin.py:95} INFO - [2019-09-15 15:42:34,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:35,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:35,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:35,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:35,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:42:35,243] {scheduler_job.py:146} INFO - Started process (PID=19948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:40,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:40,254] {logging_mixin.py:95} INFO - [2019-09-15 15:42:40,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:40,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:40,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:40,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:40,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:42:40,705] {scheduler_job.py:146} INFO - Started process (PID=19950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:45,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:45,718] {logging_mixin.py:95} INFO - [2019-09-15 15:42:45,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:46,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:46,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:46,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:46,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 15:42:46,161] {scheduler_job.py:146} INFO - Started process (PID=19951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:51,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:51,172] {logging_mixin.py:95} INFO - [2019-09-15 15:42:51,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:51,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:51,531] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:51,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:51,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 15:42:51,620] {scheduler_job.py:146} INFO - Started process (PID=19953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:56,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:42:56,637] {logging_mixin.py:95} INFO - [2019-09-15 15:42:56,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:56,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:42:57,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:42:57,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:42:57,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:42:57,080] {scheduler_job.py:146} INFO - Started process (PID=19954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:02,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:02,090] {logging_mixin.py:95} INFO - [2019-09-15 15:43:02,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:02,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:02,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:02,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:02,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:43:02,541] {scheduler_job.py:146} INFO - Started process (PID=19955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:07,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:07,552] {logging_mixin.py:95} INFO - [2019-09-15 15:43:07,551] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:07,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:07,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:07,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:07,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:43:08,005] {scheduler_job.py:146} INFO - Started process (PID=19957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:13,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:13,012] {logging_mixin.py:95} INFO - [2019-09-15 15:43:13,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:13,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:13,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:13,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:13,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:43:13,472] {scheduler_job.py:146} INFO - Started process (PID=19958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:18,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:18,478] {logging_mixin.py:95} INFO - [2019-09-15 15:43:18,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:18,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:18,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:18,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:18,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:43:18,935] {scheduler_job.py:146} INFO - Started process (PID=19960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:23,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:23,945] {logging_mixin.py:95} INFO - [2019-09-15 15:43:23,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:24,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:24,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:24,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:24,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:43:24,395] {scheduler_job.py:146} INFO - Started process (PID=19962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:29,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:29,403] {logging_mixin.py:95} INFO - [2019-09-15 15:43:29,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:29,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:29,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:29,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:29,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:43:29,847] {scheduler_job.py:146} INFO - Started process (PID=19963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:34,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:34,857] {logging_mixin.py:95} INFO - [2019-09-15 15:43:34,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:35,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:35,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:35,235] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:35,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:43:35,310] {scheduler_job.py:146} INFO - Started process (PID=19964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:40,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:40,320] {logging_mixin.py:95} INFO - [2019-09-15 15:43:40,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:40,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:40,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:40,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:40,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:43:40,766] {scheduler_job.py:146} INFO - Started process (PID=19966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:45,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:45,773] {logging_mixin.py:95} INFO - [2019-09-15 15:43:45,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:46,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:46,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:46,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:46,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:43:46,225] {scheduler_job.py:146} INFO - Started process (PID=19967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:51,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:51,233] {logging_mixin.py:95} INFO - [2019-09-15 15:43:51,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:51,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:51,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:51,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:51,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:43:51,685] {scheduler_job.py:146} INFO - Started process (PID=19969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:56,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:43:56,693] {logging_mixin.py:95} INFO - [2019-09-15 15:43:56,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:57,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:43:57,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:43:57,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:43:57,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:43:57,147] {scheduler_job.py:146} INFO - Started process (PID=19970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:02,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:02,154] {logging_mixin.py:95} INFO - [2019-09-15 15:44:02,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:02,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:02,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:02,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:02,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:44:02,608] {scheduler_job.py:146} INFO - Started process (PID=19971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:07,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:07,617] {logging_mixin.py:95} INFO - [2019-09-15 15:44:07,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:07,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:07,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:07,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:07,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:44:08,070] {scheduler_job.py:146} INFO - Started process (PID=19973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:13,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:13,077] {logging_mixin.py:95} INFO - [2019-09-15 15:44:13,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:13,417] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:13,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:13,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:13,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:44:13,531] {scheduler_job.py:146} INFO - Started process (PID=19974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:18,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:18,541] {logging_mixin.py:95} INFO - [2019-09-15 15:44:18,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:18,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:18,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:18,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:18,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:44:18,987] {scheduler_job.py:146} INFO - Started process (PID=19976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:23,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:23,993] {logging_mixin.py:95} INFO - [2019-09-15 15:44:23,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:24,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:24,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:24,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:24,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:44:24,440] {scheduler_job.py:146} INFO - Started process (PID=19978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:29,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:29,448] {logging_mixin.py:95} INFO - [2019-09-15 15:44:29,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:29,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:29,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:29,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:29,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:44:29,897] {scheduler_job.py:146} INFO - Started process (PID=19979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:34,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:34,909] {logging_mixin.py:95} INFO - [2019-09-15 15:44:34,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:35,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:35,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:35,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:35,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:44:35,353] {scheduler_job.py:146} INFO - Started process (PID=19980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:40,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:40,371] {logging_mixin.py:95} INFO - [2019-09-15 15:44:40,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:40,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:40,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:40,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:40,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:44:40,812] {scheduler_job.py:146} INFO - Started process (PID=19982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:45,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:45,819] {logging_mixin.py:95} INFO - [2019-09-15 15:44:45,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:46,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:46,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:46,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:46,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:44:46,273] {scheduler_job.py:146} INFO - Started process (PID=19983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:51,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:51,283] {logging_mixin.py:95} INFO - [2019-09-15 15:44:51,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:51,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:51,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:51,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:51,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:44:51,732] {scheduler_job.py:146} INFO - Started process (PID=19985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:56,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:44:56,739] {logging_mixin.py:95} INFO - [2019-09-15 15:44:56,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:57,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:44:57,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:44:57,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:44:57,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:44:57,190] {scheduler_job.py:146} INFO - Started process (PID=19986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:02,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:02,202] {logging_mixin.py:95} INFO - [2019-09-15 15:45:02,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:02,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:02,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:02,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:02,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:45:02,650] {scheduler_job.py:146} INFO - Started process (PID=19987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:07,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:07,659] {logging_mixin.py:95} INFO - [2019-09-15 15:45:07,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:07,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:08,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:08,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:08,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:45:08,109] {scheduler_job.py:146} INFO - Started process (PID=19989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:13,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:13,120] {logging_mixin.py:95} INFO - [2019-09-15 15:45:13,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:13,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:13,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:13,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:13,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:45:13,567] {scheduler_job.py:146} INFO - Started process (PID=19990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:18,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:18,577] {logging_mixin.py:95} INFO - [2019-09-15 15:45:18,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:18,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:18,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:18,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:18,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:45:19,037] {scheduler_job.py:146} INFO - Started process (PID=19993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:24,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:24,052] {logging_mixin.py:95} INFO - [2019-09-15 15:45:24,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:24,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:24,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:24,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:24,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:45:24,529] {scheduler_job.py:146} INFO - Started process (PID=19995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:29,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:29,544] {logging_mixin.py:95} INFO - [2019-09-15 15:45:29,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:29,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:29,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:29,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:29,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 15:45:30,025] {scheduler_job.py:146} INFO - Started process (PID=19996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:35,034] {logging_mixin.py:95} INFO - [2019-09-15 15:45:35,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:35,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:35,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:45:35,520] {scheduler_job.py:146} INFO - Started process (PID=19997) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:35,528] {logging_mixin.py:95} INFO - [2019-09-15 15:45:35,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,893] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:35,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:35,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.387 seconds
[2019-09-15 15:45:35,926] {scheduler_job.py:146} INFO - Started process (PID=19998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:35,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:35,930] {logging_mixin.py:95} INFO - [2019-09-15 15:45:35,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:36,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:36,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-15 15:45:36,335] {scheduler_job.py:146} INFO - Started process (PID=20000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:36,340] {logging_mixin.py:95} INFO - [2019-09-15 15:45:36,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:36,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:36,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-09-15 15:45:36,744] {scheduler_job.py:146} INFO - Started process (PID=20001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:36,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:36,750] {logging_mixin.py:95} INFO - [2019-09-15 15:45:36,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:37,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:37,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.364 seconds
[2019-09-15 15:45:37,154] {scheduler_job.py:146} INFO - Started process (PID=20002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:37,159] {logging_mixin.py:95} INFO - [2019-09-15 15:45:37,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:37,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:37,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.368 seconds
[2019-09-15 15:45:37,573] {scheduler_job.py:146} INFO - Started process (PID=20003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:37,579] {logging_mixin.py:95} INFO - [2019-09-15 15:45:37,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:37,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:37,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 15:45:37,974] {scheduler_job.py:146} INFO - Started process (PID=20004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:37,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:37,979] {logging_mixin.py:95} INFO - [2019-09-15 15:45:37,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:38,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:38,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-15 15:45:38,387] {scheduler_job.py:146} INFO - Started process (PID=20005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:38,392] {logging_mixin.py:95} INFO - [2019-09-15 15:45:38,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:38,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:38,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 15:45:38,795] {scheduler_job.py:146} INFO - Started process (PID=20006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:38,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:45:38,800] {logging_mixin.py:95} INFO - [2019-09-15 15:45:38,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:39,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:45:39,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:45:39,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:45:39,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 15:50:15,014] {scheduler_job.py:146} INFO - Started process (PID=20007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:15,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:15,023] {logging_mixin.py:95} INFO - [2019-09-15 15:50:15,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:15,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:15,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:15,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:15,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.842 seconds
[2019-09-15 15:50:15,934] {scheduler_job.py:146} INFO - Started process (PID=20013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:20,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:20,941] {logging_mixin.py:95} INFO - [2019-09-15 15:50:20,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:21,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:21,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:21,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:21,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:50:21,377] {scheduler_job.py:146} INFO - Started process (PID=20018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:26,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:26,388] {logging_mixin.py:95} INFO - [2019-09-15 15:50:26,388] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:26,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:26,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:26,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:26,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 15:50:26,831] {scheduler_job.py:146} INFO - Started process (PID=20020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:31,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:31,837] {logging_mixin.py:95} INFO - [2019-09-15 15:50:31,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:32,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:32,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:32,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:32,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:50:32,278] {scheduler_job.py:146} INFO - Started process (PID=20023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:37,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:37,288] {logging_mixin.py:95} INFO - [2019-09-15 15:50:37,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:37,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:37,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:37,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:37,666] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:50:37,731] {scheduler_job.py:146} INFO - Started process (PID=20024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:42,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:42,739] {logging_mixin.py:95} INFO - [2019-09-15 15:50:42,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:43,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:43,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:43,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:43,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:50:43,189] {scheduler_job.py:146} INFO - Started process (PID=20026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:48,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:48,198] {logging_mixin.py:95} INFO - [2019-09-15 15:50:48,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:48,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:48,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:48,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:48,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 15:50:48,646] {scheduler_job.py:146} INFO - Started process (PID=20027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:53,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:53,652] {logging_mixin.py:95} INFO - [2019-09-15 15:50:53,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:54,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:54,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:54,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:54,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 15:50:54,096] {scheduler_job.py:146} INFO - Started process (PID=20029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:59,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:50:59,103] {logging_mixin.py:95} INFO - [2019-09-15 15:50:59,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:59,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:50:59,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:50:59,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:50:59,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:50:59,556] {scheduler_job.py:146} INFO - Started process (PID=20031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:04,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:04,567] {logging_mixin.py:95} INFO - [2019-09-15 15:51:04,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:04,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:04,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:04,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:04,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:51:05,017] {scheduler_job.py:146} INFO - Started process (PID=20032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:10,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:10,029] {logging_mixin.py:95} INFO - [2019-09-15 15:51:10,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:10,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:10,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:10,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:10,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:51:10,479] {scheduler_job.py:146} INFO - Started process (PID=20033) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:15,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:15,500] {logging_mixin.py:95} INFO - [2019-09-15 15:51:15,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:15,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:15,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:15,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:15,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:51:15,938] {scheduler_job.py:146} INFO - Started process (PID=20035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:20,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:20,946] {logging_mixin.py:95} INFO - [2019-09-15 15:51:20,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:21,305] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:21,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:21,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:21,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 15:51:21,393] {scheduler_job.py:146} INFO - Started process (PID=20036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:26,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:26,401] {logging_mixin.py:95} INFO - [2019-09-15 15:51:26,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:26,737] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:26,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:26,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:26,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:51:26,848] {scheduler_job.py:146} INFO - Started process (PID=20038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:31,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:31,854] {logging_mixin.py:95} INFO - [2019-09-15 15:51:31,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:32,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:32,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:32,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:32,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:51:32,306] {scheduler_job.py:146} INFO - Started process (PID=20042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:37,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:37,314] {logging_mixin.py:95} INFO - [2019-09-15 15:51:37,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:37,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:37,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:37,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:37,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:51:37,767] {scheduler_job.py:146} INFO - Started process (PID=20043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:42,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:42,779] {logging_mixin.py:95} INFO - [2019-09-15 15:51:42,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:43,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:43,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:43,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:43,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:51:43,226] {scheduler_job.py:146} INFO - Started process (PID=20045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:48,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:48,236] {logging_mixin.py:95} INFO - [2019-09-15 15:51:48,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:48,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:48,599] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:48,608] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:48,613] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:51:48,683] {scheduler_job.py:146} INFO - Started process (PID=20046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:53,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:53,692] {logging_mixin.py:95} INFO - [2019-09-15 15:51:53,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:54,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:54,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:54,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:54,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:51:54,145] {scheduler_job.py:146} INFO - Started process (PID=20048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:59,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:51:59,154] {logging_mixin.py:95} INFO - [2019-09-15 15:51:59,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:59,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:51:59,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:51:59,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:51:59,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:51:59,607] {scheduler_job.py:146} INFO - Started process (PID=20050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:04,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:04,619] {logging_mixin.py:95} INFO - [2019-09-15 15:52:04,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:04,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:04,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:04,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:04,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:52:05,068] {scheduler_job.py:146} INFO - Started process (PID=20051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:10,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:10,078] {logging_mixin.py:95} INFO - [2019-09-15 15:52:10,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:10,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:10,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:10,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:10,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:52:10,531] {scheduler_job.py:146} INFO - Started process (PID=20052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:15,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:15,538] {logging_mixin.py:95} INFO - [2019-09-15 15:52:15,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:15,872] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:15,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:15,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:15,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:52:15,986] {scheduler_job.py:146} INFO - Started process (PID=20054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:20,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:20,998] {logging_mixin.py:95} INFO - [2019-09-15 15:52:20,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:21,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:21,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:21,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:21,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:52:21,447] {scheduler_job.py:146} INFO - Started process (PID=20055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:26,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:26,453] {logging_mixin.py:95} INFO - [2019-09-15 15:52:26,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:26,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:26,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:26,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:26,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:52:26,909] {scheduler_job.py:146} INFO - Started process (PID=20057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:31,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:31,926] {logging_mixin.py:95} INFO - [2019-09-15 15:52:31,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:32,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:32,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:32,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:32,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:52:32,366] {scheduler_job.py:146} INFO - Started process (PID=20058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:37,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:37,374] {logging_mixin.py:95} INFO - [2019-09-15 15:52:37,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:37,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:37,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:37,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:37,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 15:52:37,826] {scheduler_job.py:146} INFO - Started process (PID=20059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:42,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:42,836] {logging_mixin.py:95} INFO - [2019-09-15 15:52:42,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:43,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:43,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:43,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:43,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:52:43,287] {scheduler_job.py:146} INFO - Started process (PID=20061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:48,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:48,296] {logging_mixin.py:95} INFO - [2019-09-15 15:52:48,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:48,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:48,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:48,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:48,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:52:48,746] {scheduler_job.py:146} INFO - Started process (PID=20062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:53,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:53,754] {logging_mixin.py:95} INFO - [2019-09-15 15:52:53,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:54,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:54,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:54,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:54,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:52:54,206] {scheduler_job.py:146} INFO - Started process (PID=20064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:59,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:52:59,215] {logging_mixin.py:95} INFO - [2019-09-15 15:52:59,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:59,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:52:59,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:52:59,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:52:59,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:52:59,667] {scheduler_job.py:146} INFO - Started process (PID=20066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:04,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:04,677] {logging_mixin.py:95} INFO - [2019-09-15 15:53:04,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:05,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:05,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:05,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:05,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:53:05,130] {scheduler_job.py:146} INFO - Started process (PID=20067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:10,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:10,139] {logging_mixin.py:95} INFO - [2019-09-15 15:53:10,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:10,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:10,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:10,526] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:10,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 15:53:10,584] {scheduler_job.py:146} INFO - Started process (PID=20068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:15,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:15,595] {logging_mixin.py:95} INFO - [2019-09-15 15:53:15,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:15,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:15,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:15,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:15,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:53:16,035] {scheduler_job.py:146} INFO - Started process (PID=20070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:21,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:21,047] {logging_mixin.py:95} INFO - [2019-09-15 15:53:21,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:21,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:21,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:21,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:21,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:53:21,492] {scheduler_job.py:146} INFO - Started process (PID=20071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:26,500] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:26,501] {logging_mixin.py:95} INFO - [2019-09-15 15:53:26,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:26,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:26,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:26,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:26,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 15:53:26,952] {scheduler_job.py:146} INFO - Started process (PID=20073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:31,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:31,958] {logging_mixin.py:95} INFO - [2019-09-15 15:53:31,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:32,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:32,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:32,351] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:32,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:53:32,411] {scheduler_job.py:146} INFO - Started process (PID=20074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:37,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:37,417] {logging_mixin.py:95} INFO - [2019-09-15 15:53:37,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:37,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:37,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:37,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:37,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:53:37,864] {scheduler_job.py:146} INFO - Started process (PID=20075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:42,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:42,875] {logging_mixin.py:95} INFO - [2019-09-15 15:53:42,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:43,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:43,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:43,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:43,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 15:53:43,324] {scheduler_job.py:146} INFO - Started process (PID=20077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:48,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:48,330] {logging_mixin.py:95} INFO - [2019-09-15 15:53:48,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:48,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:48,710] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:48,719] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:48,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 15:53:48,773] {scheduler_job.py:146} INFO - Started process (PID=20078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:53,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:53,779] {logging_mixin.py:95} INFO - [2019-09-15 15:53:53,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:54,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:54,148] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:54,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:54,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:53:54,226] {scheduler_job.py:146} INFO - Started process (PID=20080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:59,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:53:59,236] {logging_mixin.py:95} INFO - [2019-09-15 15:53:59,235] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:59,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:53:59,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:53:59,606] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:53:59,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:53:59,677] {scheduler_job.py:146} INFO - Started process (PID=20082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:04,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:04,686] {logging_mixin.py:95} INFO - [2019-09-15 15:54:04,685] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:05,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:05,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:05,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:05,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 15:54:05,139] {scheduler_job.py:146} INFO - Started process (PID=20083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:10,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:10,149] {logging_mixin.py:95} INFO - [2019-09-15 15:54:10,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:10,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:10,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:10,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:10,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 15:54:10,595] {scheduler_job.py:146} INFO - Started process (PID=20084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:15,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:15,603] {logging_mixin.py:95} INFO - [2019-09-15 15:54:15,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:15,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:15,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:15,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:15,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 15:54:16,052] {scheduler_job.py:146} INFO - Started process (PID=20086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:21,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:21,058] {logging_mixin.py:95} INFO - [2019-09-15 15:54:21,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:21,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:21,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:21,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:21,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 15:54:21,502] {scheduler_job.py:146} INFO - Started process (PID=20087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:26,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:26,509] {logging_mixin.py:95} INFO - [2019-09-15 15:54:26,509] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:26,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:26,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:26,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:26,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:54:26,956] {scheduler_job.py:146} INFO - Started process (PID=20089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:31,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:31,965] {logging_mixin.py:95} INFO - [2019-09-15 15:54:31,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:32,305] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:32,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:32,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:32,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:54:32,407] {scheduler_job.py:146} INFO - Started process (PID=20090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:37,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:37,418] {logging_mixin.py:95} INFO - [2019-09-15 15:54:37,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:37,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:37,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:37,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:37,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:54:37,869] {scheduler_job.py:146} INFO - Started process (PID=20091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:42,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:42,877] {logging_mixin.py:95} INFO - [2019-09-15 15:54:42,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:43,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:43,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:43,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:43,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:54:43,332] {scheduler_job.py:146} INFO - Started process (PID=20093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:48,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:48,340] {logging_mixin.py:95} INFO - [2019-09-15 15:54:48,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:48,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:48,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:48,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:48,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:54:48,796] {scheduler_job.py:146} INFO - Started process (PID=20094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:53,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:53,807] {logging_mixin.py:95} INFO - [2019-09-15 15:54:53,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:54,149] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:54,172] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:54,182] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:54,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:54:54,256] {scheduler_job.py:146} INFO - Started process (PID=20096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:59,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:54:59,266] {logging_mixin.py:95} INFO - [2019-09-15 15:54:59,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:59,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:54:59,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:54:59,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:54:59,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 15:54:59,717] {scheduler_job.py:146} INFO - Started process (PID=20098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:04,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:04,723] {logging_mixin.py:95} INFO - [2019-09-15 15:55:04,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:05,057] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:05,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:05,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:05,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 15:55:05,174] {scheduler_job.py:146} INFO - Started process (PID=20099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:10,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:10,186] {logging_mixin.py:95} INFO - [2019-09-15 15:55:10,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:10,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:10,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:10,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:10,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 15:55:10,630] {scheduler_job.py:146} INFO - Started process (PID=20100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:15,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:15,646] {logging_mixin.py:95} INFO - [2019-09-15 15:55:15,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:15,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:16,005] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:16,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:16,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:55:16,088] {scheduler_job.py:146} INFO - Started process (PID=20102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:21,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:21,097] {logging_mixin.py:95} INFO - [2019-09-15 15:55:21,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:21,440] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:21,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:21,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:21,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 15:55:21,545] {scheduler_job.py:146} INFO - Started process (PID=20103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:26,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:26,556] {logging_mixin.py:95} INFO - [2019-09-15 15:55:26,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:26,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:26,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:26,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:26,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:55:27,008] {scheduler_job.py:146} INFO - Started process (PID=20105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:32,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:32,018] {logging_mixin.py:95} INFO - [2019-09-15 15:55:32,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:32,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:32,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:32,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:32,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:55:32,467] {scheduler_job.py:146} INFO - Started process (PID=20106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:37,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:37,477] {logging_mixin.py:95} INFO - [2019-09-15 15:55:37,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:37,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:37,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:37,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:37,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:55:37,929] {scheduler_job.py:146} INFO - Started process (PID=20107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:42,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:42,940] {logging_mixin.py:95} INFO - [2019-09-15 15:55:42,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:43,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:43,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:43,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:43,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:55:43,385] {scheduler_job.py:146} INFO - Started process (PID=20109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:48,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:48,397] {logging_mixin.py:95} INFO - [2019-09-15 15:55:48,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:48,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:48,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:48,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:48,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:55:48,846] {scheduler_job.py:146} INFO - Started process (PID=20110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:53,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:53,852] {logging_mixin.py:95} INFO - [2019-09-15 15:55:53,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:54,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:54,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:54,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:54,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:55:54,307] {scheduler_job.py:146} INFO - Started process (PID=20112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:59,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:55:59,318] {logging_mixin.py:95} INFO - [2019-09-15 15:55:59,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:59,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:55:59,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:55:59,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:55:59,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:55:59,768] {scheduler_job.py:146} INFO - Started process (PID=20114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:04,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:04,779] {logging_mixin.py:95} INFO - [2019-09-15 15:56:04,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:05,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:05,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:05,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:05,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:56:05,229] {scheduler_job.py:146} INFO - Started process (PID=20115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:10,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:10,238] {logging_mixin.py:95} INFO - [2019-09-15 15:56:10,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:10,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:10,599] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:10,608] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:10,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:56:10,688] {scheduler_job.py:146} INFO - Started process (PID=20116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:15,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:15,710] {logging_mixin.py:95} INFO - [2019-09-15 15:56:15,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:16,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:16,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:16,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:16,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:56:16,145] {scheduler_job.py:146} INFO - Started process (PID=20118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:21,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:21,150] {logging_mixin.py:95} INFO - [2019-09-15 15:56:21,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:21,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:21,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:21,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:21,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 15:56:21,599] {scheduler_job.py:146} INFO - Started process (PID=20119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:26,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:26,610] {logging_mixin.py:95} INFO - [2019-09-15 15:56:26,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:26,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:26,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:26,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:26,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:56:27,060] {scheduler_job.py:146} INFO - Started process (PID=20121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:32,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:32,067] {logging_mixin.py:95} INFO - [2019-09-15 15:56:32,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:32,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:32,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:32,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:32,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:56:32,523] {scheduler_job.py:146} INFO - Started process (PID=20122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:37,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:37,546] {logging_mixin.py:95} INFO - [2019-09-15 15:56:37,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:37,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:37,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:37,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:37,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 15:56:37,972] {scheduler_job.py:146} INFO - Started process (PID=20123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:42,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:42,984] {logging_mixin.py:95} INFO - [2019-09-15 15:56:42,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:43,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:43,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:43,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:43,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 15:56:43,424] {scheduler_job.py:146} INFO - Started process (PID=20125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:48,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:48,434] {logging_mixin.py:95} INFO - [2019-09-15 15:56:48,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:48,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:48,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:48,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:48,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:56:48,873] {scheduler_job.py:146} INFO - Started process (PID=20126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:53,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:53,881] {logging_mixin.py:95} INFO - [2019-09-15 15:56:53,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:54,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:54,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:54,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:54,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:56:54,336] {scheduler_job.py:146} INFO - Started process (PID=20128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:59,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:56:59,347] {logging_mixin.py:95} INFO - [2019-09-15 15:56:59,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:59,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:56:59,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:56:59,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:56:59,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:56:59,797] {scheduler_job.py:146} INFO - Started process (PID=20130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:04,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:04,807] {logging_mixin.py:95} INFO - [2019-09-15 15:57:04,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:05,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:05,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:05,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:05,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:57:05,256] {scheduler_job.py:146} INFO - Started process (PID=20131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:10,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:10,264] {logging_mixin.py:95} INFO - [2019-09-15 15:57:10,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:10,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:10,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:10,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:10,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:57:10,715] {scheduler_job.py:146} INFO - Started process (PID=20132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:15,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:15,733] {logging_mixin.py:95} INFO - [2019-09-15 15:57:15,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:16,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:16,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:16,105] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:16,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:57:16,176] {scheduler_job.py:146} INFO - Started process (PID=20134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:21,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:21,183] {logging_mixin.py:95} INFO - [2019-09-15 15:57:21,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:21,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:21,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:21,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:21,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 15:57:21,642] {scheduler_job.py:146} INFO - Started process (PID=20135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:26,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:26,650] {logging_mixin.py:95} INFO - [2019-09-15 15:57:26,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:26,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:27,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:27,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:27,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:57:27,103] {scheduler_job.py:146} INFO - Started process (PID=20137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:32,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:32,124] {logging_mixin.py:95} INFO - [2019-09-15 15:57:32,123] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:32,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:32,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:32,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:32,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 15:57:32,561] {scheduler_job.py:146} INFO - Started process (PID=20138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:37,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:37,572] {logging_mixin.py:95} INFO - [2019-09-15 15:57:37,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:37,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:37,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:37,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:37,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:57:38,021] {scheduler_job.py:146} INFO - Started process (PID=20139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:43,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:43,030] {logging_mixin.py:95} INFO - [2019-09-15 15:57:43,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:43,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:43,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:43,404] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:43,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:57:43,482] {scheduler_job.py:146} INFO - Started process (PID=20141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:48,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:48,494] {logging_mixin.py:95} INFO - [2019-09-15 15:57:48,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:48,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:48,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:48,864] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:48,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:57:48,943] {scheduler_job.py:146} INFO - Started process (PID=20142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:53,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:53,952] {logging_mixin.py:95} INFO - [2019-09-15 15:57:53,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:54,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:54,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:54,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:54,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:57:54,403] {scheduler_job.py:146} INFO - Started process (PID=20144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:59,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:57:59,411] {logging_mixin.py:95} INFO - [2019-09-15 15:57:59,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:59,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:57:59,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:57:59,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:57:59,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 15:57:59,861] {scheduler_job.py:146} INFO - Started process (PID=20146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:04,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:04,867] {logging_mixin.py:95} INFO - [2019-09-15 15:58:04,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:05,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:05,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:05,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:05,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:58:05,320] {scheduler_job.py:146} INFO - Started process (PID=20147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:10,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:10,332] {logging_mixin.py:95} INFO - [2019-09-15 15:58:10,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:10,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:10,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:10,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:10,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:58:10,777] {scheduler_job.py:146} INFO - Started process (PID=20149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:15,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:15,785] {logging_mixin.py:95} INFO - [2019-09-15 15:58:15,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:16,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:16,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:16,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:16,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 15:58:16,237] {scheduler_job.py:146} INFO - Started process (PID=20151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:21,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:21,243] {logging_mixin.py:95} INFO - [2019-09-15 15:58:21,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:21,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:21,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:21,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:21,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:58:21,693] {scheduler_job.py:146} INFO - Started process (PID=20152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:26,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:26,700] {logging_mixin.py:95} INFO - [2019-09-15 15:58:26,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:27,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:27,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:27,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:27,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 15:58:27,154] {scheduler_job.py:146} INFO - Started process (PID=20154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:32,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:32,162] {logging_mixin.py:95} INFO - [2019-09-15 15:58:32,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:32,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:32,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:32,530] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:32,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 15:58:32,611] {scheduler_job.py:146} INFO - Started process (PID=20155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:37,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:37,622] {logging_mixin.py:95} INFO - [2019-09-15 15:58:37,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:37,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:37,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:37,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:37,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 15:58:38,066] {scheduler_job.py:146} INFO - Started process (PID=20156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:43,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:43,074] {logging_mixin.py:95} INFO - [2019-09-15 15:58:43,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:43,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:43,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:43,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:43,453] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:58:43,526] {scheduler_job.py:146} INFO - Started process (PID=20158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:48,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:48,532] {logging_mixin.py:95} INFO - [2019-09-15 15:58:48,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:48,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:48,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:48,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:48,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 15:58:48,989] {scheduler_job.py:146} INFO - Started process (PID=20159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:53,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:53,997] {logging_mixin.py:95} INFO - [2019-09-15 15:58:53,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:54,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:54,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:54,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:54,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 15:58:54,450] {scheduler_job.py:146} INFO - Started process (PID=20161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:59,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:58:59,460] {logging_mixin.py:95} INFO - [2019-09-15 15:58:59,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:59,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:58:59,823] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:58:59,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:58:59,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 15:58:59,912] {scheduler_job.py:146} INFO - Started process (PID=20163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:04,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:04,923] {logging_mixin.py:95} INFO - [2019-09-15 15:59:04,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:05,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:05,290] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:05,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:05,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 15:59:05,366] {scheduler_job.py:146} INFO - Started process (PID=20164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:10,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:10,375] {logging_mixin.py:95} INFO - [2019-09-15 15:59:10,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:10,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:10,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:10,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:10,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 15:59:10,821] {scheduler_job.py:146} INFO - Started process (PID=20165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:15,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:15,837] {logging_mixin.py:95} INFO - [2019-09-15 15:59:15,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:16,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:16,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:16,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:16,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 15:59:16,278] {scheduler_job.py:146} INFO - Started process (PID=20167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:21,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:21,285] {logging_mixin.py:95} INFO - [2019-09-15 15:59:21,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:21,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:21,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:21,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:21,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 15:59:21,739] {scheduler_job.py:146} INFO - Started process (PID=20168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:26,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:26,746] {logging_mixin.py:95} INFO - [2019-09-15 15:59:26,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:27,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:27,115] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:27,124] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:27,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 15:59:27,200] {scheduler_job.py:146} INFO - Started process (PID=20170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:32,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:32,207] {logging_mixin.py:95} INFO - [2019-09-15 15:59:32,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:32,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:32,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:32,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:32,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 15:59:32,662] {scheduler_job.py:146} INFO - Started process (PID=20172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:37,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:37,674] {logging_mixin.py:95} INFO - [2019-09-15 15:59:37,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:38,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:38,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:38,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:38,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 15:59:38,159] {scheduler_job.py:146} INFO - Started process (PID=20173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:43,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:43,174] {logging_mixin.py:95} INFO - [2019-09-15 15:59:43,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:43,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:43,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:43,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:43,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 15:59:43,647] {scheduler_job.py:146} INFO - Started process (PID=20175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:48,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:48,663] {logging_mixin.py:95} INFO - [2019-09-15 15:59:48,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:48,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:49,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:49,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 15:59:49,143] {scheduler_job.py:146} INFO - Started process (PID=20176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:49,149] {logging_mixin.py:95} INFO - [2019-09-15 15:59:49,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:49,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:49,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-09-15 15:59:49,551] {scheduler_job.py:146} INFO - Started process (PID=20177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:49,556] {logging_mixin.py:95} INFO - [2019-09-15 15:59:49,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:49,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:49,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-15 15:59:49,959] {scheduler_job.py:146} INFO - Started process (PID=20178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:49,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:49,964] {logging_mixin.py:95} INFO - [2019-09-15 15:59:49,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:50,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:50,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-15 15:59:50,371] {scheduler_job.py:146} INFO - Started process (PID=20179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:50,376] {logging_mixin.py:95} INFO - [2019-09-15 15:59:50,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:50,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:50,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 15:59:50,784] {scheduler_job.py:146} INFO - Started process (PID=20181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:50,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:50,790] {logging_mixin.py:95} INFO - [2019-09-15 15:59:50,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:51,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:51,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-15 15:59:51,192] {scheduler_job.py:146} INFO - Started process (PID=20182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:51,197] {logging_mixin.py:95} INFO - [2019-09-15 15:59:51,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:51,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:51,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-15 15:59:51,602] {scheduler_job.py:146} INFO - Started process (PID=20183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:51,607] {logging_mixin.py:95} INFO - [2019-09-15 15:59:51,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:51,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:51,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:51,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 15:59:52,012] {scheduler_job.py:146} INFO - Started process (PID=20184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:52,017] {logging_mixin.py:95} INFO - [2019-09-15 15:59:52,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:52,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:52,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.392 seconds
[2019-09-15 15:59:52,422] {scheduler_job.py:146} INFO - Started process (PID=20185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:52,426] {logging_mixin.py:95} INFO - [2019-09-15 15:59:52,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:52,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:52,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 15:59:52,833] {scheduler_job.py:146} INFO - Started process (PID=20186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:52,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:52,838] {logging_mixin.py:95} INFO - [2019-09-15 15:59:52,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:53,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:53,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.372 seconds
[2019-09-15 15:59:53,242] {scheduler_job.py:146} INFO - Started process (PID=20187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:53,247] {logging_mixin.py:95} INFO - [2019-09-15 15:59:53,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 15:59:53,606] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 15:59:53,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.369 seconds
[2019-09-15 15:59:53,651] {scheduler_job.py:146} INFO - Started process (PID=20188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 15:59:53,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 15:59:53,657] {logging_mixin.py:95} INFO - [2019-09-15 15:59:53,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:22,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:22,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:22,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:22,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 3448.777 seconds
[2019-09-15 16:57:22,530] {scheduler_job.py:146} INFO - Started process (PID=20192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:22,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:22,535] {logging_mixin.py:95} INFO - [2019-09-15 16:57:22,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:23,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:23,142] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:23,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:23,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.642 seconds
[2019-09-15 16:57:23,240] {scheduler_job.py:146} INFO - Started process (PID=20196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:28,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:28,247] {logging_mixin.py:95} INFO - [2019-09-15 16:57:28,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:28,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:28,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:28,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:28,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 16:57:28,694] {scheduler_job.py:146} INFO - Started process (PID=20203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:33,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:33,702] {logging_mixin.py:95} INFO - [2019-09-15 16:57:33,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:34,082] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:34,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:34,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:34,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 16:57:34,152] {scheduler_job.py:146} INFO - Started process (PID=20206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:39,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:39,157] {logging_mixin.py:95} INFO - [2019-09-15 16:57:39,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:39,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:39,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:39,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:39,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 16:57:39,611] {scheduler_job.py:146} INFO - Started process (PID=20207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:44,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:44,617] {logging_mixin.py:95} INFO - [2019-09-15 16:57:44,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:44,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:44,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:44,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:44,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-15 16:57:45,065] {scheduler_job.py:146} INFO - Started process (PID=20209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:50,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:50,073] {logging_mixin.py:95} INFO - [2019-09-15 16:57:50,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:50,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:50,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:50,435] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:50,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 16:57:50,522] {scheduler_job.py:146} INFO - Started process (PID=20210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:55,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:57:55,531] {logging_mixin.py:95} INFO - [2019-09-15 16:57:55,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:55,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:57:55,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:57:55,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:57:55,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 16:57:55,975] {scheduler_job.py:146} INFO - Started process (PID=20212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:00,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:00,983] {logging_mixin.py:95} INFO - [2019-09-15 16:58:00,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:01,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:01,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:01,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:01,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 16:58:01,425] {scheduler_job.py:146} INFO - Started process (PID=20213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:06,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:06,433] {logging_mixin.py:95} INFO - [2019-09-15 16:58:06,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:06,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:06,792] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:06,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:06,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 16:58:06,887] {scheduler_job.py:146} INFO - Started process (PID=20214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:11,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:11,895] {logging_mixin.py:95} INFO - [2019-09-15 16:58:11,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:12,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:12,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:12,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:12,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 16:58:12,348] {scheduler_job.py:146} INFO - Started process (PID=20216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:17,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:17,357] {logging_mixin.py:95} INFO - [2019-09-15 16:58:17,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:17,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:17,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:17,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:17,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 16:58:17,807] {scheduler_job.py:146} INFO - Started process (PID=20217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:22,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:22,816] {logging_mixin.py:95} INFO - [2019-09-15 16:58:22,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:23,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:23,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:23,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:23,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 16:58:23,265] {scheduler_job.py:146} INFO - Started process (PID=20219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:28,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:28,274] {logging_mixin.py:95} INFO - [2019-09-15 16:58:28,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:28,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:28,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:28,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:28,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 16:58:28,717] {scheduler_job.py:146} INFO - Started process (PID=20221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:33,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:33,724] {logging_mixin.py:95} INFO - [2019-09-15 16:58:33,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:34,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:34,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:34,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:34,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 16:58:34,163] {scheduler_job.py:146} INFO - Started process (PID=20222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:39,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:39,171] {logging_mixin.py:95} INFO - [2019-09-15 16:58:39,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:39,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:39,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:39,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:39,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 16:58:39,619] {scheduler_job.py:146} INFO - Started process (PID=20223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:44,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:44,629] {logging_mixin.py:95} INFO - [2019-09-15 16:58:44,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:44,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:44,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:45,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:45,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 16:58:45,076] {scheduler_job.py:146} INFO - Started process (PID=20225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:50,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:50,088] {logging_mixin.py:95} INFO - [2019-09-15 16:58:50,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:50,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:50,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:50,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:50,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 16:58:50,532] {scheduler_job.py:146} INFO - Started process (PID=20226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:55,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:58:55,543] {logging_mixin.py:95} INFO - [2019-09-15 16:58:55,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:55,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:58:55,906] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:58:55,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:58:55,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 16:58:55,994] {scheduler_job.py:146} INFO - Started process (PID=20228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:01,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:01,004] {logging_mixin.py:95} INFO - [2019-09-15 16:59:01,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:01,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:01,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:01,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:01,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 16:59:01,458] {scheduler_job.py:146} INFO - Started process (PID=20229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:06,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:06,470] {logging_mixin.py:95} INFO - [2019-09-15 16:59:06,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:06,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:06,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:06,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:06,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 16:59:06,919] {scheduler_job.py:146} INFO - Started process (PID=20230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:11,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:11,928] {logging_mixin.py:95} INFO - [2019-09-15 16:59:11,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:12,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:12,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:12,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:12,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 16:59:12,379] {scheduler_job.py:146} INFO - Started process (PID=20232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:17,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:17,390] {logging_mixin.py:95} INFO - [2019-09-15 16:59:17,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:17,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:17,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:17,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:17,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 16:59:17,839] {scheduler_job.py:146} INFO - Started process (PID=20233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:22,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:22,849] {logging_mixin.py:95} INFO - [2019-09-15 16:59:22,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:23,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:23,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:23,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:23,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 16:59:23,302] {scheduler_job.py:146} INFO - Started process (PID=20235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:28,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:28,312] {logging_mixin.py:95} INFO - [2019-09-15 16:59:28,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:28,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:28,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:28,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:28,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 16:59:28,761] {scheduler_job.py:146} INFO - Started process (PID=20237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:33,766] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:33,767] {logging_mixin.py:95} INFO - [2019-09-15 16:59:33,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:34,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:34,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:34,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:34,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 16:59:34,224] {scheduler_job.py:146} INFO - Started process (PID=20238) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:39,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:39,232] {logging_mixin.py:95} INFO - [2019-09-15 16:59:39,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:39,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:39,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:39,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:39,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 16:59:39,687] {scheduler_job.py:146} INFO - Started process (PID=20239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:44,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:44,706] {logging_mixin.py:95} INFO - [2019-09-15 16:59:44,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:45,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:45,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:45,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:45,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 16:59:45,150] {scheduler_job.py:146} INFO - Started process (PID=20241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:50,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:50,162] {logging_mixin.py:95} INFO - [2019-09-15 16:59:50,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:50,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:50,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:50,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:50,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 16:59:50,608] {scheduler_job.py:146} INFO - Started process (PID=20242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:55,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 16:59:55,619] {logging_mixin.py:95} INFO - [2019-09-15 16:59:55,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:55,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 16:59:55,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 16:59:55,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 16:59:55,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 16:59:56,070] {scheduler_job.py:146} INFO - Started process (PID=20244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:01,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:01,076] {logging_mixin.py:95} INFO - [2019-09-15 17:00:01,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:01,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:01,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:01,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:01,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.359 seconds
[2019-09-15 17:00:01,522] {scheduler_job.py:146} INFO - Started process (PID=20245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:06,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:06,531] {logging_mixin.py:95} INFO - [2019-09-15 17:00:06,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:06,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:06,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:06,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:06,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-15 17:00:06,979] {scheduler_job.py:146} INFO - Started process (PID=20246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:11,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:11,987] {logging_mixin.py:95} INFO - [2019-09-15 17:00:11,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:12,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:12,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:12,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:12,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.353 seconds
[2019-09-15 17:00:12,442] {scheduler_job.py:146} INFO - Started process (PID=20248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:17,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:17,449] {logging_mixin.py:95} INFO - [2019-09-15 17:00:17,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:17,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:17,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:17,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:17,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.351 seconds
[2019-09-15 17:00:17,905] {scheduler_job.py:146} INFO - Started process (PID=20249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:22,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:22,914] {logging_mixin.py:95} INFO - [2019-09-15 17:00:22,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:23,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:23,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:23,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:23,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:00:23,360] {scheduler_job.py:146} INFO - Started process (PID=20251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:28,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:28,370] {logging_mixin.py:95} INFO - [2019-09-15 17:00:28,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:28,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:28,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:28,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:28,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:00:28,816] {scheduler_job.py:146} INFO - Started process (PID=20253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:33,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:33,822] {logging_mixin.py:95} INFO - [2019-09-15 17:00:33,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:34,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:34,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:34,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:34,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:00:34,268] {scheduler_job.py:146} INFO - Started process (PID=20254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:39,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:39,276] {logging_mixin.py:95} INFO - [2019-09-15 17:00:39,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:39,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:39,638] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:39,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:39,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:00:39,724] {scheduler_job.py:146} INFO - Started process (PID=20255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:44,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:44,731] {logging_mixin.py:95} INFO - [2019-09-15 17:00:44,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:45,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:45,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:45,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:45,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 17:00:45,180] {scheduler_job.py:146} INFO - Started process (PID=20257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:50,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:50,190] {logging_mixin.py:95} INFO - [2019-09-15 17:00:50,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:50,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:50,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:50,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:50,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-09-15 17:00:50,631] {scheduler_job.py:146} INFO - Started process (PID=20258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:55,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:00:55,637] {logging_mixin.py:95} INFO - [2019-09-15 17:00:55,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:55,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:00:55,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:00:56,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:00:56,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 17:00:56,095] {scheduler_job.py:146} INFO - Started process (PID=20260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:01,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:01,104] {logging_mixin.py:95} INFO - [2019-09-15 17:01:01,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:01,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:01,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:01,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:01,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:01:01,555] {scheduler_job.py:146} INFO - Started process (PID=20261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:06,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:06,561] {logging_mixin.py:95} INFO - [2019-09-15 17:01:06,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:06,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:06,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:06,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:06,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:01:07,008] {scheduler_job.py:146} INFO - Started process (PID=20262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:12,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:12,015] {logging_mixin.py:95} INFO - [2019-09-15 17:01:12,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:12,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:12,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:12,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:12,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:01:12,464] {scheduler_job.py:146} INFO - Started process (PID=20264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:17,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:17,473] {logging_mixin.py:95} INFO - [2019-09-15 17:01:17,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:17,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:17,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:17,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:17,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:01:17,920] {scheduler_job.py:146} INFO - Started process (PID=20265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:22,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:22,928] {logging_mixin.py:95} INFO - [2019-09-15 17:01:22,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:23,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:23,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:23,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:23,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:01:23,373] {scheduler_job.py:146} INFO - Started process (PID=20267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:28,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:28,380] {logging_mixin.py:95} INFO - [2019-09-15 17:01:28,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:28,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:28,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:28,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:28,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:01:28,826] {scheduler_job.py:146} INFO - Started process (PID=20269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:33,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:33,837] {logging_mixin.py:95} INFO - [2019-09-15 17:01:33,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:34,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:34,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:34,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:34,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 17:01:34,279] {scheduler_job.py:146} INFO - Started process (PID=20270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:39,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:39,287] {logging_mixin.py:95} INFO - [2019-09-15 17:01:39,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:39,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:39,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:39,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:39,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 17:01:39,738] {scheduler_job.py:146} INFO - Started process (PID=20271) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:44,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:44,748] {logging_mixin.py:95} INFO - [2019-09-15 17:01:44,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:45,107] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:45,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:45,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:45,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:01:45,200] {scheduler_job.py:146} INFO - Started process (PID=20273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:50,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:50,214] {logging_mixin.py:95} INFO - [2019-09-15 17:01:50,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:50,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:50,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:50,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:50,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 17:01:50,760] {scheduler_job.py:146} INFO - Started process (PID=20274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:55,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:01:55,772] {logging_mixin.py:95} INFO - [2019-09-15 17:01:55,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:56,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:01:56,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:01:56,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:01:56,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 17:01:56,210] {scheduler_job.py:146} INFO - Started process (PID=20276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:01,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:01,219] {logging_mixin.py:95} INFO - [2019-09-15 17:02:01,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:01,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:01,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:01,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:01,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:02:01,671] {scheduler_job.py:146} INFO - Started process (PID=20277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:06,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:06,677] {logging_mixin.py:95} INFO - [2019-09-15 17:02:06,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:07,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:07,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:07,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:07,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:02:07,133] {scheduler_job.py:146} INFO - Started process (PID=20278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:12,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:12,144] {logging_mixin.py:95} INFO - [2019-09-15 17:02:12,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:12,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:12,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:12,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:12,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:02:12,588] {scheduler_job.py:146} INFO - Started process (PID=20280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:17,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:17,599] {logging_mixin.py:95} INFO - [2019-09-15 17:02:17,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:17,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:17,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:17,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:17,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:02:18,047] {scheduler_job.py:146} INFO - Started process (PID=20281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:23,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:23,059] {logging_mixin.py:95} INFO - [2019-09-15 17:02:23,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:23,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:23,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:23,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:23,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:02:23,514] {scheduler_job.py:146} INFO - Started process (PID=20283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:28,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:28,522] {logging_mixin.py:95} INFO - [2019-09-15 17:02:28,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:28,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:28,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:28,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:28,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:02:28,972] {scheduler_job.py:146} INFO - Started process (PID=20285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:33,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:33,978] {logging_mixin.py:95} INFO - [2019-09-15 17:02:33,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:34,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:34,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:34,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:34,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:02:34,431] {scheduler_job.py:146} INFO - Started process (PID=20286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:39,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:39,438] {logging_mixin.py:95} INFO - [2019-09-15 17:02:39,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:39,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:39,796] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:39,805] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:39,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 17:02:39,889] {scheduler_job.py:146} INFO - Started process (PID=20287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:44,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:44,908] {logging_mixin.py:95} INFO - [2019-09-15 17:02:44,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:45,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:45,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:45,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:45,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:02:45,354] {scheduler_job.py:146} INFO - Started process (PID=20289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:50,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:50,365] {logging_mixin.py:95} INFO - [2019-09-15 17:02:50,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:50,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:50,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:50,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:50,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:02:50,814] {scheduler_job.py:146} INFO - Started process (PID=20290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:55,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:02:55,826] {logging_mixin.py:95} INFO - [2019-09-15 17:02:55,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:56,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:02:56,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:02:56,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:02:56,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 17:02:56,277] {scheduler_job.py:146} INFO - Started process (PID=20292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:01,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:01,285] {logging_mixin.py:95} INFO - [2019-09-15 17:03:01,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:01,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:01,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:01,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:01,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 17:03:01,736] {scheduler_job.py:146} INFO - Started process (PID=20293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:06,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:06,745] {logging_mixin.py:95} INFO - [2019-09-15 17:03:06,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:07,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:07,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:07,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:07,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:03:07,196] {scheduler_job.py:146} INFO - Started process (PID=20294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:12,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:12,205] {logging_mixin.py:95} INFO - [2019-09-15 17:03:12,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:12,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:12,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:12,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:12,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 17:03:12,653] {scheduler_job.py:146} INFO - Started process (PID=20296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:17,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:17,662] {logging_mixin.py:95} INFO - [2019-09-15 17:03:17,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:18,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:18,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:18,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:18,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:03:18,106] {scheduler_job.py:146} INFO - Started process (PID=20297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:23,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:23,119] {logging_mixin.py:95} INFO - [2019-09-15 17:03:23,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:23,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:23,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:23,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:23,498] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:03:23,564] {scheduler_job.py:146} INFO - Started process (PID=20299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:28,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:28,576] {logging_mixin.py:95} INFO - [2019-09-15 17:03:28,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:28,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:28,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:28,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:28,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:03:29,010] {scheduler_job.py:146} INFO - Started process (PID=20301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:34,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:34,021] {logging_mixin.py:95} INFO - [2019-09-15 17:03:34,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:34,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:34,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:34,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:34,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:03:34,468] {scheduler_job.py:146} INFO - Started process (PID=20302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:39,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:39,478] {logging_mixin.py:95} INFO - [2019-09-15 17:03:39,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:39,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:39,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:39,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:39,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:03:39,920] {scheduler_job.py:146} INFO - Started process (PID=20303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:44,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:44,933] {logging_mixin.py:95} INFO - [2019-09-15 17:03:44,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:45,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:45,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:45,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:45,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:03:45,379] {scheduler_job.py:146} INFO - Started process (PID=20305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:50,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:50,388] {logging_mixin.py:95} INFO - [2019-09-15 17:03:50,388] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:50,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:50,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:50,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:50,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:03:50,829] {scheduler_job.py:146} INFO - Started process (PID=20306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:55,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:03:55,838] {logging_mixin.py:95} INFO - [2019-09-15 17:03:55,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:56,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:03:56,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:03:56,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:03:56,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:03:56,273] {scheduler_job.py:146} INFO - Started process (PID=20308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:01,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:01,286] {logging_mixin.py:95} INFO - [2019-09-15 17:04:01,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:01,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:01,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:01,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:01,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:04:01,730] {scheduler_job.py:146} INFO - Started process (PID=20309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:06,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:06,738] {logging_mixin.py:95} INFO - [2019-09-15 17:04:06,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:07,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:07,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:07,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:07,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:04:07,176] {scheduler_job.py:146} INFO - Started process (PID=20310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:12,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:12,184] {logging_mixin.py:95} INFO - [2019-09-15 17:04:12,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:12,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:12,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:12,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:12,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:04:12,628] {scheduler_job.py:146} INFO - Started process (PID=20312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:17,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:17,638] {logging_mixin.py:95} INFO - [2019-09-15 17:04:17,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:17,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:18,015] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:18,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:18,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:04:18,078] {scheduler_job.py:146} INFO - Started process (PID=20313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:23,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:23,086] {logging_mixin.py:95} INFO - [2019-09-15 17:04:23,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:23,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:23,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:23,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:23,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 17:04:23,529] {scheduler_job.py:146} INFO - Started process (PID=20318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:28,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:28,541] {logging_mixin.py:95} INFO - [2019-09-15 17:04:28,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:28,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:28,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:28,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:28,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:04:28,979] {scheduler_job.py:146} INFO - Started process (PID=20320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:33,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:33,991] {logging_mixin.py:95} INFO - [2019-09-15 17:04:33,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:34,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:34,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:34,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:34,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:04:34,425] {scheduler_job.py:146} INFO - Started process (PID=20321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:39,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:39,434] {logging_mixin.py:95} INFO - [2019-09-15 17:04:39,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:39,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:39,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:39,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:39,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:04:39,870] {scheduler_job.py:146} INFO - Started process (PID=20322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:44,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:44,890] {logging_mixin.py:95} INFO - [2019-09-15 17:04:44,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:45,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:45,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:45,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:45,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:04:45,330] {scheduler_job.py:146} INFO - Started process (PID=20324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:50,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:50,342] {logging_mixin.py:95} INFO - [2019-09-15 17:04:50,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:50,681] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:50,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:50,713] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:50,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:04:50,785] {scheduler_job.py:146} INFO - Started process (PID=20325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:55,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:04:55,794] {logging_mixin.py:95} INFO - [2019-09-15 17:04:55,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:56,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:04:56,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:04:56,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:04:56,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 17:04:56,243] {scheduler_job.py:146} INFO - Started process (PID=20327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:01,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:01,267] {logging_mixin.py:95} INFO - [2019-09-15 17:05:01,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:01,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:01,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:01,635] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:01,640] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:05:01,702] {scheduler_job.py:146} INFO - Started process (PID=20328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:06,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:06,714] {logging_mixin.py:95} INFO - [2019-09-15 17:05:06,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:07,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:07,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:07,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:07,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:05:07,165] {scheduler_job.py:146} INFO - Started process (PID=20329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:12,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:12,177] {logging_mixin.py:95} INFO - [2019-09-15 17:05:12,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:12,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:12,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:12,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:12,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:05:12,629] {scheduler_job.py:146} INFO - Started process (PID=20331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:17,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:17,636] {logging_mixin.py:95} INFO - [2019-09-15 17:05:17,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:17,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:17,992] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:18,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:18,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 17:05:18,089] {scheduler_job.py:146} INFO - Started process (PID=20332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:23,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:23,102] {logging_mixin.py:95} INFO - [2019-09-15 17:05:23,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:23,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:23,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:23,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:23,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:05:23,551] {scheduler_job.py:146} INFO - Started process (PID=20334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:28,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:28,560] {logging_mixin.py:95} INFO - [2019-09-15 17:05:28,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:28,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:28,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:28,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:28,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:05:28,994] {scheduler_job.py:146} INFO - Started process (PID=20336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:34,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:34,003] {logging_mixin.py:95} INFO - [2019-09-15 17:05:34,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:34,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:34,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:34,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:34,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:05:34,459] {scheduler_job.py:146} INFO - Started process (PID=20337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:39,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:39,467] {logging_mixin.py:95} INFO - [2019-09-15 17:05:39,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:39,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:39,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:39,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:39,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:05:39,918] {scheduler_job.py:146} INFO - Started process (PID=20338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:44,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:44,926] {logging_mixin.py:95} INFO - [2019-09-15 17:05:44,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:45,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:45,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:45,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:45,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:05:45,370] {scheduler_job.py:146} INFO - Started process (PID=20340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:50,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:50,379] {logging_mixin.py:95} INFO - [2019-09-15 17:05:50,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:50,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:50,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:50,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:50,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:05:50,826] {scheduler_job.py:146} INFO - Started process (PID=20341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:55,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:05:55,835] {logging_mixin.py:95} INFO - [2019-09-15 17:05:55,835] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:56,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:05:56,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:05:56,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:05:56,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 17:05:56,378] {scheduler_job.py:146} INFO - Started process (PID=20350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:01,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:01,391] {logging_mixin.py:95} INFO - [2019-09-15 17:06:01,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:01,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:01,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:01,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:01,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:06:01,827] {scheduler_job.py:146} INFO - Started process (PID=20351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:06,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:06,835] {logging_mixin.py:95} INFO - [2019-09-15 17:06:06,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:07,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:07,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:07,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:07,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:06:07,268] {scheduler_job.py:146} INFO - Started process (PID=20353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:12,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:12,291] {logging_mixin.py:95} INFO - [2019-09-15 17:06:12,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:12,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:12,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:12,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:12,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 17:06:12,809] {scheduler_job.py:146} INFO - Started process (PID=20357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:17,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:17,820] {logging_mixin.py:95} INFO - [2019-09-15 17:06:17,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:18,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:18,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:18,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:18,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:06:18,254] {scheduler_job.py:146} INFO - Started process (PID=20359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:23,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:23,270] {logging_mixin.py:95} INFO - [2019-09-15 17:06:23,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:23,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:23,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:23,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:23,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:06:23,699] {scheduler_job.py:146} INFO - Started process (PID=20361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:28,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:28,710] {logging_mixin.py:95} INFO - [2019-09-15 17:06:28,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:29,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:29,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:29,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:29,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:06:29,147] {scheduler_job.py:146} INFO - Started process (PID=20364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:34,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:34,155] {logging_mixin.py:95} INFO - [2019-09-15 17:06:34,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:34,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:34,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:34,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:34,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 17:06:34,697] {scheduler_job.py:146} INFO - Started process (PID=20365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:39,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:39,710] {logging_mixin.py:95} INFO - [2019-09-15 17:06:39,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:40,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:40,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:40,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:40,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 17:06:40,141] {scheduler_job.py:146} INFO - Started process (PID=20367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:45,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:45,152] {logging_mixin.py:95} INFO - [2019-09-15 17:06:45,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:45,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:45,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:45,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:45,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:06:45,596] {scheduler_job.py:146} INFO - Started process (PID=20368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:50,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:50,606] {logging_mixin.py:95} INFO - [2019-09-15 17:06:50,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:50,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:50,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:50,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:50,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:06:51,051] {scheduler_job.py:146} INFO - Started process (PID=20369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:56,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:06:56,060] {logging_mixin.py:95} INFO - [2019-09-15 17:06:56,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:56,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:06:56,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:06:56,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:06:56,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 17:06:56,503] {scheduler_job.py:146} INFO - Started process (PID=20371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:01,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:01,512] {logging_mixin.py:95} INFO - [2019-09-15 17:07:01,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:01,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:01,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:01,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:01,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 17:07:01,951] {scheduler_job.py:146} INFO - Started process (PID=20372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:06,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:06,960] {logging_mixin.py:95} INFO - [2019-09-15 17:07:06,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:07,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:07,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:07,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:07,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:07:07,396] {scheduler_job.py:146} INFO - Started process (PID=20373) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:12,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:12,403] {logging_mixin.py:95} INFO - [2019-09-15 17:07:12,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:12,786] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:12,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:12,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:12,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 17:07:12,942] {scheduler_job.py:146} INFO - Started process (PID=20375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:17,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:17,954] {logging_mixin.py:95} INFO - [2019-09-15 17:07:17,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:18,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:18,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:18,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:18,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:07:18,371] {scheduler_job.py:146} INFO - Started process (PID=20376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:23,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:23,381] {logging_mixin.py:95} INFO - [2019-09-15 17:07:23,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:23,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:23,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:23,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:23,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 17:07:23,922] {scheduler_job.py:146} INFO - Started process (PID=20378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:28,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:28,930] {logging_mixin.py:95} INFO - [2019-09-15 17:07:28,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:29,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:29,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:29,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:29,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:07:29,371] {scheduler_job.py:146} INFO - Started process (PID=20380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:34,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:34,381] {logging_mixin.py:95} INFO - [2019-09-15 17:07:34,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:34,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:34,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:34,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:34,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:07:34,809] {scheduler_job.py:146} INFO - Started process (PID=20382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:39,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:39,818] {logging_mixin.py:95} INFO - [2019-09-15 17:07:39,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:40,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:40,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:40,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:40,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 17:07:40,357] {scheduler_job.py:146} INFO - Started process (PID=20387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:45,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:45,370] {logging_mixin.py:95} INFO - [2019-09-15 17:07:45,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:45,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:45,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:45,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:45,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 17:07:45,800] {scheduler_job.py:146} INFO - Started process (PID=20389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:50,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:50,809] {logging_mixin.py:95} INFO - [2019-09-15 17:07:50,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:51,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:51,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:51,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:51,196] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:07:51,242] {scheduler_job.py:146} INFO - Started process (PID=20390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:56,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:07:56,253] {logging_mixin.py:95} INFO - [2019-09-15 17:07:56,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:56,604] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:07:56,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:07:56,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:07:56,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:07:56,684] {scheduler_job.py:146} INFO - Started process (PID=20392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:01,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:01,693] {logging_mixin.py:95} INFO - [2019-09-15 17:08:01,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:02,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:02,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:02,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:02,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:08:02,124] {scheduler_job.py:146} INFO - Started process (PID=20393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:07,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:07,132] {logging_mixin.py:95} INFO - [2019-09-15 17:08:07,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:07,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:07,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:07,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:07,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:08:07,560] {scheduler_job.py:146} INFO - Started process (PID=20394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:12,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:12,573] {logging_mixin.py:95} INFO - [2019-09-15 17:08:12,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:12,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:12,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:12,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:12,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 17:08:13,094] {scheduler_job.py:146} INFO - Started process (PID=20396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:18,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:18,104] {logging_mixin.py:95} INFO - [2019-09-15 17:08:18,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:18,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:18,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:18,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:18,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:08:18,535] {scheduler_job.py:146} INFO - Started process (PID=20397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:23,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:23,546] {logging_mixin.py:95} INFO - [2019-09-15 17:08:23,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:23,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:23,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:23,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:23,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:08:23,977] {scheduler_job.py:146} INFO - Started process (PID=20399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:28,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:28,986] {logging_mixin.py:95} INFO - [2019-09-15 17:08:28,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:29,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:29,359] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:29,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:29,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:08:29,416] {scheduler_job.py:146} INFO - Started process (PID=20401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:34,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:34,427] {logging_mixin.py:95} INFO - [2019-09-15 17:08:34,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:34,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:34,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:34,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:34,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:08:34,859] {scheduler_job.py:146} INFO - Started process (PID=20402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:39,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:39,869] {logging_mixin.py:95} INFO - [2019-09-15 17:08:39,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:40,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:40,245] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:40,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:40,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:08:40,301] {scheduler_job.py:146} INFO - Started process (PID=20404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:45,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:45,309] {logging_mixin.py:95} INFO - [2019-09-15 17:08:45,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:45,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:45,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:45,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:45,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:08:45,741] {scheduler_job.py:146} INFO - Started process (PID=20405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:50,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:50,749] {logging_mixin.py:95} INFO - [2019-09-15 17:08:50,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:51,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:51,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:51,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:51,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:08:51,179] {scheduler_job.py:146} INFO - Started process (PID=20406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:56,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:08:56,190] {logging_mixin.py:95} INFO - [2019-09-15 17:08:56,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:56,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:08:56,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:08:56,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:08:56,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 17:08:56,724] {scheduler_job.py:146} INFO - Started process (PID=20408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:01,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:01,734] {logging_mixin.py:95} INFO - [2019-09-15 17:09:01,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:02,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:02,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:02,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:02,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 17:09:02,269] {scheduler_job.py:146} INFO - Started process (PID=20409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:07,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:07,277] {logging_mixin.py:95} INFO - [2019-09-15 17:09:07,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:07,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:07,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:07,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:07,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 17:09:07,799] {scheduler_job.py:146} INFO - Started process (PID=20418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:12,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:12,809] {logging_mixin.py:95} INFO - [2019-09-15 17:09:12,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:13,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:13,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:13,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:13,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-09-15 17:09:13,331] {scheduler_job.py:146} INFO - Started process (PID=20423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:18,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:18,341] {logging_mixin.py:95} INFO - [2019-09-15 17:09:18,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:18,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:18,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:18,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:18,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:09:18,761] {scheduler_job.py:146} INFO - Started process (PID=20425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:23,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:23,768] {logging_mixin.py:95} INFO - [2019-09-15 17:09:23,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:24,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:24,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:24,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:24,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:09:24,201] {scheduler_job.py:146} INFO - Started process (PID=20428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:29,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:29,210] {logging_mixin.py:95} INFO - [2019-09-15 17:09:29,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:29,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:29,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:29,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:29,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 17:09:29,738] {scheduler_job.py:146} INFO - Started process (PID=20432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:34,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:34,745] {logging_mixin.py:95} INFO - [2019-09-15 17:09:34,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:35,107] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:35,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:35,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:35,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:09:35,169] {scheduler_job.py:146} INFO - Started process (PID=20433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:40,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:40,180] {logging_mixin.py:95} INFO - [2019-09-15 17:09:40,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:40,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:40,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:40,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:40,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 17:09:40,619] {scheduler_job.py:146} INFO - Started process (PID=20437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:45,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:45,627] {logging_mixin.py:95} INFO - [2019-09-15 17:09:45,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:45,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:46,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:46,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:46,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:09:46,068] {scheduler_job.py:146} INFO - Started process (PID=20438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:51,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:51,076] {logging_mixin.py:95} INFO - [2019-09-15 17:09:51,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:51,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:51,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:51,481] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:51,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 17:09:51,509] {scheduler_job.py:146} INFO - Started process (PID=20439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:56,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:09:56,518] {logging_mixin.py:95} INFO - [2019-09-15 17:09:56,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:56,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:09:56,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:09:56,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:09:56,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 17:09:56,958] {scheduler_job.py:146} INFO - Started process (PID=20441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:01,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:01,965] {logging_mixin.py:95} INFO - [2019-09-15 17:10:01,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:02,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:02,359] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:02,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:02,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:10:02,408] {scheduler_job.py:146} INFO - Started process (PID=20442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:07,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:07,418] {logging_mixin.py:95} INFO - [2019-09-15 17:10:07,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:07,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:07,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:07,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:07,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:10:07,863] {scheduler_job.py:146} INFO - Started process (PID=20443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:12,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:12,872] {logging_mixin.py:95} INFO - [2019-09-15 17:10:12,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:13,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:13,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:13,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:13,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-15 17:10:13,420] {scheduler_job.py:146} INFO - Started process (PID=20445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:18,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:18,434] {logging_mixin.py:95} INFO - [2019-09-15 17:10:18,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:18,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:18,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:18,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:18,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:10:18,867] {scheduler_job.py:146} INFO - Started process (PID=20446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:23,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:23,875] {logging_mixin.py:95} INFO - [2019-09-15 17:10:23,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:24,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:24,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:24,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:24,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:10:24,313] {scheduler_job.py:146} INFO - Started process (PID=20448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:29,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:29,324] {logging_mixin.py:95} INFO - [2019-09-15 17:10:29,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:29,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:29,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:29,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:29,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:10:29,766] {scheduler_job.py:146} INFO - Started process (PID=20450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:34,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:34,774] {logging_mixin.py:95} INFO - [2019-09-15 17:10:34,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:35,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:35,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:35,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:35,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:10:35,216] {scheduler_job.py:146} INFO - Started process (PID=20451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:40,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:40,228] {logging_mixin.py:95} INFO - [2019-09-15 17:10:40,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:40,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:40,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:40,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:40,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:10:40,677] {scheduler_job.py:146} INFO - Started process (PID=20453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:45,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:45,699] {logging_mixin.py:95} INFO - [2019-09-15 17:10:45,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:46,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:46,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:46,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:46,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:10:46,139] {scheduler_job.py:146} INFO - Started process (PID=20454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:51,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:51,149] {logging_mixin.py:95} INFO - [2019-09-15 17:10:51,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:51,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:51,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:51,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:51,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:10:51,598] {scheduler_job.py:146} INFO - Started process (PID=20455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:56,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:10:56,607] {logging_mixin.py:95} INFO - [2019-09-15 17:10:56,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:56,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:10:56,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:10:56,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:10:56,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:10:57,055] {scheduler_job.py:146} INFO - Started process (PID=20457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:02,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:02,064] {logging_mixin.py:95} INFO - [2019-09-15 17:11:02,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:02,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:02,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:02,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:02,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:11:02,518] {scheduler_job.py:146} INFO - Started process (PID=20458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:07,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:07,526] {logging_mixin.py:95} INFO - [2019-09-15 17:11:07,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:07,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:07,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:07,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:07,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:11:07,978] {scheduler_job.py:146} INFO - Started process (PID=20459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:12,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:12,991] {logging_mixin.py:95} INFO - [2019-09-15 17:11:12,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:13,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:13,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:13,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:13,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:11:13,436] {scheduler_job.py:146} INFO - Started process (PID=20461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:18,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:18,447] {logging_mixin.py:95} INFO - [2019-09-15 17:11:18,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:18,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:18,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:18,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:18,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:11:18,889] {scheduler_job.py:146} INFO - Started process (PID=20462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:23,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:23,898] {logging_mixin.py:95} INFO - [2019-09-15 17:11:23,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:24,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:24,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:24,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:24,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:11:24,347] {scheduler_job.py:146} INFO - Started process (PID=20464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:29,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:29,357] {logging_mixin.py:95} INFO - [2019-09-15 17:11:29,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:29,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:29,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:29,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:29,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:11:29,802] {scheduler_job.py:146} INFO - Started process (PID=20466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:34,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:34,810] {logging_mixin.py:95} INFO - [2019-09-15 17:11:34,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:35,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:35,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:35,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:35,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:11:35,262] {scheduler_job.py:146} INFO - Started process (PID=20467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:40,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:40,274] {logging_mixin.py:95} INFO - [2019-09-15 17:11:40,274] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:40,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:40,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:40,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:40,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 17:11:40,720] {scheduler_job.py:146} INFO - Started process (PID=20469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:45,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:45,731] {logging_mixin.py:95} INFO - [2019-09-15 17:11:45,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:46,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:46,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:46,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:46,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:11:46,169] {scheduler_job.py:146} INFO - Started process (PID=20470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:51,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:51,181] {logging_mixin.py:95} INFO - [2019-09-15 17:11:51,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:51,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:51,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:51,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:51,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:11:51,621] {scheduler_job.py:146} INFO - Started process (PID=20471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:56,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:11:56,629] {logging_mixin.py:95} INFO - [2019-09-15 17:11:56,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:56,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:11:56,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:11:57,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:11:57,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:11:57,079] {scheduler_job.py:146} INFO - Started process (PID=20473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:02,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:02,089] {logging_mixin.py:95} INFO - [2019-09-15 17:12:02,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:02,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:02,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:02,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:02,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:12:02,541] {scheduler_job.py:146} INFO - Started process (PID=20474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:07,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:07,551] {logging_mixin.py:95} INFO - [2019-09-15 17:12:07,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:07,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:07,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:07,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:07,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:12:08,004] {scheduler_job.py:146} INFO - Started process (PID=20475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:13,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:13,016] {logging_mixin.py:95} INFO - [2019-09-15 17:12:13,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:13,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:13,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:13,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:13,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:12:13,460] {scheduler_job.py:146} INFO - Started process (PID=20477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:18,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:18,469] {logging_mixin.py:95} INFO - [2019-09-15 17:12:18,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:18,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:18,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:18,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:18,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:12:18,920] {scheduler_job.py:146} INFO - Started process (PID=20478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:23,931] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:23,932] {logging_mixin.py:95} INFO - [2019-09-15 17:12:23,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:24,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:24,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:24,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:24,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:12:24,389] {scheduler_job.py:146} INFO - Started process (PID=20480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:29,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:29,396] {logging_mixin.py:95} INFO - [2019-09-15 17:12:29,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:29,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:29,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:29,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:29,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:12:29,845] {scheduler_job.py:146} INFO - Started process (PID=20482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:34,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:34,854] {logging_mixin.py:95} INFO - [2019-09-15 17:12:34,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:35,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:35,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:35,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:35,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:12:35,301] {scheduler_job.py:146} INFO - Started process (PID=20483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:40,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:40,309] {logging_mixin.py:95} INFO - [2019-09-15 17:12:40,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:40,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:40,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:40,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:40,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:12:40,762] {scheduler_job.py:146} INFO - Started process (PID=20485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:45,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:45,771] {logging_mixin.py:95} INFO - [2019-09-15 17:12:45,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:46,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:46,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:46,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:46,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:12:46,220] {scheduler_job.py:146} INFO - Started process (PID=20486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:51,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:51,227] {logging_mixin.py:95} INFO - [2019-09-15 17:12:51,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:51,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:51,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:51,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:51,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:12:51,684] {scheduler_job.py:146} INFO - Started process (PID=20487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:56,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:12:56,693] {logging_mixin.py:95} INFO - [2019-09-15 17:12:56,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:57,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:12:57,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:12:57,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:12:57,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:12:57,143] {scheduler_job.py:146} INFO - Started process (PID=20489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:02,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:02,155] {logging_mixin.py:95} INFO - [2019-09-15 17:13:02,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:02,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:02,526] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:02,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:02,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:13:02,603] {scheduler_job.py:146} INFO - Started process (PID=20490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:07,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:07,614] {logging_mixin.py:95} INFO - [2019-09-15 17:13:07,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:07,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:07,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:07,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:07,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:13:08,065] {scheduler_job.py:146} INFO - Started process (PID=20491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:13,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:13,086] {logging_mixin.py:95} INFO - [2019-09-15 17:13:13,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:13,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:13,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:13,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:13,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:13:13,528] {scheduler_job.py:146} INFO - Started process (PID=20493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:18,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:18,537] {logging_mixin.py:95} INFO - [2019-09-15 17:13:18,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:18,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:18,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:18,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:18,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:13:18,986] {scheduler_job.py:146} INFO - Started process (PID=20494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:23,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:23,994] {logging_mixin.py:95} INFO - [2019-09-15 17:13:23,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:24,337] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:24,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:24,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:24,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:13:24,449] {scheduler_job.py:146} INFO - Started process (PID=20496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:29,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:29,455] {logging_mixin.py:95} INFO - [2019-09-15 17:13:29,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:29,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:29,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:29,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:29,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 17:13:29,904] {scheduler_job.py:146} INFO - Started process (PID=20498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:34,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:34,914] {logging_mixin.py:95} INFO - [2019-09-15 17:13:34,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:35,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:35,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:35,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:35,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:13:35,360] {scheduler_job.py:146} INFO - Started process (PID=20499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:40,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:40,371] {logging_mixin.py:95} INFO - [2019-09-15 17:13:40,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:40,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:40,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:40,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:40,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:13:40,815] {scheduler_job.py:146} INFO - Started process (PID=20501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:45,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:45,826] {logging_mixin.py:95} INFO - [2019-09-15 17:13:45,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:46,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:46,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:46,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:46,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:13:46,280] {scheduler_job.py:146} INFO - Started process (PID=20502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:51,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:51,286] {logging_mixin.py:95} INFO - [2019-09-15 17:13:51,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:51,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:51,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:51,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:51,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:13:51,736] {scheduler_job.py:146} INFO - Started process (PID=20503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:56,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:13:56,741] {logging_mixin.py:95} INFO - [2019-09-15 17:13:56,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:57,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:13:57,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:13:57,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:13:57,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:13:57,200] {scheduler_job.py:146} INFO - Started process (PID=20505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:02,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:02,208] {logging_mixin.py:95} INFO - [2019-09-15 17:14:02,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:02,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:02,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:02,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:02,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:14:02,655] {scheduler_job.py:146} INFO - Started process (PID=20506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:07,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:07,669] {logging_mixin.py:95} INFO - [2019-09-15 17:14:07,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:08,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:08,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:08,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:08,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:14:08,115] {scheduler_job.py:146} INFO - Started process (PID=20507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:13,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:13,136] {logging_mixin.py:95} INFO - [2019-09-15 17:14:13,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:13,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:13,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:13,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:13,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 17:14:13,576] {scheduler_job.py:146} INFO - Started process (PID=20509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:18,581] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:18,582] {logging_mixin.py:95} INFO - [2019-09-15 17:14:18,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:18,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:18,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:18,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:18,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:14:19,038] {scheduler_job.py:146} INFO - Started process (PID=20510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:24,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:24,045] {logging_mixin.py:95} INFO - [2019-09-15 17:14:24,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:24,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:24,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:24,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:24,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:14:24,499] {scheduler_job.py:146} INFO - Started process (PID=20512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:29,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:29,508] {logging_mixin.py:95} INFO - [2019-09-15 17:14:29,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:29,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:29,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:29,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:29,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:14:29,949] {scheduler_job.py:146} INFO - Started process (PID=20514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:34,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:34,956] {logging_mixin.py:95} INFO - [2019-09-15 17:14:34,955] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:35,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:35,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:35,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:35,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:14:35,404] {scheduler_job.py:146} INFO - Started process (PID=20515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:40,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:40,412] {logging_mixin.py:95} INFO - [2019-09-15 17:14:40,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:40,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:40,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:40,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:40,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:14:40,859] {scheduler_job.py:146} INFO - Started process (PID=20517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:45,869] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:45,870] {logging_mixin.py:95} INFO - [2019-09-15 17:14:45,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:46,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:46,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:46,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:46,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:14:46,322] {scheduler_job.py:146} INFO - Started process (PID=20518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:51,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:51,329] {logging_mixin.py:95} INFO - [2019-09-15 17:14:51,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:51,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:51,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:51,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:51,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:14:51,787] {scheduler_job.py:146} INFO - Started process (PID=20519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:56,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:14:56,796] {logging_mixin.py:95} INFO - [2019-09-15 17:14:56,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:57,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:14:57,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:14:57,195] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:14:57,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:14:57,236] {scheduler_job.py:146} INFO - Started process (PID=20521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:02,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:02,253] {logging_mixin.py:95} INFO - [2019-09-15 17:15:02,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:02,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:02,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:02,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:02,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:15:02,690] {scheduler_job.py:146} INFO - Started process (PID=20522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:07,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:07,700] {logging_mixin.py:95} INFO - [2019-09-15 17:15:07,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:08,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:08,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:08,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:08,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:15:08,152] {scheduler_job.py:146} INFO - Started process (PID=20523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:13,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:13,168] {logging_mixin.py:95} INFO - [2019-09-15 17:15:13,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:13,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:13,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:13,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:13,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:15:13,611] {scheduler_job.py:146} INFO - Started process (PID=20525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:18,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:18,618] {logging_mixin.py:95} INFO - [2019-09-15 17:15:18,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:18,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:19,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:19,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:19,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:15:19,064] {scheduler_job.py:146} INFO - Started process (PID=20527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:24,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:24,072] {logging_mixin.py:95} INFO - [2019-09-15 17:15:24,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:24,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:24,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:24,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:24,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:15:24,517] {scheduler_job.py:146} INFO - Started process (PID=20529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:29,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:29,525] {logging_mixin.py:95} INFO - [2019-09-15 17:15:29,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:29,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:29,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:29,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:29,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:15:29,975] {scheduler_job.py:146} INFO - Started process (PID=20532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:34,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:34,984] {logging_mixin.py:95} INFO - [2019-09-15 17:15:34,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:35,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:35,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:35,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:35,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:15:35,432] {scheduler_job.py:146} INFO - Started process (PID=20533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:40,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:40,442] {logging_mixin.py:95} INFO - [2019-09-15 17:15:40,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:40,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:40,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:40,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:40,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:15:40,887] {scheduler_job.py:146} INFO - Started process (PID=20535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:45,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:45,899] {logging_mixin.py:95} INFO - [2019-09-15 17:15:45,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:46,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:46,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:46,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:46,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:15:46,346] {scheduler_job.py:146} INFO - Started process (PID=20536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:51,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:51,354] {logging_mixin.py:95} INFO - [2019-09-15 17:15:51,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:51,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:51,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:51,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:51,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:15:51,812] {scheduler_job.py:146} INFO - Started process (PID=20537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:56,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:15:56,820] {logging_mixin.py:95} INFO - [2019-09-15 17:15:56,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:57,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:15:57,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:15:57,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:15:57,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:15:57,275] {scheduler_job.py:146} INFO - Started process (PID=20539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:02,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:02,286] {logging_mixin.py:95} INFO - [2019-09-15 17:16:02,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:02,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:02,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:02,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:02,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:16:02,732] {scheduler_job.py:146} INFO - Started process (PID=20540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:07,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:07,739] {logging_mixin.py:95} INFO - [2019-09-15 17:16:07,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:08,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:08,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:08,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:08,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:16:08,193] {scheduler_job.py:146} INFO - Started process (PID=20541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:13,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:13,212] {logging_mixin.py:95} INFO - [2019-09-15 17:16:13,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:13,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:13,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:13,589] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:13,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:16:13,653] {scheduler_job.py:146} INFO - Started process (PID=20543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:18,659] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:18,660] {logging_mixin.py:95} INFO - [2019-09-15 17:16:18,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:19,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:19,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:19,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:19,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:16:19,114] {scheduler_job.py:146} INFO - Started process (PID=20544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:24,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:24,121] {logging_mixin.py:95} INFO - [2019-09-15 17:16:24,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:24,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:24,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:24,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:24,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:16:24,566] {scheduler_job.py:146} INFO - Started process (PID=20546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:29,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:29,577] {logging_mixin.py:95} INFO - [2019-09-15 17:16:29,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:29,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:29,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:29,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:29,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:16:30,016] {scheduler_job.py:146} INFO - Started process (PID=20548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:35,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:35,025] {logging_mixin.py:95} INFO - [2019-09-15 17:16:35,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:35,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:35,389] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:35,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:35,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:16:35,479] {scheduler_job.py:146} INFO - Started process (PID=20549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:40,485] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:40,486] {logging_mixin.py:95} INFO - [2019-09-15 17:16:40,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:40,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:40,848] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:40,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:40,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:16:40,938] {scheduler_job.py:146} INFO - Started process (PID=20551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:45,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:45,946] {logging_mixin.py:95} INFO - [2019-09-15 17:16:45,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:46,286] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:46,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:46,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:46,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:16:46,398] {scheduler_job.py:146} INFO - Started process (PID=20552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:51,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:51,409] {logging_mixin.py:95} INFO - [2019-09-15 17:16:51,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:51,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:51,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:51,782] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:51,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:16:51,858] {scheduler_job.py:146} INFO - Started process (PID=20553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:56,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:16:56,869] {logging_mixin.py:95} INFO - [2019-09-15 17:16:56,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:57,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:16:57,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:16:57,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:16:57,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:16:57,318] {scheduler_job.py:146} INFO - Started process (PID=20555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:02,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:02,326] {logging_mixin.py:95} INFO - [2019-09-15 17:17:02,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:02,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:02,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:02,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:02,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:17:02,779] {scheduler_job.py:146} INFO - Started process (PID=20556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:07,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:07,785] {logging_mixin.py:95} INFO - [2019-09-15 17:17:07,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:08,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:08,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:08,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:08,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:17:08,247] {scheduler_job.py:146} INFO - Started process (PID=20557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:13,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:13,263] {logging_mixin.py:95} INFO - [2019-09-15 17:17:13,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:13,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:13,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:13,635] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:13,640] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:17:13,705] {scheduler_job.py:146} INFO - Started process (PID=20559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:18,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:18,715] {logging_mixin.py:95} INFO - [2019-09-15 17:17:18,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:19,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:19,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:19,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:19,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:17:19,165] {scheduler_job.py:146} INFO - Started process (PID=20560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:24,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:24,174] {logging_mixin.py:95} INFO - [2019-09-15 17:17:24,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:24,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:24,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:24,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:24,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:17:24,625] {scheduler_job.py:146} INFO - Started process (PID=20562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:29,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:29,632] {logging_mixin.py:95} INFO - [2019-09-15 17:17:29,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:29,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:30,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:30,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:30,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:17:30,081] {scheduler_job.py:146} INFO - Started process (PID=20564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:35,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:35,091] {logging_mixin.py:95} INFO - [2019-09-15 17:17:35,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:35,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:35,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:35,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:35,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:17:35,537] {scheduler_job.py:146} INFO - Started process (PID=20565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:40,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:40,545] {logging_mixin.py:95} INFO - [2019-09-15 17:17:40,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:40,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:40,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:40,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:40,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:17:40,993] {scheduler_job.py:146} INFO - Started process (PID=20567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:46,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:46,012] {logging_mixin.py:95} INFO - [2019-09-15 17:17:46,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:46,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:46,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:46,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:46,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 17:17:46,447] {scheduler_job.py:146} INFO - Started process (PID=20568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:51,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:51,455] {logging_mixin.py:95} INFO - [2019-09-15 17:17:51,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:51,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:51,825] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:51,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:51,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:17:51,911] {scheduler_job.py:146} INFO - Started process (PID=20569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:56,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:17:56,918] {logging_mixin.py:95} INFO - [2019-09-15 17:17:56,918] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:57,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:17:57,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:17:57,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:17:57,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:17:57,367] {scheduler_job.py:146} INFO - Started process (PID=20571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:02,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:02,375] {logging_mixin.py:95} INFO - [2019-09-15 17:18:02,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:02,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:02,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:02,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:02,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:18:02,823] {scheduler_job.py:146} INFO - Started process (PID=20572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:07,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:07,833] {logging_mixin.py:95} INFO - [2019-09-15 17:18:07,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:08,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:08,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:08,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:08,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:18:08,284] {scheduler_job.py:146} INFO - Started process (PID=20573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:13,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:13,305] {logging_mixin.py:95} INFO - [2019-09-15 17:18:13,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:13,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:13,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:13,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:13,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:18:13,746] {scheduler_job.py:146} INFO - Started process (PID=20575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:18,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:18,752] {logging_mixin.py:95} INFO - [2019-09-15 17:18:18,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:19,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:19,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:19,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:19,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 17:18:19,207] {scheduler_job.py:146} INFO - Started process (PID=20576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:24,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:24,217] {logging_mixin.py:95} INFO - [2019-09-15 17:18:24,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:24,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:24,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:24,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:24,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:18:24,664] {scheduler_job.py:146} INFO - Started process (PID=20578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:29,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:29,675] {logging_mixin.py:95} INFO - [2019-09-15 17:18:29,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:30,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:30,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:30,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:30,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 17:18:30,121] {scheduler_job.py:146} INFO - Started process (PID=20580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:35,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:35,133] {logging_mixin.py:95} INFO - [2019-09-15 17:18:35,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:35,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:35,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:35,506] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:35,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:18:35,572] {scheduler_job.py:146} INFO - Started process (PID=20581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:40,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:40,581] {logging_mixin.py:95} INFO - [2019-09-15 17:18:40,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:40,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:40,953] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:40,962] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:40,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:18:41,034] {scheduler_job.py:146} INFO - Started process (PID=20583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:46,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:46,053] {logging_mixin.py:95} INFO - [2019-09-15 17:18:46,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:46,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:46,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:46,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:46,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:18:46,491] {scheduler_job.py:146} INFO - Started process (PID=20584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:51,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:51,500] {logging_mixin.py:95} INFO - [2019-09-15 17:18:51,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:51,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:51,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:51,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:51,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:18:51,948] {scheduler_job.py:146} INFO - Started process (PID=20585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:56,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:18:56,956] {logging_mixin.py:95} INFO - [2019-09-15 17:18:56,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:57,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:18:57,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:18:57,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:18:57,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:18:57,407] {scheduler_job.py:146} INFO - Started process (PID=20587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:02,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:02,416] {logging_mixin.py:95} INFO - [2019-09-15 17:19:02,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:02,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:02,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:02,822] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:02,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 17:19:02,867] {scheduler_job.py:146} INFO - Started process (PID=20588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:07,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:07,877] {logging_mixin.py:95} INFO - [2019-09-15 17:19:07,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:08,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:08,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:08,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:08,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:19:08,325] {scheduler_job.py:146} INFO - Started process (PID=20589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:13,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:13,346] {logging_mixin.py:95} INFO - [2019-09-15 17:19:13,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:13,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:13,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:13,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:13,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:19:13,786] {scheduler_job.py:146} INFO - Started process (PID=20591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:18,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:18,795] {logging_mixin.py:95} INFO - [2019-09-15 17:19:18,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:19,140] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:19,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:19,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:19,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:19:19,243] {scheduler_job.py:146} INFO - Started process (PID=20592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:24,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:24,254] {logging_mixin.py:95} INFO - [2019-09-15 17:19:24,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:24,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:24,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:24,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:24,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:19:24,708] {scheduler_job.py:146} INFO - Started process (PID=20594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:29,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:29,715] {logging_mixin.py:95} INFO - [2019-09-15 17:19:29,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:30,057] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:30,082] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:30,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:30,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:19:30,167] {scheduler_job.py:146} INFO - Started process (PID=20596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:35,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:35,178] {logging_mixin.py:95} INFO - [2019-09-15 17:19:35,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:35,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:35,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:35,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:35,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:19:35,627] {scheduler_job.py:146} INFO - Started process (PID=20597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:40,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:40,634] {logging_mixin.py:95} INFO - [2019-09-15 17:19:40,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:41,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:41,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:41,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:41,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:19:41,082] {scheduler_job.py:146} INFO - Started process (PID=20599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:46,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:46,092] {logging_mixin.py:95} INFO - [2019-09-15 17:19:46,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:46,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:46,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:46,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:46,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:19:46,544] {scheduler_job.py:146} INFO - Started process (PID=20600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:51,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:51,550] {logging_mixin.py:95} INFO - [2019-09-15 17:19:51,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:51,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:51,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:51,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:51,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 17:19:51,994] {scheduler_job.py:146} INFO - Started process (PID=20601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:56,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:19:57,001] {logging_mixin.py:95} INFO - [2019-09-15 17:19:57,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:57,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:19:57,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:19:57,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:19:57,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:19:57,445] {scheduler_job.py:146} INFO - Started process (PID=20603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:02,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:02,463] {logging_mixin.py:95} INFO - [2019-09-15 17:20:02,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:02,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:02,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:02,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:02,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:20:02,904] {scheduler_job.py:146} INFO - Started process (PID=20604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:07,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:07,913] {logging_mixin.py:95} INFO - [2019-09-15 17:20:07,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:08,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:08,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:08,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:08,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:20:08,361] {scheduler_job.py:146} INFO - Started process (PID=20605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:13,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:13,382] {logging_mixin.py:95} INFO - [2019-09-15 17:20:13,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:13,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:13,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:13,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:13,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:20:13,821] {scheduler_job.py:146} INFO - Started process (PID=20607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:18,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:18,828] {logging_mixin.py:95} INFO - [2019-09-15 17:20:18,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:19,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:19,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:19,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:19,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:20:19,285] {scheduler_job.py:146} INFO - Started process (PID=20608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:24,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:24,296] {logging_mixin.py:95} INFO - [2019-09-15 17:20:24,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:24,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:24,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:24,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:24,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:20:24,747] {scheduler_job.py:146} INFO - Started process (PID=20610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:29,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:29,758] {logging_mixin.py:95} INFO - [2019-09-15 17:20:29,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:30,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:30,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:30,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:30,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:20:30,206] {scheduler_job.py:146} INFO - Started process (PID=20612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:35,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:35,217] {logging_mixin.py:95} INFO - [2019-09-15 17:20:35,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:35,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:35,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:35,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:35,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:20:35,662] {scheduler_job.py:146} INFO - Started process (PID=20613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:40,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:40,670] {logging_mixin.py:95} INFO - [2019-09-15 17:20:40,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:41,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:41,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:41,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:41,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:20:41,124] {scheduler_job.py:146} INFO - Started process (PID=20615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:46,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:46,133] {logging_mixin.py:95} INFO - [2019-09-15 17:20:46,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:46,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:46,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:46,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:46,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:20:46,581] {scheduler_job.py:146} INFO - Started process (PID=20616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:51,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:51,589] {logging_mixin.py:95} INFO - [2019-09-15 17:20:51,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:51,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:51,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:51,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:51,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:20:52,043] {scheduler_job.py:146} INFO - Started process (PID=20617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:57,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:20:57,053] {logging_mixin.py:95} INFO - [2019-09-15 17:20:57,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:57,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:20:57,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:20:57,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:20:57,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:20:57,505] {scheduler_job.py:146} INFO - Started process (PID=20619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:02,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:02,516] {logging_mixin.py:95} INFO - [2019-09-15 17:21:02,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:02,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:02,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:02,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:02,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:21:02,962] {scheduler_job.py:146} INFO - Started process (PID=20620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:07,970] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:07,971] {logging_mixin.py:95} INFO - [2019-09-15 17:21:07,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:08,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:08,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:08,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:08,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:21:08,422] {scheduler_job.py:146} INFO - Started process (PID=20621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:13,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:13,443] {logging_mixin.py:95} INFO - [2019-09-15 17:21:13,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:13,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:13,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:13,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:13,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:21:13,882] {scheduler_job.py:146} INFO - Started process (PID=20623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:18,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:18,888] {logging_mixin.py:95} INFO - [2019-09-15 17:21:18,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:19,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:19,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:19,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:19,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:21:19,341] {scheduler_job.py:146} INFO - Started process (PID=20624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:24,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:24,348] {logging_mixin.py:95} INFO - [2019-09-15 17:21:24,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:24,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:24,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:24,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:24,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:21:24,798] {scheduler_job.py:146} INFO - Started process (PID=20626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:29,804] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:29,805] {logging_mixin.py:95} INFO - [2019-09-15 17:21:29,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:30,149] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:30,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:30,182] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:30,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:21:30,250] {scheduler_job.py:146} INFO - Started process (PID=20628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:35,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:35,261] {logging_mixin.py:95} INFO - [2019-09-15 17:21:35,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:35,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:35,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:35,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:35,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:21:35,710] {scheduler_job.py:146} INFO - Started process (PID=20629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:40,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:40,717] {logging_mixin.py:95} INFO - [2019-09-15 17:21:40,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:41,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:41,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:41,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:41,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-15 17:21:41,271] {scheduler_job.py:146} INFO - Started process (PID=20631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:46,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:46,281] {logging_mixin.py:95} INFO - [2019-09-15 17:21:46,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:46,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:46,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:46,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:46,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:21:46,728] {scheduler_job.py:146} INFO - Started process (PID=20632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:51,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:51,736] {logging_mixin.py:95} INFO - [2019-09-15 17:21:51,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:52,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:52,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:52,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:52,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:21:52,186] {scheduler_job.py:146} INFO - Started process (PID=20633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:57,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:21:57,197] {logging_mixin.py:95} INFO - [2019-09-15 17:21:57,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:57,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:21:57,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:21:57,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:21:57,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:21:57,645] {scheduler_job.py:146} INFO - Started process (PID=20635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:02,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:02,652] {logging_mixin.py:95} INFO - [2019-09-15 17:22:02,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:02,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:03,015] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:03,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:03,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:22:03,111] {scheduler_job.py:146} INFO - Started process (PID=20636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:08,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:08,118] {logging_mixin.py:95} INFO - [2019-09-15 17:22:08,117] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:08,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:08,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:08,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:08,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:22:08,567] {scheduler_job.py:146} INFO - Started process (PID=20637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:13,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:13,578] {logging_mixin.py:95} INFO - [2019-09-15 17:22:13,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:13,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:13,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:13,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:13,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:22:14,026] {scheduler_job.py:146} INFO - Started process (PID=20639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:19,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:19,032] {logging_mixin.py:95} INFO - [2019-09-15 17:22:19,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:19,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:19,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:19,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:19,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:22:19,483] {scheduler_job.py:146} INFO - Started process (PID=20640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:24,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:24,494] {logging_mixin.py:95} INFO - [2019-09-15 17:22:24,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:24,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:24,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:24,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:24,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:22:24,948] {scheduler_job.py:146} INFO - Started process (PID=20642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:29,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:29,956] {logging_mixin.py:95} INFO - [2019-09-15 17:22:29,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:30,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:30,320] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:30,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:30,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:22:30,408] {scheduler_job.py:146} INFO - Started process (PID=20644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:35,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:35,417] {logging_mixin.py:95} INFO - [2019-09-15 17:22:35,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:35,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:35,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:35,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:35,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:22:35,863] {scheduler_job.py:146} INFO - Started process (PID=20645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:40,869] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:40,870] {logging_mixin.py:95} INFO - [2019-09-15 17:22:40,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:41,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:41,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:41,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:41,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:22:41,322] {scheduler_job.py:146} INFO - Started process (PID=20647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:46,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:46,329] {logging_mixin.py:95} INFO - [2019-09-15 17:22:46,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:46,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:46,690] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:46,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:46,705] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 17:22:46,777] {scheduler_job.py:146} INFO - Started process (PID=20648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:51,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:51,785] {logging_mixin.py:95} INFO - [2019-09-15 17:22:51,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:52,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:52,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:52,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:52,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:22:52,236] {scheduler_job.py:146} INFO - Started process (PID=20649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:57,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:22:57,247] {logging_mixin.py:95} INFO - [2019-09-15 17:22:57,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:57,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:22:57,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:22:57,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:22:57,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:22:57,699] {scheduler_job.py:146} INFO - Started process (PID=20651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:02,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:02,708] {logging_mixin.py:95} INFO - [2019-09-15 17:23:02,707] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:03,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:03,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:03,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:03,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:23:03,162] {scheduler_job.py:146} INFO - Started process (PID=20652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:08,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:08,171] {logging_mixin.py:95} INFO - [2019-09-15 17:23:08,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:08,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:08,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:08,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:08,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:23:08,622] {scheduler_job.py:146} INFO - Started process (PID=20653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:13,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:13,638] {logging_mixin.py:95} INFO - [2019-09-15 17:23:13,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:13,985] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:14,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:14,018] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:14,023] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:23:14,082] {scheduler_job.py:146} INFO - Started process (PID=20655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:19,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:19,087] {logging_mixin.py:95} INFO - [2019-09-15 17:23:19,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:19,441] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:19,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:19,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:19,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:23:19,542] {scheduler_job.py:146} INFO - Started process (PID=20656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:24,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:24,550] {logging_mixin.py:95} INFO - [2019-09-15 17:23:24,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:24,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:24,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:24,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:24,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:23:25,003] {scheduler_job.py:146} INFO - Started process (PID=20658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:30,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:30,015] {logging_mixin.py:95} INFO - [2019-09-15 17:23:30,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:30,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:30,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:30,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:30,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:23:30,463] {scheduler_job.py:146} INFO - Started process (PID=20660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:35,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:35,474] {logging_mixin.py:95} INFO - [2019-09-15 17:23:35,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:35,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:35,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:35,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:35,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:23:35,923] {scheduler_job.py:146} INFO - Started process (PID=20661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:40,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:40,930] {logging_mixin.py:95} INFO - [2019-09-15 17:23:40,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:41,275] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:41,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:41,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:41,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:23:41,381] {scheduler_job.py:146} INFO - Started process (PID=20663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:46,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:46,391] {logging_mixin.py:95} INFO - [2019-09-15 17:23:46,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:46,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:46,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:46,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:46,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:23:46,844] {scheduler_job.py:146} INFO - Started process (PID=20664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:51,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:51,855] {logging_mixin.py:95} INFO - [2019-09-15 17:23:51,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:52,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:52,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:52,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:52,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:23:52,304] {scheduler_job.py:146} INFO - Started process (PID=20665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:57,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:23:57,311] {logging_mixin.py:95} INFO - [2019-09-15 17:23:57,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:57,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:23:57,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:23:57,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:23:57,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:23:57,764] {scheduler_job.py:146} INFO - Started process (PID=20667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:02,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:02,775] {logging_mixin.py:95} INFO - [2019-09-15 17:24:02,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:03,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:03,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:03,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:03,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:24:03,222] {scheduler_job.py:146} INFO - Started process (PID=20668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:08,230] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:08,231] {logging_mixin.py:95} INFO - [2019-09-15 17:24:08,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:08,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:08,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:08,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:08,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:24:08,685] {scheduler_job.py:146} INFO - Started process (PID=20669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:13,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:13,703] {logging_mixin.py:95} INFO - [2019-09-15 17:24:13,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:14,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:14,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:14,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:14,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:24:14,145] {scheduler_job.py:146} INFO - Started process (PID=20671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:19,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:19,152] {logging_mixin.py:95} INFO - [2019-09-15 17:24:19,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:19,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:19,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:19,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:19,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:24:19,608] {scheduler_job.py:146} INFO - Started process (PID=20672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:24,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:24,620] {logging_mixin.py:95} INFO - [2019-09-15 17:24:24,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:24,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:25,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:25,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:25,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:24:25,070] {scheduler_job.py:146} INFO - Started process (PID=20674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:30,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:30,079] {logging_mixin.py:95} INFO - [2019-09-15 17:24:30,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:30,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:30,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:30,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:30,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:24:30,528] {scheduler_job.py:146} INFO - Started process (PID=20676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:35,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:35,535] {logging_mixin.py:95} INFO - [2019-09-15 17:24:35,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:35,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:35,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:35,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:35,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:24:35,989] {scheduler_job.py:146} INFO - Started process (PID=20677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:40,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:40,995] {logging_mixin.py:95} INFO - [2019-09-15 17:24:40,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:41,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:41,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:41,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:41,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:24:41,450] {scheduler_job.py:146} INFO - Started process (PID=20679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:46,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:46,458] {logging_mixin.py:95} INFO - [2019-09-15 17:24:46,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:46,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:46,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:46,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:46,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:24:46,907] {scheduler_job.py:146} INFO - Started process (PID=20680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:51,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:51,917] {logging_mixin.py:95} INFO - [2019-09-15 17:24:51,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:52,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:52,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:52,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:52,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:24:52,363] {scheduler_job.py:146} INFO - Started process (PID=20681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:57,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:24:57,371] {logging_mixin.py:95} INFO - [2019-09-15 17:24:57,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:57,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:24:57,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:24:57,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:24:57,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:24:57,819] {scheduler_job.py:146} INFO - Started process (PID=20683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:02,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:02,829] {logging_mixin.py:95} INFO - [2019-09-15 17:25:02,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:03,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:03,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:03,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:03,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:25:03,274] {scheduler_job.py:146} INFO - Started process (PID=20686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:08,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:08,284] {logging_mixin.py:95} INFO - [2019-09-15 17:25:08,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:08,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:08,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:08,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:08,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 17:25:08,727] {scheduler_job.py:146} INFO - Started process (PID=20687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:13,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:13,734] {logging_mixin.py:95} INFO - [2019-09-15 17:25:13,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:14,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:14,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:14,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:14,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:25:14,185] {scheduler_job.py:146} INFO - Started process (PID=20689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:19,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:19,195] {logging_mixin.py:95} INFO - [2019-09-15 17:25:19,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:19,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:19,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:19,576] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:19,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:25:19,646] {scheduler_job.py:146} INFO - Started process (PID=20690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:24,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:24,657] {logging_mixin.py:95} INFO - [2019-09-15 17:25:24,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:25,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:25,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:25,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:25,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:25:25,107] {scheduler_job.py:146} INFO - Started process (PID=20692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:30,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:30,114] {logging_mixin.py:95} INFO - [2019-09-15 17:25:30,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:30,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:30,482] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:30,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:30,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:25:30,568] {scheduler_job.py:146} INFO - Started process (PID=20694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:35,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:35,579] {logging_mixin.py:95} INFO - [2019-09-15 17:25:35,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:35,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:35,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:35,953] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:35,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:25:36,024] {scheduler_job.py:146} INFO - Started process (PID=20695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:41,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:41,034] {logging_mixin.py:95} INFO - [2019-09-15 17:25:41,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:41,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:41,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:41,414] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:41,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:25:41,483] {scheduler_job.py:146} INFO - Started process (PID=20697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:46,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:46,493] {logging_mixin.py:95} INFO - [2019-09-15 17:25:46,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:46,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:46,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:46,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:46,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:25:46,940] {scheduler_job.py:146} INFO - Started process (PID=20698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:51,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:51,949] {logging_mixin.py:95} INFO - [2019-09-15 17:25:51,949] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:52,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:52,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:52,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:52,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:25:52,394] {scheduler_job.py:146} INFO - Started process (PID=20699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:57,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:25:57,404] {logging_mixin.py:95} INFO - [2019-09-15 17:25:57,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:57,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:25:57,776] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:25:57,785] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:25:57,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:25:57,848] {scheduler_job.py:146} INFO - Started process (PID=20701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:02,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:02,857] {logging_mixin.py:95} INFO - [2019-09-15 17:26:02,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:03,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:03,225] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:03,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:03,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:26:03,306] {scheduler_job.py:146} INFO - Started process (PID=20702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:08,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:08,312] {logging_mixin.py:95} INFO - [2019-09-15 17:26:08,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:08,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:08,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:08,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:08,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:26:08,766] {scheduler_job.py:146} INFO - Started process (PID=20703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:13,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:13,786] {logging_mixin.py:95} INFO - [2019-09-15 17:26:13,786] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:14,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:14,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:14,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:14,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:26:14,227] {scheduler_job.py:146} INFO - Started process (PID=20705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:19,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:19,239] {logging_mixin.py:95} INFO - [2019-09-15 17:26:19,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:19,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:19,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:19,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:19,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:26:19,686] {scheduler_job.py:146} INFO - Started process (PID=20706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:24,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:24,693] {logging_mixin.py:95} INFO - [2019-09-15 17:26:24,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:25,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:25,082] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:25,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:25,097] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:26:25,141] {scheduler_job.py:146} INFO - Started process (PID=20708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:30,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:30,153] {logging_mixin.py:95} INFO - [2019-09-15 17:26:30,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:30,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:30,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:30,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:30,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:26:30,592] {scheduler_job.py:146} INFO - Started process (PID=20710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:35,599] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:35,600] {logging_mixin.py:95} INFO - [2019-09-15 17:26:35,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:35,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:35,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:35,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:35,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:26:36,055] {scheduler_job.py:146} INFO - Started process (PID=20711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:41,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:41,063] {logging_mixin.py:95} INFO - [2019-09-15 17:26:41,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:41,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:41,434] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:41,443] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:41,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:26:41,511] {scheduler_job.py:146} INFO - Started process (PID=20713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:46,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:46,523] {logging_mixin.py:95} INFO - [2019-09-15 17:26:46,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:46,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:46,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:46,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:46,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:26:46,971] {scheduler_job.py:146} INFO - Started process (PID=20714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:51,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:51,977] {logging_mixin.py:95} INFO - [2019-09-15 17:26:51,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:52,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:52,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:52,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:52,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:26:52,434] {scheduler_job.py:146} INFO - Started process (PID=20715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:57,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:26:57,446] {logging_mixin.py:95} INFO - [2019-09-15 17:26:57,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:57,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:26:57,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:26:57,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:26:57,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:26:57,892] {scheduler_job.py:146} INFO - Started process (PID=20717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:02,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:02,904] {logging_mixin.py:95} INFO - [2019-09-15 17:27:02,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:03,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:03,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:03,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:03,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:27:03,352] {scheduler_job.py:146} INFO - Started process (PID=20718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:08,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:08,359] {logging_mixin.py:95} INFO - [2019-09-15 17:27:08,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:08,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:08,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:08,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:08,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:27:08,812] {scheduler_job.py:146} INFO - Started process (PID=20719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:13,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:13,821] {logging_mixin.py:95} INFO - [2019-09-15 17:27:13,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:14,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:14,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:14,195] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:14,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:27:14,272] {scheduler_job.py:146} INFO - Started process (PID=20721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:19,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:19,280] {logging_mixin.py:95} INFO - [2019-09-15 17:27:19,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:19,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:19,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:19,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:19,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:27:19,729] {scheduler_job.py:146} INFO - Started process (PID=20722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:24,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:24,738] {logging_mixin.py:95} INFO - [2019-09-15 17:27:24,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:25,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:25,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:25,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:25,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:27:25,192] {scheduler_job.py:146} INFO - Started process (PID=20724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:30,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:30,203] {logging_mixin.py:95} INFO - [2019-09-15 17:27:30,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:30,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:30,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:30,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:30,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:27:30,651] {scheduler_job.py:146} INFO - Started process (PID=20726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:35,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:35,659] {logging_mixin.py:95} INFO - [2019-09-15 17:27:35,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:36,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:36,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:36,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:36,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:27:36,098] {scheduler_job.py:146} INFO - Started process (PID=20727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:41,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:41,109] {logging_mixin.py:95} INFO - [2019-09-15 17:27:41,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:41,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:41,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:41,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:41,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:27:41,558] {scheduler_job.py:146} INFO - Started process (PID=20729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:46,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:46,566] {logging_mixin.py:95} INFO - [2019-09-15 17:27:46,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:46,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:46,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:46,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:46,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:27:47,014] {scheduler_job.py:146} INFO - Started process (PID=20730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:52,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:52,025] {logging_mixin.py:95} INFO - [2019-09-15 17:27:52,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:52,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:52,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:52,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:52,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:27:52,476] {scheduler_job.py:146} INFO - Started process (PID=20731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:57,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:27:57,488] {logging_mixin.py:95} INFO - [2019-09-15 17:27:57,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:57,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:27:57,860] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:27:57,869] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:27:57,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:27:57,942] {scheduler_job.py:146} INFO - Started process (PID=20733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:02,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:02,953] {logging_mixin.py:95} INFO - [2019-09-15 17:28:02,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:03,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:03,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:03,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:03,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:28:03,403] {scheduler_job.py:146} INFO - Started process (PID=20734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:08,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:08,411] {logging_mixin.py:95} INFO - [2019-09-15 17:28:08,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:08,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:08,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:08,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:08,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 17:28:08,865] {scheduler_job.py:146} INFO - Started process (PID=20735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:13,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:13,884] {logging_mixin.py:95} INFO - [2019-09-15 17:28:13,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:14,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:14,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:14,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:14,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:28:14,321] {scheduler_job.py:146} INFO - Started process (PID=20737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:19,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:19,328] {logging_mixin.py:95} INFO - [2019-09-15 17:28:19,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:19,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:19,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:19,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:19,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-15 17:28:19,876] {scheduler_job.py:146} INFO - Started process (PID=20738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:24,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:24,885] {logging_mixin.py:95} INFO - [2019-09-15 17:28:24,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:25,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:25,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:25,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:25,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:28:25,325] {scheduler_job.py:146} INFO - Started process (PID=20740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:30,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:30,334] {logging_mixin.py:95} INFO - [2019-09-15 17:28:30,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:30,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:30,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:30,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:30,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 17:28:30,875] {scheduler_job.py:146} INFO - Started process (PID=20742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:35,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:35,884] {logging_mixin.py:95} INFO - [2019-09-15 17:28:35,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:36,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:36,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:36,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:36,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 17:28:36,322] {scheduler_job.py:146} INFO - Started process (PID=20743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:41,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:41,330] {logging_mixin.py:95} INFO - [2019-09-15 17:28:41,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:41,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:41,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:41,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:41,708] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:28:41,772] {scheduler_job.py:146} INFO - Started process (PID=20745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:46,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:46,780] {logging_mixin.py:95} INFO - [2019-09-15 17:28:46,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:47,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:47,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:47,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:47,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:28:47,234] {scheduler_job.py:146} INFO - Started process (PID=20746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:52,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:52,245] {logging_mixin.py:95} INFO - [2019-09-15 17:28:52,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:52,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:52,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:52,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:52,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:28:52,692] {scheduler_job.py:146} INFO - Started process (PID=20747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:57,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:28:57,703] {logging_mixin.py:95} INFO - [2019-09-15 17:28:57,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:58,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:28:58,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:28:58,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:28:58,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:28:58,150] {scheduler_job.py:146} INFO - Started process (PID=20749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:03,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:03,157] {logging_mixin.py:95} INFO - [2019-09-15 17:29:03,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:03,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:03,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:03,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:03,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:29:03,608] {scheduler_job.py:146} INFO - Started process (PID=20750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:08,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:08,620] {logging_mixin.py:95} INFO - [2019-09-15 17:29:08,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:08,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:08,988] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:08,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:09,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:29:09,073] {scheduler_job.py:146} INFO - Started process (PID=20751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:14,079] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:14,091] {logging_mixin.py:95} INFO - [2019-09-15 17:29:14,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:14,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:14,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:14,471] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:14,477] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:29:14,533] {scheduler_job.py:146} INFO - Started process (PID=20753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:19,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:19,542] {logging_mixin.py:95} INFO - [2019-09-15 17:29:19,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:19,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:19,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:19,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:19,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:29:19,995] {scheduler_job.py:146} INFO - Started process (PID=20754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:25,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:25,002] {logging_mixin.py:95} INFO - [2019-09-15 17:29:25,001] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:25,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:25,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:25,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:25,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:29:25,455] {scheduler_job.py:146} INFO - Started process (PID=20756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:30,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:30,465] {logging_mixin.py:95} INFO - [2019-09-15 17:29:30,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:30,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:30,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:30,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:30,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:29:30,914] {scheduler_job.py:146} INFO - Started process (PID=20758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:35,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:35,922] {logging_mixin.py:95} INFO - [2019-09-15 17:29:35,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:36,275] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:36,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:36,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:36,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:29:36,372] {scheduler_job.py:146} INFO - Started process (PID=20759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:41,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:41,378] {logging_mixin.py:95} INFO - [2019-09-15 17:29:41,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:41,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:41,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:41,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:41,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 17:29:41,831] {scheduler_job.py:146} INFO - Started process (PID=20761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:46,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:46,838] {logging_mixin.py:95} INFO - [2019-09-15 17:29:46,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:47,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:47,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:47,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:47,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:29:47,289] {scheduler_job.py:146} INFO - Started process (PID=20762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:52,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:52,296] {logging_mixin.py:95} INFO - [2019-09-15 17:29:52,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:52,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:52,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:52,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:52,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:29:52,746] {scheduler_job.py:146} INFO - Started process (PID=20763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:57,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:29:57,754] {logging_mixin.py:95} INFO - [2019-09-15 17:29:57,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:58,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:29:58,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:29:58,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:29:58,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:29:58,196] {scheduler_job.py:146} INFO - Started process (PID=20766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:03,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:03,203] {logging_mixin.py:95} INFO - [2019-09-15 17:30:03,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:03,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:03,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:03,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:03,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:30:03,644] {scheduler_job.py:146} INFO - Started process (PID=20768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:08,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:08,652] {logging_mixin.py:95} INFO - [2019-09-15 17:30:08,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:09,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:09,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:09,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:09,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 17:30:09,193] {scheduler_job.py:146} INFO - Started process (PID=20769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:14,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:14,202] {logging_mixin.py:95} INFO - [2019-09-15 17:30:14,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:14,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:14,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:14,589] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:14,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:30:14,644] {scheduler_job.py:146} INFO - Started process (PID=20771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:19,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:19,652] {logging_mixin.py:95} INFO - [2019-09-15 17:30:19,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:20,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:20,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:20,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:20,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:30:20,101] {scheduler_job.py:146} INFO - Started process (PID=20772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:25,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:25,110] {logging_mixin.py:95} INFO - [2019-09-15 17:30:25,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:25,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:25,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:25,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:25,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:30:25,556] {scheduler_job.py:146} INFO - Started process (PID=20774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:30,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:30,564] {logging_mixin.py:95} INFO - [2019-09-15 17:30:30,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:30,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:30,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:30,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:30,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:30:31,019] {scheduler_job.py:146} INFO - Started process (PID=20776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:36,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:36,028] {logging_mixin.py:95} INFO - [2019-09-15 17:30:36,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:36,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:36,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:36,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:36,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:30:36,471] {scheduler_job.py:146} INFO - Started process (PID=20777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:41,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:41,479] {logging_mixin.py:95} INFO - [2019-09-15 17:30:41,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:41,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:41,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:41,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:41,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:30:41,930] {scheduler_job.py:146} INFO - Started process (PID=20779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:46,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:46,941] {logging_mixin.py:95} INFO - [2019-09-15 17:30:46,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:47,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:47,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:47,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:47,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:30:47,386] {scheduler_job.py:146} INFO - Started process (PID=20780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:52,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:52,394] {logging_mixin.py:95} INFO - [2019-09-15 17:30:52,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:52,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:52,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:52,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:52,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:30:52,836] {scheduler_job.py:146} INFO - Started process (PID=20781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:57,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:30:57,843] {logging_mixin.py:95} INFO - [2019-09-15 17:30:57,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:58,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:30:58,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:30:58,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:30:58,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:30:58,296] {scheduler_job.py:146} INFO - Started process (PID=20783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:03,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:03,307] {logging_mixin.py:95} INFO - [2019-09-15 17:31:03,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:03,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:03,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:03,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:03,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:31:03,749] {scheduler_job.py:146} INFO - Started process (PID=20784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:08,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:08,760] {logging_mixin.py:95} INFO - [2019-09-15 17:31:08,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:09,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:09,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:09,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:09,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:31:09,210] {scheduler_job.py:146} INFO - Started process (PID=20785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:14,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:14,222] {logging_mixin.py:95} INFO - [2019-09-15 17:31:14,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:14,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:14,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:14,606] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:14,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:31:14,666] {scheduler_job.py:146} INFO - Started process (PID=20787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:19,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:19,677] {logging_mixin.py:95} INFO - [2019-09-15 17:31:19,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:20,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:20,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:20,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:20,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:31:20,126] {scheduler_job.py:146} INFO - Started process (PID=20788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:25,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:25,136] {logging_mixin.py:95} INFO - [2019-09-15 17:31:25,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:25,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:25,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:25,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:25,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:31:25,582] {scheduler_job.py:146} INFO - Started process (PID=20790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:30,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:30,590] {logging_mixin.py:95} INFO - [2019-09-15 17:31:30,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:30,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:30,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:30,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:30,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:31:31,043] {scheduler_job.py:146} INFO - Started process (PID=20792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:36,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:36,052] {logging_mixin.py:95} INFO - [2019-09-15 17:31:36,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:36,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:36,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:36,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:36,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:31:36,496] {scheduler_job.py:146} INFO - Started process (PID=20793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:41,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:41,508] {logging_mixin.py:95} INFO - [2019-09-15 17:31:41,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:41,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:41,872] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:41,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:41,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:31:41,954] {scheduler_job.py:146} INFO - Started process (PID=20795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:46,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:46,962] {logging_mixin.py:95} INFO - [2019-09-15 17:31:46,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:47,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:47,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:47,346] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:47,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:31:47,407] {scheduler_job.py:146} INFO - Started process (PID=20796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:52,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:52,414] {logging_mixin.py:95} INFO - [2019-09-15 17:31:52,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:52,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:52,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:52,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:52,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:31:52,860] {scheduler_job.py:146} INFO - Started process (PID=20797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:57,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:31:57,871] {logging_mixin.py:95} INFO - [2019-09-15 17:31:57,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:58,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:31:58,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:31:58,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:31:58,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:31:58,310] {scheduler_job.py:146} INFO - Started process (PID=20799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:03,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:03,319] {logging_mixin.py:95} INFO - [2019-09-15 17:32:03,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:03,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:03,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:03,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:03,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:32:03,766] {scheduler_job.py:146} INFO - Started process (PID=20800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:08,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:08,777] {logging_mixin.py:95} INFO - [2019-09-15 17:32:08,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:09,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:09,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:09,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:09,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:32:09,221] {scheduler_job.py:146} INFO - Started process (PID=20801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:14,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:14,232] {logging_mixin.py:95} INFO - [2019-09-15 17:32:14,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:14,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:14,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:14,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:14,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:32:14,675] {scheduler_job.py:146} INFO - Started process (PID=20803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:19,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:19,685] {logging_mixin.py:95} INFO - [2019-09-15 17:32:19,685] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:20,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:20,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:20,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:20,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:32:20,130] {scheduler_job.py:146} INFO - Started process (PID=20804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:25,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:25,137] {logging_mixin.py:95} INFO - [2019-09-15 17:32:25,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:25,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:25,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:25,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:25,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 17:32:25,587] {scheduler_job.py:146} INFO - Started process (PID=20806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:30,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:30,596] {logging_mixin.py:95} INFO - [2019-09-15 17:32:30,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:30,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:30,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:30,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:30,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:32:31,050] {scheduler_job.py:146} INFO - Started process (PID=20808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:36,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:36,059] {logging_mixin.py:95} INFO - [2019-09-15 17:32:36,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:36,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:36,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:36,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:36,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:32:36,504] {scheduler_job.py:146} INFO - Started process (PID=20809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:41,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:41,516] {logging_mixin.py:95} INFO - [2019-09-15 17:32:41,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:41,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:41,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:41,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:41,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:32:41,960] {scheduler_job.py:146} INFO - Started process (PID=20811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:46,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:46,966] {logging_mixin.py:95} INFO - [2019-09-15 17:32:46,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:47,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:47,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:47,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:47,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:32:47,417] {scheduler_job.py:146} INFO - Started process (PID=20812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:52,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:52,427] {logging_mixin.py:95} INFO - [2019-09-15 17:32:52,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:52,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:52,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:52,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:52,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 17:32:52,879] {scheduler_job.py:146} INFO - Started process (PID=20813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:57,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:32:57,888] {logging_mixin.py:95} INFO - [2019-09-15 17:32:57,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:58,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:32:58,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:32:58,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:32:58,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:32:58,328] {scheduler_job.py:146} INFO - Started process (PID=20815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:03,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:03,337] {logging_mixin.py:95} INFO - [2019-09-15 17:33:03,337] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:03,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:03,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:03,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:03,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:33:03,788] {scheduler_job.py:146} INFO - Started process (PID=20816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:08,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:08,798] {logging_mixin.py:95} INFO - [2019-09-15 17:33:08,798] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:09,140] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:09,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:09,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:09,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:33:09,248] {scheduler_job.py:146} INFO - Started process (PID=20817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:14,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:14,256] {logging_mixin.py:95} INFO - [2019-09-15 17:33:14,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:14,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:14,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:14,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:14,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:33:14,708] {scheduler_job.py:146} INFO - Started process (PID=20819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:19,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:19,718] {logging_mixin.py:95} INFO - [2019-09-15 17:33:19,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:20,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:20,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:20,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:20,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:33:20,166] {scheduler_job.py:146} INFO - Started process (PID=20820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:25,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:25,176] {logging_mixin.py:95} INFO - [2019-09-15 17:33:25,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:25,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:25,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:25,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:25,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:33:25,628] {scheduler_job.py:146} INFO - Started process (PID=20822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:30,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:30,636] {logging_mixin.py:95} INFO - [2019-09-15 17:33:30,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:30,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:31,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:31,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:31,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:33:31,086] {scheduler_job.py:146} INFO - Started process (PID=20824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:36,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:36,093] {logging_mixin.py:95} INFO - [2019-09-15 17:33:36,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:36,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:36,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:36,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:36,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:33:36,543] {scheduler_job.py:146} INFO - Started process (PID=20825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:41,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:41,555] {logging_mixin.py:95} INFO - [2019-09-15 17:33:41,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:41,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:41,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:41,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:41,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:33:42,003] {scheduler_job.py:146} INFO - Started process (PID=20827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:47,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:47,014] {logging_mixin.py:95} INFO - [2019-09-15 17:33:47,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:47,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:47,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:47,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:47,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:33:47,466] {scheduler_job.py:146} INFO - Started process (PID=20828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:52,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:52,476] {logging_mixin.py:95} INFO - [2019-09-15 17:33:52,475] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:52,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:52,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:52,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:52,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:33:52,922] {scheduler_job.py:146} INFO - Started process (PID=20829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:57,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:33:57,934] {logging_mixin.py:95} INFO - [2019-09-15 17:33:57,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:58,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:33:58,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:33:58,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:33:58,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:33:58,386] {scheduler_job.py:146} INFO - Started process (PID=20831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:03,392] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:03,393] {logging_mixin.py:95} INFO - [2019-09-15 17:34:03,393] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:03,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:03,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:03,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:03,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:34:03,839] {scheduler_job.py:146} INFO - Started process (PID=20832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:08,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:08,848] {logging_mixin.py:95} INFO - [2019-09-15 17:34:08,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:09,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:09,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:09,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:09,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:34:09,293] {scheduler_job.py:146} INFO - Started process (PID=20833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:14,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:14,312] {logging_mixin.py:95} INFO - [2019-09-15 17:34:14,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:14,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:14,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:14,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:14,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:34:14,753] {scheduler_job.py:146} INFO - Started process (PID=20835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:19,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:19,762] {logging_mixin.py:95} INFO - [2019-09-15 17:34:19,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:20,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:20,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:20,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:20,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:34:20,209] {scheduler_job.py:146} INFO - Started process (PID=20836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:25,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:25,218] {logging_mixin.py:95} INFO - [2019-09-15 17:34:25,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:25,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:25,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:25,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:25,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:34:25,666] {scheduler_job.py:146} INFO - Started process (PID=20838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:30,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:30,673] {logging_mixin.py:95} INFO - [2019-09-15 17:34:30,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:31,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:31,044] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:31,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:31,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:34:31,127] {scheduler_job.py:146} INFO - Started process (PID=20840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:36,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:36,136] {logging_mixin.py:95} INFO - [2019-09-15 17:34:36,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:36,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:36,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:36,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:36,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:34:36,587] {scheduler_job.py:146} INFO - Started process (PID=20841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:41,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:41,598] {logging_mixin.py:95} INFO - [2019-09-15 17:34:41,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:41,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:41,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:41,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:41,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:34:42,042] {scheduler_job.py:146} INFO - Started process (PID=20843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:47,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:47,053] {logging_mixin.py:95} INFO - [2019-09-15 17:34:47,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:47,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:47,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:47,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:47,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:34:47,497] {scheduler_job.py:146} INFO - Started process (PID=20844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:52,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:52,508] {logging_mixin.py:95} INFO - [2019-09-15 17:34:52,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:52,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:52,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:52,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:52,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:34:52,952] {scheduler_job.py:146} INFO - Started process (PID=20845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:57,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:34:57,963] {logging_mixin.py:95} INFO - [2019-09-15 17:34:57,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:58,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:34:58,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:34:58,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:34:58,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:34:58,411] {scheduler_job.py:146} INFO - Started process (PID=20847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:03,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:03,419] {logging_mixin.py:95} INFO - [2019-09-15 17:35:03,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:03,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:03,795] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:03,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:03,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:35:03,873] {scheduler_job.py:146} INFO - Started process (PID=20848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:08,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:08,883] {logging_mixin.py:95} INFO - [2019-09-15 17:35:08,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:09,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:09,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:09,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:09,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:35:09,324] {scheduler_job.py:146} INFO - Started process (PID=20849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:14,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:14,331] {logging_mixin.py:95} INFO - [2019-09-15 17:35:14,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:14,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:14,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:14,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:14,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:35:14,775] {scheduler_job.py:146} INFO - Started process (PID=20851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:19,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:19,784] {logging_mixin.py:95} INFO - [2019-09-15 17:35:19,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:20,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:20,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:20,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:20,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:35:20,231] {scheduler_job.py:146} INFO - Started process (PID=20853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:25,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:25,238] {logging_mixin.py:95} INFO - [2019-09-15 17:35:25,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:25,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:25,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:25,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:25,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:35:25,685] {scheduler_job.py:146} INFO - Started process (PID=20855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:30,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:30,703] {logging_mixin.py:95} INFO - [2019-09-15 17:35:30,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:31,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:31,082] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:31,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:31,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:35:31,137] {scheduler_job.py:146} INFO - Started process (PID=20857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:36,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:36,143] {logging_mixin.py:95} INFO - [2019-09-15 17:35:36,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:36,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:36,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:36,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:36,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:35:36,596] {scheduler_job.py:146} INFO - Started process (PID=20858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:41,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:41,604] {logging_mixin.py:95} INFO - [2019-09-15 17:35:41,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:41,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:41,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:42,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:42,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 17:35:42,044] {scheduler_job.py:146} INFO - Started process (PID=20860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:47,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:47,055] {logging_mixin.py:95} INFO - [2019-09-15 17:35:47,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:47,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:47,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:47,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:47,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:35:47,486] {scheduler_job.py:146} INFO - Started process (PID=20861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:52,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:52,495] {logging_mixin.py:95} INFO - [2019-09-15 17:35:52,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:52,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:52,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:52,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:52,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:35:52,935] {scheduler_job.py:146} INFO - Started process (PID=20862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:57,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:35:57,943] {logging_mixin.py:95} INFO - [2019-09-15 17:35:57,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:58,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:35:58,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:35:58,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:35:58,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:35:58,378] {scheduler_job.py:146} INFO - Started process (PID=20864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:03,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:03,384] {logging_mixin.py:95} INFO - [2019-09-15 17:36:03,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:03,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:03,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:03,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:03,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 17:36:03,830] {scheduler_job.py:146} INFO - Started process (PID=20865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:08,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:08,839] {logging_mixin.py:95} INFO - [2019-09-15 17:36:08,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:09,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:09,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:09,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:09,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:36:09,283] {scheduler_job.py:146} INFO - Started process (PID=20866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:14,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:14,291] {logging_mixin.py:95} INFO - [2019-09-15 17:36:14,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:14,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:14,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:14,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:14,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:36:14,735] {scheduler_job.py:146} INFO - Started process (PID=20868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:19,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:19,742] {logging_mixin.py:95} INFO - [2019-09-15 17:36:19,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:20,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:20,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:20,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:20,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:36:20,185] {scheduler_job.py:146} INFO - Started process (PID=20869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:25,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:25,191] {logging_mixin.py:95} INFO - [2019-09-15 17:36:25,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:25,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:25,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:25,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:25,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:36:25,640] {scheduler_job.py:146} INFO - Started process (PID=20871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:30,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:30,657] {logging_mixin.py:95} INFO - [2019-09-15 17:36:30,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:30,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:31,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:31,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:31,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:36:31,098] {scheduler_job.py:146} INFO - Started process (PID=20873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:36,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:36,107] {logging_mixin.py:95} INFO - [2019-09-15 17:36:36,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:36,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:36,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:36,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:36,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:36:36,558] {scheduler_job.py:146} INFO - Started process (PID=20874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:41,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:41,568] {logging_mixin.py:95} INFO - [2019-09-15 17:36:41,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:41,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:41,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:41,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:41,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 17:36:42,020] {scheduler_job.py:146} INFO - Started process (PID=20876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:47,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:47,030] {logging_mixin.py:95} INFO - [2019-09-15 17:36:47,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:47,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:47,399] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:47,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:47,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 17:36:47,477] {scheduler_job.py:146} INFO - Started process (PID=20877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:52,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:52,483] {logging_mixin.py:95} INFO - [2019-09-15 17:36:52,483] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:52,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:52,853] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:52,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:52,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:36:52,932] {scheduler_job.py:146} INFO - Started process (PID=20878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:57,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:36:57,941] {logging_mixin.py:95} INFO - [2019-09-15 17:36:57,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:58,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:36:58,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:36:58,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:36:58,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:36:58,389] {scheduler_job.py:146} INFO - Started process (PID=20880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:03,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:03,396] {logging_mixin.py:95} INFO - [2019-09-15 17:37:03,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:03,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:03,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:03,779] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:03,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:37:03,839] {scheduler_job.py:146} INFO - Started process (PID=20882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:08,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:08,851] {logging_mixin.py:95} INFO - [2019-09-15 17:37:08,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:09,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:09,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:09,280] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:09,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 17:37:09,390] {scheduler_job.py:146} INFO - Started process (PID=20883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:14,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:14,398] {logging_mixin.py:95} INFO - [2019-09-15 17:37:14,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:14,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:14,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:14,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:14,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:37:14,841] {scheduler_job.py:146} INFO - Started process (PID=20885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:19,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:19,848] {logging_mixin.py:95} INFO - [2019-09-15 17:37:19,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:20,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:20,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:20,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:20,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:37:20,283] {scheduler_job.py:146} INFO - Started process (PID=20886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:25,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:25,291] {logging_mixin.py:95} INFO - [2019-09-15 17:37:25,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:25,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:25,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:25,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:25,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:37:25,729] {scheduler_job.py:146} INFO - Started process (PID=20889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:30,739] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:30,740] {logging_mixin.py:95} INFO - [2019-09-15 17:37:30,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:31,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:31,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:31,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:31,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 17:37:31,182] {scheduler_job.py:146} INFO - Started process (PID=20891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:36,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:36,190] {logging_mixin.py:95} INFO - [2019-09-15 17:37:36,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:36,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:36,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:36,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:36,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:37:36,633] {scheduler_job.py:146} INFO - Started process (PID=20892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:41,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:41,642] {logging_mixin.py:95} INFO - [2019-09-15 17:37:41,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:42,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:42,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:42,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:42,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:37:42,084] {scheduler_job.py:146} INFO - Started process (PID=20894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:47,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:47,096] {logging_mixin.py:95} INFO - [2019-09-15 17:37:47,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:47,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:47,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:47,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:47,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 17:37:47,535] {scheduler_job.py:146} INFO - Started process (PID=20895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:52,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:52,543] {logging_mixin.py:95} INFO - [2019-09-15 17:37:52,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:52,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:52,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:52,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:52,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:37:52,975] {scheduler_job.py:146} INFO - Started process (PID=20896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:57,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:37:57,983] {logging_mixin.py:95} INFO - [2019-09-15 17:37:57,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:58,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:37:58,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:37:58,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:37:58,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:37:58,433] {scheduler_job.py:146} INFO - Started process (PID=20898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:03,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:03,443] {logging_mixin.py:95} INFO - [2019-09-15 17:38:03,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:03,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:03,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:03,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:03,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 17:38:03,881] {scheduler_job.py:146} INFO - Started process (PID=20899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:08,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:08,888] {logging_mixin.py:95} INFO - [2019-09-15 17:38:08,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:09,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:09,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:09,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:09,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:38:09,328] {scheduler_job.py:146} INFO - Started process (PID=20900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:14,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:14,336] {logging_mixin.py:95} INFO - [2019-09-15 17:38:14,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:14,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:14,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:14,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:14,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:38:14,784] {scheduler_job.py:146} INFO - Started process (PID=20902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:19,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:19,793] {logging_mixin.py:95} INFO - [2019-09-15 17:38:19,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:20,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:20,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:20,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:20,189] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:38:20,236] {scheduler_job.py:146} INFO - Started process (PID=20903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:25,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:25,245] {logging_mixin.py:95} INFO - [2019-09-15 17:38:25,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:25,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:25,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:25,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:25,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:38:25,689] {scheduler_job.py:146} INFO - Started process (PID=20905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:30,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:30,701] {logging_mixin.py:95} INFO - [2019-09-15 17:38:30,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:31,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:31,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:31,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:31,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:38:31,141] {scheduler_job.py:146} INFO - Started process (PID=20907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:36,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:36,148] {logging_mixin.py:95} INFO - [2019-09-15 17:38:36,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:36,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:36,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:36,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:36,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:38:36,592] {scheduler_job.py:146} INFO - Started process (PID=20908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:41,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:41,601] {logging_mixin.py:95} INFO - [2019-09-15 17:38:41,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:41,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:42,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:42,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:42,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 17:38:42,137] {scheduler_job.py:146} INFO - Started process (PID=20910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:47,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:47,149] {logging_mixin.py:95} INFO - [2019-09-15 17:38:47,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:47,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:47,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:47,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:47,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:38:47,591] {scheduler_job.py:146} INFO - Started process (PID=20911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:52,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:52,598] {logging_mixin.py:95} INFO - [2019-09-15 17:38:52,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:52,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:52,992] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:53,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:53,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:38:53,044] {scheduler_job.py:146} INFO - Started process (PID=20912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:58,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:38:58,056] {logging_mixin.py:95} INFO - [2019-09-15 17:38:58,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:58,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:38:58,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:38:58,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:38:58,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-15 17:38:58,495] {scheduler_job.py:146} INFO - Started process (PID=20914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:03,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:03,501] {logging_mixin.py:95} INFO - [2019-09-15 17:39:03,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:03,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:03,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:03,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:03,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:39:03,947] {scheduler_job.py:146} INFO - Started process (PID=20915) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:08,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:08,955] {logging_mixin.py:95} INFO - [2019-09-15 17:39:08,955] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:09,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:09,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:09,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:09,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:39:09,400] {scheduler_job.py:146} INFO - Started process (PID=20916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:14,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:14,407] {logging_mixin.py:95} INFO - [2019-09-15 17:39:14,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:14,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:14,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:14,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:14,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 17:39:14,856] {scheduler_job.py:146} INFO - Started process (PID=20918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:19,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:19,865] {logging_mixin.py:95} INFO - [2019-09-15 17:39:19,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:20,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:20,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:20,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:20,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 17:39:20,312] {scheduler_job.py:146} INFO - Started process (PID=20919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:25,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:25,323] {logging_mixin.py:95} INFO - [2019-09-15 17:39:25,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:25,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:25,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:25,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:25,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:39:25,769] {scheduler_job.py:146} INFO - Started process (PID=20921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:30,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:30,779] {logging_mixin.py:95} INFO - [2019-09-15 17:39:30,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:31,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:31,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:31,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:31,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:39:31,218] {scheduler_job.py:146} INFO - Started process (PID=20923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:36,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:36,227] {logging_mixin.py:95} INFO - [2019-09-15 17:39:36,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:36,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:36,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:36,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:36,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 17:39:36,667] {scheduler_job.py:146} INFO - Started process (PID=20924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:41,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:41,676] {logging_mixin.py:95} INFO - [2019-09-15 17:39:41,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:42,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:42,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:42,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:42,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:39:42,118] {scheduler_job.py:146} INFO - Started process (PID=20926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:47,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:47,129] {logging_mixin.py:95} INFO - [2019-09-15 17:39:47,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:47,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:47,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:47,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:47,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:39:47,571] {scheduler_job.py:146} INFO - Started process (PID=20927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:52,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:52,581] {logging_mixin.py:95} INFO - [2019-09-15 17:39:52,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:52,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:52,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:52,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:52,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:39:53,023] {scheduler_job.py:146} INFO - Started process (PID=20930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:58,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:39:58,030] {logging_mixin.py:95} INFO - [2019-09-15 17:39:58,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:58,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:39:58,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:39:58,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:39:58,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:39:58,476] {scheduler_job.py:146} INFO - Started process (PID=20932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:03,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:03,486] {logging_mixin.py:95} INFO - [2019-09-15 17:40:03,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:03,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:03,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:03,914] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:03,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 17:40:04,030] {scheduler_job.py:146} INFO - Started process (PID=20933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:09,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:09,037] {logging_mixin.py:95} INFO - [2019-09-15 17:40:09,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:09,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:09,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:09,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:09,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:40:09,482] {scheduler_job.py:146} INFO - Started process (PID=20934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:14,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:14,499] {logging_mixin.py:95} INFO - [2019-09-15 17:40:14,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:14,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:14,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:14,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:14,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:40:14,943] {scheduler_job.py:146} INFO - Started process (PID=20936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:19,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:19,950] {logging_mixin.py:95} INFO - [2019-09-15 17:40:19,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:20,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:20,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:20,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:20,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:40:20,390] {scheduler_job.py:146} INFO - Started process (PID=20937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:25,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:25,401] {logging_mixin.py:95} INFO - [2019-09-15 17:40:25,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:25,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:25,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:25,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:25,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:40:25,844] {scheduler_job.py:146} INFO - Started process (PID=20939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:30,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:30,851] {logging_mixin.py:95} INFO - [2019-09-15 17:40:30,850] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:31,195] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:31,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:31,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:31,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:40:31,307] {scheduler_job.py:146} INFO - Started process (PID=20941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:36,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:36,316] {logging_mixin.py:95} INFO - [2019-09-15 17:40:36,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:36,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:36,678] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:36,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:36,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:40:36,776] {scheduler_job.py:146} INFO - Started process (PID=20942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:41,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:41,787] {logging_mixin.py:95} INFO - [2019-09-15 17:40:41,786] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:42,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:42,143] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:42,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:42,157] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 17:40:42,235] {scheduler_job.py:146} INFO - Started process (PID=20944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:47,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:47,241] {logging_mixin.py:95} INFO - [2019-09-15 17:40:47,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:47,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:47,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:47,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:47,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 17:40:47,691] {scheduler_job.py:146} INFO - Started process (PID=20945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:52,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:52,702] {logging_mixin.py:95} INFO - [2019-09-15 17:40:52,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:53,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:53,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:53,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:53,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 17:40:53,149] {scheduler_job.py:146} INFO - Started process (PID=20946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:58,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:40:58,158] {logging_mixin.py:95} INFO - [2019-09-15 17:40:58,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:58,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:40:58,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:40:58,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:40:58,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 17:40:58,604] {scheduler_job.py:146} INFO - Started process (PID=20948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:03,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:03,614] {logging_mixin.py:95} INFO - [2019-09-15 17:41:03,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:03,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:03,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:03,990] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:03,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:41:04,067] {scheduler_job.py:146} INFO - Started process (PID=20949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:09,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:09,073] {logging_mixin.py:95} INFO - [2019-09-15 17:41:09,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:09,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:09,440] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:09,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:09,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:41:09,525] {scheduler_job.py:146} INFO - Started process (PID=20950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:14,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:14,541] {logging_mixin.py:95} INFO - [2019-09-15 17:41:14,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:14,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:14,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:14,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:14,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:41:14,978] {scheduler_job.py:146} INFO - Started process (PID=20952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:19,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:19,989] {logging_mixin.py:95} INFO - [2019-09-15 17:41:19,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:20,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:20,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:20,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:20,393] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:41:20,427] {scheduler_job.py:146} INFO - Started process (PID=20953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:25,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:25,436] {logging_mixin.py:95} INFO - [2019-09-15 17:41:25,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:25,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:25,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:25,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:25,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 17:41:25,876] {scheduler_job.py:146} INFO - Started process (PID=20955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:30,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:30,887] {logging_mixin.py:95} INFO - [2019-09-15 17:41:30,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:31,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:31,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:31,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:31,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:41:31,331] {scheduler_job.py:146} INFO - Started process (PID=20957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:36,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:36,339] {logging_mixin.py:95} INFO - [2019-09-15 17:41:36,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:36,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:36,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:36,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:36,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 17:41:36,790] {scheduler_job.py:146} INFO - Started process (PID=20958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:41,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:41,802] {logging_mixin.py:95} INFO - [2019-09-15 17:41:41,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:42,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:42,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:42,182] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:42,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:41:42,246] {scheduler_job.py:146} INFO - Started process (PID=20960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:47,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:47,255] {logging_mixin.py:95} INFO - [2019-09-15 17:41:47,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:47,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:47,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:47,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:47,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-09-15 17:41:47,704] {scheduler_job.py:146} INFO - Started process (PID=20961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:52,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:52,712] {logging_mixin.py:95} INFO - [2019-09-15 17:41:52,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:53,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:53,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:53,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:53,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.360 seconds
[2019-09-15 17:41:53,166] {scheduler_job.py:146} INFO - Started process (PID=20962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:58,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:41:58,173] {logging_mixin.py:95} INFO - [2019-09-15 17:41:58,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:58,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:41:58,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:41:58,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:41:58,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.355 seconds
[2019-09-15 17:41:58,621] {scheduler_job.py:146} INFO - Started process (PID=20964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:03,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:03,629] {logging_mixin.py:95} INFO - [2019-09-15 17:42:03,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:03,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:03,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:03,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:03,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-15 17:42:04,077] {scheduler_job.py:146} INFO - Started process (PID=20965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:09,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:09,082] {logging_mixin.py:95} INFO - [2019-09-15 17:42:09,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:09,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:09,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:09,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:09,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 17:42:09,525] {scheduler_job.py:146} INFO - Started process (PID=20966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:14,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:14,531] {logging_mixin.py:95} INFO - [2019-09-15 17:42:14,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:14,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:14,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:14,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:14,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 17:42:15,065] {scheduler_job.py:146} INFO - Started process (PID=20968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:20,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:20,071] {logging_mixin.py:95} INFO - [2019-09-15 17:42:20,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:20,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:20,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:20,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:20,453] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:42:20,507] {scheduler_job.py:146} INFO - Started process (PID=20970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:25,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:25,515] {logging_mixin.py:95} INFO - [2019-09-15 17:42:25,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:25,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:25,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:25,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:25,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 17:42:26,058] {scheduler_job.py:146} INFO - Started process (PID=20973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:31,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:31,066] {logging_mixin.py:95} INFO - [2019-09-15 17:42:31,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:31,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:31,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:31,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:31,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.563 seconds
[2019-09-15 17:42:31,695] {scheduler_job.py:146} INFO - Started process (PID=20978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:36,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:36,705] {logging_mixin.py:95} INFO - [2019-09-15 17:42:36,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:37,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:37,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:37,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:37,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 17:42:37,233] {scheduler_job.py:146} INFO - Started process (PID=20980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:42,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:42,242] {logging_mixin.py:95} INFO - [2019-09-15 17:42:42,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:42,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:42,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:42,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:42,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:42:42,682] {scheduler_job.py:146} INFO - Started process (PID=20982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:47,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:47,693] {logging_mixin.py:95} INFO - [2019-09-15 17:42:47,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:48,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:48,148] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:48,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:48,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-09-15 17:42:48,236] {scheduler_job.py:146} INFO - Started process (PID=20983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:53,248] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:53,249] {logging_mixin.py:95} INFO - [2019-09-15 17:42:53,249] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:53,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:53,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:53,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:53,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:42:53,684] {scheduler_job.py:146} INFO - Started process (PID=20984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:58,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:42:58,692] {logging_mixin.py:95} INFO - [2019-09-15 17:42:58,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:59,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:42:59,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:42:59,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:42:59,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:42:59,132] {scheduler_job.py:146} INFO - Started process (PID=20986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:04,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:04,139] {logging_mixin.py:95} INFO - [2019-09-15 17:43:04,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:04,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:04,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:04,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:04,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 17:43:04,587] {scheduler_job.py:146} INFO - Started process (PID=20987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:09,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:09,597] {logging_mixin.py:95} INFO - [2019-09-15 17:43:09,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:09,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:09,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:09,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:09,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 17:43:10,045] {scheduler_job.py:146} INFO - Started process (PID=20989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:15,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:15,054] {logging_mixin.py:95} INFO - [2019-09-15 17:43:15,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:15,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:15,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:15,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:15,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:43:15,505] {scheduler_job.py:146} INFO - Started process (PID=20991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:20,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:20,511] {logging_mixin.py:95} INFO - [2019-09-15 17:43:20,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:20,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:20,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:20,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:20,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 17:43:20,964] {scheduler_job.py:146} INFO - Started process (PID=20992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:25,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:25,975] {logging_mixin.py:95} INFO - [2019-09-15 17:43:25,975] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:26,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:26,359] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:26,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:26,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:43:26,413] {scheduler_job.py:146} INFO - Started process (PID=20994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:31,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:31,421] {logging_mixin.py:95} INFO - [2019-09-15 17:43:31,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:31,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:31,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:31,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:31,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 17:43:31,852] {scheduler_job.py:146} INFO - Started process (PID=21000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:36,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:36,862] {logging_mixin.py:95} INFO - [2019-09-15 17:43:36,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:37,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:37,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:37,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:37,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 17:43:37,294] {scheduler_job.py:146} INFO - Started process (PID=21002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:42,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:42,303] {logging_mixin.py:95} INFO - [2019-09-15 17:43:42,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:42,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:42,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:42,700] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:42,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:43:42,739] {scheduler_job.py:146} INFO - Started process (PID=21004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:47,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:47,749] {logging_mixin.py:95} INFO - [2019-09-15 17:43:47,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:48,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:48,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:48,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:48,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 17:43:48,185] {scheduler_job.py:146} INFO - Started process (PID=21005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:53,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:53,196] {logging_mixin.py:95} INFO - [2019-09-15 17:43:53,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:53,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:53,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:53,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:53,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 17:43:53,734] {scheduler_job.py:146} INFO - Started process (PID=21006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:58,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:43:58,744] {logging_mixin.py:95} INFO - [2019-09-15 17:43:58,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:59,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:43:59,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:43:59,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:43:59,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:43:59,177] {scheduler_job.py:146} INFO - Started process (PID=21008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:04,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:04,187] {logging_mixin.py:95} INFO - [2019-09-15 17:44:04,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:04,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:04,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:04,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:04,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:44:04,631] {scheduler_job.py:146} INFO - Started process (PID=21009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:09,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:09,642] {logging_mixin.py:95} INFO - [2019-09-15 17:44:09,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:10,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:10,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:10,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:10,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 17:44:10,085] {scheduler_job.py:146} INFO - Started process (PID=21010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:15,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:15,096] {logging_mixin.py:95} INFO - [2019-09-15 17:44:15,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:15,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:15,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:15,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:15,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:44:15,531] {scheduler_job.py:146} INFO - Started process (PID=21012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:20,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:20,540] {logging_mixin.py:95} INFO - [2019-09-15 17:44:20,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:20,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:20,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:20,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:20,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:20,977] {scheduler_job.py:146} INFO - Started process (PID=21013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:25,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:25,984] {logging_mixin.py:95} INFO - [2019-09-15 17:44:25,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:26,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:26,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:26,376] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:26,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:44:26,429] {scheduler_job.py:146} INFO - Started process (PID=21015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:31,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:31,441] {logging_mixin.py:95} INFO - [2019-09-15 17:44:31,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:31,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:31,821] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:31,830] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:31,835] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:31,878] {scheduler_job.py:146} INFO - Started process (PID=21017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:36,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:36,887] {logging_mixin.py:95} INFO - [2019-09-15 17:44:36,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:37,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:37,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:37,280] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:37,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:37,327] {scheduler_job.py:146} INFO - Started process (PID=21018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:42,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:42,335] {logging_mixin.py:95} INFO - [2019-09-15 17:44:42,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:42,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:42,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:42,728] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:42,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:42,774] {scheduler_job.py:146} INFO - Started process (PID=21020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:47,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:47,782] {logging_mixin.py:95} INFO - [2019-09-15 17:44:47,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:48,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:48,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:48,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:48,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:48,219] {scheduler_job.py:146} INFO - Started process (PID=21021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:53,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:53,230] {logging_mixin.py:95} INFO - [2019-09-15 17:44:53,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:53,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:53,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:53,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:53,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:44:53,672] {scheduler_job.py:146} INFO - Started process (PID=21022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:58,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:44:58,682] {logging_mixin.py:95} INFO - [2019-09-15 17:44:58,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:59,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:44:59,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:44:59,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:44:59,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:44:59,121] {scheduler_job.py:146} INFO - Started process (PID=21024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:04,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:04,133] {logging_mixin.py:95} INFO - [2019-09-15 17:45:04,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:04,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:04,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:04,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:04,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:45:04,572] {scheduler_job.py:146} INFO - Started process (PID=21025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:09,581] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:09,582] {logging_mixin.py:95} INFO - [2019-09-15 17:45:09,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:09,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:09,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:09,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:09,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:45:10,024] {scheduler_job.py:146} INFO - Started process (PID=21026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:15,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:15,042] {logging_mixin.py:95} INFO - [2019-09-15 17:45:15,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:15,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:15,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:15,432] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:15,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:45:15,473] {scheduler_job.py:146} INFO - Started process (PID=21028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:20,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:20,482] {logging_mixin.py:95} INFO - [2019-09-15 17:45:20,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:20,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:20,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:20,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:20,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:45:20,920] {scheduler_job.py:146} INFO - Started process (PID=21029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:25,931] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:25,932] {logging_mixin.py:95} INFO - [2019-09-15 17:45:25,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:26,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:26,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:26,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:26,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:45:26,366] {scheduler_job.py:146} INFO - Started process (PID=21031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:31,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:31,375] {logging_mixin.py:95} INFO - [2019-09-15 17:45:31,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:31,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:31,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:31,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:31,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:45:31,813] {scheduler_job.py:146} INFO - Started process (PID=21033) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:36,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:36,822] {logging_mixin.py:95} INFO - [2019-09-15 17:45:36,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:37,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:37,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:37,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:37,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 17:45:37,264] {scheduler_job.py:146} INFO - Started process (PID=21034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:42,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:42,275] {logging_mixin.py:95} INFO - [2019-09-15 17:45:42,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:42,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:42,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:42,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:42,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:45:42,707] {scheduler_job.py:146} INFO - Started process (PID=21036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:47,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:47,713] {logging_mixin.py:95} INFO - [2019-09-15 17:45:47,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:48,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:48,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:48,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:48,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:45:48,154] {scheduler_job.py:146} INFO - Started process (PID=21037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:53,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:53,163] {logging_mixin.py:95} INFO - [2019-09-15 17:45:53,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:53,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:53,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:53,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:53,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:45:53,598] {scheduler_job.py:146} INFO - Started process (PID=21038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:58,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:45:58,608] {logging_mixin.py:95} INFO - [2019-09-15 17:45:58,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:58,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:45:58,988] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:45:58,996] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:45:59,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:45:59,054] {scheduler_job.py:146} INFO - Started process (PID=21040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:04,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:04,064] {logging_mixin.py:95} INFO - [2019-09-15 17:46:04,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:04,422] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:04,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:04,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:04,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:46:04,502] {scheduler_job.py:146} INFO - Started process (PID=21041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:09,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:09,509] {logging_mixin.py:95} INFO - [2019-09-15 17:46:09,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:09,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:09,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:09,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:09,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:46:09,952] {scheduler_job.py:146} INFO - Started process (PID=21042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:14,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:14,963] {logging_mixin.py:95} INFO - [2019-09-15 17:46:14,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:15,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:15,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:15,353] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:15,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:46:15,398] {scheduler_job.py:146} INFO - Started process (PID=21044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:20,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:20,409] {logging_mixin.py:95} INFO - [2019-09-15 17:46:20,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:20,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:20,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:20,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:20,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:46:20,846] {scheduler_job.py:146} INFO - Started process (PID=21045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:25,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:25,856] {logging_mixin.py:95} INFO - [2019-09-15 17:46:25,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:26,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:26,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:26,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:26,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:46:26,292] {scheduler_job.py:146} INFO - Started process (PID=21047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:31,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:31,303] {logging_mixin.py:95} INFO - [2019-09-15 17:46:31,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:31,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:31,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:31,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:31,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:46:31,748] {scheduler_job.py:146} INFO - Started process (PID=21049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:36,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:36,756] {logging_mixin.py:95} INFO - [2019-09-15 17:46:36,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:37,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:37,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:37,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:37,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:46:37,195] {scheduler_job.py:146} INFO - Started process (PID=21050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:42,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:42,204] {logging_mixin.py:95} INFO - [2019-09-15 17:46:42,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:42,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:42,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:42,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:42,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:46:42,649] {scheduler_job.py:146} INFO - Started process (PID=21052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:47,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:47,661] {logging_mixin.py:95} INFO - [2019-09-15 17:46:47,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:48,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:48,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:48,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:48,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:46:48,099] {scheduler_job.py:146} INFO - Started process (PID=21053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:53,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:53,109] {logging_mixin.py:95} INFO - [2019-09-15 17:46:53,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:53,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:53,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:53,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:53,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:46:53,546] {scheduler_job.py:146} INFO - Started process (PID=21054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:58,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:46:58,554] {logging_mixin.py:95} INFO - [2019-09-15 17:46:58,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:58,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:46:58,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:46:58,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:46:58,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 17:46:58,992] {scheduler_job.py:146} INFO - Started process (PID=21056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:04,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:04,003] {logging_mixin.py:95} INFO - [2019-09-15 17:47:04,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:04,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:04,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:04,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:04,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:47:04,444] {scheduler_job.py:146} INFO - Started process (PID=21057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:09,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:09,454] {logging_mixin.py:95} INFO - [2019-09-15 17:47:09,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:09,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:09,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:09,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:09,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:47:09,892] {scheduler_job.py:146} INFO - Started process (PID=21058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:14,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:14,901] {logging_mixin.py:95} INFO - [2019-09-15 17:47:14,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:15,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:15,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:15,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:15,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:47:15,344] {scheduler_job.py:146} INFO - Started process (PID=21060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:20,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:20,351] {logging_mixin.py:95} INFO - [2019-09-15 17:47:20,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:20,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:20,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:20,740] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:20,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:47:20,793] {scheduler_job.py:146} INFO - Started process (PID=21061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:25,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:25,803] {logging_mixin.py:95} INFO - [2019-09-15 17:47:25,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:26,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:26,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:26,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:26,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:47:26,252] {scheduler_job.py:146} INFO - Started process (PID=21063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:31,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:31,261] {logging_mixin.py:95} INFO - [2019-09-15 17:47:31,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:31,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:31,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:31,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:31,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:47:31,704] {scheduler_job.py:146} INFO - Started process (PID=21065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:36,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:36,713] {logging_mixin.py:95} INFO - [2019-09-15 17:47:36,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:37,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:37,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:37,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:37,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:47:37,153] {scheduler_job.py:146} INFO - Started process (PID=21066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:42,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:42,161] {logging_mixin.py:95} INFO - [2019-09-15 17:47:42,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:42,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:42,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:42,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:42,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:47:42,606] {scheduler_job.py:146} INFO - Started process (PID=21068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:47,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:47,616] {logging_mixin.py:95} INFO - [2019-09-15 17:47:47,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:47,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:47,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:48,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:48,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:47:48,061] {scheduler_job.py:146} INFO - Started process (PID=21069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:53,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:53,069] {logging_mixin.py:95} INFO - [2019-09-15 17:47:53,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:53,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:53,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:53,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:53,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:47:53,512] {scheduler_job.py:146} INFO - Started process (PID=21070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:58,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:47:58,520] {logging_mixin.py:95} INFO - [2019-09-15 17:47:58,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:58,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:47:58,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:47:58,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:47:58,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:47:58,961] {scheduler_job.py:146} INFO - Started process (PID=21072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:03,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:03,967] {logging_mixin.py:95} INFO - [2019-09-15 17:48:03,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:04,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:04,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:04,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:04,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 17:48:04,413] {scheduler_job.py:146} INFO - Started process (PID=21073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:09,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:09,421] {logging_mixin.py:95} INFO - [2019-09-15 17:48:09,420] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:09,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:09,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:09,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:09,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:48:09,866] {scheduler_job.py:146} INFO - Started process (PID=21074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:14,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:14,877] {logging_mixin.py:95} INFO - [2019-09-15 17:48:14,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:15,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:15,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:15,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:15,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:48:15,312] {scheduler_job.py:146} INFO - Started process (PID=21076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:20,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:20,323] {logging_mixin.py:95} INFO - [2019-09-15 17:48:20,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:20,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:20,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:20,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:20,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:48:20,759] {scheduler_job.py:146} INFO - Started process (PID=21077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:25,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:25,768] {logging_mixin.py:95} INFO - [2019-09-15 17:48:25,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:26,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:26,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:26,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:26,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 17:48:26,206] {scheduler_job.py:146} INFO - Started process (PID=21079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:31,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:31,213] {logging_mixin.py:95} INFO - [2019-09-15 17:48:31,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:31,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:31,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:31,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:31,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:48:31,654] {scheduler_job.py:146} INFO - Started process (PID=21081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:36,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:36,663] {logging_mixin.py:95} INFO - [2019-09-15 17:48:36,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:37,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:37,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:37,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:37,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:48:37,102] {scheduler_job.py:146} INFO - Started process (PID=21082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:42,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:42,109] {logging_mixin.py:95} INFO - [2019-09-15 17:48:42,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:42,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:42,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:42,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:42,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 17:48:42,551] {scheduler_job.py:146} INFO - Started process (PID=21084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:47,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:47,561] {logging_mixin.py:95} INFO - [2019-09-15 17:48:47,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:47,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:47,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:47,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:47,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:48:47,997] {scheduler_job.py:146} INFO - Started process (PID=21086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:53,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:53,004] {logging_mixin.py:95} INFO - [2019-09-15 17:48:53,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:53,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:53,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:53,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:53,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:48:53,452] {scheduler_job.py:146} INFO - Started process (PID=21087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:58,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:48:58,463] {logging_mixin.py:95} INFO - [2019-09-15 17:48:58,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:58,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:48:58,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:48:58,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:48:58,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:48:58,895] {scheduler_job.py:146} INFO - Started process (PID=21089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:03,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:03,906] {logging_mixin.py:95} INFO - [2019-09-15 17:49:03,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:04,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:04,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:04,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:04,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:49:04,345] {scheduler_job.py:146} INFO - Started process (PID=21090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:09,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:09,353] {logging_mixin.py:95} INFO - [2019-09-15 17:49:09,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:09,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:09,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:09,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:09,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:49:09,790] {scheduler_job.py:146} INFO - Started process (PID=21091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:14,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:14,803] {logging_mixin.py:95} INFO - [2019-09-15 17:49:14,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:15,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:15,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:15,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:15,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:49:15,251] {scheduler_job.py:146} INFO - Started process (PID=21093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:20,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:20,262] {logging_mixin.py:95} INFO - [2019-09-15 17:49:20,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:20,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:20,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:20,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:20,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:49:20,724] {scheduler_job.py:146} INFO - Started process (PID=21094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:25,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:25,736] {logging_mixin.py:95} INFO - [2019-09-15 17:49:25,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:26,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:26,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:26,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:26,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:49:26,189] {scheduler_job.py:146} INFO - Started process (PID=21099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:31,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:31,212] {logging_mixin.py:95} INFO - [2019-09-15 17:49:31,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:31,571] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:31,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:31,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:31,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:49:31,654] {scheduler_job.py:146} INFO - Started process (PID=21101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:36,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:36,666] {logging_mixin.py:95} INFO - [2019-09-15 17:49:36,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:37,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:37,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:37,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:37,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:49:37,126] {scheduler_job.py:146} INFO - Started process (PID=21102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:42,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:42,141] {logging_mixin.py:95} INFO - [2019-09-15 17:49:42,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:42,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:42,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:42,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:42,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:49:42,589] {scheduler_job.py:146} INFO - Started process (PID=21104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:47,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:47,603] {logging_mixin.py:95} INFO - [2019-09-15 17:49:47,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:47,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:47,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:47,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:47,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:49:48,058] {scheduler_job.py:146} INFO - Started process (PID=21105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:53,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:53,071] {logging_mixin.py:95} INFO - [2019-09-15 17:49:53,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:53,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:53,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:53,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:53,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:49:53,527] {scheduler_job.py:146} INFO - Started process (PID=21106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:58,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:49:58,544] {logging_mixin.py:95} INFO - [2019-09-15 17:49:58,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:58,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:49:58,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:49:58,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:49:58,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:49:58,994] {scheduler_job.py:146} INFO - Started process (PID=21108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:04,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:04,007] {logging_mixin.py:95} INFO - [2019-09-15 17:50:04,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:04,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:04,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:04,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:04,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:50:04,456] {scheduler_job.py:146} INFO - Started process (PID=21109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:09,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:09,470] {logging_mixin.py:95} INFO - [2019-09-15 17:50:09,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:09,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:09,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:09,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:09,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:50:09,923] {scheduler_job.py:146} INFO - Started process (PID=21110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:14,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:14,950] {logging_mixin.py:95} INFO - [2019-09-15 17:50:14,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:15,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:15,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:15,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:15,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 17:50:15,390] {scheduler_job.py:146} INFO - Started process (PID=21112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:20,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:20,403] {logging_mixin.py:95} INFO - [2019-09-15 17:50:20,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:20,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:20,783] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:20,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:20,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:50:20,856] {scheduler_job.py:146} INFO - Started process (PID=21113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:25,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:25,869] {logging_mixin.py:95} INFO - [2019-09-15 17:50:25,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:26,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:26,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:26,257] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:26,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:50:26,324] {scheduler_job.py:146} INFO - Started process (PID=21115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:31,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:31,336] {logging_mixin.py:95} INFO - [2019-09-15 17:50:31,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:31,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:31,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:31,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:31,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:50:31,795] {scheduler_job.py:146} INFO - Started process (PID=21117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:36,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:36,808] {logging_mixin.py:95} INFO - [2019-09-15 17:50:36,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:37,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:37,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:37,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:37,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:50:37,263] {scheduler_job.py:146} INFO - Started process (PID=21118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:42,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:42,278] {logging_mixin.py:95} INFO - [2019-09-15 17:50:42,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:42,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:42,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:42,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:42,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:50:42,734] {scheduler_job.py:146} INFO - Started process (PID=21120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:47,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:47,743] {logging_mixin.py:95} INFO - [2019-09-15 17:50:47,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:48,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:48,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:48,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:48,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:50:48,194] {scheduler_job.py:146} INFO - Started process (PID=21121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:53,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:53,207] {logging_mixin.py:95} INFO - [2019-09-15 17:50:53,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:53,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:53,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:53,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:53,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:50:53,667] {scheduler_job.py:146} INFO - Started process (PID=21122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:58,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:50:58,683] {logging_mixin.py:95} INFO - [2019-09-15 17:50:58,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:59,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:50:59,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:50:59,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:50:59,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:50:59,135] {scheduler_job.py:146} INFO - Started process (PID=21124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:04,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:04,142] {logging_mixin.py:95} INFO - [2019-09-15 17:51:04,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:04,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:04,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:04,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:04,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:51:04,606] {scheduler_job.py:146} INFO - Started process (PID=21125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:09,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:09,622] {logging_mixin.py:95} INFO - [2019-09-15 17:51:09,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:09,985] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:10,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:10,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:10,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 17:51:10,075] {scheduler_job.py:146} INFO - Started process (PID=21126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:15,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:15,098] {logging_mixin.py:95} INFO - [2019-09-15 17:51:15,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:15,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:15,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:15,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:15,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:51:15,543] {scheduler_job.py:146} INFO - Started process (PID=21128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:20,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:20,559] {logging_mixin.py:95} INFO - [2019-09-15 17:51:20,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:20,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:20,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:20,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:20,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:51:21,009] {scheduler_job.py:146} INFO - Started process (PID=21129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:26,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:26,022] {logging_mixin.py:95} INFO - [2019-09-15 17:51:26,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:26,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:26,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:26,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:26,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:51:26,478] {scheduler_job.py:146} INFO - Started process (PID=21131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:31,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:31,497] {logging_mixin.py:95} INFO - [2019-09-15 17:51:31,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:31,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:31,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:31,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:31,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:51:31,947] {scheduler_job.py:146} INFO - Started process (PID=21133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:36,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:36,962] {logging_mixin.py:95} INFO - [2019-09-15 17:51:36,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:37,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:37,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:37,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:37,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:51:37,415] {scheduler_job.py:146} INFO - Started process (PID=21134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:42,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:42,431] {logging_mixin.py:95} INFO - [2019-09-15 17:51:42,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:42,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:42,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:42,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:42,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:51:42,880] {scheduler_job.py:146} INFO - Started process (PID=21136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:47,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:47,890] {logging_mixin.py:95} INFO - [2019-09-15 17:51:47,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:48,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:48,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:48,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:48,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:51:48,342] {scheduler_job.py:146} INFO - Started process (PID=21137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:53,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:53,356] {logging_mixin.py:95} INFO - [2019-09-15 17:51:53,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:53,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:53,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:53,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:53,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:51:53,815] {scheduler_job.py:146} INFO - Started process (PID=21138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:58,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:51:58,826] {logging_mixin.py:95} INFO - [2019-09-15 17:51:58,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:59,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:51:59,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:51:59,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:51:59,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:51:59,284] {scheduler_job.py:146} INFO - Started process (PID=21140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:04,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:04,297] {logging_mixin.py:95} INFO - [2019-09-15 17:52:04,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:04,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:04,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:04,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:04,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:52:04,743] {scheduler_job.py:146} INFO - Started process (PID=21141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:09,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:09,757] {logging_mixin.py:95} INFO - [2019-09-15 17:52:09,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:10,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:10,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:10,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:10,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:52:10,215] {scheduler_job.py:146} INFO - Started process (PID=21142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:15,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:15,226] {logging_mixin.py:95} INFO - [2019-09-15 17:52:15,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:15,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:15,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:15,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:15,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:52:15,679] {scheduler_job.py:146} INFO - Started process (PID=21144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:20,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:20,694] {logging_mixin.py:95} INFO - [2019-09-15 17:52:20,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:21,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:21,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:21,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:21,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:52:21,139] {scheduler_job.py:146} INFO - Started process (PID=21145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:26,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:26,151] {logging_mixin.py:95} INFO - [2019-09-15 17:52:26,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:26,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:26,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:26,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:26,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:52:26,617] {scheduler_job.py:146} INFO - Started process (PID=21147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:31,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:31,631] {logging_mixin.py:95} INFO - [2019-09-15 17:52:31,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:31,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:32,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:32,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:32,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:52:32,084] {scheduler_job.py:146} INFO - Started process (PID=21149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:37,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:37,107] {logging_mixin.py:95} INFO - [2019-09-15 17:52:37,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:37,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:37,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:37,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:37,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 17:52:37,554] {scheduler_job.py:146} INFO - Started process (PID=21150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:42,564] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:42,565] {logging_mixin.py:95} INFO - [2019-09-15 17:52:42,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:42,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:42,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:42,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:42,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:52:43,026] {scheduler_job.py:146} INFO - Started process (PID=21152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:48,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:48,044] {logging_mixin.py:95} INFO - [2019-09-15 17:52:48,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:48,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:48,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:48,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:48,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:52:48,486] {scheduler_job.py:146} INFO - Started process (PID=21153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:53,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:53,504] {logging_mixin.py:95} INFO - [2019-09-15 17:52:53,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:53,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:53,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:53,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:53,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:52:53,956] {scheduler_job.py:146} INFO - Started process (PID=21154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:58,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:52:58,965] {logging_mixin.py:95} INFO - [2019-09-15 17:52:58,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:59,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:52:59,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:52:59,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:52:59,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:52:59,428] {scheduler_job.py:146} INFO - Started process (PID=21156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:04,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:04,437] {logging_mixin.py:95} INFO - [2019-09-15 17:53:04,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:04,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:04,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:04,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:04,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:53:04,895] {scheduler_job.py:146} INFO - Started process (PID=21157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:09,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:09,910] {logging_mixin.py:95} INFO - [2019-09-15 17:53:09,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:10,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:10,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:10,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:10,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:53:10,364] {scheduler_job.py:146} INFO - Started process (PID=21158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:15,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:15,379] {logging_mixin.py:95} INFO - [2019-09-15 17:53:15,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:15,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:15,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:15,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:15,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:53:15,833] {scheduler_job.py:146} INFO - Started process (PID=21160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:20,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:20,844] {logging_mixin.py:95} INFO - [2019-09-15 17:53:20,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:21,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:21,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:21,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:21,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:53:21,306] {scheduler_job.py:146} INFO - Started process (PID=21161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:26,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:26,324] {logging_mixin.py:95} INFO - [2019-09-15 17:53:26,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:26,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:26,702] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:26,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:26,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:53:26,770] {scheduler_job.py:146} INFO - Started process (PID=21163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:31,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:31,784] {logging_mixin.py:95} INFO - [2019-09-15 17:53:31,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:32,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:32,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:32,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:32,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:53:32,241] {scheduler_job.py:146} INFO - Started process (PID=21165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:37,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:37,258] {logging_mixin.py:95} INFO - [2019-09-15 17:53:37,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:37,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:37,638] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:37,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:37,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:53:37,710] {scheduler_job.py:146} INFO - Started process (PID=21166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:42,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:42,727] {logging_mixin.py:95} INFO - [2019-09-15 17:53:42,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:43,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:43,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:43,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:43,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 17:53:43,168] {scheduler_job.py:146} INFO - Started process (PID=21168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:48,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:48,186] {logging_mixin.py:95} INFO - [2019-09-15 17:53:48,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:48,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:48,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:48,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:48,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:53:48,633] {scheduler_job.py:146} INFO - Started process (PID=21169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:53,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:53,646] {logging_mixin.py:95} INFO - [2019-09-15 17:53:53,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:54,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:54,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:54,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:54,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:53:54,100] {scheduler_job.py:146} INFO - Started process (PID=21170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:59,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:53:59,118] {logging_mixin.py:95} INFO - [2019-09-15 17:53:59,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:59,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:53:59,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:53:59,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:53:59,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 17:53:59,557] {scheduler_job.py:146} INFO - Started process (PID=21172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:04,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:04,571] {logging_mixin.py:95} INFO - [2019-09-15 17:54:04,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:04,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:04,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:04,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:04,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:54:05,026] {scheduler_job.py:146} INFO - Started process (PID=21173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:10,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:10,043] {logging_mixin.py:95} INFO - [2019-09-15 17:54:10,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:10,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:10,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:10,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:10,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:54:10,497] {scheduler_job.py:146} INFO - Started process (PID=21174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:15,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:15,508] {logging_mixin.py:95} INFO - [2019-09-15 17:54:15,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:15,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:15,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:15,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:15,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:54:15,958] {scheduler_job.py:146} INFO - Started process (PID=21176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:20,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:20,973] {logging_mixin.py:95} INFO - [2019-09-15 17:54:20,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:21,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:21,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:21,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:21,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:54:21,424] {scheduler_job.py:146} INFO - Started process (PID=21177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:26,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:26,433] {logging_mixin.py:95} INFO - [2019-09-15 17:54:26,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:26,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:26,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:26,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:26,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:54:26,890] {scheduler_job.py:146} INFO - Started process (PID=21179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:31,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:31,914] {logging_mixin.py:95} INFO - [2019-09-15 17:54:31,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:32,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:32,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:32,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:32,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:54:32,355] {scheduler_job.py:146} INFO - Started process (PID=21181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:37,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:37,364] {logging_mixin.py:95} INFO - [2019-09-15 17:54:37,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:37,720] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:37,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:37,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:37,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:54:37,828] {scheduler_job.py:146} INFO - Started process (PID=21182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:42,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:42,844] {logging_mixin.py:95} INFO - [2019-09-15 17:54:42,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:43,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:43,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:43,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:43,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 17:54:43,295] {scheduler_job.py:146} INFO - Started process (PID=21184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:48,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:48,308] {logging_mixin.py:95} INFO - [2019-09-15 17:54:48,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:48,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:48,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:48,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:48,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:54:48,768] {scheduler_job.py:146} INFO - Started process (PID=21185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:53,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:53,782] {logging_mixin.py:95} INFO - [2019-09-15 17:54:53,782] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:54,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:54,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:54,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:54,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:54:54,236] {scheduler_job.py:146} INFO - Started process (PID=21186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:59,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:54:59,253] {logging_mixin.py:95} INFO - [2019-09-15 17:54:59,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:59,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:54:59,623] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:54:59,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:54:59,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:54:59,706] {scheduler_job.py:146} INFO - Started process (PID=21188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:04,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:04,721] {logging_mixin.py:95} INFO - [2019-09-15 17:55:04,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:05,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:05,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:05,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:05,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:55:05,173] {scheduler_job.py:146} INFO - Started process (PID=21189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:10,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:10,183] {logging_mixin.py:95} INFO - [2019-09-15 17:55:10,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:10,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:10,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:10,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:10,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:55:10,647] {scheduler_job.py:146} INFO - Started process (PID=21190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:15,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:15,673] {logging_mixin.py:95} INFO - [2019-09-15 17:55:15,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:16,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:16,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:16,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:16,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 17:55:16,118] {scheduler_job.py:146} INFO - Started process (PID=21192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:21,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:21,130] {logging_mixin.py:95} INFO - [2019-09-15 17:55:21,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:21,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:21,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:21,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:21,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:55:21,593] {scheduler_job.py:146} INFO - Started process (PID=21193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:26,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:26,606] {logging_mixin.py:95} INFO - [2019-09-15 17:55:26,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:26,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:26,986] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:26,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:27,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 17:55:27,056] {scheduler_job.py:146} INFO - Started process (PID=21195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:32,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:32,066] {logging_mixin.py:95} INFO - [2019-09-15 17:55:32,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:32,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:32,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:32,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:32,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:55:32,523] {scheduler_job.py:146} INFO - Started process (PID=21197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:37,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:37,535] {logging_mixin.py:95} INFO - [2019-09-15 17:55:37,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:37,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:37,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:37,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:37,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:55:37,994] {scheduler_job.py:146} INFO - Started process (PID=21198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:43,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:43,009] {logging_mixin.py:95} INFO - [2019-09-15 17:55:43,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:43,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:43,396] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:43,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:43,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:55:43,471] {scheduler_job.py:146} INFO - Started process (PID=21200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:48,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:48,484] {logging_mixin.py:95} INFO - [2019-09-15 17:55:48,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:48,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:48,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:48,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:48,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:55:48,938] {scheduler_job.py:146} INFO - Started process (PID=21201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:53,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:53,951] {logging_mixin.py:95} INFO - [2019-09-15 17:55:53,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:54,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:54,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:54,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:54,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:55:54,414] {scheduler_job.py:146} INFO - Started process (PID=21202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:59,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:55:59,429] {logging_mixin.py:95} INFO - [2019-09-15 17:55:59,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:59,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:55:59,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:55:59,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:55:59,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:55:59,876] {scheduler_job.py:146} INFO - Started process (PID=21204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:04,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:04,884] {logging_mixin.py:95} INFO - [2019-09-15 17:56:04,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:05,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:05,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:05,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:05,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:56:05,347] {scheduler_job.py:146} INFO - Started process (PID=21205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:10,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:10,357] {logging_mixin.py:95} INFO - [2019-09-15 17:56:10,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:10,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:10,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:10,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:10,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:56:10,816] {scheduler_job.py:146} INFO - Started process (PID=21206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:15,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:15,837] {logging_mixin.py:95} INFO - [2019-09-15 17:56:15,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:16,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:16,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:16,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:16,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:56:16,286] {scheduler_job.py:146} INFO - Started process (PID=21208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:21,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:21,297] {logging_mixin.py:95} INFO - [2019-09-15 17:56:21,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:21,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:21,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:21,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:21,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:56:21,758] {scheduler_job.py:146} INFO - Started process (PID=21209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:26,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:26,771] {logging_mixin.py:95} INFO - [2019-09-15 17:56:26,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:27,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:27,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:27,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:27,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:56:27,225] {scheduler_job.py:146} INFO - Started process (PID=21211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:32,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:32,249] {logging_mixin.py:95} INFO - [2019-09-15 17:56:32,249] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:32,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:32,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:32,635] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:32,640] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:56:32,696] {scheduler_job.py:146} INFO - Started process (PID=21213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:37,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:37,712] {logging_mixin.py:95} INFO - [2019-09-15 17:56:37,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:38,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:38,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:38,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:38,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:56:38,157] {scheduler_job.py:146} INFO - Started process (PID=21214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:43,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:43,175] {logging_mixin.py:95} INFO - [2019-09-15 17:56:43,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:43,535] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:43,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:43,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:43,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 17:56:43,622] {scheduler_job.py:146} INFO - Started process (PID=21216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:48,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:48,638] {logging_mixin.py:95} INFO - [2019-09-15 17:56:48,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:48,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:49,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:49,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:49,036] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:56:49,085] {scheduler_job.py:146} INFO - Started process (PID=21217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:54,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:54,095] {logging_mixin.py:95} INFO - [2019-09-15 17:56:54,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:54,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:54,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:54,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:54,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 17:56:54,547] {scheduler_job.py:146} INFO - Started process (PID=21218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:59,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:56:59,561] {logging_mixin.py:95} INFO - [2019-09-15 17:56:59,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:59,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:56:59,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:56:59,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:56:59,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:57:00,008] {scheduler_job.py:146} INFO - Started process (PID=21220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:05,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:05,024] {logging_mixin.py:95} INFO - [2019-09-15 17:57:05,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:05,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:05,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:05,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:05,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:57:05,472] {scheduler_job.py:146} INFO - Started process (PID=21221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:10,485] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:10,487] {logging_mixin.py:95} INFO - [2019-09-15 17:57:10,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:10,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:10,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:10,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:10,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:57:10,936] {scheduler_job.py:146} INFO - Started process (PID=21222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:15,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:15,955] {logging_mixin.py:95} INFO - [2019-09-15 17:57:15,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:16,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:16,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:16,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:16,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:57:16,413] {scheduler_job.py:146} INFO - Started process (PID=21224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:21,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:21,426] {logging_mixin.py:95} INFO - [2019-09-15 17:57:21,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:21,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:21,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:21,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:21,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:57:21,877] {scheduler_job.py:146} INFO - Started process (PID=21225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:26,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:26,891] {logging_mixin.py:95} INFO - [2019-09-15 17:57:26,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:27,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:27,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:27,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:27,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:57:27,344] {scheduler_job.py:146} INFO - Started process (PID=21227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:32,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:32,359] {logging_mixin.py:95} INFO - [2019-09-15 17:57:32,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:32,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:32,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:32,740] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:32,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 17:57:32,815] {scheduler_job.py:146} INFO - Started process (PID=21229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:37,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:37,829] {logging_mixin.py:95} INFO - [2019-09-15 17:57:37,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:38,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:38,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:38,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:38,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:57:38,283] {scheduler_job.py:146} INFO - Started process (PID=21230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:43,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:43,295] {logging_mixin.py:95} INFO - [2019-09-15 17:57:43,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:43,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:43,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:43,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:43,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:57:43,747] {scheduler_job.py:146} INFO - Started process (PID=21232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:48,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:48,765] {logging_mixin.py:95} INFO - [2019-09-15 17:57:48,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:49,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:49,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:49,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:49,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 17:57:49,217] {scheduler_job.py:146} INFO - Started process (PID=21233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:54,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:54,229] {logging_mixin.py:95} INFO - [2019-09-15 17:57:54,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:54,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:54,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:57:54,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:57:54,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:57:54,696] {scheduler_job.py:146} INFO - Started process (PID=21234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:57:59,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:57:59,712] {logging_mixin.py:95} INFO - [2019-09-15 17:57:59,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:00,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:00,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:00,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:00,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:58:00,173] {scheduler_job.py:146} INFO - Started process (PID=21236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:05,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:05,187] {logging_mixin.py:95} INFO - [2019-09-15 17:58:05,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:05,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:05,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:05,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:05,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 17:58:05,637] {scheduler_job.py:146} INFO - Started process (PID=21237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:10,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:10,653] {logging_mixin.py:95} INFO - [2019-09-15 17:58:10,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:11,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:11,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:11,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:11,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:58:11,105] {scheduler_job.py:146} INFO - Started process (PID=21238) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:16,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:16,119] {logging_mixin.py:95} INFO - [2019-09-15 17:58:16,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:16,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:16,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:16,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:16,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:58:16,577] {scheduler_job.py:146} INFO - Started process (PID=21240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:21,586] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:21,587] {logging_mixin.py:95} INFO - [2019-09-15 17:58:21,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:21,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:21,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:21,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:21,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:58:22,040] {scheduler_job.py:146} INFO - Started process (PID=21241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:27,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:27,050] {logging_mixin.py:95} INFO - [2019-09-15 17:58:27,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:27,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:27,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:27,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:27,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 17:58:27,512] {scheduler_job.py:146} INFO - Started process (PID=21243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:32,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:32,537] {logging_mixin.py:95} INFO - [2019-09-15 17:58:32,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:32,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:32,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:32,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:32,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 17:58:32,988] {scheduler_job.py:146} INFO - Started process (PID=21245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:37,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:37,998] {logging_mixin.py:95} INFO - [2019-09-15 17:58:37,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:38,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:38,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:38,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:38,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 17:58:38,454] {scheduler_job.py:146} INFO - Started process (PID=21246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:43,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:43,479] {logging_mixin.py:95} INFO - [2019-09-15 17:58:43,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:43,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:43,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:43,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:43,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 17:58:43,921] {scheduler_job.py:146} INFO - Started process (PID=21248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:48,931] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:48,932] {logging_mixin.py:95} INFO - [2019-09-15 17:58:48,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:49,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:49,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:49,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:49,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 17:58:49,392] {scheduler_job.py:146} INFO - Started process (PID=21249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:54,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:54,405] {logging_mixin.py:95} INFO - [2019-09-15 17:58:54,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:54,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:54,783] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:58:54,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:58:54,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 17:58:54,856] {scheduler_job.py:146} INFO - Started process (PID=21250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:58:59,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:58:59,874] {logging_mixin.py:95} INFO - [2019-09-15 17:58:59,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:00,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:00,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:00,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:00,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 17:59:00,325] {scheduler_job.py:146} INFO - Started process (PID=21252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:05,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:05,334] {logging_mixin.py:95} INFO - [2019-09-15 17:59:05,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:05,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:05,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:05,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:05,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 17:59:05,792] {scheduler_job.py:146} INFO - Started process (PID=21253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:10,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:10,801] {logging_mixin.py:95} INFO - [2019-09-15 17:59:10,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:11,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:11,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:11,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:11,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 17:59:11,245] {scheduler_job.py:146} INFO - Started process (PID=21254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:16,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:16,255] {logging_mixin.py:95} INFO - [2019-09-15 17:59:16,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:16,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:16,660] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:16,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:16,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 17:59:16,788] {scheduler_job.py:146} INFO - Started process (PID=21256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:21,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:21,804] {logging_mixin.py:95} INFO - [2019-09-15 17:59:21,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:22,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:22,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:22,207] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:22,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 17:59:22,234] {scheduler_job.py:146} INFO - Started process (PID=21263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:27,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:27,242] {logging_mixin.py:95} INFO - [2019-09-15 17:59:27,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:27,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:27,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:27,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:27,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 17:59:27,679] {scheduler_job.py:146} INFO - Started process (PID=21265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:32,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:32,686] {logging_mixin.py:95} INFO - [2019-09-15 17:59:32,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:33,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:33,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:33,105] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:33,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 17:59:33,213] {scheduler_job.py:146} INFO - Started process (PID=21269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:38,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:38,223] {logging_mixin.py:95} INFO - [2019-09-15 17:59:38,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:38,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:38,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:38,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:38,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 17:59:38,654] {scheduler_job.py:146} INFO - Started process (PID=21270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:43,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:43,676] {logging_mixin.py:95} INFO - [2019-09-15 17:59:43,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:44,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:44,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:44,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:44,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 17:59:44,197] {scheduler_job.py:146} INFO - Started process (PID=21272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:49,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:49,208] {logging_mixin.py:95} INFO - [2019-09-15 17:59:49,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:49,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:49,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:49,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:49,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 17:59:49,737] {scheduler_job.py:146} INFO - Started process (PID=21273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:54,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 17:59:54,747] {logging_mixin.py:95} INFO - [2019-09-15 17:59:54,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:55,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 17:59:55,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 17:59:55,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 17:59:55,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-15 17:59:55,278] {scheduler_job.py:146} INFO - Started process (PID=21274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:00,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:00,287] {logging_mixin.py:95} INFO - [2019-09-15 18:00:00,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:00,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:00,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:00,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:00,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 18:00:00,817] {scheduler_job.py:146} INFO - Started process (PID=21276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:05,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:05,827] {logging_mixin.py:95} INFO - [2019-09-15 18:00:05,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:06,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:06,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:06,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:06,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:00:06,266] {scheduler_job.py:146} INFO - Started process (PID=21277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:11,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:11,277] {logging_mixin.py:95} INFO - [2019-09-15 18:00:11,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:11,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:11,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:11,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:11,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 18:00:11,819] {scheduler_job.py:146} INFO - Started process (PID=21278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:16,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:16,827] {logging_mixin.py:95} INFO - [2019-09-15 18:00:16,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:17,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:17,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:17,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:17,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:00:17,269] {scheduler_job.py:146} INFO - Started process (PID=21280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:22,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:22,281] {logging_mixin.py:95} INFO - [2019-09-15 18:00:22,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:22,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:22,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:22,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:22,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:00:22,717] {scheduler_job.py:146} INFO - Started process (PID=21281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:27,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:27,725] {logging_mixin.py:95} INFO - [2019-09-15 18:00:27,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:28,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:28,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:28,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:28,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:00:28,167] {scheduler_job.py:146} INFO - Started process (PID=21284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:33,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:33,177] {logging_mixin.py:95} INFO - [2019-09-15 18:00:33,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:33,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:33,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:33,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:33,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:00:33,612] {scheduler_job.py:146} INFO - Started process (PID=21285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:38,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:38,621] {logging_mixin.py:95} INFO - [2019-09-15 18:00:38,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:38,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:38,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:39,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:39,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:00:39,059] {scheduler_job.py:146} INFO - Started process (PID=21286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:44,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:44,078] {logging_mixin.py:95} INFO - [2019-09-15 18:00:44,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:44,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:44,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:44,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:44,477] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:00:44,511] {scheduler_job.py:146} INFO - Started process (PID=21288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:49,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:49,518] {logging_mixin.py:95} INFO - [2019-09-15 18:00:49,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:49,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:49,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:49,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:49,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:00:49,957] {scheduler_job.py:146} INFO - Started process (PID=21289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:54,968] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:00:54,969] {logging_mixin.py:95} INFO - [2019-09-15 18:00:54,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:55,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:00:55,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:00:55,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:00:55,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:00:55,407] {scheduler_job.py:146} INFO - Started process (PID=21290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:00,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:00,416] {logging_mixin.py:95} INFO - [2019-09-15 18:01:00,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:00,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:00,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:00,799] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:00,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:01:00,856] {scheduler_job.py:146} INFO - Started process (PID=21292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:05,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:05,867] {logging_mixin.py:95} INFO - [2019-09-15 18:01:05,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:06,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:06,243] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:06,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:06,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:01:06,302] {scheduler_job.py:146} INFO - Started process (PID=21293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:11,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:11,311] {logging_mixin.py:95} INFO - [2019-09-15 18:01:11,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:11,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:11,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:11,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:11,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:01:11,746] {scheduler_job.py:146} INFO - Started process (PID=21294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:16,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:16,755] {logging_mixin.py:95} INFO - [2019-09-15 18:01:16,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:17,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:17,131] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:17,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:17,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:01:17,196] {scheduler_job.py:146} INFO - Started process (PID=21296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:22,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:22,207] {logging_mixin.py:95} INFO - [2019-09-15 18:01:22,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:22,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:22,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:22,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:22,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:01:22,646] {scheduler_job.py:146} INFO - Started process (PID=21297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:27,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:27,654] {logging_mixin.py:95} INFO - [2019-09-15 18:01:27,654] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:28,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:28,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:28,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:28,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:01:28,090] {scheduler_job.py:146} INFO - Started process (PID=21300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:33,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:33,101] {logging_mixin.py:95} INFO - [2019-09-15 18:01:33,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:33,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:33,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:33,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:33,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:01:33,537] {scheduler_job.py:146} INFO - Started process (PID=21301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:38,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:38,546] {logging_mixin.py:95} INFO - [2019-09-15 18:01:38,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:38,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:38,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:38,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:38,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:01:38,986] {scheduler_job.py:146} INFO - Started process (PID=21302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:43,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:43,996] {logging_mixin.py:95} INFO - [2019-09-15 18:01:43,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:44,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:44,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:44,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:44,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:01:44,432] {scheduler_job.py:146} INFO - Started process (PID=21304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:49,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:49,443] {logging_mixin.py:95} INFO - [2019-09-15 18:01:49,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:49,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:49,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:49,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:49,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:01:49,878] {scheduler_job.py:146} INFO - Started process (PID=21305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:54,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:01:54,888] {logging_mixin.py:95} INFO - [2019-09-15 18:01:54,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:55,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:01:55,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:01:55,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:01:55,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:01:55,323] {scheduler_job.py:146} INFO - Started process (PID=21306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:00,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:00,333] {logging_mixin.py:95} INFO - [2019-09-15 18:02:00,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:00,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:00,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:00,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:00,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:02:00,776] {scheduler_job.py:146} INFO - Started process (PID=21308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:05,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:05,788] {logging_mixin.py:95} INFO - [2019-09-15 18:02:05,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:06,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:06,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:06,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:06,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:02:06,225] {scheduler_job.py:146} INFO - Started process (PID=21309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:11,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:11,237] {logging_mixin.py:95} INFO - [2019-09-15 18:02:11,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:11,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:11,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:11,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:11,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:02:11,675] {scheduler_job.py:146} INFO - Started process (PID=21310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:16,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:16,688] {logging_mixin.py:95} INFO - [2019-09-15 18:02:16,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:17,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:17,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:17,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:17,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:02:17,127] {scheduler_job.py:146} INFO - Started process (PID=21312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:22,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:22,138] {logging_mixin.py:95} INFO - [2019-09-15 18:02:22,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:22,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:22,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:22,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:22,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:02:22,576] {scheduler_job.py:146} INFO - Started process (PID=21313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:27,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:27,585] {logging_mixin.py:95} INFO - [2019-09-15 18:02:27,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:27,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:27,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:27,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:27,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:02:28,031] {scheduler_job.py:146} INFO - Started process (PID=21316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:33,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:33,040] {logging_mixin.py:95} INFO - [2019-09-15 18:02:33,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:33,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:33,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:33,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:33,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:02:33,479] {scheduler_job.py:146} INFO - Started process (PID=21317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:38,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:38,489] {logging_mixin.py:95} INFO - [2019-09-15 18:02:38,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:38,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:38,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:38,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:38,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:02:38,928] {scheduler_job.py:146} INFO - Started process (PID=21318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:43,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:43,939] {logging_mixin.py:95} INFO - [2019-09-15 18:02:43,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:44,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:44,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:44,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:44,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:02:44,378] {scheduler_job.py:146} INFO - Started process (PID=21320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:49,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:49,386] {logging_mixin.py:95} INFO - [2019-09-15 18:02:49,386] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:49,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:49,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:49,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:49,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:02:49,831] {scheduler_job.py:146} INFO - Started process (PID=21321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:54,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:02:54,841] {logging_mixin.py:95} INFO - [2019-09-15 18:02:54,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:55,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:02:55,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:02:55,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:02:55,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:02:55,282] {scheduler_job.py:146} INFO - Started process (PID=21322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:00,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:00,290] {logging_mixin.py:95} INFO - [2019-09-15 18:03:00,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:00,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:00,667] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:00,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:00,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:03:00,728] {scheduler_job.py:146} INFO - Started process (PID=21324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:05,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:05,736] {logging_mixin.py:95} INFO - [2019-09-15 18:03:05,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:06,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:06,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:06,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:06,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:03:06,178] {scheduler_job.py:146} INFO - Started process (PID=21325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:11,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:11,186] {logging_mixin.py:95} INFO - [2019-09-15 18:03:11,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:11,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:11,566] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:11,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:11,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:03:11,631] {scheduler_job.py:146} INFO - Started process (PID=21326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:16,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:16,637] {logging_mixin.py:95} INFO - [2019-09-15 18:03:16,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:16,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:17,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:17,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:17,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:03:17,080] {scheduler_job.py:146} INFO - Started process (PID=21328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:22,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:22,090] {logging_mixin.py:95} INFO - [2019-09-15 18:03:22,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:22,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:22,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:22,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:22,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:03:22,533] {scheduler_job.py:146} INFO - Started process (PID=21329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:27,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:27,540] {logging_mixin.py:95} INFO - [2019-09-15 18:03:27,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:27,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:27,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:27,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:27,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:03:27,982] {scheduler_job.py:146} INFO - Started process (PID=21332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:32,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:33,002] {logging_mixin.py:95} INFO - [2019-09-15 18:03:33,001] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:33,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:33,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:33,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:33,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:03:33,431] {scheduler_job.py:146} INFO - Started process (PID=21333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:38,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:38,440] {logging_mixin.py:95} INFO - [2019-09-15 18:03:38,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:38,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:38,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:38,826] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:38,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:03:38,882] {scheduler_job.py:146} INFO - Started process (PID=21334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:43,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:43,888] {logging_mixin.py:95} INFO - [2019-09-15 18:03:43,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:44,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:44,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:44,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:44,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:03:44,330] {scheduler_job.py:146} INFO - Started process (PID=21336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:49,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:49,337] {logging_mixin.py:95} INFO - [2019-09-15 18:03:49,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:49,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:49,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:49,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:49,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:03:49,774] {scheduler_job.py:146} INFO - Started process (PID=21337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:54,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:03:54,784] {logging_mixin.py:95} INFO - [2019-09-15 18:03:54,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:55,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:03:55,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:03:55,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:03:55,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:03:55,219] {scheduler_job.py:146} INFO - Started process (PID=21338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:00,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:00,229] {logging_mixin.py:95} INFO - [2019-09-15 18:04:00,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:00,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:00,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:00,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:00,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:04:00,673] {scheduler_job.py:146} INFO - Started process (PID=21340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:05,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:05,682] {logging_mixin.py:95} INFO - [2019-09-15 18:04:05,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:06,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:06,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:06,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:06,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:04:06,118] {scheduler_job.py:146} INFO - Started process (PID=21341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:11,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:11,127] {logging_mixin.py:95} INFO - [2019-09-15 18:04:11,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:11,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:11,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:11,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:11,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:04:11,569] {scheduler_job.py:146} INFO - Started process (PID=21342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:16,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:16,579] {logging_mixin.py:95} INFO - [2019-09-15 18:04:16,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:16,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:16,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:16,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:16,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:04:17,019] {scheduler_job.py:146} INFO - Started process (PID=21344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:22,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:22,029] {logging_mixin.py:95} INFO - [2019-09-15 18:04:22,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:22,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:22,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:22,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:22,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:04:22,466] {scheduler_job.py:146} INFO - Started process (PID=21345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:27,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:27,476] {logging_mixin.py:95} INFO - [2019-09-15 18:04:27,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:27,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:27,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:27,869] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:27,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:04:27,914] {scheduler_job.py:146} INFO - Started process (PID=21347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:32,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:32,935] {logging_mixin.py:95} INFO - [2019-09-15 18:04:32,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:33,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:33,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:33,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:33,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:04:33,360] {scheduler_job.py:146} INFO - Started process (PID=21349) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:38,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:38,368] {logging_mixin.py:95} INFO - [2019-09-15 18:04:38,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:38,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:38,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:38,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:38,763] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:04:38,808] {scheduler_job.py:146} INFO - Started process (PID=21350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:43,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:43,825] {logging_mixin.py:95} INFO - [2019-09-15 18:04:43,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:44,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:44,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:44,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:44,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:04:44,257] {scheduler_job.py:146} INFO - Started process (PID=21352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:49,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:49,268] {logging_mixin.py:95} INFO - [2019-09-15 18:04:49,267] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:49,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:49,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:49,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:49,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:04:49,701] {scheduler_job.py:146} INFO - Started process (PID=21353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:54,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:04:54,711] {logging_mixin.py:95} INFO - [2019-09-15 18:04:54,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:55,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:04:55,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:04:55,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:04:55,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:04:55,154] {scheduler_job.py:146} INFO - Started process (PID=21354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:00,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:00,160] {logging_mixin.py:95} INFO - [2019-09-15 18:05:00,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:00,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:00,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:00,548] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:00,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:05:00,599] {scheduler_job.py:146} INFO - Started process (PID=21356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:05,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:05,607] {logging_mixin.py:95} INFO - [2019-09-15 18:05:05,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:05,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:05,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:05,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:05,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:05:06,061] {scheduler_job.py:146} INFO - Started process (PID=21357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:11,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:11,078] {logging_mixin.py:95} INFO - [2019-09-15 18:05:11,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:11,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:11,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:11,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:11,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:05:11,537] {scheduler_job.py:146} INFO - Started process (PID=21358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:16,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:16,547] {logging_mixin.py:95} INFO - [2019-09-15 18:05:16,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:16,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:16,931] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:16,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:16,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:05:17,003] {scheduler_job.py:146} INFO - Started process (PID=21360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:22,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:22,016] {logging_mixin.py:95} INFO - [2019-09-15 18:05:22,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:22,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:22,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:22,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:22,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:05:22,472] {scheduler_job.py:146} INFO - Started process (PID=21361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:27,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:27,487] {logging_mixin.py:95} INFO - [2019-09-15 18:05:27,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:27,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:27,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:27,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:27,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:05:27,934] {scheduler_job.py:146} INFO - Started process (PID=21363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:32,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:32,945] {logging_mixin.py:95} INFO - [2019-09-15 18:05:32,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:33,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:33,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:33,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:33,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:05:33,403] {scheduler_job.py:146} INFO - Started process (PID=21365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:38,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:38,418] {logging_mixin.py:95} INFO - [2019-09-15 18:05:38,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:38,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:38,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:38,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:38,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:05:38,868] {scheduler_job.py:146} INFO - Started process (PID=21366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:43,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:43,882] {logging_mixin.py:95} INFO - [2019-09-15 18:05:43,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:44,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:44,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:44,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:44,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:05:44,331] {scheduler_job.py:146} INFO - Started process (PID=21368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:49,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:49,342] {logging_mixin.py:95} INFO - [2019-09-15 18:05:49,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:49,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:49,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:49,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:49,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:05:49,798] {scheduler_job.py:146} INFO - Started process (PID=21369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:54,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:05:54,808] {logging_mixin.py:95} INFO - [2019-09-15 18:05:54,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:55,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:05:55,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:05:55,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:05:55,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:05:55,268] {scheduler_job.py:146} INFO - Started process (PID=21370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:00,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:00,282] {logging_mixin.py:95} INFO - [2019-09-15 18:06:00,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:00,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:00,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:00,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:00,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:06:00,729] {scheduler_job.py:146} INFO - Started process (PID=21372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:05,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:05,744] {logging_mixin.py:95} INFO - [2019-09-15 18:06:05,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:06,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:06,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:06,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:06,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:06:06,205] {scheduler_job.py:146} INFO - Started process (PID=21373) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:11,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:11,218] {logging_mixin.py:95} INFO - [2019-09-15 18:06:11,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:11,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:11,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:11,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:11,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:06:11,675] {scheduler_job.py:146} INFO - Started process (PID=21374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:16,683] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:16,684] {logging_mixin.py:95} INFO - [2019-09-15 18:06:16,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:17,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:17,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:17,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:17,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:06:17,146] {scheduler_job.py:146} INFO - Started process (PID=21376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:22,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:22,160] {logging_mixin.py:95} INFO - [2019-09-15 18:06:22,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:22,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:22,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:22,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:22,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:06:22,615] {scheduler_job.py:146} INFO - Started process (PID=21377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:27,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:27,625] {logging_mixin.py:95} INFO - [2019-09-15 18:06:27,625] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:27,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:28,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:28,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:28,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:06:28,068] {scheduler_job.py:146} INFO - Started process (PID=21379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:33,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:33,076] {logging_mixin.py:95} INFO - [2019-09-15 18:06:33,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:33,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:33,454] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:33,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:33,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:06:33,518] {scheduler_job.py:146} INFO - Started process (PID=21381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:38,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:38,528] {logging_mixin.py:95} INFO - [2019-09-15 18:06:38,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:38,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:38,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:38,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:38,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:06:38,963] {scheduler_job.py:146} INFO - Started process (PID=21382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:43,970] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:43,971] {logging_mixin.py:95} INFO - [2019-09-15 18:06:43,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:44,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:44,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:44,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:44,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:06:44,412] {scheduler_job.py:146} INFO - Started process (PID=21384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:49,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:49,423] {logging_mixin.py:95} INFO - [2019-09-15 18:06:49,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:49,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:49,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:49,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:49,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:06:49,860] {scheduler_job.py:146} INFO - Started process (PID=21385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:54,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:06:54,867] {logging_mixin.py:95} INFO - [2019-09-15 18:06:54,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:55,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:06:55,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:06:55,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:06:55,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 18:06:55,406] {scheduler_job.py:146} INFO - Started process (PID=21386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:00,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:00,414] {logging_mixin.py:95} INFO - [2019-09-15 18:07:00,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:00,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:00,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:00,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:00,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:07:00,847] {scheduler_job.py:146} INFO - Started process (PID=21388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:05,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:05,858] {logging_mixin.py:95} INFO - [2019-09-15 18:07:05,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:06,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:06,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:06,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:06,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:07:06,297] {scheduler_job.py:146} INFO - Started process (PID=21389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:11,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:11,307] {logging_mixin.py:95} INFO - [2019-09-15 18:07:11,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:11,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:11,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:11,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:11,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:07:11,748] {scheduler_job.py:146} INFO - Started process (PID=21390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:16,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:16,757] {logging_mixin.py:95} INFO - [2019-09-15 18:07:16,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:17,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:17,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:17,146] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:17,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:07:17,199] {scheduler_job.py:146} INFO - Started process (PID=21392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:22,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:22,207] {logging_mixin.py:95} INFO - [2019-09-15 18:07:22,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:22,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:22,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:22,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:22,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:07:22,656] {scheduler_job.py:146} INFO - Started process (PID=21393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:27,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:27,665] {logging_mixin.py:95} INFO - [2019-09-15 18:07:27,665] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:28,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:28,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:28,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:28,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:07:28,107] {scheduler_job.py:146} INFO - Started process (PID=21395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:33,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:33,114] {logging_mixin.py:95} INFO - [2019-09-15 18:07:33,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:33,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:33,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:33,526] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:33,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 18:07:33,553] {scheduler_job.py:146} INFO - Started process (PID=21397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:38,562] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:38,563] {logging_mixin.py:95} INFO - [2019-09-15 18:07:38,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:38,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:38,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:38,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:38,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:07:38,998] {scheduler_job.py:146} INFO - Started process (PID=21398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:44,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:44,007] {logging_mixin.py:95} INFO - [2019-09-15 18:07:44,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:44,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:44,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:44,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:44,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 18:07:44,545] {scheduler_job.py:146} INFO - Started process (PID=21400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:49,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:49,554] {logging_mixin.py:95} INFO - [2019-09-15 18:07:49,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:49,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:49,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:49,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:49,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:07:49,997] {scheduler_job.py:146} INFO - Started process (PID=21401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:55,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:07:55,008] {logging_mixin.py:95} INFO - [2019-09-15 18:07:55,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:55,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:07:55,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:07:55,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:07:55,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:07:55,448] {scheduler_job.py:146} INFO - Started process (PID=21402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:00,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:00,458] {logging_mixin.py:95} INFO - [2019-09-15 18:08:00,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:00,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:00,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:00,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:00,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:08:00,896] {scheduler_job.py:146} INFO - Started process (PID=21404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:05,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:05,903] {logging_mixin.py:95} INFO - [2019-09-15 18:08:05,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:06,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:06,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:06,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:06,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:08:06,344] {scheduler_job.py:146} INFO - Started process (PID=21405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:11,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:11,353] {logging_mixin.py:95} INFO - [2019-09-15 18:08:11,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:11,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:11,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:11,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:11,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:08:11,790] {scheduler_job.py:146} INFO - Started process (PID=21406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:16,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:16,800] {logging_mixin.py:95} INFO - [2019-09-15 18:08:16,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:17,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:17,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:17,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:17,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:08:17,231] {scheduler_job.py:146} INFO - Started process (PID=21408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:22,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:22,242] {logging_mixin.py:95} INFO - [2019-09-15 18:08:22,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:22,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:22,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:22,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:22,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:08:22,680] {scheduler_job.py:146} INFO - Started process (PID=21409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:27,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:27,688] {logging_mixin.py:95} INFO - [2019-09-15 18:08:27,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:28,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:28,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:28,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:28,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 18:08:28,227] {scheduler_job.py:146} INFO - Started process (PID=21412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:33,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:33,237] {logging_mixin.py:95} INFO - [2019-09-15 18:08:33,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:33,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:33,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:33,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:33,632] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:08:33,678] {scheduler_job.py:146} INFO - Started process (PID=21413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:38,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:38,687] {logging_mixin.py:95} INFO - [2019-09-15 18:08:38,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:39,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:39,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:39,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:39,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 18:08:39,132] {scheduler_job.py:146} INFO - Started process (PID=21414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:44,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:44,141] {logging_mixin.py:95} INFO - [2019-09-15 18:08:44,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:44,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:44,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:44,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:44,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:08:44,570] {scheduler_job.py:146} INFO - Started process (PID=21416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:49,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:49,580] {logging_mixin.py:95} INFO - [2019-09-15 18:08:49,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:49,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:49,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:49,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:49,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:08:50,016] {scheduler_job.py:146} INFO - Started process (PID=21417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:55,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:08:55,026] {logging_mixin.py:95} INFO - [2019-09-15 18:08:55,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:55,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:08:55,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:08:55,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:08:55,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:08:55,469] {scheduler_job.py:146} INFO - Started process (PID=21418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:00,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:00,479] {logging_mixin.py:95} INFO - [2019-09-15 18:09:00,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:00,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:00,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:00,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:00,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:09:00,918] {scheduler_job.py:146} INFO - Started process (PID=21420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:05,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:05,926] {logging_mixin.py:95} INFO - [2019-09-15 18:09:05,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:06,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:06,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:06,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:06,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:09:06,370] {scheduler_job.py:146} INFO - Started process (PID=21421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:11,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:11,377] {logging_mixin.py:95} INFO - [2019-09-15 18:09:11,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:11,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:11,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:11,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:11,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:09:11,816] {scheduler_job.py:146} INFO - Started process (PID=21422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:16,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:16,828] {logging_mixin.py:95} INFO - [2019-09-15 18:09:16,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:17,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:17,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:17,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:17,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:09:17,264] {scheduler_job.py:146} INFO - Started process (PID=21424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:22,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:22,271] {logging_mixin.py:95} INFO - [2019-09-15 18:09:22,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:22,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:22,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:22,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:22,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:09:22,716] {scheduler_job.py:146} INFO - Started process (PID=21426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:27,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:27,726] {logging_mixin.py:95} INFO - [2019-09-15 18:09:27,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:28,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:28,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:28,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:28,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:09:28,171] {scheduler_job.py:146} INFO - Started process (PID=21428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:33,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:33,181] {logging_mixin.py:95} INFO - [2019-09-15 18:09:33,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:33,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:33,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:33,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:33,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:09:33,619] {scheduler_job.py:146} INFO - Started process (PID=21430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:38,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:38,628] {logging_mixin.py:95} INFO - [2019-09-15 18:09:38,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:38,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:39,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:39,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:39,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:09:39,062] {scheduler_job.py:146} INFO - Started process (PID=21431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:44,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:44,070] {logging_mixin.py:95} INFO - [2019-09-15 18:09:44,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:44,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:44,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:44,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:44,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:09:44,508] {scheduler_job.py:146} INFO - Started process (PID=21433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:49,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:49,515] {logging_mixin.py:95} INFO - [2019-09-15 18:09:49,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:49,875] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:49,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:49,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:49,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:09:49,956] {scheduler_job.py:146} INFO - Started process (PID=21434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:54,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:09:54,966] {logging_mixin.py:95} INFO - [2019-09-15 18:09:54,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:55,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:09:55,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:09:55,358] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:09:55,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:09:55,405] {scheduler_job.py:146} INFO - Started process (PID=21435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:00,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:00,411] {logging_mixin.py:95} INFO - [2019-09-15 18:10:00,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:00,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:00,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:00,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:00,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:10:00,856] {scheduler_job.py:146} INFO - Started process (PID=21437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:05,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:05,866] {logging_mixin.py:95} INFO - [2019-09-15 18:10:05,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:06,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:06,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:06,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:06,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:10:06,302] {scheduler_job.py:146} INFO - Started process (PID=21438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:11,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:11,319] {logging_mixin.py:95} INFO - [2019-09-15 18:10:11,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:11,681] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:11,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:11,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:11,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:10:11,756] {scheduler_job.py:146} INFO - Started process (PID=21439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:16,766] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:16,767] {logging_mixin.py:95} INFO - [2019-09-15 18:10:16,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:17,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:17,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:17,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:17,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:10:17,205] {scheduler_job.py:146} INFO - Started process (PID=21441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:22,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:22,213] {logging_mixin.py:95} INFO - [2019-09-15 18:10:22,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:22,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:22,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:22,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:22,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:10:22,646] {scheduler_job.py:146} INFO - Started process (PID=21442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:27,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:27,653] {logging_mixin.py:95} INFO - [2019-09-15 18:10:27,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:28,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:28,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:28,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:28,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:10:28,091] {scheduler_job.py:146} INFO - Started process (PID=21444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:33,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:33,099] {logging_mixin.py:95} INFO - [2019-09-15 18:10:33,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:33,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:33,482] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:33,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:33,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:10:33,548] {scheduler_job.py:146} INFO - Started process (PID=21446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:38,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:38,557] {logging_mixin.py:95} INFO - [2019-09-15 18:10:38,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:38,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:38,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:38,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:38,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:10:38,999] {scheduler_job.py:146} INFO - Started process (PID=21447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:44,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:44,008] {logging_mixin.py:95} INFO - [2019-09-15 18:10:44,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:44,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:44,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:44,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:44,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:10:44,445] {scheduler_job.py:146} INFO - Started process (PID=21449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:49,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:49,454] {logging_mixin.py:95} INFO - [2019-09-15 18:10:49,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:49,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:49,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:49,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:49,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:10:49,894] {scheduler_job.py:146} INFO - Started process (PID=21450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:54,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:10:54,903] {logging_mixin.py:95} INFO - [2019-09-15 18:10:54,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:55,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:10:55,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:10:55,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:10:55,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:10:55,341] {scheduler_job.py:146} INFO - Started process (PID=21451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:00,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:00,348] {logging_mixin.py:95} INFO - [2019-09-15 18:11:00,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:00,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:00,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:00,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:00,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:11:00,790] {scheduler_job.py:146} INFO - Started process (PID=21453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:05,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:05,797] {logging_mixin.py:95} INFO - [2019-09-15 18:11:05,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:06,149] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:06,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:06,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:06,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:11:06,238] {scheduler_job.py:146} INFO - Started process (PID=21454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:11,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:11,247] {logging_mixin.py:95} INFO - [2019-09-15 18:11:11,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:11,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:11,623] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:11,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:11,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:11:11,692] {scheduler_job.py:146} INFO - Started process (PID=21455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:16,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:16,699] {logging_mixin.py:95} INFO - [2019-09-15 18:11:16,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:17,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:17,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:17,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:17,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:11:17,142] {scheduler_job.py:146} INFO - Started process (PID=21457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:22,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:22,149] {logging_mixin.py:95} INFO - [2019-09-15 18:11:22,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:22,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:22,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:22,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:22,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:11:22,588] {scheduler_job.py:146} INFO - Started process (PID=21458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:27,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:27,599] {logging_mixin.py:95} INFO - [2019-09-15 18:11:27,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:27,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:27,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:27,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:27,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:11:28,038] {scheduler_job.py:146} INFO - Started process (PID=21460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:33,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:33,049] {logging_mixin.py:95} INFO - [2019-09-15 18:11:33,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:33,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:33,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:33,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:33,453] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:11:33,486] {scheduler_job.py:146} INFO - Started process (PID=21462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:38,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:38,497] {logging_mixin.py:95} INFO - [2019-09-15 18:11:38,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:38,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:38,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:38,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:38,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:11:38,938] {scheduler_job.py:146} INFO - Started process (PID=21463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:43,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:43,948] {logging_mixin.py:95} INFO - [2019-09-15 18:11:43,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:44,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:44,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:44,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:44,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:11:44,390] {scheduler_job.py:146} INFO - Started process (PID=21465) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:49,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:49,397] {logging_mixin.py:95} INFO - [2019-09-15 18:11:49,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:49,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:49,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:49,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:49,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:11:49,840] {scheduler_job.py:146} INFO - Started process (PID=21466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:54,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:11:54,849] {logging_mixin.py:95} INFO - [2019-09-15 18:11:54,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:55,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:11:55,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:11:55,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:11:55,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:11:55,291] {scheduler_job.py:146} INFO - Started process (PID=21467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:00,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:00,301] {logging_mixin.py:95} INFO - [2019-09-15 18:12:00,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:00,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:00,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:00,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:00,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:12:00,736] {scheduler_job.py:146} INFO - Started process (PID=21469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:05,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:05,747] {logging_mixin.py:95} INFO - [2019-09-15 18:12:05,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:06,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:06,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:06,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:06,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:12:06,186] {scheduler_job.py:146} INFO - Started process (PID=21470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:11,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:11,194] {logging_mixin.py:95} INFO - [2019-09-15 18:12:11,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:11,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:11,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:11,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:11,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:12:11,639] {scheduler_job.py:146} INFO - Started process (PID=21471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:16,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:16,646] {logging_mixin.py:95} INFO - [2019-09-15 18:12:16,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:17,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:17,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:17,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:17,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 18:12:17,088] {scheduler_job.py:146} INFO - Started process (PID=21473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:22,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:22,095] {logging_mixin.py:95} INFO - [2019-09-15 18:12:22,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:22,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:22,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:22,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:22,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:12:22,534] {scheduler_job.py:146} INFO - Started process (PID=21474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:27,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:27,541] {logging_mixin.py:95} INFO - [2019-09-15 18:12:27,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:27,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:27,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:27,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:27,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:12:27,979] {scheduler_job.py:146} INFO - Started process (PID=21476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:32,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:32,988] {logging_mixin.py:95} INFO - [2019-09-15 18:12:32,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:33,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:33,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:33,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:33,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 18:12:33,532] {scheduler_job.py:146} INFO - Started process (PID=21478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:38,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:38,545] {logging_mixin.py:95} INFO - [2019-09-15 18:12:38,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:38,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:38,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:38,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:38,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:12:38,979] {scheduler_job.py:146} INFO - Started process (PID=21479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:43,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:43,988] {logging_mixin.py:95} INFO - [2019-09-15 18:12:43,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:44,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:44,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:44,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:44,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:12:44,426] {scheduler_job.py:146} INFO - Started process (PID=21481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:49,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:49,435] {logging_mixin.py:95} INFO - [2019-09-15 18:12:49,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:49,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:49,818] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:49,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:49,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:12:49,868] {scheduler_job.py:146} INFO - Started process (PID=21482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:54,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:12:54,878] {logging_mixin.py:95} INFO - [2019-09-15 18:12:54,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:55,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:12:55,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:12:55,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:12:55,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 18:12:55,314] {scheduler_job.py:146} INFO - Started process (PID=21483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:00,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:00,322] {logging_mixin.py:95} INFO - [2019-09-15 18:13:00,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:00,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:00,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:00,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:00,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 18:13:00,860] {scheduler_job.py:146} INFO - Started process (PID=21485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:05,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:05,867] {logging_mixin.py:95} INFO - [2019-09-15 18:13:05,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:06,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:06,245] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:06,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:06,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:13:06,308] {scheduler_job.py:146} INFO - Started process (PID=21486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:11,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:11,317] {logging_mixin.py:95} INFO - [2019-09-15 18:13:11,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:11,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:11,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:11,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:11,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:13:11,758] {scheduler_job.py:146} INFO - Started process (PID=21487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:16,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:16,766] {logging_mixin.py:95} INFO - [2019-09-15 18:13:16,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:17,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:17,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:17,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:17,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:13:17,211] {scheduler_job.py:146} INFO - Started process (PID=21489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:22,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:22,220] {logging_mixin.py:95} INFO - [2019-09-15 18:13:22,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:22,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:22,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:22,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:22,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:13:22,658] {scheduler_job.py:146} INFO - Started process (PID=21490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:27,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:27,667] {logging_mixin.py:95} INFO - [2019-09-15 18:13:27,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:28,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:28,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:28,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:28,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:13:28,103] {scheduler_job.py:146} INFO - Started process (PID=21492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:33,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:33,110] {logging_mixin.py:95} INFO - [2019-09-15 18:13:33,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:33,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:33,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:33,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:33,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:13:33,547] {scheduler_job.py:146} INFO - Started process (PID=21494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:38,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:38,558] {logging_mixin.py:95} INFO - [2019-09-15 18:13:38,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:38,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:38,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:38,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:38,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:13:38,994] {scheduler_job.py:146} INFO - Started process (PID=21495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:44,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:44,004] {logging_mixin.py:95} INFO - [2019-09-15 18:13:44,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:44,361] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:44,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:44,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:44,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:13:44,441] {scheduler_job.py:146} INFO - Started process (PID=21497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:49,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:49,449] {logging_mixin.py:95} INFO - [2019-09-15 18:13:49,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:49,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:49,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:49,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:49,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:13:49,894] {scheduler_job.py:146} INFO - Started process (PID=21498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:54,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:13:54,909] {logging_mixin.py:95} INFO - [2019-09-15 18:13:54,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:55,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:13:55,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:13:55,315] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:13:55,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:13:55,341] {scheduler_job.py:146} INFO - Started process (PID=21499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:00,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:00,348] {logging_mixin.py:95} INFO - [2019-09-15 18:14:00,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:00,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:00,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:00,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:00,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:14:00,794] {scheduler_job.py:146} INFO - Started process (PID=21501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:05,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:05,803] {logging_mixin.py:95} INFO - [2019-09-15 18:14:05,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:06,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:06,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:06,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:06,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:14:06,240] {scheduler_job.py:146} INFO - Started process (PID=21502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:11,249] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:11,250] {logging_mixin.py:95} INFO - [2019-09-15 18:14:11,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:11,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:11,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:11,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:11,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:14:11,693] {scheduler_job.py:146} INFO - Started process (PID=21503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:16,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:16,704] {logging_mixin.py:95} INFO - [2019-09-15 18:14:16,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:17,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:17,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:17,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:17,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:14:17,136] {scheduler_job.py:146} INFO - Started process (PID=21506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:22,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:22,147] {logging_mixin.py:95} INFO - [2019-09-15 18:14:22,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:22,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:22,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:22,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:22,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:14:22,580] {scheduler_job.py:146} INFO - Started process (PID=21507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:27,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:27,590] {logging_mixin.py:95} INFO - [2019-09-15 18:14:27,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:27,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:27,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:27,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:27,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:14:28,027] {scheduler_job.py:146} INFO - Started process (PID=21509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:33,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:33,039] {logging_mixin.py:95} INFO - [2019-09-15 18:14:33,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:33,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:33,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:33,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:33,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:14:33,475] {scheduler_job.py:146} INFO - Started process (PID=21511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:38,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:38,482] {logging_mixin.py:95} INFO - [2019-09-15 18:14:38,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:38,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:38,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:38,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:38,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:14:38,918] {scheduler_job.py:146} INFO - Started process (PID=21512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:43,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:43,929] {logging_mixin.py:95} INFO - [2019-09-15 18:14:43,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:44,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:44,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:44,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:44,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:14:44,366] {scheduler_job.py:146} INFO - Started process (PID=21514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:49,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:49,377] {logging_mixin.py:95} INFO - [2019-09-15 18:14:49,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:49,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:49,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:49,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:49,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:14:49,810] {scheduler_job.py:146} INFO - Started process (PID=21515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:54,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:14:54,818] {logging_mixin.py:95} INFO - [2019-09-15 18:14:54,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:55,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:14:55,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:14:55,207] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:14:55,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:14:55,263] {scheduler_job.py:146} INFO - Started process (PID=21516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:00,268] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:00,270] {logging_mixin.py:95} INFO - [2019-09-15 18:15:00,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:00,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:00,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:00,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:00,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:15:00,712] {scheduler_job.py:146} INFO - Started process (PID=21518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:05,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:05,720] {logging_mixin.py:95} INFO - [2019-09-15 18:15:05,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:06,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:06,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:06,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:06,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:15:06,160] {scheduler_job.py:146} INFO - Started process (PID=21519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:11,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:11,167] {logging_mixin.py:95} INFO - [2019-09-15 18:15:11,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:11,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:11,547] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:11,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:11,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:15:11,611] {scheduler_job.py:146} INFO - Started process (PID=21520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:16,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:16,621] {logging_mixin.py:95} INFO - [2019-09-15 18:15:16,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:16,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:16,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:17,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:17,011] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:15:17,058] {scheduler_job.py:146} INFO - Started process (PID=21522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:22,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:22,069] {logging_mixin.py:95} INFO - [2019-09-15 18:15:22,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:22,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:22,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:22,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:22,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:15:22,507] {scheduler_job.py:146} INFO - Started process (PID=21523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:27,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:27,519] {logging_mixin.py:95} INFO - [2019-09-15 18:15:27,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:27,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:27,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:27,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:27,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:15:27,956] {scheduler_job.py:146} INFO - Started process (PID=21525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:32,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:32,964] {logging_mixin.py:95} INFO - [2019-09-15 18:15:32,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:33,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:33,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:33,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:33,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:15:33,406] {scheduler_job.py:146} INFO - Started process (PID=21527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:38,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:38,414] {logging_mixin.py:95} INFO - [2019-09-15 18:15:38,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:38,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:38,795] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:38,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:38,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:15:38,858] {scheduler_job.py:146} INFO - Started process (PID=21528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:43,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:43,866] {logging_mixin.py:95} INFO - [2019-09-15 18:15:43,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:44,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:44,243] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:44,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:44,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:15:44,306] {scheduler_job.py:146} INFO - Started process (PID=21530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:49,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:49,316] {logging_mixin.py:95} INFO - [2019-09-15 18:15:49,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:49,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:49,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:49,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:49,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:15:49,753] {scheduler_job.py:146} INFO - Started process (PID=21531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:54,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:15:54,764] {logging_mixin.py:95} INFO - [2019-09-15 18:15:54,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:55,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:15:55,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:15:55,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:15:55,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:15:55,200] {scheduler_job.py:146} INFO - Started process (PID=21532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:00,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:00,209] {logging_mixin.py:95} INFO - [2019-09-15 18:16:00,209] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:00,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:00,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:00,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:00,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:16:00,645] {scheduler_job.py:146} INFO - Started process (PID=21534) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:05,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:05,651] {logging_mixin.py:95} INFO - [2019-09-15 18:16:05,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:06,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:06,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:06,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:06,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:16:06,095] {scheduler_job.py:146} INFO - Started process (PID=21535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:11,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:11,106] {logging_mixin.py:95} INFO - [2019-09-15 18:16:11,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:11,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:11,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:11,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:11,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:16:11,541] {scheduler_job.py:146} INFO - Started process (PID=21536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:16,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:16,550] {logging_mixin.py:95} INFO - [2019-09-15 18:16:16,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:16,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:16,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:16,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:16,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:16:16,993] {scheduler_job.py:146} INFO - Started process (PID=21538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:22,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:22,003] {logging_mixin.py:95} INFO - [2019-09-15 18:16:22,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:22,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:22,389] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:22,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:22,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:16:22,440] {scheduler_job.py:146} INFO - Started process (PID=21539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:27,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:27,449] {logging_mixin.py:95} INFO - [2019-09-15 18:16:27,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:27,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:27,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:27,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:27,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:16:27,891] {scheduler_job.py:146} INFO - Started process (PID=21541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:32,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:32,900] {logging_mixin.py:95} INFO - [2019-09-15 18:16:32,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:33,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:33,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:33,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:33,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:16:33,337] {scheduler_job.py:146} INFO - Started process (PID=21543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:38,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:38,348] {logging_mixin.py:95} INFO - [2019-09-15 18:16:38,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:38,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:38,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:38,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:38,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:16:38,785] {scheduler_job.py:146} INFO - Started process (PID=21544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:43,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:43,795] {logging_mixin.py:95} INFO - [2019-09-15 18:16:43,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:44,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:44,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:44,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:44,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:16:44,234] {scheduler_job.py:146} INFO - Started process (PID=21546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:49,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:49,243] {logging_mixin.py:95} INFO - [2019-09-15 18:16:49,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:49,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:49,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:49,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:49,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:16:49,683] {scheduler_job.py:146} INFO - Started process (PID=21547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:54,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:16:54,695] {logging_mixin.py:95} INFO - [2019-09-15 18:16:54,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:55,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:16:55,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:16:55,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:16:55,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:16:55,131] {scheduler_job.py:146} INFO - Started process (PID=21548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:00,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:00,140] {logging_mixin.py:95} INFO - [2019-09-15 18:17:00,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:00,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:00,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:00,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:00,532] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:17:00,575] {scheduler_job.py:146} INFO - Started process (PID=21550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:05,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:05,584] {logging_mixin.py:95} INFO - [2019-09-15 18:17:05,583] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:05,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:05,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:05,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:05,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:17:06,023] {scheduler_job.py:146} INFO - Started process (PID=21551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:11,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:11,033] {logging_mixin.py:95} INFO - [2019-09-15 18:17:11,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:11,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:11,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:11,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:11,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:17:11,476] {scheduler_job.py:146} INFO - Started process (PID=21552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:16,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:16,482] {logging_mixin.py:95} INFO - [2019-09-15 18:17:16,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:16,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:16,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:16,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:16,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:17:16,918] {scheduler_job.py:146} INFO - Started process (PID=21555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:21,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:21,930] {logging_mixin.py:95} INFO - [2019-09-15 18:17:21,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:22,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:22,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:22,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:22,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:17:22,368] {scheduler_job.py:146} INFO - Started process (PID=21556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:27,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:27,380] {logging_mixin.py:95} INFO - [2019-09-15 18:17:27,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:27,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:27,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:27,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:27,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:17:27,814] {scheduler_job.py:146} INFO - Started process (PID=21558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:32,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:32,823] {logging_mixin.py:95} INFO - [2019-09-15 18:17:32,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:33,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:33,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:33,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:33,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:17:33,266] {scheduler_job.py:146} INFO - Started process (PID=21560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:38,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:38,274] {logging_mixin.py:95} INFO - [2019-09-15 18:17:38,274] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:38,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:38,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:38,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:38,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:17:38,715] {scheduler_job.py:146} INFO - Started process (PID=21561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:43,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:43,723] {logging_mixin.py:95} INFO - [2019-09-15 18:17:43,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:44,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:44,110] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:44,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:44,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:17:44,158] {scheduler_job.py:146} INFO - Started process (PID=21563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:49,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:49,168] {logging_mixin.py:95} INFO - [2019-09-15 18:17:49,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:49,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:49,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:49,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:49,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:17:49,607] {scheduler_job.py:146} INFO - Started process (PID=21564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:54,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:17:54,616] {logging_mixin.py:95} INFO - [2019-09-15 18:17:54,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:54,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:17:54,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:17:55,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:17:55,011] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:17:55,061] {scheduler_job.py:146} INFO - Started process (PID=21565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:00,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:00,070] {logging_mixin.py:95} INFO - [2019-09-15 18:18:00,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:00,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:00,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:00,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:00,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 18:18:00,506] {scheduler_job.py:146} INFO - Started process (PID=21567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:05,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:05,517] {logging_mixin.py:95} INFO - [2019-09-15 18:18:05,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:05,857] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:05,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:05,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:05,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:18:05,957] {scheduler_job.py:146} INFO - Started process (PID=21569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:10,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:10,964] {logging_mixin.py:95} INFO - [2019-09-15 18:18:10,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:11,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:11,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:11,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:11,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 18:18:11,418] {scheduler_job.py:146} INFO - Started process (PID=21570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:16,424] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:16,425] {logging_mixin.py:95} INFO - [2019-09-15 18:18:16,425] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:16,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:16,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:16,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:16,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:18:16,875] {scheduler_job.py:146} INFO - Started process (PID=21572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:21,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:21,886] {logging_mixin.py:95} INFO - [2019-09-15 18:18:21,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:22,239] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:22,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:22,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:22,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:18:22,334] {scheduler_job.py:146} INFO - Started process (PID=21573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:27,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:27,342] {logging_mixin.py:95} INFO - [2019-09-15 18:18:27,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:27,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:27,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:27,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:27,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:18:27,796] {scheduler_job.py:146} INFO - Started process (PID=21575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:32,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:32,808] {logging_mixin.py:95} INFO - [2019-09-15 18:18:32,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:33,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:33,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:33,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:33,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:18:33,258] {scheduler_job.py:146} INFO - Started process (PID=21577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:38,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:38,267] {logging_mixin.py:95} INFO - [2019-09-15 18:18:38,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:38,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:38,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:38,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:38,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 18:18:38,709] {scheduler_job.py:146} INFO - Started process (PID=21578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:43,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:43,717] {logging_mixin.py:95} INFO - [2019-09-15 18:18:43,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:44,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:44,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:44,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:44,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:18:44,175] {scheduler_job.py:146} INFO - Started process (PID=21580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:49,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:49,183] {logging_mixin.py:95} INFO - [2019-09-15 18:18:49,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:49,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:49,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:49,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:49,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:18:49,633] {scheduler_job.py:146} INFO - Started process (PID=21581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:54,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:18:54,641] {logging_mixin.py:95} INFO - [2019-09-15 18:18:54,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:54,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:18:55,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:18:55,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:18:55,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:18:55,089] {scheduler_job.py:146} INFO - Started process (PID=21582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:00,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:00,097] {logging_mixin.py:95} INFO - [2019-09-15 18:19:00,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:00,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:00,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:00,477] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:00,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:19:00,549] {scheduler_job.py:146} INFO - Started process (PID=21584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:05,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:05,561] {logging_mixin.py:95} INFO - [2019-09-15 18:19:05,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:05,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:05,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:05,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:05,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:19:06,008] {scheduler_job.py:146} INFO - Started process (PID=21585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:11,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:11,018] {logging_mixin.py:95} INFO - [2019-09-15 18:19:11,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:11,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:11,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:11,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:11,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:19:11,471] {scheduler_job.py:146} INFO - Started process (PID=21586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:16,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:16,479] {logging_mixin.py:95} INFO - [2019-09-15 18:19:16,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:16,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:16,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:16,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:16,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:19:16,932] {scheduler_job.py:146} INFO - Started process (PID=21588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:21,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:21,944] {logging_mixin.py:95} INFO - [2019-09-15 18:19:21,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:22,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:22,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:22,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:22,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:19:22,395] {scheduler_job.py:146} INFO - Started process (PID=21589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:27,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:27,408] {logging_mixin.py:95} INFO - [2019-09-15 18:19:27,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:27,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:27,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:27,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:27,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:19:27,854] {scheduler_job.py:146} INFO - Started process (PID=21591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:32,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:32,863] {logging_mixin.py:95} INFO - [2019-09-15 18:19:32,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:33,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:33,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:33,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:33,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:19:33,308] {scheduler_job.py:146} INFO - Started process (PID=21593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:38,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:38,314] {logging_mixin.py:95} INFO - [2019-09-15 18:19:38,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:38,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:38,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:38,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:38,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:19:38,772] {scheduler_job.py:146} INFO - Started process (PID=21594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:43,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:43,780] {logging_mixin.py:95} INFO - [2019-09-15 18:19:43,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:44,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:44,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:44,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:44,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:19:44,229] {scheduler_job.py:146} INFO - Started process (PID=21596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:49,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:49,239] {logging_mixin.py:95} INFO - [2019-09-15 18:19:49,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:49,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:49,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:49,607] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:49,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 18:19:49,692] {scheduler_job.py:146} INFO - Started process (PID=21597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:54,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:19:54,704] {logging_mixin.py:95} INFO - [2019-09-15 18:19:54,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:55,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:19:55,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:19:55,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:19:55,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:19:55,158] {scheduler_job.py:146} INFO - Started process (PID=21598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:00,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:00,164] {logging_mixin.py:95} INFO - [2019-09-15 18:20:00,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:00,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:00,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:00,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:00,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:20:00,614] {scheduler_job.py:146} INFO - Started process (PID=21600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:05,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:05,621] {logging_mixin.py:95} INFO - [2019-09-15 18:20:05,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:05,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:05,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:06,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:06,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:20:06,071] {scheduler_job.py:146} INFO - Started process (PID=21601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:11,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:11,077] {logging_mixin.py:95} INFO - [2019-09-15 18:20:11,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:11,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:11,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:11,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:11,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:20:11,525] {scheduler_job.py:146} INFO - Started process (PID=21602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:16,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:16,535] {logging_mixin.py:95} INFO - [2019-09-15 18:20:16,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:16,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:16,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:16,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:16,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:20:16,984] {scheduler_job.py:146} INFO - Started process (PID=21604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:21,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:21,991] {logging_mixin.py:95} INFO - [2019-09-15 18:20:21,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:22,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:22,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:22,376] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:22,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:20:22,434] {scheduler_job.py:146} INFO - Started process (PID=21605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:27,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:27,441] {logging_mixin.py:95} INFO - [2019-09-15 18:20:27,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:27,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:27,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:27,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:27,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:20:27,890] {scheduler_job.py:146} INFO - Started process (PID=21607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:32,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:32,901] {logging_mixin.py:95} INFO - [2019-09-15 18:20:32,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:33,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:33,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:33,280] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:33,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:20:33,354] {scheduler_job.py:146} INFO - Started process (PID=21609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:38,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:38,363] {logging_mixin.py:95} INFO - [2019-09-15 18:20:38,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:38,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:38,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:38,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:38,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:20:38,809] {scheduler_job.py:146} INFO - Started process (PID=21610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:43,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:43,818] {logging_mixin.py:95} INFO - [2019-09-15 18:20:43,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:44,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:44,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:44,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:44,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:20:44,270] {scheduler_job.py:146} INFO - Started process (PID=21612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:49,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:49,279] {logging_mixin.py:95} INFO - [2019-09-15 18:20:49,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:49,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:49,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:49,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:49,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:20:49,729] {scheduler_job.py:146} INFO - Started process (PID=21613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:54,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:20:54,741] {logging_mixin.py:95} INFO - [2019-09-15 18:20:54,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:55,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:20:55,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:20:55,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:20:55,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:20:55,192] {scheduler_job.py:146} INFO - Started process (PID=21614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:00,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:00,203] {logging_mixin.py:95} INFO - [2019-09-15 18:21:00,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:00,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:00,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:00,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:00,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:21:00,650] {scheduler_job.py:146} INFO - Started process (PID=21616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:05,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:05,661] {logging_mixin.py:95} INFO - [2019-09-15 18:21:05,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:06,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:06,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:06,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:06,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:21:06,111] {scheduler_job.py:146} INFO - Started process (PID=21617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:11,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:11,122] {logging_mixin.py:95} INFO - [2019-09-15 18:21:11,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:11,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:11,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:11,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:11,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:21:11,573] {scheduler_job.py:146} INFO - Started process (PID=21618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:16,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:16,580] {logging_mixin.py:95} INFO - [2019-09-15 18:21:16,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:16,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:16,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:16,961] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:16,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:21:17,023] {scheduler_job.py:146} INFO - Started process (PID=21620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:22,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:22,030] {logging_mixin.py:95} INFO - [2019-09-15 18:21:22,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:22,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:22,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:22,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:22,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:21:22,479] {scheduler_job.py:146} INFO - Started process (PID=21621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:27,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:27,486] {logging_mixin.py:95} INFO - [2019-09-15 18:21:27,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:27,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:27,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:27,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:27,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 18:21:28,027] {scheduler_job.py:146} INFO - Started process (PID=21623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:33,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:33,050] {logging_mixin.py:95} INFO - [2019-09-15 18:21:33,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:33,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:33,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:33,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:33,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:21:33,478] {scheduler_job.py:146} INFO - Started process (PID=21625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:38,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:38,488] {logging_mixin.py:95} INFO - [2019-09-15 18:21:38,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:38,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:38,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:38,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:38,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:21:38,939] {scheduler_job.py:146} INFO - Started process (PID=21626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:43,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:43,949] {logging_mixin.py:95} INFO - [2019-09-15 18:21:43,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:44,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:44,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:44,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:44,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-09-15 18:21:44,482] {scheduler_job.py:146} INFO - Started process (PID=21635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:49,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:49,495] {logging_mixin.py:95} INFO - [2019-09-15 18:21:49,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:49,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:49,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:49,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:49,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 18:21:50,022] {scheduler_job.py:146} INFO - Started process (PID=21636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:55,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:21:55,031] {logging_mixin.py:95} INFO - [2019-09-15 18:21:55,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:55,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:21:55,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:21:55,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:21:55,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-15 18:21:55,571] {scheduler_job.py:146} INFO - Started process (PID=21637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:00,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:00,579] {logging_mixin.py:95} INFO - [2019-09-15 18:22:00,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:00,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:00,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:00,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:00,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:22:01,016] {scheduler_job.py:146} INFO - Started process (PID=21639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:06,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:06,026] {logging_mixin.py:95} INFO - [2019-09-15 18:22:06,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:06,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:06,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:06,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:06,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:22:06,460] {scheduler_job.py:146} INFO - Started process (PID=21640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:11,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:11,467] {logging_mixin.py:95} INFO - [2019-09-15 18:22:11,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:11,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:11,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:11,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:11,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 18:22:12,000] {scheduler_job.py:146} INFO - Started process (PID=21641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:17,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:17,009] {logging_mixin.py:95} INFO - [2019-09-15 18:22:17,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:17,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:17,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:17,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:17,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:22:17,541] {scheduler_job.py:146} INFO - Started process (PID=21643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:22,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:22,547] {logging_mixin.py:95} INFO - [2019-09-15 18:22:22,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:22,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:22,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:22,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:22,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 18:22:22,989] {scheduler_job.py:146} INFO - Started process (PID=21644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:27,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:27,996] {logging_mixin.py:95} INFO - [2019-09-15 18:22:27,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:28,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:28,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:28,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:28,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.563 seconds
[2019-09-15 18:22:28,631] {scheduler_job.py:146} INFO - Started process (PID=21649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:33,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:33,638] {logging_mixin.py:95} INFO - [2019-09-15 18:22:33,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:33,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:34,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:34,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:34,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:22:34,081] {scheduler_job.py:146} INFO - Started process (PID=21651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:39,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:39,092] {logging_mixin.py:95} INFO - [2019-09-15 18:22:39,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:39,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:39,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:39,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:39,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 18:22:39,636] {scheduler_job.py:146} INFO - Started process (PID=21652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:44,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:44,645] {logging_mixin.py:95} INFO - [2019-09-15 18:22:44,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:44,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:45,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:45,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:45,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:22:45,083] {scheduler_job.py:146} INFO - Started process (PID=21654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:50,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:50,092] {logging_mixin.py:95} INFO - [2019-09-15 18:22:50,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:50,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:50,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:50,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:50,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:22:50,529] {scheduler_job.py:146} INFO - Started process (PID=21655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:55,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:22:55,540] {logging_mixin.py:95} INFO - [2019-09-15 18:22:55,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:55,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:22:55,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:22:55,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:22:55,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:22:55,989] {scheduler_job.py:146} INFO - Started process (PID=21656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:00,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:00,998] {logging_mixin.py:95} INFO - [2019-09-15 18:23:00,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:01,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:01,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:01,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:01,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:23:01,445] {scheduler_job.py:146} INFO - Started process (PID=21658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:06,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:06,454] {logging_mixin.py:95} INFO - [2019-09-15 18:23:06,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:06,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:06,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:06,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:06,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:23:06,894] {scheduler_job.py:146} INFO - Started process (PID=21659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:11,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:11,902] {logging_mixin.py:95} INFO - [2019-09-15 18:23:11,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:12,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:12,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:12,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:12,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:23:12,349] {scheduler_job.py:146} INFO - Started process (PID=21660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:17,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:17,358] {logging_mixin.py:95} INFO - [2019-09-15 18:23:17,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:17,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:17,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:17,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:17,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:23:17,805] {scheduler_job.py:146} INFO - Started process (PID=21662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:22,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:22,812] {logging_mixin.py:95} INFO - [2019-09-15 18:23:22,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:23,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:23,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:23,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:23,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:23:23,255] {scheduler_job.py:146} INFO - Started process (PID=21663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:28,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:28,264] {logging_mixin.py:95} INFO - [2019-09-15 18:23:28,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:28,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:28,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:28,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:28,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 18:23:28,800] {scheduler_job.py:146} INFO - Started process (PID=21665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:33,804] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:33,805] {logging_mixin.py:95} INFO - [2019-09-15 18:23:33,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:34,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:34,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:34,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:34,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 18:23:34,341] {scheduler_job.py:146} INFO - Started process (PID=21667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:39,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:39,348] {logging_mixin.py:95} INFO - [2019-09-15 18:23:39,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:39,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:39,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:39,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:39,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-15 18:23:39,880] {scheduler_job.py:146} INFO - Started process (PID=21668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:44,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:44,889] {logging_mixin.py:95} INFO - [2019-09-15 18:23:44,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:45,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:45,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:45,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:45,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:23:45,315] {scheduler_job.py:146} INFO - Started process (PID=21670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:50,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:50,323] {logging_mixin.py:95} INFO - [2019-09-15 18:23:50,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:50,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:50,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:50,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:50,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:23:50,752] {scheduler_job.py:146} INFO - Started process (PID=21671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:55,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:23:55,760] {logging_mixin.py:95} INFO - [2019-09-15 18:23:55,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:56,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:23:56,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:23:56,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:23:56,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:23:56,197] {scheduler_job.py:146} INFO - Started process (PID=21672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:01,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:01,204] {logging_mixin.py:95} INFO - [2019-09-15 18:24:01,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:01,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:01,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:01,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:01,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-15 18:24:01,726] {scheduler_job.py:146} INFO - Started process (PID=21674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:06,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:06,736] {logging_mixin.py:95} INFO - [2019-09-15 18:24:06,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:07,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:07,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:07,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:07,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 18:24:07,260] {scheduler_job.py:146} INFO - Started process (PID=21675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:12,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:12,272] {logging_mixin.py:95} INFO - [2019-09-15 18:24:12,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:12,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:12,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:12,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:12,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.490 seconds
[2019-09-15 18:24:12,802] {scheduler_job.py:146} INFO - Started process (PID=21676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:17,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:17,812] {logging_mixin.py:95} INFO - [2019-09-15 18:24:17,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:18,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:18,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:18,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:18,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-15 18:24:18,338] {scheduler_job.py:146} INFO - Started process (PID=21678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:23,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:23,345] {logging_mixin.py:95} INFO - [2019-09-15 18:24:23,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:23,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:23,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:23,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:23,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:24:23,783] {scheduler_job.py:146} INFO - Started process (PID=21679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:28,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:28,792] {logging_mixin.py:95} INFO - [2019-09-15 18:24:28,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:29,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:29,172] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:29,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:29,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:24:29,226] {scheduler_job.py:146} INFO - Started process (PID=21682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:34,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:34,236] {logging_mixin.py:95} INFO - [2019-09-15 18:24:34,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:34,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:34,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:34,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:34,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 18:24:34,778] {scheduler_job.py:146} INFO - Started process (PID=21683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:39,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:39,787] {logging_mixin.py:95} INFO - [2019-09-15 18:24:39,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:40,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:40,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:40,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:40,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 18:24:40,314] {scheduler_job.py:146} INFO - Started process (PID=21684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:45,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:45,325] {logging_mixin.py:95} INFO - [2019-09-15 18:24:45,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:45,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:45,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:45,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:45,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:24:45,750] {scheduler_job.py:146} INFO - Started process (PID=21686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:50,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:50,761] {logging_mixin.py:95} INFO - [2019-09-15 18:24:50,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:51,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:51,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:51,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:51,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:24:51,185] {scheduler_job.py:146} INFO - Started process (PID=21687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:56,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:24:56,196] {logging_mixin.py:95} INFO - [2019-09-15 18:24:56,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:56,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:24:56,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:24:56,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:24:56,636] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 18:24:56,727] {scheduler_job.py:146} INFO - Started process (PID=21688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:01,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:01,736] {logging_mixin.py:95} INFO - [2019-09-15 18:25:01,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:02,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:02,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:02,146] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:02,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:25:02,268] {scheduler_job.py:146} INFO - Started process (PID=21690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:07,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:07,276] {logging_mixin.py:95} INFO - [2019-09-15 18:25:07,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:07,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:07,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:07,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:07,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 18:25:07,806] {scheduler_job.py:146} INFO - Started process (PID=21691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:12,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:12,813] {logging_mixin.py:95} INFO - [2019-09-15 18:25:12,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:13,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:13,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:13,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:13,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 18:25:13,343] {scheduler_job.py:146} INFO - Started process (PID=21692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:18,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:18,349] {logging_mixin.py:95} INFO - [2019-09-15 18:25:18,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:18,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:18,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:18,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:18,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:25:18,782] {scheduler_job.py:146} INFO - Started process (PID=21694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:23,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:23,793] {logging_mixin.py:95} INFO - [2019-09-15 18:25:23,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:24,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:24,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:24,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:24,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:25:24,214] {scheduler_job.py:146} INFO - Started process (PID=21695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:29,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:29,222] {logging_mixin.py:95} INFO - [2019-09-15 18:25:29,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:29,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:29,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:29,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:29,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:25:29,659] {scheduler_job.py:146} INFO - Started process (PID=21698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:34,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:34,675] {logging_mixin.py:95} INFO - [2019-09-15 18:25:34,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:35,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:35,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:35,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:35,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-09-15 18:25:35,200] {scheduler_job.py:146} INFO - Started process (PID=21699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:40,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:40,208] {logging_mixin.py:95} INFO - [2019-09-15 18:25:40,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:40,571] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:40,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:40,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:40,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:25:40,636] {scheduler_job.py:146} INFO - Started process (PID=21700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:45,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:45,642] {logging_mixin.py:95} INFO - [2019-09-15 18:25:45,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:46,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:46,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:46,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:46,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.533 seconds
[2019-09-15 18:25:46,278] {scheduler_job.py:146} INFO - Started process (PID=21702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:51,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:51,285] {logging_mixin.py:95} INFO - [2019-09-15 18:25:51,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:51,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:51,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:51,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:51,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:25:51,717] {scheduler_job.py:146} INFO - Started process (PID=21703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:56,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:25:56,728] {logging_mixin.py:95} INFO - [2019-09-15 18:25:56,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:57,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:25:57,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:25:57,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:25:57,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 18:25:57,259] {scheduler_job.py:146} INFO - Started process (PID=21704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:02,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:02,265] {logging_mixin.py:95} INFO - [2019-09-15 18:26:02,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:02,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:02,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:02,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:02,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 18:26:02,796] {scheduler_job.py:146} INFO - Started process (PID=21706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:07,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:07,803] {logging_mixin.py:95} INFO - [2019-09-15 18:26:07,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:08,327] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:08,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:08,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:08,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.564 seconds
[2019-09-15 18:26:08,437] {scheduler_job.py:146} INFO - Started process (PID=21708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:13,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:13,444] {logging_mixin.py:95} INFO - [2019-09-15 18:26:13,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:13,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:13,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:13,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:13,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 18:26:13,983] {scheduler_job.py:146} INFO - Started process (PID=21711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:18,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:18,994] {logging_mixin.py:95} INFO - [2019-09-15 18:26:18,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:19,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:19,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:19,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:19,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 18:26:19,521] {scheduler_job.py:146} INFO - Started process (PID=21713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:24,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:24,528] {logging_mixin.py:95} INFO - [2019-09-15 18:26:24,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:24,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:24,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:24,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:24,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 18:26:25,070] {scheduler_job.py:146} INFO - Started process (PID=21714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:30,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:30,077] {logging_mixin.py:95} INFO - [2019-09-15 18:26:30,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:30,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:30,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:30,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:30,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:26:30,503] {scheduler_job.py:146} INFO - Started process (PID=21718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:35,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:35,513] {logging_mixin.py:95} INFO - [2019-09-15 18:26:35,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:35,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:35,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:35,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:35,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:26:36,038] {scheduler_job.py:146} INFO - Started process (PID=21719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:41,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:41,045] {logging_mixin.py:95} INFO - [2019-09-15 18:26:41,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:41,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:41,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:41,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:41,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:26:41,489] {scheduler_job.py:146} INFO - Started process (PID=21721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:46,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:46,498] {logging_mixin.py:95} INFO - [2019-09-15 18:26:46,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:46,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:46,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:46,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:46,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:26:46,950] {scheduler_job.py:146} INFO - Started process (PID=21723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:51,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:51,959] {logging_mixin.py:95} INFO - [2019-09-15 18:26:51,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:52,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:52,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:52,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:52,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:26:52,408] {scheduler_job.py:146} INFO - Started process (PID=21724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:57,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:26:57,419] {logging_mixin.py:95} INFO - [2019-09-15 18:26:57,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:57,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:26:57,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:26:57,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:26:57,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:26:57,871] {scheduler_job.py:146} INFO - Started process (PID=21725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:02,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:02,878] {logging_mixin.py:95} INFO - [2019-09-15 18:27:02,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:03,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:03,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:03,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:03,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:27:03,316] {scheduler_job.py:146} INFO - Started process (PID=21727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:08,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:08,325] {logging_mixin.py:95} INFO - [2019-09-15 18:27:08,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:08,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:08,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:08,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:08,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 18:27:08,863] {scheduler_job.py:146} INFO - Started process (PID=21728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:13,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:13,871] {logging_mixin.py:95} INFO - [2019-09-15 18:27:13,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:14,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:14,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:14,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:14,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:27:14,308] {scheduler_job.py:146} INFO - Started process (PID=21730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:19,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:19,316] {logging_mixin.py:95} INFO - [2019-09-15 18:27:19,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:19,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:19,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:19,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:19,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:27:19,757] {scheduler_job.py:146} INFO - Started process (PID=21733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:24,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:24,765] {logging_mixin.py:95} INFO - [2019-09-15 18:27:24,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:25,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:25,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:25,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:25,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:27:25,213] {scheduler_job.py:146} INFO - Started process (PID=21737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:30,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:30,223] {logging_mixin.py:95} INFO - [2019-09-15 18:27:30,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:30,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:30,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:30,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:30,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:27:30,667] {scheduler_job.py:146} INFO - Started process (PID=21740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:35,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:35,673] {logging_mixin.py:95} INFO - [2019-09-15 18:27:35,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:36,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:36,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:36,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:36,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:27:36,117] {scheduler_job.py:146} INFO - Started process (PID=21741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:41,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:41,124] {logging_mixin.py:95} INFO - [2019-09-15 18:27:41,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:41,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:41,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:41,548] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:41,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 18:27:41,675] {scheduler_job.py:146} INFO - Started process (PID=21742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:46,683] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:46,684] {logging_mixin.py:95} INFO - [2019-09-15 18:27:46,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:47,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:47,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:47,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:47,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 18:27:47,220] {scheduler_job.py:146} INFO - Started process (PID=21746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:52,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:52,226] {logging_mixin.py:95} INFO - [2019-09-15 18:27:52,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:52,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:52,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:52,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:52,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:27:52,661] {scheduler_job.py:146} INFO - Started process (PID=21747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:57,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:27:57,670] {logging_mixin.py:95} INFO - [2019-09-15 18:27:57,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:58,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:27:58,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:27:58,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:27:58,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:27:58,111] {scheduler_job.py:146} INFO - Started process (PID=21748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:03,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:03,119] {logging_mixin.py:95} INFO - [2019-09-15 18:28:03,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:03,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:03,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:03,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:03,504] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:28:03,562] {scheduler_job.py:146} INFO - Started process (PID=21750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:08,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:08,574] {logging_mixin.py:95} INFO - [2019-09-15 18:28:08,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:08,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:08,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:08,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:08,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:28:09,019] {scheduler_job.py:146} INFO - Started process (PID=21751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:14,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:14,030] {logging_mixin.py:95} INFO - [2019-09-15 18:28:14,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:14,380] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:14,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:14,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:14,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:28:14,475] {scheduler_job.py:146} INFO - Started process (PID=21753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:19,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:19,486] {logging_mixin.py:95} INFO - [2019-09-15 18:28:19,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:19,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:19,848] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:19,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:19,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 18:28:19,936] {scheduler_job.py:146} INFO - Started process (PID=21754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:24,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:24,945] {logging_mixin.py:95} INFO - [2019-09-15 18:28:24,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:25,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:25,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:25,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:25,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:28:25,395] {scheduler_job.py:146} INFO - Started process (PID=21755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:30,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:30,401] {logging_mixin.py:95} INFO - [2019-09-15 18:28:30,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:30,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:30,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:30,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:30,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:28:30,851] {scheduler_job.py:146} INFO - Started process (PID=21758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:35,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:35,868] {logging_mixin.py:95} INFO - [2019-09-15 18:28:35,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:36,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:36,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:36,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:36,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:28:36,315] {scheduler_job.py:146} INFO - Started process (PID=21759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:41,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:41,323] {logging_mixin.py:95} INFO - [2019-09-15 18:28:41,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:41,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:41,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:41,731] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:41,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:28:41,769] {scheduler_job.py:146} INFO - Started process (PID=21762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:46,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:46,779] {logging_mixin.py:95} INFO - [2019-09-15 18:28:46,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:47,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:47,178] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:47,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:47,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:28:47,226] {scheduler_job.py:146} INFO - Started process (PID=21764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:52,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:52,238] {logging_mixin.py:95} INFO - [2019-09-15 18:28:52,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:52,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:52,614] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:52,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:52,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:28:52,680] {scheduler_job.py:146} INFO - Started process (PID=21765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:57,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:28:57,689] {logging_mixin.py:95} INFO - [2019-09-15 18:28:57,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:58,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:28:58,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:28:58,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:28:58,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:28:58,128] {scheduler_job.py:146} INFO - Started process (PID=21766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:03,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:03,135] {logging_mixin.py:95} INFO - [2019-09-15 18:29:03,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:03,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:03,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:03,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:03,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:29:03,585] {scheduler_job.py:146} INFO - Started process (PID=21768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:08,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:08,595] {logging_mixin.py:95} INFO - [2019-09-15 18:29:08,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:08,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:09,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:09,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:09,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 18:29:09,136] {scheduler_job.py:146} INFO - Started process (PID=21769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:14,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:14,144] {logging_mixin.py:95} INFO - [2019-09-15 18:29:14,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:14,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:14,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:14,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:14,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:29:14,584] {scheduler_job.py:146} INFO - Started process (PID=21771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:19,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:19,592] {logging_mixin.py:95} INFO - [2019-09-15 18:29:19,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:19,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:19,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:19,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:19,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:29:20,043] {scheduler_job.py:146} INFO - Started process (PID=21772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:25,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:25,054] {logging_mixin.py:95} INFO - [2019-09-15 18:29:25,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:25,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:25,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:25,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:25,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:29:25,487] {scheduler_job.py:146} INFO - Started process (PID=21773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:30,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:30,494] {logging_mixin.py:95} INFO - [2019-09-15 18:29:30,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:30,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:30,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:30,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:30,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:29:30,934] {scheduler_job.py:146} INFO - Started process (PID=21776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:35,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:35,941] {logging_mixin.py:95} INFO - [2019-09-15 18:29:35,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:36,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:36,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:36,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:36,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:29:36,385] {scheduler_job.py:146} INFO - Started process (PID=21777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:41,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:41,391] {logging_mixin.py:95} INFO - [2019-09-15 18:29:41,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:41,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:41,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:41,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:41,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:29:41,841] {scheduler_job.py:146} INFO - Started process (PID=21778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:46,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:46,850] {logging_mixin.py:95} INFO - [2019-09-15 18:29:46,850] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:47,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:47,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:47,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:47,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:29:47,284] {scheduler_job.py:146} INFO - Started process (PID=21780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:52,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:52,291] {logging_mixin.py:95} INFO - [2019-09-15 18:29:52,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:52,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:52,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:52,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:52,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:29:52,743] {scheduler_job.py:146} INFO - Started process (PID=21781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:57,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:29:57,754] {logging_mixin.py:95} INFO - [2019-09-15 18:29:57,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:58,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:29:58,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:29:58,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:29:58,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:29:58,191] {scheduler_job.py:146} INFO - Started process (PID=21782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:03,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:03,198] {logging_mixin.py:95} INFO - [2019-09-15 18:30:03,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:03,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:03,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:03,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:03,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:30:03,650] {scheduler_job.py:146} INFO - Started process (PID=21785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:08,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:08,657] {logging_mixin.py:95} INFO - [2019-09-15 18:30:08,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:08,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:09,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:09,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:09,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 18:30:09,109] {scheduler_job.py:146} INFO - Started process (PID=21786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:14,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:14,116] {logging_mixin.py:95} INFO - [2019-09-15 18:30:14,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:14,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:14,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:14,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:14,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:30:14,570] {scheduler_job.py:146} INFO - Started process (PID=21788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:19,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:19,578] {logging_mixin.py:95} INFO - [2019-09-15 18:30:19,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:19,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:19,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:19,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:19,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:30:20,027] {scheduler_job.py:146} INFO - Started process (PID=21789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:25,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:25,034] {logging_mixin.py:95} INFO - [2019-09-15 18:30:25,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:25,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:25,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:25,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:25,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:30:25,486] {scheduler_job.py:146} INFO - Started process (PID=21790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:30,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:30,493] {logging_mixin.py:95} INFO - [2019-09-15 18:30:30,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:30,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:30,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:30,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:30,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:30:30,945] {scheduler_job.py:146} INFO - Started process (PID=21793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:35,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:35,956] {logging_mixin.py:95} INFO - [2019-09-15 18:30:35,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:36,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:36,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:36,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:36,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:30:36,402] {scheduler_job.py:146} INFO - Started process (PID=21794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:41,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:41,414] {logging_mixin.py:95} INFO - [2019-09-15 18:30:41,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:41,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:41,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:41,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:41,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:30:41,862] {scheduler_job.py:146} INFO - Started process (PID=21795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:46,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:46,872] {logging_mixin.py:95} INFO - [2019-09-15 18:30:46,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:47,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:47,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:47,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:47,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:30:47,319] {scheduler_job.py:146} INFO - Started process (PID=21797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:52,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:52,327] {logging_mixin.py:95} INFO - [2019-09-15 18:30:52,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:52,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:52,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:52,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:52,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 18:30:52,781] {scheduler_job.py:146} INFO - Started process (PID=21798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:57,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:30:57,790] {logging_mixin.py:95} INFO - [2019-09-15 18:30:57,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:58,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:30:58,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:30:58,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:30:58,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:30:58,241] {scheduler_job.py:146} INFO - Started process (PID=21799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:03,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:03,248] {logging_mixin.py:95} INFO - [2019-09-15 18:31:03,248] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:03,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:03,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:03,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:03,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:31:03,703] {scheduler_job.py:146} INFO - Started process (PID=21801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:08,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:08,713] {logging_mixin.py:95} INFO - [2019-09-15 18:31:08,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:09,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:09,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:09,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:09,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:31:09,160] {scheduler_job.py:146} INFO - Started process (PID=21802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:14,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:14,171] {logging_mixin.py:95} INFO - [2019-09-15 18:31:14,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:14,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:14,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:14,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:14,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:31:14,621] {scheduler_job.py:146} INFO - Started process (PID=21804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:19,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:19,633] {logging_mixin.py:95} INFO - [2019-09-15 18:31:19,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:19,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:19,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:20,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:20,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:31:20,081] {scheduler_job.py:146} INFO - Started process (PID=21805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:25,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:25,089] {logging_mixin.py:95} INFO - [2019-09-15 18:31:25,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:25,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:25,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:25,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:25,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:31:25,542] {scheduler_job.py:146} INFO - Started process (PID=21806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:30,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:30,555] {logging_mixin.py:95} INFO - [2019-09-15 18:31:30,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:30,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:30,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:30,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:30,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:31:31,005] {scheduler_job.py:146} INFO - Started process (PID=21809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:36,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:36,015] {logging_mixin.py:95} INFO - [2019-09-15 18:31:36,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:36,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:36,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:36,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:36,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:31:36,457] {scheduler_job.py:146} INFO - Started process (PID=21810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:41,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:41,468] {logging_mixin.py:95} INFO - [2019-09-15 18:31:41,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:41,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:41,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:41,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:41,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:31:41,909] {scheduler_job.py:146} INFO - Started process (PID=21811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:46,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:46,915] {logging_mixin.py:95} INFO - [2019-09-15 18:31:46,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:47,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:47,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:47,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:47,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:31:47,359] {scheduler_job.py:146} INFO - Started process (PID=21813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:52,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:52,365] {logging_mixin.py:95} INFO - [2019-09-15 18:31:52,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:52,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:52,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:52,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:52,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:31:52,811] {scheduler_job.py:146} INFO - Started process (PID=21814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:57,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:31:57,820] {logging_mixin.py:95} INFO - [2019-09-15 18:31:57,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:58,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:31:58,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:31:58,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:31:58,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:31:58,262] {scheduler_job.py:146} INFO - Started process (PID=21815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:03,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:03,273] {logging_mixin.py:95} INFO - [2019-09-15 18:32:03,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:03,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:03,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:03,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:03,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:32:03,715] {scheduler_job.py:146} INFO - Started process (PID=21817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:08,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:08,724] {logging_mixin.py:95} INFO - [2019-09-15 18:32:08,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:09,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:09,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:09,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:09,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:32:09,167] {scheduler_job.py:146} INFO - Started process (PID=21818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:14,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:14,173] {logging_mixin.py:95} INFO - [2019-09-15 18:32:14,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:14,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:14,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:14,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:14,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 18:32:14,625] {scheduler_job.py:146} INFO - Started process (PID=21820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:19,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:19,633] {logging_mixin.py:95} INFO - [2019-09-15 18:32:19,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:19,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:20,005] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:20,014] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:20,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:32:20,079] {scheduler_job.py:146} INFO - Started process (PID=21821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:25,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:25,088] {logging_mixin.py:95} INFO - [2019-09-15 18:32:25,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:25,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:25,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:25,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:25,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:32:25,531] {scheduler_job.py:146} INFO - Started process (PID=21822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:30,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:30,538] {logging_mixin.py:95} INFO - [2019-09-15 18:32:30,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:30,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:30,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:30,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:30,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 18:32:30,990] {scheduler_job.py:146} INFO - Started process (PID=21825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:35,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:35,997] {logging_mixin.py:95} INFO - [2019-09-15 18:32:35,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:36,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:36,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:36,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:36,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:32:36,438] {scheduler_job.py:146} INFO - Started process (PID=21826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:41,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:41,449] {logging_mixin.py:95} INFO - [2019-09-15 18:32:41,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:41,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:41,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:41,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:41,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 18:32:42,004] {scheduler_job.py:146} INFO - Started process (PID=21827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:47,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:47,012] {logging_mixin.py:95} INFO - [2019-09-15 18:32:47,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:47,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:47,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:47,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:47,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:32:47,456] {scheduler_job.py:146} INFO - Started process (PID=21829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:52,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:52,463] {logging_mixin.py:95} INFO - [2019-09-15 18:32:52,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:52,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:52,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:52,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:52,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:32:52,908] {scheduler_job.py:146} INFO - Started process (PID=21830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:57,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:32:57,916] {logging_mixin.py:95} INFO - [2019-09-15 18:32:57,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:58,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:32:58,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:32:58,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:32:58,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:32:58,365] {scheduler_job.py:146} INFO - Started process (PID=21831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:03,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:03,373] {logging_mixin.py:95} INFO - [2019-09-15 18:33:03,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:03,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:03,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:03,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:03,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 18:33:03,821] {scheduler_job.py:146} INFO - Started process (PID=21833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:08,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:08,828] {logging_mixin.py:95} INFO - [2019-09-15 18:33:08,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:09,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:09,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:09,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:09,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:33:09,281] {scheduler_job.py:146} INFO - Started process (PID=21834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:14,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:14,288] {logging_mixin.py:95} INFO - [2019-09-15 18:33:14,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:14,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:14,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:14,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:14,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 18:33:14,835] {scheduler_job.py:146} INFO - Started process (PID=21836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:19,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:19,844] {logging_mixin.py:95} INFO - [2019-09-15 18:33:19,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:20,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:20,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:20,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:20,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-15 18:33:20,373] {scheduler_job.py:146} INFO - Started process (PID=21837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:25,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:25,381] {logging_mixin.py:95} INFO - [2019-09-15 18:33:25,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:25,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:25,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:25,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:25,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:33:25,814] {scheduler_job.py:146} INFO - Started process (PID=21838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:30,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:30,820] {logging_mixin.py:95} INFO - [2019-09-15 18:33:30,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:31,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:31,199] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:31,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:31,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:33:31,257] {scheduler_job.py:146} INFO - Started process (PID=21841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:36,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:36,266] {logging_mixin.py:95} INFO - [2019-09-15 18:33:36,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:36,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:36,645] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:36,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:36,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:33:36,698] {scheduler_job.py:146} INFO - Started process (PID=21842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:41,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:41,704] {logging_mixin.py:95} INFO - [2019-09-15 18:33:41,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:42,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:42,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:42,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:42,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:33:42,137] {scheduler_job.py:146} INFO - Started process (PID=21843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:47,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:47,146] {logging_mixin.py:95} INFO - [2019-09-15 18:33:47,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:47,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:47,531] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:47,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:47,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:33:47,586] {scheduler_job.py:146} INFO - Started process (PID=21845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:52,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:52,594] {logging_mixin.py:95} INFO - [2019-09-15 18:33:52,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:52,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:52,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:52,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:52,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:33:53,026] {scheduler_job.py:146} INFO - Started process (PID=21846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:58,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:33:58,033] {logging_mixin.py:95} INFO - [2019-09-15 18:33:58,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:58,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:33:58,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:33:58,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:33:58,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:33:58,472] {scheduler_job.py:146} INFO - Started process (PID=21847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:03,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:03,478] {logging_mixin.py:95} INFO - [2019-09-15 18:34:03,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:03,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:03,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:03,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:03,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:34:03,920] {scheduler_job.py:146} INFO - Started process (PID=21849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:08,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:08,939] {logging_mixin.py:95} INFO - [2019-09-15 18:34:08,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:09,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:09,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:09,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:09,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:34:09,365] {scheduler_job.py:146} INFO - Started process (PID=21850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:14,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:14,383] {logging_mixin.py:95} INFO - [2019-09-15 18:34:14,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:14,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:14,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:14,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:14,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:34:14,807] {scheduler_job.py:146} INFO - Started process (PID=21852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:19,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:19,813] {logging_mixin.py:95} INFO - [2019-09-15 18:34:19,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:20,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:20,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:20,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:20,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:34:20,341] {scheduler_job.py:146} INFO - Started process (PID=21853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:25,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:25,352] {logging_mixin.py:95} INFO - [2019-09-15 18:34:25,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:25,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:25,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:25,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:25,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-15 18:34:25,879] {scheduler_job.py:146} INFO - Started process (PID=21854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:30,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:30,886] {logging_mixin.py:95} INFO - [2019-09-15 18:34:30,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:31,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:31,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:31,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:31,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:34:31,314] {scheduler_job.py:146} INFO - Started process (PID=21857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:36,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:36,320] {logging_mixin.py:95} INFO - [2019-09-15 18:34:36,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:36,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:36,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:36,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:36,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:34:36,758] {scheduler_job.py:146} INFO - Started process (PID=21858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:41,766] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:41,767] {logging_mixin.py:95} INFO - [2019-09-15 18:34:41,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:42,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:42,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:42,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:42,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:34:42,206] {scheduler_job.py:146} INFO - Started process (PID=21859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:47,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:47,214] {logging_mixin.py:95} INFO - [2019-09-15 18:34:47,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:47,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:47,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:47,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:47,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:34:47,648] {scheduler_job.py:146} INFO - Started process (PID=21861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:52,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:52,655] {logging_mixin.py:95} INFO - [2019-09-15 18:34:52,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:53,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:53,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:53,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:53,050] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:34:53,100] {scheduler_job.py:146} INFO - Started process (PID=21862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:58,111] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:34:58,113] {logging_mixin.py:95} INFO - [2019-09-15 18:34:58,112] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:58,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:34:58,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:34:58,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:34:58,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:34:58,547] {scheduler_job.py:146} INFO - Started process (PID=21863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:03,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:03,554] {logging_mixin.py:95} INFO - [2019-09-15 18:35:03,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:03,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:03,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:03,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:03,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:35:03,997] {scheduler_job.py:146} INFO - Started process (PID=21865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:09,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:09,004] {logging_mixin.py:95} INFO - [2019-09-15 18:35:09,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:09,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:09,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:09,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:09,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:35:09,439] {scheduler_job.py:146} INFO - Started process (PID=21866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:14,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:14,447] {logging_mixin.py:95} INFO - [2019-09-15 18:35:14,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:14,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:14,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:14,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:14,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:35:14,880] {scheduler_job.py:146} INFO - Started process (PID=21868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:19,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:19,889] {logging_mixin.py:95} INFO - [2019-09-15 18:35:19,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:20,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:20,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:20,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:20,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:35:20,317] {scheduler_job.py:146} INFO - Started process (PID=21869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:25,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:25,327] {logging_mixin.py:95} INFO - [2019-09-15 18:35:25,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:25,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:25,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:25,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:25,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:35:25,762] {scheduler_job.py:146} INFO - Started process (PID=21870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:30,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:30,769] {logging_mixin.py:95} INFO - [2019-09-15 18:35:30,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:31,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:31,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:31,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:31,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:35:31,202] {scheduler_job.py:146} INFO - Started process (PID=21873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:36,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:36,209] {logging_mixin.py:95} INFO - [2019-09-15 18:35:36,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:36,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:36,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:36,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:36,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:35:36,647] {scheduler_job.py:146} INFO - Started process (PID=21874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:41,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:41,653] {logging_mixin.py:95} INFO - [2019-09-15 18:35:41,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:42,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:42,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:42,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:42,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:35:42,088] {scheduler_job.py:146} INFO - Started process (PID=21875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:47,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:47,097] {logging_mixin.py:95} INFO - [2019-09-15 18:35:47,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:47,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:47,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:47,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:47,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:35:47,531] {scheduler_job.py:146} INFO - Started process (PID=21877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:52,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:52,538] {logging_mixin.py:95} INFO - [2019-09-15 18:35:52,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:52,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:52,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:52,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:52,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 18:35:52,984] {scheduler_job.py:146} INFO - Started process (PID=21878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:57,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:35:57,992] {logging_mixin.py:95} INFO - [2019-09-15 18:35:57,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:58,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:35:58,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:35:58,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:35:58,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:35:58,436] {scheduler_job.py:146} INFO - Started process (PID=21879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:03,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:03,443] {logging_mixin.py:95} INFO - [2019-09-15 18:36:03,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:03,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:03,818] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:03,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:03,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:36:03,886] {scheduler_job.py:146} INFO - Started process (PID=21881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:08,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:08,893] {logging_mixin.py:95} INFO - [2019-09-15 18:36:08,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:09,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:09,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:09,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:09,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:36:09,328] {scheduler_job.py:146} INFO - Started process (PID=21882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:14,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:14,345] {logging_mixin.py:95} INFO - [2019-09-15 18:36:14,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:14,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:14,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:14,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:14,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:36:14,782] {scheduler_job.py:146} INFO - Started process (PID=21884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:19,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:19,790] {logging_mixin.py:95} INFO - [2019-09-15 18:36:19,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:20,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:20,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:20,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:20,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 18:36:20,325] {scheduler_job.py:146} INFO - Started process (PID=21885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:25,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:25,332] {logging_mixin.py:95} INFO - [2019-09-15 18:36:25,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:25,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:25,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:25,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:25,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:36:25,766] {scheduler_job.py:146} INFO - Started process (PID=21886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:30,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:30,775] {logging_mixin.py:95} INFO - [2019-09-15 18:36:30,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:31,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:31,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:31,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:31,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:36:31,211] {scheduler_job.py:146} INFO - Started process (PID=21889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:36,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:36,218] {logging_mixin.py:95} INFO - [2019-09-15 18:36:36,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:36,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:36,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:36,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:36,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:36:36,652] {scheduler_job.py:146} INFO - Started process (PID=21890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:41,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:41,659] {logging_mixin.py:95} INFO - [2019-09-15 18:36:41,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:42,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:42,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:42,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:42,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:36:42,100] {scheduler_job.py:146} INFO - Started process (PID=21891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:47,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:47,107] {logging_mixin.py:95} INFO - [2019-09-15 18:36:47,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:47,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:47,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:47,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:47,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:36:47,540] {scheduler_job.py:146} INFO - Started process (PID=21893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:52,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:52,550] {logging_mixin.py:95} INFO - [2019-09-15 18:36:52,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:52,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:52,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:52,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:53,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-15 18:36:53,083] {scheduler_job.py:146} INFO - Started process (PID=21894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:58,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:36:58,091] {logging_mixin.py:95} INFO - [2019-09-15 18:36:58,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:58,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:36:58,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:36:58,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:36:58,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:36:58,528] {scheduler_job.py:146} INFO - Started process (PID=21895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:03,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:03,535] {logging_mixin.py:95} INFO - [2019-09-15 18:37:03,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:03,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:03,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:03,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:03,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:37:03,983] {scheduler_job.py:146} INFO - Started process (PID=21897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:08,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:08,988] {logging_mixin.py:95} INFO - [2019-09-15 18:37:08,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:09,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:09,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:09,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:09,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:37:09,434] {scheduler_job.py:146} INFO - Started process (PID=21898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:14,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:14,445] {logging_mixin.py:95} INFO - [2019-09-15 18:37:14,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:14,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:14,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:14,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:14,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 18:37:14,884] {scheduler_job.py:146} INFO - Started process (PID=21900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:19,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:19,891] {logging_mixin.py:95} INFO - [2019-09-15 18:37:19,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:20,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:20,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:20,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:20,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:37:20,334] {scheduler_job.py:146} INFO - Started process (PID=21904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:25,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:25,341] {logging_mixin.py:95} INFO - [2019-09-15 18:37:25,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:25,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:25,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:25,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:25,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:37:25,784] {scheduler_job.py:146} INFO - Started process (PID=21905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:30,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:30,793] {logging_mixin.py:95} INFO - [2019-09-15 18:37:30,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:31,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:31,178] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:31,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:31,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:37:31,229] {scheduler_job.py:146} INFO - Started process (PID=21908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:36,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:36,235] {logging_mixin.py:95} INFO - [2019-09-15 18:37:36,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:36,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:36,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:36,612] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:36,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:37:36,688] {scheduler_job.py:146} INFO - Started process (PID=21909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:41,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:41,694] {logging_mixin.py:95} INFO - [2019-09-15 18:37:41,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:42,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:42,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:42,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:42,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 18:37:42,149] {scheduler_job.py:146} INFO - Started process (PID=21910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:47,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:47,157] {logging_mixin.py:95} INFO - [2019-09-15 18:37:47,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:47,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:47,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:47,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:47,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:37:47,610] {scheduler_job.py:146} INFO - Started process (PID=21912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:52,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:52,621] {logging_mixin.py:95} INFO - [2019-09-15 18:37:52,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:52,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:52,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:52,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:52,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:37:53,075] {scheduler_job.py:146} INFO - Started process (PID=21913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:58,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:37:58,084] {logging_mixin.py:95} INFO - [2019-09-15 18:37:58,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:58,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:37:58,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:37:58,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:37:58,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:37:58,537] {scheduler_job.py:146} INFO - Started process (PID=21914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:03,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:03,544] {logging_mixin.py:95} INFO - [2019-09-15 18:38:03,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:03,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:03,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:03,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:03,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:38:03,996] {scheduler_job.py:146} INFO - Started process (PID=21916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:09,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:09,007] {logging_mixin.py:95} INFO - [2019-09-15 18:38:09,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:09,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:09,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:09,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:09,393] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:38:09,454] {scheduler_job.py:146} INFO - Started process (PID=21917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:14,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:14,465] {logging_mixin.py:95} INFO - [2019-09-15 18:38:14,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:14,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:14,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:14,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:14,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:38:14,912] {scheduler_job.py:146} INFO - Started process (PID=21919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:19,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:19,921] {logging_mixin.py:95} INFO - [2019-09-15 18:38:19,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:20,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:20,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:20,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:20,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:38:20,372] {scheduler_job.py:146} INFO - Started process (PID=21920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:25,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:25,383] {logging_mixin.py:95} INFO - [2019-09-15 18:38:25,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:25,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:25,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:25,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:25,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:38:25,835] {scheduler_job.py:146} INFO - Started process (PID=21921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:30,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:30,846] {logging_mixin.py:95} INFO - [2019-09-15 18:38:30,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:31,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:31,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:31,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:31,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:38:31,297] {scheduler_job.py:146} INFO - Started process (PID=21924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:36,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:36,304] {logging_mixin.py:95} INFO - [2019-09-15 18:38:36,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:36,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:36,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:36,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:36,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:38:36,762] {scheduler_job.py:146} INFO - Started process (PID=21925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:41,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:41,769] {logging_mixin.py:95} INFO - [2019-09-15 18:38:41,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:42,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:42,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:42,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:42,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:38:42,225] {scheduler_job.py:146} INFO - Started process (PID=21926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:47,230] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:47,232] {logging_mixin.py:95} INFO - [2019-09-15 18:38:47,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:47,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:47,600] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:47,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:47,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:38:47,685] {scheduler_job.py:146} INFO - Started process (PID=21928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:52,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:52,694] {logging_mixin.py:95} INFO - [2019-09-15 18:38:52,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:53,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:53,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:53,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:53,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:38:53,145] {scheduler_job.py:146} INFO - Started process (PID=21929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:58,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:38:58,152] {logging_mixin.py:95} INFO - [2019-09-15 18:38:58,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:58,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:38:58,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:38:58,530] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:38:58,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:38:58,611] {scheduler_job.py:146} INFO - Started process (PID=21930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:03,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:03,620] {logging_mixin.py:95} INFO - [2019-09-15 18:39:03,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:03,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:03,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:03,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:03,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:39:04,073] {scheduler_job.py:146} INFO - Started process (PID=21932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:09,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:09,083] {logging_mixin.py:95} INFO - [2019-09-15 18:39:09,083] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:09,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:09,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:09,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:09,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:39:09,533] {scheduler_job.py:146} INFO - Started process (PID=21933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:14,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:14,544] {logging_mixin.py:95} INFO - [2019-09-15 18:39:14,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:14,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:14,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:14,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:14,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:39:14,994] {scheduler_job.py:146} INFO - Started process (PID=21935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:20,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:20,006] {logging_mixin.py:95} INFO - [2019-09-15 18:39:20,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:20,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:20,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:20,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:20,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:39:20,453] {scheduler_job.py:146} INFO - Started process (PID=21936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:25,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:25,465] {logging_mixin.py:95} INFO - [2019-09-15 18:39:25,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:25,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:25,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:25,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:25,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:39:25,912] {scheduler_job.py:146} INFO - Started process (PID=21937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:30,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:30,923] {logging_mixin.py:95} INFO - [2019-09-15 18:39:30,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:31,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:31,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:31,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:31,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:39:31,374] {scheduler_job.py:146} INFO - Started process (PID=21940) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:36,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:36,383] {logging_mixin.py:95} INFO - [2019-09-15 18:39:36,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:36,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:36,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:36,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:36,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:39:36,837] {scheduler_job.py:146} INFO - Started process (PID=21941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:41,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:41,846] {logging_mixin.py:95} INFO - [2019-09-15 18:39:41,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:42,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:42,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:42,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:42,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:39:42,294] {scheduler_job.py:146} INFO - Started process (PID=21942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:47,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:47,305] {logging_mixin.py:95} INFO - [2019-09-15 18:39:47,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:47,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:47,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:47,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:47,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:39:47,754] {scheduler_job.py:146} INFO - Started process (PID=21944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:52,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:52,762] {logging_mixin.py:95} INFO - [2019-09-15 18:39:52,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:53,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:53,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:53,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:53,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:39:53,211] {scheduler_job.py:146} INFO - Started process (PID=21945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:58,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:39:58,218] {logging_mixin.py:95} INFO - [2019-09-15 18:39:58,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:58,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:39:58,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:39:58,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:39:58,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:39:58,672] {scheduler_job.py:146} INFO - Started process (PID=21946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:03,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:03,683] {logging_mixin.py:95} INFO - [2019-09-15 18:40:03,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:04,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:04,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:04,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:04,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:40:04,139] {scheduler_job.py:146} INFO - Started process (PID=21948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:09,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:09,150] {logging_mixin.py:95} INFO - [2019-09-15 18:40:09,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:09,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:09,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:09,526] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:09,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:40:09,602] {scheduler_job.py:146} INFO - Started process (PID=21949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:14,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:14,612] {logging_mixin.py:95} INFO - [2019-09-15 18:40:14,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:14,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:14,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:15,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:15,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:40:15,057] {scheduler_job.py:146} INFO - Started process (PID=21951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:20,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:20,065] {logging_mixin.py:95} INFO - [2019-09-15 18:40:20,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:20,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:20,435] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:20,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:20,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:40:20,512] {scheduler_job.py:146} INFO - Started process (PID=21952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:25,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:25,519] {logging_mixin.py:95} INFO - [2019-09-15 18:40:25,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:25,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:25,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:25,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:25,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:40:25,969] {scheduler_job.py:146} INFO - Started process (PID=21953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:30,975] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:30,976] {logging_mixin.py:95} INFO - [2019-09-15 18:40:30,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:31,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:31,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:31,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:31,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:40:31,416] {scheduler_job.py:146} INFO - Started process (PID=21956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:36,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:36,422] {logging_mixin.py:95} INFO - [2019-09-15 18:40:36,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:36,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:36,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:36,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:36,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:40:36,877] {scheduler_job.py:146} INFO - Started process (PID=21957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:41,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:41,886] {logging_mixin.py:95} INFO - [2019-09-15 18:40:41,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:42,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:42,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:42,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:42,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 18:40:42,340] {scheduler_job.py:146} INFO - Started process (PID=21958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:47,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:47,350] {logging_mixin.py:95} INFO - [2019-09-15 18:40:47,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:47,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:47,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:47,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:47,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:40:47,801] {scheduler_job.py:146} INFO - Started process (PID=21960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:52,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:52,810] {logging_mixin.py:95} INFO - [2019-09-15 18:40:52,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:53,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:53,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:53,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:53,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:40:53,254] {scheduler_job.py:146} INFO - Started process (PID=21961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:58,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:40:58,261] {logging_mixin.py:95} INFO - [2019-09-15 18:40:58,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:58,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:40:58,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:40:58,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:40:58,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:40:58,710] {scheduler_job.py:146} INFO - Started process (PID=21962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:03,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:03,718] {logging_mixin.py:95} INFO - [2019-09-15 18:41:03,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:04,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:04,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:04,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:04,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:41:04,166] {scheduler_job.py:146} INFO - Started process (PID=21964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:09,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:09,176] {logging_mixin.py:95} INFO - [2019-09-15 18:41:09,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:09,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:09,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:09,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:09,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:41:09,621] {scheduler_job.py:146} INFO - Started process (PID=21965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:14,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:14,639] {logging_mixin.py:95} INFO - [2019-09-15 18:41:14,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:14,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:15,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:15,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:15,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:41:15,081] {scheduler_job.py:146} INFO - Started process (PID=21967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:20,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:20,093] {logging_mixin.py:95} INFO - [2019-09-15 18:41:20,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:20,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:20,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:20,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:20,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:41:20,543] {scheduler_job.py:146} INFO - Started process (PID=21968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:25,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:25,555] {logging_mixin.py:95} INFO - [2019-09-15 18:41:25,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:25,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:25,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:25,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:25,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 18:41:26,004] {scheduler_job.py:146} INFO - Started process (PID=21969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:31,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:31,016] {logging_mixin.py:95} INFO - [2019-09-15 18:41:31,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:31,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:31,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:31,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:31,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:41:31,465] {scheduler_job.py:146} INFO - Started process (PID=21972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:36,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:36,471] {logging_mixin.py:95} INFO - [2019-09-15 18:41:36,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:36,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:36,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:36,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:36,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 18:41:37,022] {scheduler_job.py:146} INFO - Started process (PID=21973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:42,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:42,030] {logging_mixin.py:95} INFO - [2019-09-15 18:41:42,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:42,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:42,440] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:42,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:42,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 18:41:42,483] {scheduler_job.py:146} INFO - Started process (PID=21976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:47,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:47,491] {logging_mixin.py:95} INFO - [2019-09-15 18:41:47,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:47,870] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:47,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:47,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:47,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:41:47,941] {scheduler_job.py:146} INFO - Started process (PID=21978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:52,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:52,949] {logging_mixin.py:95} INFO - [2019-09-15 18:41:52,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:53,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:53,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:53,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:53,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:41:53,398] {scheduler_job.py:146} INFO - Started process (PID=21979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:58,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:41:58,410] {logging_mixin.py:95} INFO - [2019-09-15 18:41:58,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:58,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:41:58,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:41:58,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:41:58,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:41:58,859] {scheduler_job.py:146} INFO - Started process (PID=21980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:03,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:03,871] {logging_mixin.py:95} INFO - [2019-09-15 18:42:03,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:04,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:04,243] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:04,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:04,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:42:04,320] {scheduler_job.py:146} INFO - Started process (PID=21982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:09,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:09,329] {logging_mixin.py:95} INFO - [2019-09-15 18:42:09,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:09,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:09,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:09,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:09,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 18:42:09,776] {scheduler_job.py:146} INFO - Started process (PID=21983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:14,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:14,784] {logging_mixin.py:95} INFO - [2019-09-15 18:42:14,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:15,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:15,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:15,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:15,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:42:15,234] {scheduler_job.py:146} INFO - Started process (PID=21985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:20,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:20,243] {logging_mixin.py:95} INFO - [2019-09-15 18:42:20,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:20,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:20,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:20,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:20,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:42:20,693] {scheduler_job.py:146} INFO - Started process (PID=21987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:25,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:25,700] {logging_mixin.py:95} INFO - [2019-09-15 18:42:25,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:26,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:26,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:26,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:26,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:42:26,151] {scheduler_job.py:146} INFO - Started process (PID=21988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:31,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:31,159] {logging_mixin.py:95} INFO - [2019-09-15 18:42:31,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:31,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:31,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:31,538] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:31,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:42:31,605] {scheduler_job.py:146} INFO - Started process (PID=21993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:36,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:36,612] {logging_mixin.py:95} INFO - [2019-09-15 18:42:36,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:36,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:36,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:36,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:36,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 18:42:37,068] {scheduler_job.py:146} INFO - Started process (PID=21994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:42,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:42,079] {logging_mixin.py:95} INFO - [2019-09-15 18:42:42,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:42,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:42,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:42,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:42,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:42:42,535] {scheduler_job.py:146} INFO - Started process (PID=21995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:47,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:47,542] {logging_mixin.py:95} INFO - [2019-09-15 18:42:47,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:47,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:47,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:47,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:47,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:42:47,997] {scheduler_job.py:146} INFO - Started process (PID=21997) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:53,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:53,006] {logging_mixin.py:95} INFO - [2019-09-15 18:42:53,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:53,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:53,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:53,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:53,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:42:53,452] {scheduler_job.py:146} INFO - Started process (PID=21998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:58,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:42:58,464] {logging_mixin.py:95} INFO - [2019-09-15 18:42:58,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:58,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:42:58,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:42:58,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:42:58,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:42:58,909] {scheduler_job.py:146} INFO - Started process (PID=21999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:03,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:03,920] {logging_mixin.py:95} INFO - [2019-09-15 18:43:03,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:04,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:04,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:04,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:04,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:43:04,374] {scheduler_job.py:146} INFO - Started process (PID=22001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:09,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:09,383] {logging_mixin.py:95} INFO - [2019-09-15 18:43:09,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:09,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:09,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:09,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:09,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:43:09,820] {scheduler_job.py:146} INFO - Started process (PID=22003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:14,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:14,827] {logging_mixin.py:95} INFO - [2019-09-15 18:43:14,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:15,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:15,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:15,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:15,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 18:43:15,286] {scheduler_job.py:146} INFO - Started process (PID=22005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:20,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:20,294] {logging_mixin.py:95} INFO - [2019-09-15 18:43:20,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:20,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:20,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:20,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:20,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 18:43:20,752] {scheduler_job.py:146} INFO - Started process (PID=22006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:25,758] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:25,759] {logging_mixin.py:95} INFO - [2019-09-15 18:43:25,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:26,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:26,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:26,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:26,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 18:43:26,212] {scheduler_job.py:146} INFO - Started process (PID=22007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:31,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:31,225] {logging_mixin.py:95} INFO - [2019-09-15 18:43:31,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:31,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:31,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:31,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:31,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:43:31,674] {scheduler_job.py:146} INFO - Started process (PID=22010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:36,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:36,682] {logging_mixin.py:95} INFO - [2019-09-15 18:43:36,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:37,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:37,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:37,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:37,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:43:37,139] {scheduler_job.py:146} INFO - Started process (PID=22011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:42,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:42,149] {logging_mixin.py:95} INFO - [2019-09-15 18:43:42,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:42,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:42,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:42,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:42,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:43:42,602] {scheduler_job.py:146} INFO - Started process (PID=22012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:47,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:47,612] {logging_mixin.py:95} INFO - [2019-09-15 18:43:47,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:47,962] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:47,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:47,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:47,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:43:48,062] {scheduler_job.py:146} INFO - Started process (PID=22014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:53,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:53,070] {logging_mixin.py:95} INFO - [2019-09-15 18:43:53,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:53,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:53,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:53,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:53,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:43:53,522] {scheduler_job.py:146} INFO - Started process (PID=22015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:58,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:43:58,530] {logging_mixin.py:95} INFO - [2019-09-15 18:43:58,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:58,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:43:58,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:43:58,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:43:58,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:43:58,983] {scheduler_job.py:146} INFO - Started process (PID=22016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:03,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:03,995] {logging_mixin.py:95} INFO - [2019-09-15 18:44:03,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:04,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:04,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:04,373] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:04,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:44:04,441] {scheduler_job.py:146} INFO - Started process (PID=22018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:09,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:09,455] {logging_mixin.py:95} INFO - [2019-09-15 18:44:09,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:09,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:09,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:09,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:09,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 18:44:09,907] {scheduler_job.py:146} INFO - Started process (PID=22019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:14,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:14,916] {logging_mixin.py:95} INFO - [2019-09-15 18:44:14,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:15,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:15,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:15,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:15,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:44:15,369] {scheduler_job.py:146} INFO - Started process (PID=22021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:20,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:20,377] {logging_mixin.py:95} INFO - [2019-09-15 18:44:20,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:20,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:20,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:20,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:20,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 18:44:20,830] {scheduler_job.py:146} INFO - Started process (PID=22022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:25,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:25,840] {logging_mixin.py:95} INFO - [2019-09-15 18:44:25,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:26,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:26,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:26,217] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:26,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 18:44:26,292] {scheduler_job.py:146} INFO - Started process (PID=22023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:31,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:31,305] {logging_mixin.py:95} INFO - [2019-09-15 18:44:31,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:31,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:31,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:31,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:31,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 18:44:31,748] {scheduler_job.py:146} INFO - Started process (PID=22026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:36,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:36,757] {logging_mixin.py:95} INFO - [2019-09-15 18:44:36,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:37,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:37,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:37,141] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:37,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 18:44:37,210] {scheduler_job.py:146} INFO - Started process (PID=22027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:42,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:42,223] {logging_mixin.py:95} INFO - [2019-09-15 18:44:42,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:42,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:42,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:42,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:42,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:44:42,676] {scheduler_job.py:146} INFO - Started process (PID=22028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:47,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:47,690] {logging_mixin.py:95} INFO - [2019-09-15 18:44:47,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:48,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:48,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:48,070] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:48,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:44:48,129] {scheduler_job.py:146} INFO - Started process (PID=22030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:53,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:53,142] {logging_mixin.py:95} INFO - [2019-09-15 18:44:53,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:53,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:53,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:53,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:53,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:44:53,591] {scheduler_job.py:146} INFO - Started process (PID=22031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:58,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:44:58,603] {logging_mixin.py:95} INFO - [2019-09-15 18:44:58,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:58,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:44:58,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:44:58,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:44:58,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:44:59,057] {scheduler_job.py:146} INFO - Started process (PID=22032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:04,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:04,070] {logging_mixin.py:95} INFO - [2019-09-15 18:45:04,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:04,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:04,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:04,446] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:04,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:45:04,519] {scheduler_job.py:146} INFO - Started process (PID=22034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:09,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:09,531] {logging_mixin.py:95} INFO - [2019-09-15 18:45:09,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:09,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:09,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:09,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:09,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 18:45:09,983] {scheduler_job.py:146} INFO - Started process (PID=22035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:14,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:14,997] {logging_mixin.py:95} INFO - [2019-09-15 18:45:14,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:15,347] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:15,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:15,379] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:15,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:45:15,441] {scheduler_job.py:146} INFO - Started process (PID=22037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:20,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:20,454] {logging_mixin.py:95} INFO - [2019-09-15 18:45:20,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:20,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:20,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:20,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:20,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:45:20,900] {scheduler_job.py:146} INFO - Started process (PID=22038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:25,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:25,912] {logging_mixin.py:95} INFO - [2019-09-15 18:45:25,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:26,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:26,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:26,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:26,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:45:26,358] {scheduler_job.py:146} INFO - Started process (PID=22039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:31,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:31,372] {logging_mixin.py:95} INFO - [2019-09-15 18:45:31,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:31,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:31,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:31,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:31,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:45:31,815] {scheduler_job.py:146} INFO - Started process (PID=22042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:36,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:36,824] {logging_mixin.py:95} INFO - [2019-09-15 18:45:36,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:37,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:37,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:37,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:37,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:45:37,279] {scheduler_job.py:146} INFO - Started process (PID=22043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:42,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:42,292] {logging_mixin.py:95} INFO - [2019-09-15 18:45:42,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:42,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:42,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:42,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:42,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:45:42,737] {scheduler_job.py:146} INFO - Started process (PID=22044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:47,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:47,748] {logging_mixin.py:95} INFO - [2019-09-15 18:45:47,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:48,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:48,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:48,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:48,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:45:48,191] {scheduler_job.py:146} INFO - Started process (PID=22046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:53,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:53,203] {logging_mixin.py:95} INFO - [2019-09-15 18:45:53,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:53,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:53,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:53,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:53,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 18:45:53,650] {scheduler_job.py:146} INFO - Started process (PID=22047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:58,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:45:58,661] {logging_mixin.py:95} INFO - [2019-09-15 18:45:58,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:58,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:45:59,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:45:59,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:45:59,036] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:45:59,109] {scheduler_job.py:146} INFO - Started process (PID=22048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:04,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:04,118] {logging_mixin.py:95} INFO - [2019-09-15 18:46:04,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:04,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:04,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:04,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:04,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 18:46:04,575] {scheduler_job.py:146} INFO - Started process (PID=22050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:09,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:09,584] {logging_mixin.py:95} INFO - [2019-09-15 18:46:09,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:09,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:09,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:09,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:09,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 18:46:10,031] {scheduler_job.py:146} INFO - Started process (PID=22051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:15,041] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:15,042] {logging_mixin.py:95} INFO - [2019-09-15 18:46:15,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:15,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:15,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:15,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:15,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 18:46:15,495] {scheduler_job.py:146} INFO - Started process (PID=22053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:20,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:20,511] {logging_mixin.py:95} INFO - [2019-09-15 18:46:20,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:20,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:20,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:20,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:20,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 18:46:20,990] {scheduler_job.py:146} INFO - Started process (PID=22055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:25,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:25,998] {logging_mixin.py:95} INFO - [2019-09-15 18:46:25,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:26,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:26,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:26,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:26,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 18:46:26,483] {scheduler_job.py:146} INFO - Started process (PID=22056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:31,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:31,499] {logging_mixin.py:95} INFO - [2019-09-15 18:46:31,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:31,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:31,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:31,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:31,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:46:31,970] {scheduler_job.py:146} INFO - Started process (PID=22059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:31,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:31,977] {logging_mixin.py:95} INFO - [2019-09-15 18:46:31,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:32,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:32,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-09-15 18:46:32,378] {scheduler_job.py:146} INFO - Started process (PID=22060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:32,384] {logging_mixin.py:95} INFO - [2019-09-15 18:46:32,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:32,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:32,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.377 seconds
[2019-09-15 18:46:32,789] {scheduler_job.py:146} INFO - Started process (PID=22061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:32,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:32,795] {logging_mixin.py:95} INFO - [2019-09-15 18:46:32,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:33,169] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:33,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.386 seconds
[2019-09-15 18:46:33,202] {scheduler_job.py:146} INFO - Started process (PID=22062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:33,209] {logging_mixin.py:95} INFO - [2019-09-15 18:46:33,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:33,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:33,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-09-15 18:46:33,616] {scheduler_job.py:146} INFO - Started process (PID=22063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:33,622] {logging_mixin.py:95} INFO - [2019-09-15 18:46:33,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:33,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:33,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:33,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-09-15 18:46:34,022] {scheduler_job.py:146} INFO - Started process (PID=22064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:34,028] {logging_mixin.py:95} INFO - [2019-09-15 18:46:34,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:34,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:34,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-09-15 18:46:34,433] {scheduler_job.py:146} INFO - Started process (PID=22065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:34,440] {logging_mixin.py:95} INFO - [2019-09-15 18:46:34,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:34,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:34,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-09-15 18:46:34,841] {scheduler_job.py:146} INFO - Started process (PID=22066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:34,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:34,847] {logging_mixin.py:95} INFO - [2019-09-15 18:46:34,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:35,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:35,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 18:46:35,255] {scheduler_job.py:146} INFO - Started process (PID=22067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:35,261] {logging_mixin.py:95} INFO - [2019-09-15 18:46:35,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:35,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:35,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-15 18:46:35,667] {scheduler_job.py:146} INFO - Started process (PID=22068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:35,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:35,673] {logging_mixin.py:95} INFO - [2019-09-15 18:46:35,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:36,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:36,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.377 seconds
[2019-09-15 18:46:36,077] {scheduler_job.py:146} INFO - Started process (PID=22069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:36,084] {logging_mixin.py:95} INFO - [2019-09-15 18:46:36,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:36,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:36,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 18:46:36,486] {scheduler_job.py:146} INFO - Started process (PID=22070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:36,493] {logging_mixin.py:95} INFO - [2019-09-15 18:46:36,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:36,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:36,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:36,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.407 seconds
[2019-09-15 18:46:36,997] {scheduler_job.py:146} INFO - Started process (PID=22071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:37,004] {logging_mixin.py:95} INFO - [2019-09-15 18:46:37,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:37,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:37,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-15 18:46:37,412] {scheduler_job.py:146} INFO - Started process (PID=22072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,418] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:37,418] {logging_mixin.py:95} INFO - [2019-09-15 18:46:37,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:37,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:37,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 18:46:37,822] {scheduler_job.py:146} INFO - Started process (PID=22073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:37,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:46:37,829] {logging_mixin.py:95} INFO - [2019-09-15 18:46:37,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:38,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:46:38,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:46:38,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:46:38,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 18:47:12,010] {scheduler_job.py:146} INFO - Started process (PID=22074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:12,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:12,017] {logging_mixin.py:95} INFO - [2019-09-15 18:47:12,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:12,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:12,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:12,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:12,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.398 seconds
[2019-09-15 18:47:12,519] {scheduler_job.py:146} INFO - Started process (PID=22075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:12,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:12,526] {logging_mixin.py:95} INFO - [2019-09-15 18:47:12,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:13,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:13,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:13,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:13,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.536 seconds
[2019-09-15 18:47:13,127] {scheduler_job.py:146} INFO - Started process (PID=22076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:18,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:18,136] {logging_mixin.py:95} INFO - [2019-09-15 18:47:18,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:18,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:18,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:18,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:18,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.551 seconds
[2019-09-15 18:47:18,791] {scheduler_job.py:146} INFO - Started process (PID=22082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:23,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:23,799] {logging_mixin.py:95} INFO - [2019-09-15 18:47:23,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:24,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:24,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:24,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:24,211] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:47:24,235] {scheduler_job.py:146} INFO - Started process (PID=22083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:29,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:29,244] {logging_mixin.py:95} INFO - [2019-09-15 18:47:29,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:29,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:29,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:29,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:29,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:47:29,680] {scheduler_job.py:146} INFO - Started process (PID=22086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:34,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:34,688] {logging_mixin.py:95} INFO - [2019-09-15 18:47:34,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:35,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:35,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:35,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:35,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 18:47:35,128] {scheduler_job.py:146} INFO - Started process (PID=22088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:40,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:40,139] {logging_mixin.py:95} INFO - [2019-09-15 18:47:40,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:40,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:40,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:40,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:40,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:47:40,571] {scheduler_job.py:146} INFO - Started process (PID=22089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:45,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:45,585] {logging_mixin.py:95} INFO - [2019-09-15 18:47:45,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:45,897] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:45,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:45,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:45,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 18:47:46,027] {scheduler_job.py:146} INFO - Started process (PID=22090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:51,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:51,034] {logging_mixin.py:95} INFO - [2019-09-15 18:47:51,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:51,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:51,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:51,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:51,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 18:47:51,475] {scheduler_job.py:146} INFO - Started process (PID=22098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:56,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:47:56,482] {logging_mixin.py:95} INFO - [2019-09-15 18:47:56,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:56,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:47:56,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:47:56,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:47:56,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-15 18:47:57,013] {scheduler_job.py:146} INFO - Started process (PID=22102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:02,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:02,026] {logging_mixin.py:95} INFO - [2019-09-15 18:48:02,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:02,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:02,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:02,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:02,486] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-15 18:48:02,539] {scheduler_job.py:146} INFO - Started process (PID=22105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:07,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:07,546] {logging_mixin.py:95} INFO - [2019-09-15 18:48:07,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:07,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:07,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:07,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:07,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 18:48:08,067] {scheduler_job.py:146} INFO - Started process (PID=22107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:13,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:13,077] {logging_mixin.py:95} INFO - [2019-09-15 18:48:13,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:13,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:13,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:13,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:13,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:48:13,598] {scheduler_job.py:146} INFO - Started process (PID=22109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:18,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:18,606] {logging_mixin.py:95} INFO - [2019-09-15 18:48:18,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:18,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:19,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:19,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:19,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 18:48:19,051] {scheduler_job.py:146} INFO - Started process (PID=22111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:24,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:24,058] {logging_mixin.py:95} INFO - [2019-09-15 18:48:24,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:24,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:24,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:24,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:24,473] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:48:24,578] {scheduler_job.py:146} INFO - Started process (PID=22112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:29,586] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:29,587] {logging_mixin.py:95} INFO - [2019-09-15 18:48:29,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:29,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:29,979] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:29,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:29,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:48:30,018] {scheduler_job.py:146} INFO - Started process (PID=22113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:35,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:35,037] {logging_mixin.py:95} INFO - [2019-09-15 18:48:35,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:35,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:35,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:35,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:35,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:48:35,468] {scheduler_job.py:146} INFO - Started process (PID=22115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:40,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:40,478] {logging_mixin.py:95} INFO - [2019-09-15 18:48:40,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:40,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:40,860] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:40,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:40,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:48:40,926] {scheduler_job.py:146} INFO - Started process (PID=22116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:45,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:45,934] {logging_mixin.py:95} INFO - [2019-09-15 18:48:45,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:46,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:46,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:46,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:46,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 18:48:46,476] {scheduler_job.py:146} INFO - Started process (PID=22117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:51,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:51,488] {logging_mixin.py:95} INFO - [2019-09-15 18:48:51,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:51,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:51,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:51,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:51,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:48:51,933] {scheduler_job.py:146} INFO - Started process (PID=22119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:56,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:48:56,942] {logging_mixin.py:95} INFO - [2019-09-15 18:48:56,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:57,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:48:57,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:48:57,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:48:57,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:48:57,385] {scheduler_job.py:146} INFO - Started process (PID=22120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:02,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:02,394] {logging_mixin.py:95} INFO - [2019-09-15 18:49:02,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:02,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:02,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:02,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:02,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:49:02,829] {scheduler_job.py:146} INFO - Started process (PID=22122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:07,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:07,847] {logging_mixin.py:95} INFO - [2019-09-15 18:49:07,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:08,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:08,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:08,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:08,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:49:08,272] {scheduler_job.py:146} INFO - Started process (PID=22124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:13,279] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:13,280] {logging_mixin.py:95} INFO - [2019-09-15 18:49:13,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:13,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:13,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:13,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:13,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:49:13,722] {scheduler_job.py:146} INFO - Started process (PID=22125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:18,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:18,739] {logging_mixin.py:95} INFO - [2019-09-15 18:49:18,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:19,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:19,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:19,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:19,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:49:19,167] {scheduler_job.py:146} INFO - Started process (PID=22127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:24,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:24,184] {logging_mixin.py:95} INFO - [2019-09-15 18:49:24,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:24,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:24,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:24,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:24,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:49:24,621] {scheduler_job.py:146} INFO - Started process (PID=22128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:29,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:29,629] {logging_mixin.py:95} INFO - [2019-09-15 18:49:29,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:29,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:30,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:30,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:30,025] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:49:30,072] {scheduler_job.py:146} INFO - Started process (PID=22129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:35,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:35,090] {logging_mixin.py:95} INFO - [2019-09-15 18:49:35,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:35,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:35,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:35,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:35,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:49:35,514] {scheduler_job.py:146} INFO - Started process (PID=22131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:40,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:40,524] {logging_mixin.py:95} INFO - [2019-09-15 18:49:40,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:40,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:40,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:40,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:40,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:49:40,966] {scheduler_job.py:146} INFO - Started process (PID=22132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:45,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:45,973] {logging_mixin.py:95} INFO - [2019-09-15 18:49:45,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:46,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:46,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:46,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:46,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 18:49:46,428] {scheduler_job.py:146} INFO - Started process (PID=22133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:51,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:51,450] {logging_mixin.py:95} INFO - [2019-09-15 18:49:51,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:51,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:51,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:51,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:51,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:49:51,870] {scheduler_job.py:146} INFO - Started process (PID=22135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:56,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:49:56,879] {logging_mixin.py:95} INFO - [2019-09-15 18:49:56,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:57,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:49:57,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:49:57,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:49:57,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:49:57,323] {scheduler_job.py:146} INFO - Started process (PID=22136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:02,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:02,330] {logging_mixin.py:95} INFO - [2019-09-15 18:50:02,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:02,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:02,711] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:02,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:02,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:50:02,775] {scheduler_job.py:146} INFO - Started process (PID=22138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:07,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:07,785] {logging_mixin.py:95} INFO - [2019-09-15 18:50:07,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:08,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:08,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:08,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:08,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 18:50:08,222] {scheduler_job.py:146} INFO - Started process (PID=22140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:13,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:13,230] {logging_mixin.py:95} INFO - [2019-09-15 18:50:13,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:13,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:13,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:13,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:13,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:50:13,670] {scheduler_job.py:146} INFO - Started process (PID=22141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:18,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:18,676] {logging_mixin.py:95} INFO - [2019-09-15 18:50:18,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:19,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:19,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:19,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:19,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:50:19,122] {scheduler_job.py:146} INFO - Started process (PID=22146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:24,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:24,144] {logging_mixin.py:95} INFO - [2019-09-15 18:50:24,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:24,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:24,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:24,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:24,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:50:24,569] {scheduler_job.py:146} INFO - Started process (PID=22147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:29,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:29,577] {logging_mixin.py:95} INFO - [2019-09-15 18:50:29,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:29,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:29,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:29,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:29,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 18:50:30,023] {scheduler_job.py:146} INFO - Started process (PID=22148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:35,035] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:35,036] {logging_mixin.py:95} INFO - [2019-09-15 18:50:35,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:35,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:35,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:35,432] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:35,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:50:35,482] {scheduler_job.py:146} INFO - Started process (PID=22150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:40,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:40,493] {logging_mixin.py:95} INFO - [2019-09-15 18:50:40,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:40,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:40,881] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:40,890] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:40,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:50:40,931] {scheduler_job.py:146} INFO - Started process (PID=22151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:45,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:45,942] {logging_mixin.py:95} INFO - [2019-09-15 18:50:45,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:46,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:46,334] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:46,346] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:46,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 18:50:46,387] {scheduler_job.py:146} INFO - Started process (PID=22152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:51,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:51,397] {logging_mixin.py:95} INFO - [2019-09-15 18:50:51,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:51,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:51,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:51,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:51,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:50:51,834] {scheduler_job.py:146} INFO - Started process (PID=22154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:56,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:50:56,856] {logging_mixin.py:95} INFO - [2019-09-15 18:50:56,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:57,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:50:57,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:50:57,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:50:57,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:50:57,283] {scheduler_job.py:146} INFO - Started process (PID=22155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:02,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:02,300] {logging_mixin.py:95} INFO - [2019-09-15 18:51:02,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:02,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:02,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:02,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:02,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 18:51:02,739] {scheduler_job.py:146} INFO - Started process (PID=22157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:07,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:07,753] {logging_mixin.py:95} INFO - [2019-09-15 18:51:07,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:08,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:08,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:08,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:08,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:51:08,189] {scheduler_job.py:146} INFO - Started process (PID=22159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:13,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:13,202] {logging_mixin.py:95} INFO - [2019-09-15 18:51:13,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:13,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:13,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:13,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:13,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:51:13,633] {scheduler_job.py:146} INFO - Started process (PID=22160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:18,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:18,643] {logging_mixin.py:95} INFO - [2019-09-15 18:51:18,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:19,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:19,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:19,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:19,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:51:19,086] {scheduler_job.py:146} INFO - Started process (PID=22162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:24,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:24,093] {logging_mixin.py:95} INFO - [2019-09-15 18:51:24,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:24,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:24,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:24,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:24,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:51:24,536] {scheduler_job.py:146} INFO - Started process (PID=22163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:29,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:29,546] {logging_mixin.py:95} INFO - [2019-09-15 18:51:29,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:29,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:29,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:29,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:29,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:51:29,982] {scheduler_job.py:146} INFO - Started process (PID=22164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:34,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:35,000] {logging_mixin.py:95} INFO - [2019-09-15 18:51:34,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:35,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:35,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:35,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:35,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:51:35,432] {scheduler_job.py:146} INFO - Started process (PID=22166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:40,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:40,445] {logging_mixin.py:95} INFO - [2019-09-15 18:51:40,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:40,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:40,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:40,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:40,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:51:40,888] {scheduler_job.py:146} INFO - Started process (PID=22167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:45,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:45,900] {logging_mixin.py:95} INFO - [2019-09-15 18:51:45,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:46,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:46,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:46,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:46,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:51:46,337] {scheduler_job.py:146} INFO - Started process (PID=22168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:51,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:51,346] {logging_mixin.py:95} INFO - [2019-09-15 18:51:51,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:51,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:51,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:51,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:51,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 18:51:51,786] {scheduler_job.py:146} INFO - Started process (PID=22170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:56,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:51:56,794] {logging_mixin.py:95} INFO - [2019-09-15 18:51:56,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:57,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:51:57,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:51:57,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:51:57,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:51:57,235] {scheduler_job.py:146} INFO - Started process (PID=22171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:02,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:02,243] {logging_mixin.py:95} INFO - [2019-09-15 18:52:02,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:02,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:02,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:02,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:02,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:52:02,680] {scheduler_job.py:146} INFO - Started process (PID=22173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:07,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:07,705] {logging_mixin.py:95} INFO - [2019-09-15 18:52:07,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:08,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:08,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:08,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:08,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:52:08,132] {scheduler_job.py:146} INFO - Started process (PID=22175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:13,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:13,142] {logging_mixin.py:95} INFO - [2019-09-15 18:52:13,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:13,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:13,556] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:13,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:13,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 18:52:13,678] {scheduler_job.py:146} INFO - Started process (PID=22176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:18,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:18,693] {logging_mixin.py:95} INFO - [2019-09-15 18:52:18,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:19,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:19,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:19,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:19,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:52:19,135] {scheduler_job.py:146} INFO - Started process (PID=22178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:24,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:24,148] {logging_mixin.py:95} INFO - [2019-09-15 18:52:24,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:24,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:24,531] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:24,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:24,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:52:24,582] {scheduler_job.py:146} INFO - Started process (PID=22179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:29,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:29,592] {logging_mixin.py:95} INFO - [2019-09-15 18:52:29,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:29,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:29,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:30,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:30,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:52:30,031] {scheduler_job.py:146} INFO - Started process (PID=22180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:35,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:35,051] {logging_mixin.py:95} INFO - [2019-09-15 18:52:35,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:35,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:35,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:35,446] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:35,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:52:35,489] {scheduler_job.py:146} INFO - Started process (PID=22182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:40,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:40,500] {logging_mixin.py:95} INFO - [2019-09-15 18:52:40,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:40,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:40,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:40,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:40,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 18:52:40,944] {scheduler_job.py:146} INFO - Started process (PID=22183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:45,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:45,953] {logging_mixin.py:95} INFO - [2019-09-15 18:52:45,952] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:46,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:46,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:46,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:46,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 18:52:46,405] {scheduler_job.py:146} INFO - Started process (PID=22184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:51,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:51,412] {logging_mixin.py:95} INFO - [2019-09-15 18:52:51,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:51,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:51,796] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:51,805] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:51,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 18:52:51,856] {scheduler_job.py:146} INFO - Started process (PID=22186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:56,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:52:56,864] {logging_mixin.py:95} INFO - [2019-09-15 18:52:56,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:57,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:52:57,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:52:57,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:52:57,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:52:57,304] {scheduler_job.py:146} INFO - Started process (PID=22187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:02,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:02,315] {logging_mixin.py:95} INFO - [2019-09-15 18:53:02,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:02,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:02,702] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:02,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:02,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:53:02,750] {scheduler_job.py:146} INFO - Started process (PID=22189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:07,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:07,757] {logging_mixin.py:95} INFO - [2019-09-15 18:53:07,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:08,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:08,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:08,146] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:08,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:53:08,205] {scheduler_job.py:146} INFO - Started process (PID=22191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:13,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:13,220] {logging_mixin.py:95} INFO - [2019-09-15 18:53:13,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:13,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:13,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:13,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:13,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:53:13,664] {scheduler_job.py:146} INFO - Started process (PID=22192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:18,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:18,676] {logging_mixin.py:95} INFO - [2019-09-15 18:53:18,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:19,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:19,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:19,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:19,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:53:19,136] {scheduler_job.py:146} INFO - Started process (PID=22194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:24,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:24,154] {logging_mixin.py:95} INFO - [2019-09-15 18:53:24,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:24,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:24,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:24,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:24,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:53:24,604] {scheduler_job.py:146} INFO - Started process (PID=22195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:29,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:29,620] {logging_mixin.py:95} INFO - [2019-09-15 18:53:29,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:29,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:30,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:30,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:30,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 18:53:30,066] {scheduler_job.py:146} INFO - Started process (PID=22196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:35,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:35,084] {logging_mixin.py:95} INFO - [2019-09-15 18:53:35,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:35,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:35,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:35,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:35,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:53:35,535] {scheduler_job.py:146} INFO - Started process (PID=22198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:40,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:40,542] {logging_mixin.py:95} INFO - [2019-09-15 18:53:40,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:40,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:40,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:40,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:40,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:53:41,003] {scheduler_job.py:146} INFO - Started process (PID=22199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:46,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:46,011] {logging_mixin.py:95} INFO - [2019-09-15 18:53:46,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:46,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:46,397] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:46,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:46,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:53:46,487] {scheduler_job.py:146} INFO - Started process (PID=22200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:51,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:51,499] {logging_mixin.py:95} INFO - [2019-09-15 18:53:51,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:51,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:51,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:51,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:51,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:53:51,949] {scheduler_job.py:146} INFO - Started process (PID=22202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:56,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:53:56,955] {logging_mixin.py:95} INFO - [2019-09-15 18:53:56,955] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:57,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:53:57,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:53:57,351] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:53:57,357] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:53:57,412] {scheduler_job.py:146} INFO - Started process (PID=22203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:02,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:02,421] {logging_mixin.py:95} INFO - [2019-09-15 18:54:02,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:02,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:02,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:02,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:02,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:54:02,884] {scheduler_job.py:146} INFO - Started process (PID=22205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:07,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:07,901] {logging_mixin.py:95} INFO - [2019-09-15 18:54:07,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:08,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:08,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:08,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:08,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:54:08,351] {scheduler_job.py:146} INFO - Started process (PID=22207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:13,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:13,366] {logging_mixin.py:95} INFO - [2019-09-15 18:54:13,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:13,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:13,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:13,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:13,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:54:13,832] {scheduler_job.py:146} INFO - Started process (PID=22208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:18,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:18,839] {logging_mixin.py:95} INFO - [2019-09-15 18:54:18,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:19,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:19,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:19,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:19,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 18:54:19,307] {scheduler_job.py:146} INFO - Started process (PID=22210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:24,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:24,320] {logging_mixin.py:95} INFO - [2019-09-15 18:54:24,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:24,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:24,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:24,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:24,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:54:24,775] {scheduler_job.py:146} INFO - Started process (PID=22211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:29,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:29,790] {logging_mixin.py:95} INFO - [2019-09-15 18:54:29,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:30,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:30,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:30,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:30,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:54:30,257] {scheduler_job.py:146} INFO - Started process (PID=22212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:35,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:35,279] {logging_mixin.py:95} INFO - [2019-09-15 18:54:35,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:35,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:35,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:35,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:35,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:54:35,726] {scheduler_job.py:146} INFO - Started process (PID=22214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:40,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:40,738] {logging_mixin.py:95} INFO - [2019-09-15 18:54:40,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:41,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:41,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:41,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:41,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:54:41,193] {scheduler_job.py:146} INFO - Started process (PID=22215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:46,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:46,201] {logging_mixin.py:95} INFO - [2019-09-15 18:54:46,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:46,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:46,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:46,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:46,636] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 18:54:46,666] {scheduler_job.py:146} INFO - Started process (PID=22216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:51,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:51,679] {logging_mixin.py:95} INFO - [2019-09-15 18:54:51,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:52,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:52,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:52,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:52,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:54:52,144] {scheduler_job.py:146} INFO - Started process (PID=22218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:57,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:54:57,159] {logging_mixin.py:95} INFO - [2019-09-15 18:54:57,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:57,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:54:57,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:54:57,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:54:57,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:54:57,617] {scheduler_job.py:146} INFO - Started process (PID=22219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:02,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:02,625] {logging_mixin.py:95} INFO - [2019-09-15 18:55:02,625] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:02,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:03,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:03,018] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:03,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:55:03,098] {scheduler_job.py:146} INFO - Started process (PID=22221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:08,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:08,109] {logging_mixin.py:95} INFO - [2019-09-15 18:55:08,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:08,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:08,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:08,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:08,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:55:08,580] {scheduler_job.py:146} INFO - Started process (PID=22223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:13,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:13,586] {logging_mixin.py:95} INFO - [2019-09-15 18:55:13,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:13,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:13,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:13,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:13,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 18:55:14,044] {scheduler_job.py:146} INFO - Started process (PID=22224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:19,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:19,054] {logging_mixin.py:95} INFO - [2019-09-15 18:55:19,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:19,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:19,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:19,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:19,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 18:55:19,510] {scheduler_job.py:146} INFO - Started process (PID=22226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:24,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:24,518] {logging_mixin.py:95} INFO - [2019-09-15 18:55:24,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:24,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:24,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:24,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:24,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:55:24,982] {scheduler_job.py:146} INFO - Started process (PID=22227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:29,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:29,999] {logging_mixin.py:95} INFO - [2019-09-15 18:55:29,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:30,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:30,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:30,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:30,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 18:55:30,458] {scheduler_job.py:146} INFO - Started process (PID=22228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:35,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:35,477] {logging_mixin.py:95} INFO - [2019-09-15 18:55:35,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:35,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:35,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:35,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:35,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 18:55:35,933] {scheduler_job.py:146} INFO - Started process (PID=22230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:40,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:40,949] {logging_mixin.py:95} INFO - [2019-09-15 18:55:40,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:41,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:41,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:41,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:41,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 18:55:41,402] {scheduler_job.py:146} INFO - Started process (PID=22231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:46,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:46,409] {logging_mixin.py:95} INFO - [2019-09-15 18:55:46,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:46,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:46,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:46,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:46,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 18:55:46,876] {scheduler_job.py:146} INFO - Started process (PID=22232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:51,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:51,887] {logging_mixin.py:95} INFO - [2019-09-15 18:55:51,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:52,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:52,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:52,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:52,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:55:52,350] {scheduler_job.py:146} INFO - Started process (PID=22234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:57,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:55:57,356] {logging_mixin.py:95} INFO - [2019-09-15 18:55:57,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:57,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:55:57,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:55:57,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:55:57,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:55:57,822] {scheduler_job.py:146} INFO - Started process (PID=22235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:02,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:02,843] {logging_mixin.py:95} INFO - [2019-09-15 18:56:02,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:03,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:03,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:03,238] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:03,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:56:03,295] {scheduler_job.py:146} INFO - Started process (PID=22237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:08,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:08,319] {logging_mixin.py:95} INFO - [2019-09-15 18:56:08,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:08,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:08,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:08,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:08,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:56:08,772] {scheduler_job.py:146} INFO - Started process (PID=22239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:13,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:13,783] {logging_mixin.py:95} INFO - [2019-09-15 18:56:13,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:14,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:14,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:14,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:14,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 18:56:14,242] {scheduler_job.py:146} INFO - Started process (PID=22240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:19,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:19,252] {logging_mixin.py:95} INFO - [2019-09-15 18:56:19,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:19,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:19,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:19,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:19,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:56:19,712] {scheduler_job.py:146} INFO - Started process (PID=22242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:24,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:24,728] {logging_mixin.py:95} INFO - [2019-09-15 18:56:24,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:25,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:25,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:25,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:25,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:56:25,196] {scheduler_job.py:146} INFO - Started process (PID=22243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:30,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:30,210] {logging_mixin.py:95} INFO - [2019-09-15 18:56:30,209] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:30,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:30,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:30,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:30,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:56:30,672] {scheduler_job.py:146} INFO - Started process (PID=22244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:35,683] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:35,694] {logging_mixin.py:95} INFO - [2019-09-15 18:56:35,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:36,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:36,077] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:36,088] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:36,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 18:56:36,145] {scheduler_job.py:146} INFO - Started process (PID=22246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:41,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:41,158] {logging_mixin.py:95} INFO - [2019-09-15 18:56:41,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:41,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:41,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:41,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:41,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 18:56:41,615] {scheduler_job.py:146} INFO - Started process (PID=22247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:46,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:46,635] {logging_mixin.py:95} INFO - [2019-09-15 18:56:46,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:47,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:47,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:47,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:47,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 18:56:47,082] {scheduler_job.py:146} INFO - Started process (PID=22248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:52,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:52,088] {logging_mixin.py:95} INFO - [2019-09-15 18:56:52,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:52,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:52,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:52,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:52,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:56:52,562] {scheduler_job.py:146} INFO - Started process (PID=22250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:57,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:56:57,574] {logging_mixin.py:95} INFO - [2019-09-15 18:56:57,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:57,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:56:57,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:56:57,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:56:57,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:56:58,036] {scheduler_job.py:146} INFO - Started process (PID=22251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:03,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:03,060] {logging_mixin.py:95} INFO - [2019-09-15 18:57:03,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:03,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:03,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:03,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:03,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 18:57:03,501] {scheduler_job.py:146} INFO - Started process (PID=22253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:08,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:08,521] {logging_mixin.py:95} INFO - [2019-09-15 18:57:08,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:08,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:08,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:08,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:08,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:57:08,974] {scheduler_job.py:146} INFO - Started process (PID=22255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:13,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:13,985] {logging_mixin.py:95} INFO - [2019-09-15 18:57:13,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:14,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:14,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:14,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:14,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:57:14,449] {scheduler_job.py:146} INFO - Started process (PID=22256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:19,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:19,458] {logging_mixin.py:95} INFO - [2019-09-15 18:57:19,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:19,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:19,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:19,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:19,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:57:19,920] {scheduler_job.py:146} INFO - Started process (PID=22258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:24,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:24,928] {logging_mixin.py:95} INFO - [2019-09-15 18:57:24,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:25,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:25,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:25,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:25,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:57:25,397] {scheduler_job.py:146} INFO - Started process (PID=22259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:30,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:30,404] {logging_mixin.py:95} INFO - [2019-09-15 18:57:30,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:30,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:30,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:30,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:30,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 18:57:30,873] {scheduler_job.py:146} INFO - Started process (PID=22260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:35,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:35,893] {logging_mixin.py:95} INFO - [2019-09-15 18:57:35,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:36,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:36,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:36,294] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:36,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:57:36,342] {scheduler_job.py:146} INFO - Started process (PID=22262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:41,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:41,354] {logging_mixin.py:95} INFO - [2019-09-15 18:57:41,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:41,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:41,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:41,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:41,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:57:41,807] {scheduler_job.py:146} INFO - Started process (PID=22263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:46,816] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:46,827] {logging_mixin.py:95} INFO - [2019-09-15 18:57:46,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:47,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:47,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:47,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:47,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:57:47,273] {scheduler_job.py:146} INFO - Started process (PID=22264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:52,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:52,286] {logging_mixin.py:95} INFO - [2019-09-15 18:57:52,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:52,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:52,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:52,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:52,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 18:57:52,739] {scheduler_job.py:146} INFO - Started process (PID=22266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:57,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:57:57,752] {logging_mixin.py:95} INFO - [2019-09-15 18:57:57,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:58,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:57:58,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:57:58,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:57:58,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:57:58,207] {scheduler_job.py:146} INFO - Started process (PID=22267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:03,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:03,217] {logging_mixin.py:95} INFO - [2019-09-15 18:58:03,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:03,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:03,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:03,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:03,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:58:03,679] {scheduler_job.py:146} INFO - Started process (PID=22270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:08,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:08,691] {logging_mixin.py:95} INFO - [2019-09-15 18:58:08,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:09,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:09,078] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:09,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:09,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 18:58:09,147] {scheduler_job.py:146} INFO - Started process (PID=22272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:14,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:14,159] {logging_mixin.py:95} INFO - [2019-09-15 18:58:14,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:14,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:14,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:14,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:14,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:58:14,615] {scheduler_job.py:146} INFO - Started process (PID=22275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:19,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:19,631] {logging_mixin.py:95} INFO - [2019-09-15 18:58:19,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:19,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:20,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:20,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:20,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 18:58:20,085] {scheduler_job.py:146} INFO - Started process (PID=22277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:25,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:25,099] {logging_mixin.py:95} INFO - [2019-09-15 18:58:25,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:25,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:25,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:25,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:25,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 18:58:25,546] {scheduler_job.py:146} INFO - Started process (PID=22278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:30,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:30,557] {logging_mixin.py:95} INFO - [2019-09-15 18:58:30,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:30,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:30,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:30,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:30,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 18:58:31,019] {scheduler_job.py:146} INFO - Started process (PID=22279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:36,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:36,033] {logging_mixin.py:95} INFO - [2019-09-15 18:58:36,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:36,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:36,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:36,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:36,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 18:58:36,485] {scheduler_job.py:146} INFO - Started process (PID=22281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:41,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:41,499] {logging_mixin.py:95} INFO - [2019-09-15 18:58:41,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:41,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:41,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:41,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:41,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 18:58:41,953] {scheduler_job.py:146} INFO - Started process (PID=22282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:46,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:46,976] {logging_mixin.py:95} INFO - [2019-09-15 18:58:46,975] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:47,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:47,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:47,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:47,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 18:58:47,428] {scheduler_job.py:146} INFO - Started process (PID=22283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:52,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:52,441] {logging_mixin.py:95} INFO - [2019-09-15 18:58:52,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:52,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:52,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:52,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:52,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 18:58:52,900] {scheduler_job.py:146} INFO - Started process (PID=22285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:57,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:58:57,911] {logging_mixin.py:95} INFO - [2019-09-15 18:58:57,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:58,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:58:58,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:58:58,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:58:58,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 18:58:58,362] {scheduler_job.py:146} INFO - Started process (PID=22286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:03,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:03,378] {logging_mixin.py:95} INFO - [2019-09-15 18:59:03,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:03,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:03,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:03,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:03,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:59:03,838] {scheduler_job.py:146} INFO - Started process (PID=22288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:08,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:08,856] {logging_mixin.py:95} INFO - [2019-09-15 18:59:08,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:09,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:09,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:09,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:09,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 18:59:09,312] {scheduler_job.py:146} INFO - Started process (PID=22290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:14,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:14,327] {logging_mixin.py:95} INFO - [2019-09-15 18:59:14,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:14,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:14,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:14,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:14,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:59:14,781] {scheduler_job.py:146} INFO - Started process (PID=22291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:19,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:19,792] {logging_mixin.py:95} INFO - [2019-09-15 18:59:19,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:20,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:20,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:20,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:20,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 18:59:20,265] {scheduler_job.py:146} INFO - Started process (PID=22293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:25,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:25,272] {logging_mixin.py:95} INFO - [2019-09-15 18:59:25,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:25,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:25,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:25,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:25,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 18:59:25,735] {scheduler_job.py:146} INFO - Started process (PID=22294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:30,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:30,750] {logging_mixin.py:95} INFO - [2019-09-15 18:59:30,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:31,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:31,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:31,150] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:31,157] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 18:59:31,197] {scheduler_job.py:146} INFO - Started process (PID=22295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:36,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:36,218] {logging_mixin.py:95} INFO - [2019-09-15 18:59:36,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:36,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:36,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:36,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:36,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 18:59:36,689] {scheduler_job.py:146} INFO - Started process (PID=22297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:41,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:41,703] {logging_mixin.py:95} INFO - [2019-09-15 18:59:41,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:42,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:42,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:42,094] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:42,100] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 18:59:42,162] {scheduler_job.py:146} INFO - Started process (PID=22298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:47,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:47,181] {logging_mixin.py:95} INFO - [2019-09-15 18:59:47,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:47,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:47,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:47,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:47,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 18:59:47,640] {scheduler_job.py:146} INFO - Started process (PID=22299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:52,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:52,656] {logging_mixin.py:95} INFO - [2019-09-15 18:59:52,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:53,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:53,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:53,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:53,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 18:59:53,106] {scheduler_job.py:146} INFO - Started process (PID=22301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:58,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 18:59:58,120] {logging_mixin.py:95} INFO - [2019-09-15 18:59:58,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:58,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 18:59:58,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 18:59:58,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 18:59:58,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 18:59:58,579] {scheduler_job.py:146} INFO - Started process (PID=22302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:03,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:03,589] {logging_mixin.py:95} INFO - [2019-09-15 19:00:03,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:03,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:03,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:03,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:03,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
