[2019-09-12 13:32:17,979] {scheduler_job.py:146} INFO - Started process (PID=27328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:22,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:22,990] {logging_mixin.py:95} INFO - [2019-09-12 13:32:22,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:23,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:23,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:23,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:23,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.920 seconds
[2019-09-12 13:32:23,941] {scheduler_job.py:146} INFO - Started process (PID=27334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:28,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:28,951] {logging_mixin.py:95} INFO - [2019-09-12 13:32:28,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:29,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:29,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:29,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:29,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 13:32:29,394] {scheduler_job.py:146} INFO - Started process (PID=27335) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:34,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:34,401] {logging_mixin.py:95} INFO - [2019-09-12 13:32:34,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:34,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:34,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:34,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:34,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 13:32:34,841] {scheduler_job.py:146} INFO - Started process (PID=27337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:39,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:39,848] {logging_mixin.py:95} INFO - [2019-09-12 13:32:39,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:40,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:40,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:40,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:40,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 13:32:40,297] {scheduler_job.py:146} INFO - Started process (PID=27341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:45,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:45,305] {logging_mixin.py:95} INFO - [2019-09-12 13:32:45,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:45,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:45,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:45,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:45,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 13:32:45,843] {scheduler_job.py:146} INFO - Started process (PID=27342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:50,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:50,849] {logging_mixin.py:95} INFO - [2019-09-12 13:32:50,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:51,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:51,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:51,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:51,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 13:32:51,289] {scheduler_job.py:146} INFO - Started process (PID=27353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:56,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:32:56,299] {logging_mixin.py:95} INFO - [2019-09-12 13:32:56,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:56,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:32:56,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:32:56,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:32:56,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-12 13:32:56,739] {scheduler_job.py:146} INFO - Started process (PID=27354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:01,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:01,746] {logging_mixin.py:95} INFO - [2019-09-12 13:33:01,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:02,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:02,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:02,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:02,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-12 13:33:02,193] {scheduler_job.py:146} INFO - Started process (PID=27356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:07,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:07,202] {logging_mixin.py:95} INFO - [2019-09-12 13:33:07,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:07,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:07,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:07,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:07,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:33:07,649] {scheduler_job.py:146} INFO - Started process (PID=27358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:12,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:12,656] {logging_mixin.py:95} INFO - [2019-09-12 13:33:12,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:12,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:13,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:13,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:13,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:33:13,106] {scheduler_job.py:146} INFO - Started process (PID=27362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:18,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:18,115] {logging_mixin.py:95} INFO - [2019-09-12 13:33:18,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:18,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:18,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:18,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:18,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:33:18,563] {scheduler_job.py:146} INFO - Started process (PID=27365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:23,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:23,568] {logging_mixin.py:95} INFO - [2019-09-12 13:33:23,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:23,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:23,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:23,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:23,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 13:33:24,021] {scheduler_job.py:146} INFO - Started process (PID=27368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:29,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:29,030] {logging_mixin.py:95} INFO - [2019-09-12 13:33:29,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:29,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:29,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:29,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:29,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 13:33:29,470] {scheduler_job.py:146} INFO - Started process (PID=27372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:34,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:34,477] {logging_mixin.py:95} INFO - [2019-09-12 13:33:34,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:34,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:34,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:34,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:34,895] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 13:33:34,918] {scheduler_job.py:146} INFO - Started process (PID=27374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:39,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:39,925] {logging_mixin.py:95} INFO - [2019-09-12 13:33:39,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:40,286] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:40,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:40,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:40,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 13:33:40,376] {scheduler_job.py:146} INFO - Started process (PID=27375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:45,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:45,386] {logging_mixin.py:95} INFO - [2019-09-12 13:33:45,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:45,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:45,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:45,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:45,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 13:33:45,827] {scheduler_job.py:146} INFO - Started process (PID=27379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:50,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:50,837] {logging_mixin.py:95} INFO - [2019-09-12 13:33:50,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:51,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:51,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:51,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:51,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 13:33:51,275] {scheduler_job.py:146} INFO - Started process (PID=27381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:56,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:33:56,285] {logging_mixin.py:95} INFO - [2019-09-12 13:33:56,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:56,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:33:56,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:33:56,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:33:56,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:33:56,730] {scheduler_job.py:146} INFO - Started process (PID=27385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:01,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:01,739] {logging_mixin.py:95} INFO - [2019-09-12 13:34:01,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:02,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:02,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:02,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:02,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:34:02,192] {scheduler_job.py:146} INFO - Started process (PID=27386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:07,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:07,203] {logging_mixin.py:95} INFO - [2019-09-12 13:34:07,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:07,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:07,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:07,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:07,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:34:07,656] {scheduler_job.py:146} INFO - Started process (PID=27388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:12,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:12,666] {logging_mixin.py:95} INFO - [2019-09-12 13:34:12,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:13,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:13,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:13,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:13,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 13:34:13,118] {scheduler_job.py:146} INFO - Started process (PID=27389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:18,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:18,128] {logging_mixin.py:95} INFO - [2019-09-12 13:34:18,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:18,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:18,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:18,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:18,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:34:18,579] {scheduler_job.py:146} INFO - Started process (PID=27394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:23,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:23,589] {logging_mixin.py:95} INFO - [2019-09-12 13:34:23,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:23,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:23,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:23,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:23,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:34:24,040] {scheduler_job.py:146} INFO - Started process (PID=27396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:29,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:29,049] {logging_mixin.py:95} INFO - [2019-09-12 13:34:29,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:29,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:29,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:29,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:29,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:34:29,493] {scheduler_job.py:146} INFO - Started process (PID=27400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:34,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:34,502] {logging_mixin.py:95} INFO - [2019-09-12 13:34:34,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:34,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:34,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:34,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:34,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:34:34,955] {scheduler_job.py:146} INFO - Started process (PID=27402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:39,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:39,965] {logging_mixin.py:95} INFO - [2019-09-12 13:34:39,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:40,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:40,334] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:40,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:40,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:34:40,417] {scheduler_job.py:146} INFO - Started process (PID=27403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:45,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:45,428] {logging_mixin.py:95} INFO - [2019-09-12 13:34:45,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:45,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:45,794] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:45,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:45,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:34:45,879] {scheduler_job.py:146} INFO - Started process (PID=27407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:50,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:50,889] {logging_mixin.py:95} INFO - [2019-09-12 13:34:50,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:51,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:51,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:51,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:51,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:34:51,341] {scheduler_job.py:146} INFO - Started process (PID=27409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:56,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:34:56,353] {logging_mixin.py:95} INFO - [2019-09-12 13:34:56,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:56,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:34:56,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:34:56,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:34:56,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:34:56,802] {scheduler_job.py:146} INFO - Started process (PID=27410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:01,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:01,809] {logging_mixin.py:95} INFO - [2019-09-12 13:35:01,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:02,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:02,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:02,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:02,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:35:02,264] {scheduler_job.py:146} INFO - Started process (PID=27411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:07,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:07,272] {logging_mixin.py:95} INFO - [2019-09-12 13:35:07,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:07,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:07,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:07,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:07,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:35:07,727] {scheduler_job.py:146} INFO - Started process (PID=27416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:12,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:12,737] {logging_mixin.py:95} INFO - [2019-09-12 13:35:12,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:13,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:13,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:13,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:13,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:35:13,189] {scheduler_job.py:146} INFO - Started process (PID=27417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:18,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:18,199] {logging_mixin.py:95} INFO - [2019-09-12 13:35:18,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:18,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:18,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:18,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:18,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:35:18,647] {scheduler_job.py:146} INFO - Started process (PID=27422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:23,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:23,655] {logging_mixin.py:95} INFO - [2019-09-12 13:35:23,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:23,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:24,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:24,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:24,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-12 13:35:24,108] {scheduler_job.py:146} INFO - Started process (PID=27424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:29,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:29,115] {logging_mixin.py:95} INFO - [2019-09-12 13:35:29,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:29,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:29,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:29,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:29,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:35:29,568] {scheduler_job.py:146} INFO - Started process (PID=27425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:34,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:34,575] {logging_mixin.py:95} INFO - [2019-09-12 13:35:34,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:34,914] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:34,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:34,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:34,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-12 13:35:35,025] {scheduler_job.py:146} INFO - Started process (PID=27427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:40,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:40,032] {logging_mixin.py:95} INFO - [2019-09-12 13:35:40,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:40,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:40,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:40,409] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:40,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:35:40,488] {scheduler_job.py:146} INFO - Started process (PID=27431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:45,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:45,497] {logging_mixin.py:95} INFO - [2019-09-12 13:35:45,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:45,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:45,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:45,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:45,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:35:45,942] {scheduler_job.py:146} INFO - Started process (PID=27435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:50,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:50,948] {logging_mixin.py:95} INFO - [2019-09-12 13:35:50,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:51,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:51,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:51,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:51,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:35:51,401] {scheduler_job.py:146} INFO - Started process (PID=27437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:56,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:35:56,408] {logging_mixin.py:95} INFO - [2019-09-12 13:35:56,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:56,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:35:56,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:35:56,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:35:56,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 13:35:56,863] {scheduler_job.py:146} INFO - Started process (PID=27438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:01,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:01,871] {logging_mixin.py:95} INFO - [2019-09-12 13:36:01,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:02,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:02,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:02,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:02,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:36:02,325] {scheduler_job.py:146} INFO - Started process (PID=27439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:07,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:07,332] {logging_mixin.py:95} INFO - [2019-09-12 13:36:07,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:07,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:07,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:07,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:07,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-12 13:36:07,787] {scheduler_job.py:146} INFO - Started process (PID=27444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:12,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:12,794] {logging_mixin.py:95} INFO - [2019-09-12 13:36:12,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:13,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:13,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:13,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:13,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:36:13,253] {scheduler_job.py:146} INFO - Started process (PID=27445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:18,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:18,264] {logging_mixin.py:95} INFO - [2019-09-12 13:36:18,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:18,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:18,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:18,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:18,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:36:18,716] {scheduler_job.py:146} INFO - Started process (PID=27447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:23,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:23,723] {logging_mixin.py:95} INFO - [2019-09-12 13:36:23,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:24,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:24,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:24,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:24,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:36:24,178] {scheduler_job.py:146} INFO - Started process (PID=27449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:29,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:29,187] {logging_mixin.py:95} INFO - [2019-09-12 13:36:29,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:29,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:29,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:29,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:29,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:36:29,640] {scheduler_job.py:146} INFO - Started process (PID=27453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:34,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:34,648] {logging_mixin.py:95} INFO - [2019-09-12 13:36:34,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:34,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:35,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:35,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:35,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-12 13:36:35,099] {scheduler_job.py:146} INFO - Started process (PID=27455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:40,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:40,109] {logging_mixin.py:95} INFO - [2019-09-12 13:36:40,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:40,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:40,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:40,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:40,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:36:40,555] {scheduler_job.py:146} INFO - Started process (PID=27459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:45,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:45,566] {logging_mixin.py:95} INFO - [2019-09-12 13:36:45,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:45,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:45,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:45,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:45,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:36:46,018] {scheduler_job.py:146} INFO - Started process (PID=27460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:51,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:51,028] {logging_mixin.py:95} INFO - [2019-09-12 13:36:51,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:51,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:51,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:51,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:51,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:36:51,480] {scheduler_job.py:146} INFO - Started process (PID=27462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:56,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:36:56,487] {logging_mixin.py:95} INFO - [2019-09-12 13:36:56,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:56,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:36:56,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:36:56,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:36:56,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 13:36:56,941] {scheduler_job.py:146} INFO - Started process (PID=27466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:01,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:01,947] {logging_mixin.py:95} INFO - [2019-09-12 13:37:01,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:02,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:02,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:02,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:02,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 13:37:02,399] {scheduler_job.py:146} INFO - Started process (PID=27467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:07,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:07,407] {logging_mixin.py:95} INFO - [2019-09-12 13:37:07,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:07,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:07,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:07,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:07,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:37:07,858] {scheduler_job.py:146} INFO - Started process (PID=27472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:12,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:12,868] {logging_mixin.py:95} INFO - [2019-09-12 13:37:12,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:13,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:13,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:13,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:13,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 13:37:13,323] {scheduler_job.py:146} INFO - Started process (PID=27473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:18,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:18,334] {logging_mixin.py:95} INFO - [2019-09-12 13:37:18,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:18,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:18,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:18,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:18,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:37:18,798] {scheduler_job.py:146} INFO - Started process (PID=27475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:23,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:23,806] {logging_mixin.py:95} INFO - [2019-09-12 13:37:23,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:24,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:24,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:24,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:24,189] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:37:24,263] {scheduler_job.py:146} INFO - Started process (PID=27477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:29,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:29,271] {logging_mixin.py:95} INFO - [2019-09-12 13:37:29,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:29,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:29,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:29,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:29,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:37:29,725] {scheduler_job.py:146} INFO - Started process (PID=27481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:34,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:34,735] {logging_mixin.py:95} INFO - [2019-09-12 13:37:34,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:35,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:35,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:35,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:35,097] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-12 13:37:35,182] {scheduler_job.py:146} INFO - Started process (PID=27483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:40,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:40,194] {logging_mixin.py:95} INFO - [2019-09-12 13:37:40,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:40,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:40,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:40,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:40,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:37:40,645] {scheduler_job.py:146} INFO - Started process (PID=27487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:45,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:45,654] {logging_mixin.py:95} INFO - [2019-09-12 13:37:45,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:45,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:46,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:46,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:46,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:37:46,106] {scheduler_job.py:146} INFO - Started process (PID=27488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:51,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:51,118] {logging_mixin.py:95} INFO - [2019-09-12 13:37:51,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:51,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:51,487] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:51,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:51,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:37:51,572] {scheduler_job.py:146} INFO - Started process (PID=27490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:56,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:37:56,584] {logging_mixin.py:95} INFO - [2019-09-12 13:37:56,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:56,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:37:56,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:37:56,961] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:37:56,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:37:57,037] {scheduler_job.py:146} INFO - Started process (PID=27491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:02,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:02,047] {logging_mixin.py:95} INFO - [2019-09-12 13:38:02,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:02,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:02,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:02,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:02,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:38:02,496] {scheduler_job.py:146} INFO - Started process (PID=27495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:07,505] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:07,506] {logging_mixin.py:95} INFO - [2019-09-12 13:38:07,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:07,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:07,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:07,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:07,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:38:07,961] {scheduler_job.py:146} INFO - Started process (PID=27497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:12,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:12,970] {logging_mixin.py:95} INFO - [2019-09-12 13:38:12,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:13,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:13,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:13,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:13,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:38:13,422] {scheduler_job.py:146} INFO - Started process (PID=27498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:18,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:18,435] {logging_mixin.py:95} INFO - [2019-09-12 13:38:18,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:18,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:18,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:18,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:18,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:38:18,887] {scheduler_job.py:146} INFO - Started process (PID=27503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:23,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:23,898] {logging_mixin.py:95} INFO - [2019-09-12 13:38:23,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:24,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:24,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:24,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:24,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:38:24,350] {scheduler_job.py:146} INFO - Started process (PID=27505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:29,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:29,359] {logging_mixin.py:95} INFO - [2019-09-12 13:38:29,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:29,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:29,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:29,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:29,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:38:29,812] {scheduler_job.py:146} INFO - Started process (PID=27509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:34,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:34,820] {logging_mixin.py:95} INFO - [2019-09-12 13:38:34,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:35,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:35,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:35,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:35,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 13:38:35,276] {scheduler_job.py:146} INFO - Started process (PID=27511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:40,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:40,287] {logging_mixin.py:95} INFO - [2019-09-12 13:38:40,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:40,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:40,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:40,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:40,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:38:40,734] {scheduler_job.py:146} INFO - Started process (PID=27512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:45,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:45,742] {logging_mixin.py:95} INFO - [2019-09-12 13:38:45,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:46,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:46,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:46,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:46,123] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:38:46,203] {scheduler_job.py:146} INFO - Started process (PID=27513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:51,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:51,218] {logging_mixin.py:95} INFO - [2019-09-12 13:38:51,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:51,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:51,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:51,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:51,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:38:51,695] {scheduler_job.py:146} INFO - Started process (PID=27519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:56,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:38:56,704] {logging_mixin.py:95} INFO - [2019-09-12 13:38:56,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:57,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:38:57,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:38:57,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:38:57,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 13:38:57,185] {scheduler_job.py:146} INFO - Started process (PID=27520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:02,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:02,202] {logging_mixin.py:95} INFO - [2019-09-12 13:39:02,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:02,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:02,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:02,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:02,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 13:39:02,674] {scheduler_job.py:146} INFO - Started process (PID=27521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:07,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:07,686] {logging_mixin.py:95} INFO - [2019-09-12 13:39:07,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:08,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:08,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:08,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:08,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-12 13:39:08,078] {scheduler_job.py:146} INFO - Started process (PID=27523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:13,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:13,092] {logging_mixin.py:95} INFO - [2019-09-12 13:39:13,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:13,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:13,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:13,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:13,476] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:39:13,575] {scheduler_job.py:146} INFO - Started process (PID=27527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:18,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:18,596] {logging_mixin.py:95} INFO - [2019-09-12 13:39:18,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:18,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:18,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:18,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:18,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 13:39:19,066] {scheduler_job.py:146} INFO - Started process (PID=27529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:24,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:24,083] {logging_mixin.py:95} INFO - [2019-09-12 13:39:24,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:24,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:24,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:24,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:24,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:39:24,552] {scheduler_job.py:146} INFO - Started process (PID=27531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:29,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:29,567] {logging_mixin.py:95} INFO - [2019-09-12 13:39:29,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:29,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:29,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:29,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:29,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:39:30,052] {scheduler_job.py:146} INFO - Started process (PID=27535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:35,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:35,069] {logging_mixin.py:95} INFO - [2019-09-12 13:39:35,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:35,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:35,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:35,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:35,453] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:39:35,550] {scheduler_job.py:146} INFO - Started process (PID=27537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:40,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:40,567] {logging_mixin.py:95} INFO - [2019-09-12 13:39:40,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:40,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:40,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:40,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:40,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:39:41,034] {scheduler_job.py:146} INFO - Started process (PID=27538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:46,041] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:46,042] {logging_mixin.py:95} INFO - [2019-09-12 13:39:46,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:46,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:46,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:46,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:46,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:39:46,526] {scheduler_job.py:146} INFO - Started process (PID=27539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:51,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:51,542] {logging_mixin.py:95} INFO - [2019-09-12 13:39:51,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:51,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:51,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:51,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:51,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 13:39:52,020] {scheduler_job.py:146} INFO - Started process (PID=27544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:57,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:39:57,030] {logging_mixin.py:95} INFO - [2019-09-12 13:39:57,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:57,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:39:57,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:39:57,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:39:57,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 13:39:57,516] {scheduler_job.py:146} INFO - Started process (PID=27545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:02,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:02,533] {logging_mixin.py:95} INFO - [2019-09-12 13:40:02,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:02,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:02,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:02,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:02,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 13:40:03,013] {scheduler_job.py:146} INFO - Started process (PID=27546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:08,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:08,022] {logging_mixin.py:95} INFO - [2019-09-12 13:40:08,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:08,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:08,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:08,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:08,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:40:08,510] {scheduler_job.py:146} INFO - Started process (PID=27548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:13,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:13,523] {logging_mixin.py:95} INFO - [2019-09-12 13:40:13,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:13,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:13,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:13,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:13,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:40:14,003] {scheduler_job.py:146} INFO - Started process (PID=27552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:19,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:19,025] {logging_mixin.py:95} INFO - [2019-09-12 13:40:19,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:19,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:19,397] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:19,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:19,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 13:40:19,492] {scheduler_job.py:146} INFO - Started process (PID=27555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:24,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:24,501] {logging_mixin.py:95} INFO - [2019-09-12 13:40:24,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:24,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:24,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:24,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:24,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:40:24,989] {scheduler_job.py:146} INFO - Started process (PID=27556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:29,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:29,999] {logging_mixin.py:95} INFO - [2019-09-12 13:40:29,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:30,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:30,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:30,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:30,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-12 13:40:30,482] {scheduler_job.py:146} INFO - Started process (PID=27560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:35,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:35,491] {logging_mixin.py:95} INFO - [2019-09-12 13:40:35,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:35,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:35,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:35,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:35,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:40:35,984] {scheduler_job.py:146} INFO - Started process (PID=27562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:40,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:40,999] {logging_mixin.py:95} INFO - [2019-09-12 13:40:40,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:41,347] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:41,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:41,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:41,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 13:40:41,475] {scheduler_job.py:146} INFO - Started process (PID=27563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:46,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:46,490] {logging_mixin.py:95} INFO - [2019-09-12 13:40:46,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:46,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:46,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:46,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:46,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:40:46,972] {scheduler_job.py:146} INFO - Started process (PID=27564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:51,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:51,988] {logging_mixin.py:95} INFO - [2019-09-12 13:40:51,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:52,337] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:52,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:52,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:52,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 13:40:52,470] {scheduler_job.py:146} INFO - Started process (PID=27569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:57,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:40:57,478] {logging_mixin.py:95} INFO - [2019-09-12 13:40:57,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:57,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:40:57,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:40:57,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:40:57,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:40:57,957] {scheduler_job.py:146} INFO - Started process (PID=27570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:02,968] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:02,969] {logging_mixin.py:95} INFO - [2019-09-12 13:41:02,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:03,314] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:03,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:03,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:03,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 13:41:03,451] {scheduler_job.py:146} INFO - Started process (PID=27571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:08,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:08,459] {logging_mixin.py:95} INFO - [2019-09-12 13:41:08,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:08,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:08,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:08,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:08,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:41:08,948] {scheduler_job.py:146} INFO - Started process (PID=27573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:13,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:13,958] {logging_mixin.py:95} INFO - [2019-09-12 13:41:13,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:14,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:14,328] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:14,337] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:14,342] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:41:14,431] {scheduler_job.py:146} INFO - Started process (PID=27579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:19,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:19,444] {logging_mixin.py:95} INFO - [2019-09-12 13:41:19,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:19,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:19,821] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:19,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:19,836] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 13:41:19,901] {scheduler_job.py:146} INFO - Started process (PID=27582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:24,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:24,914] {logging_mixin.py:95} INFO - [2019-09-12 13:41:24,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:25,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:25,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:25,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:25,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:41:25,379] {scheduler_job.py:146} INFO - Started process (PID=27583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:30,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:30,396] {logging_mixin.py:95} INFO - [2019-09-12 13:41:30,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:30,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:30,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:30,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:30,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 13:41:30,884] {scheduler_job.py:146} INFO - Started process (PID=27584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:35,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:35,900] {logging_mixin.py:95} INFO - [2019-09-12 13:41:35,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:36,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:36,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:36,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:36,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 13:41:36,383] {scheduler_job.py:146} INFO - Started process (PID=27589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:41,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:41,395] {logging_mixin.py:95} INFO - [2019-09-12 13:41:41,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:41,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:41,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:41,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:41,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-12 13:41:41,874] {scheduler_job.py:146} INFO - Started process (PID=27590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:46,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:46,888] {logging_mixin.py:95} INFO - [2019-09-12 13:41:46,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:47,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:47,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:47,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:47,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 13:41:47,366] {scheduler_job.py:146} INFO - Started process (PID=27591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:52,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:52,377] {logging_mixin.py:95} INFO - [2019-09-12 13:41:52,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:52,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:52,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:52,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:52,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:41:52,860] {scheduler_job.py:146} INFO - Started process (PID=27593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:57,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:41:57,877] {logging_mixin.py:95} INFO - [2019-09-12 13:41:57,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:58,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:41:58,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:41:58,257] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:41:58,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:41:58,358] {scheduler_job.py:146} INFO - Started process (PID=27597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:03,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:03,366] {logging_mixin.py:95} INFO - [2019-09-12 13:42:03,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:03,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:03,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:03,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:03,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:42:03,859] {scheduler_job.py:146} INFO - Started process (PID=27598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:08,869] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:08,881] {logging_mixin.py:95} INFO - [2019-09-12 13:42:08,880] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:09,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:09,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:09,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:09,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 13:42:09,359] {scheduler_job.py:146} INFO - Started process (PID=27600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:14,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:14,366] {logging_mixin.py:95} INFO - [2019-09-12 13:42:14,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:14,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:14,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:14,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:14,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 13:42:14,855] {scheduler_job.py:146} INFO - Started process (PID=27605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:19,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:19,864] {logging_mixin.py:95} INFO - [2019-09-12 13:42:19,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:20,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:20,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:20,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:20,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 13:42:20,351] {scheduler_job.py:146} INFO - Started process (PID=27607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:25,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:25,360] {logging_mixin.py:95} INFO - [2019-09-12 13:42:25,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:25,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:25,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:25,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:25,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:42:25,852] {scheduler_job.py:146} INFO - Started process (PID=27608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:30,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:30,866] {logging_mixin.py:95} INFO - [2019-09-12 13:42:30,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:31,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:31,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:31,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:31,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:42:31,353] {scheduler_job.py:146} INFO - Started process (PID=27609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:36,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:36,363] {logging_mixin.py:95} INFO - [2019-09-12 13:42:36,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:36,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:36,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:36,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:36,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 13:42:36,844] {scheduler_job.py:146} INFO - Started process (PID=27615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:41,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:41,851] {logging_mixin.py:95} INFO - [2019-09-12 13:42:41,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:42,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:42,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:42,235] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:42,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 13:42:42,343] {scheduler_job.py:146} INFO - Started process (PID=27616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:47,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:47,355] {logging_mixin.py:95} INFO - [2019-09-12 13:42:47,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:47,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:47,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:47,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:47,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-12 13:42:47,824] {scheduler_job.py:146} INFO - Started process (PID=27618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:52,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:52,837] {logging_mixin.py:95} INFO - [2019-09-12 13:42:52,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:53,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:53,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:53,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:53,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-12 13:42:53,226] {scheduler_job.py:146} INFO - Started process (PID=27620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:58,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:42:58,240] {logging_mixin.py:95} INFO - [2019-09-12 13:42:58,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:58,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:42:58,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:42:58,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:42:58,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.362 seconds
[2019-09-12 13:42:58,621] {scheduler_job.py:146} INFO - Started process (PID=27624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:03,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:03,632] {logging_mixin.py:95} INFO - [2019-09-12 13:43:03,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:03,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:03,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:03,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:03,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.352 seconds
[2019-09-12 13:43:04,013] {scheduler_job.py:146} INFO - Started process (PID=27625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:09,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:09,041] {logging_mixin.py:95} INFO - [2019-09-12 13:43:09,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:09,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:09,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:09,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:09,393] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-12 13:43:09,509] {scheduler_job.py:146} INFO - Started process (PID=27627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:14,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:14,520] {logging_mixin.py:95} INFO - [2019-09-12 13:43:14,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:14,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:14,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:14,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:14,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 13:43:15,006] {scheduler_job.py:146} INFO - Started process (PID=27632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:20,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:20,015] {logging_mixin.py:95} INFO - [2019-09-12 13:43:20,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:20,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:20,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:20,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:20,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 13:43:20,506] {scheduler_job.py:146} INFO - Started process (PID=27634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:25,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:25,515] {logging_mixin.py:95} INFO - [2019-09-12 13:43:25,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:25,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:25,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:25,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:25,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 13:43:25,993] {scheduler_job.py:146} INFO - Started process (PID=27635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:31,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:31,007] {logging_mixin.py:95} INFO - [2019-09-12 13:43:31,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:31,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:31,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:31,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:31,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:43:31,490] {scheduler_job.py:146} INFO - Started process (PID=27636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:36,505] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:36,506] {logging_mixin.py:95} INFO - [2019-09-12 13:43:36,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:36,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:36,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:36,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:36,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:43:36,983] {scheduler_job.py:146} INFO - Started process (PID=27641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:41,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:41,991] {logging_mixin.py:95} INFO - [2019-09-12 13:43:41,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:42,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:42,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:42,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:42,370] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 13:43:42,476] {scheduler_job.py:146} INFO - Started process (PID=27642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:47,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:47,482] {logging_mixin.py:95} INFO - [2019-09-12 13:43:47,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:47,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:47,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:47,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:47,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 13:43:47,970] {scheduler_job.py:146} INFO - Started process (PID=27643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:52,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:52,981] {logging_mixin.py:95} INFO - [2019-09-12 13:43:52,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:53,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:53,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:53,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:53,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 13:43:53,461] {scheduler_job.py:146} INFO - Started process (PID=27645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:58,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:43:58,469] {logging_mixin.py:95} INFO - [2019-09-12 13:43:58,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:58,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:43:58,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:43:58,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:43:58,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 13:43:58,954] {scheduler_job.py:146} INFO - Started process (PID=27649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:03,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:03,964] {logging_mixin.py:95} INFO - [2019-09-12 13:44:03,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:04,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:04,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:04,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:04,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 13:44:04,443] {scheduler_job.py:146} INFO - Started process (PID=27650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:09,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:09,458] {logging_mixin.py:95} INFO - [2019-09-12 13:44:09,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:09,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:09,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:09,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:09,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 13:44:09,933] {scheduler_job.py:146} INFO - Started process (PID=27652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:14,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:14,946] {logging_mixin.py:95} INFO - [2019-09-12 13:44:14,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:15,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:15,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:15,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:15,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 13:44:15,426] {scheduler_job.py:146} INFO - Started process (PID=27654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:20,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:20,436] {logging_mixin.py:95} INFO - [2019-09-12 13:44:20,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:20,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:20,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:20,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:20,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 13:44:20,921] {scheduler_job.py:146} INFO - Started process (PID=27656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:25,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:25,927] {logging_mixin.py:95} INFO - [2019-09-12 13:44:25,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:26,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:26,293] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:26,303] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:26,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 13:44:26,421] {scheduler_job.py:146} INFO - Started process (PID=27660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:31,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:31,437] {logging_mixin.py:95} INFO - [2019-09-12 13:44:31,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:31,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:31,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:31,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:31,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 13:44:31,920] {scheduler_job.py:146} INFO - Started process (PID=27661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:36,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:36,931] {logging_mixin.py:95} INFO - [2019-09-12 13:44:36,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:37,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:37,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:37,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:37,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 13:44:37,410] {scheduler_job.py:146} INFO - Started process (PID=27663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:42,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:42,424] {logging_mixin.py:95} INFO - [2019-09-12 13:44:42,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:42,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:42,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:42,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:42,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 13:44:42,907] {scheduler_job.py:146} INFO - Started process (PID=27664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:47,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 13:44:47,917] {logging_mixin.py:95} INFO - [2019-09-12 13:44:47,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:48,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 13:44:48,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 13:44:48,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 13:44:48,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 13:44:48,409] {scheduler_job.py:146} INFO - Started process (PID=27668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:18,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:18,519] {logging_mixin.py:95} INFO - [2019-09-12 14:29:18,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:18,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:18,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:18,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:18,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2670.535 seconds
[2019-09-12 14:29:19,051] {scheduler_job.py:146} INFO - Started process (PID=27671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:24,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:24,840] {logging_mixin.py:95} INFO - [2019-09-12 14:29:24,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:25,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:25,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:25,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:25,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.185 seconds
[2019-09-12 14:29:25,279] {scheduler_job.py:146} INFO - Started process (PID=27679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:30,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:30,287] {logging_mixin.py:95} INFO - [2019-09-12 14:29:30,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:30,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:30,710] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:30,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:30,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-12 14:29:30,823] {scheduler_job.py:146} INFO - Started process (PID=27682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:35,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:35,849] {logging_mixin.py:95} INFO - [2019-09-12 14:29:35,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:36,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:36,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:36,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:36,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 14:29:36,276] {scheduler_job.py:146} INFO - Started process (PID=27690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:41,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:41,284] {logging_mixin.py:95} INFO - [2019-09-12 14:29:41,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:41,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:41,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:41,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:41,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:29:41,732] {scheduler_job.py:146} INFO - Started process (PID=27692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:46,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:46,739] {logging_mixin.py:95} INFO - [2019-09-12 14:29:46,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:47,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:47,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:47,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:47,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 14:29:47,189] {scheduler_job.py:146} INFO - Started process (PID=27694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:52,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:52,194] {logging_mixin.py:95} INFO - [2019-09-12 14:29:52,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:52,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:52,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:52,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:52,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:29:52,653] {scheduler_job.py:146} INFO - Started process (PID=27698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:57,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:29:57,659] {logging_mixin.py:95} INFO - [2019-09-12 14:29:57,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:58,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:29:58,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:29:58,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:29:58,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 14:29:58,110] {scheduler_job.py:146} INFO - Started process (PID=27700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:03,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:03,120] {logging_mixin.py:95} INFO - [2019-09-12 14:30:03,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:03,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:03,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:03,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:03,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:30:03,569] {scheduler_job.py:146} INFO - Started process (PID=27704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:08,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:08,580] {logging_mixin.py:95} INFO - [2019-09-12 14:30:08,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:08,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:08,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:08,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:08,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:30:09,032] {scheduler_job.py:146} INFO - Started process (PID=27708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:14,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:14,038] {logging_mixin.py:95} INFO - [2019-09-12 14:30:14,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:14,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:14,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:14,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:14,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 14:30:14,496] {scheduler_job.py:146} INFO - Started process (PID=27709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:19,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:19,502] {logging_mixin.py:95} INFO - [2019-09-12 14:30:19,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:19,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:19,873] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:19,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:19,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:30:19,946] {scheduler_job.py:146} INFO - Started process (PID=27711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:24,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:24,954] {logging_mixin.py:95} INFO - [2019-09-12 14:30:24,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:25,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:25,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:25,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:25,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:30:25,407] {scheduler_job.py:146} INFO - Started process (PID=27712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:30,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:30,415] {logging_mixin.py:95} INFO - [2019-09-12 14:30:30,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:30,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:30,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:30,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:30,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:30:30,869] {scheduler_job.py:146} INFO - Started process (PID=27714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:35,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:35,875] {logging_mixin.py:95} INFO - [2019-09-12 14:30:35,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:36,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:36,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:36,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:36,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 14:30:36,329] {scheduler_job.py:146} INFO - Started process (PID=27718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:41,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:41,338] {logging_mixin.py:95} INFO - [2019-09-12 14:30:41,337] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:41,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:41,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:41,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:41,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:30:41,793] {scheduler_job.py:146} INFO - Started process (PID=27723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:46,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:46,802] {logging_mixin.py:95} INFO - [2019-09-12 14:30:46,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:47,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:47,168] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:47,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:47,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:30:47,253] {scheduler_job.py:146} INFO - Started process (PID=27725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:52,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:52,263] {logging_mixin.py:95} INFO - [2019-09-12 14:30:52,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:52,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:52,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:52,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:52,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:30:52,715] {scheduler_job.py:146} INFO - Started process (PID=27726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:57,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:30:57,726] {logging_mixin.py:95} INFO - [2019-09-12 14:30:57,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:58,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:30:58,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:30:58,105] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:30:58,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:30:58,177] {scheduler_job.py:146} INFO - Started process (PID=27727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:03,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:03,184] {logging_mixin.py:95} INFO - [2019-09-12 14:31:03,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:03,535] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:03,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:03,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:03,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 14:31:03,641] {scheduler_job.py:146} INFO - Started process (PID=27732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:08,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:08,651] {logging_mixin.py:95} INFO - [2019-09-12 14:31:08,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:08,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:09,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:09,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:09,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:31:09,096] {scheduler_job.py:146} INFO - Started process (PID=27733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:14,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:14,105] {logging_mixin.py:95} INFO - [2019-09-12 14:31:14,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:14,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:14,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:14,484] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:14,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:31:14,561] {scheduler_job.py:146} INFO - Started process (PID=27734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:19,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:19,567] {logging_mixin.py:95} INFO - [2019-09-12 14:31:19,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:19,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:19,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:19,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:19,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:31:20,021] {scheduler_job.py:146} INFO - Started process (PID=27736) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:25,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:25,031] {logging_mixin.py:95} INFO - [2019-09-12 14:31:25,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:25,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:25,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:25,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:25,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:31:25,479] {scheduler_job.py:146} INFO - Started process (PID=27740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:30,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:30,485] {logging_mixin.py:95} INFO - [2019-09-12 14:31:30,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:30,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:30,853] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:30,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:30,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:31:30,946] {scheduler_job.py:146} INFO - Started process (PID=27742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:35,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:35,967] {logging_mixin.py:95} INFO - [2019-09-12 14:31:35,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:36,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:36,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:36,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:36,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 14:31:36,406] {scheduler_job.py:146} INFO - Started process (PID=27746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:41,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:41,412] {logging_mixin.py:95} INFO - [2019-09-12 14:31:41,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:41,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:41,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:41,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:41,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:31:41,867] {scheduler_job.py:146} INFO - Started process (PID=27748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:46,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:46,874] {logging_mixin.py:95} INFO - [2019-09-12 14:31:46,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:47,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:47,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:47,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:47,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:31:47,330] {scheduler_job.py:146} INFO - Started process (PID=27750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:52,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:52,337] {logging_mixin.py:95} INFO - [2019-09-12 14:31:52,337] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:52,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:52,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:52,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:52,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:31:52,789] {scheduler_job.py:146} INFO - Started process (PID=27754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:57,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:31:57,797] {logging_mixin.py:95} INFO - [2019-09-12 14:31:57,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:58,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:31:58,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:31:58,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:31:58,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:31:58,249] {scheduler_job.py:146} INFO - Started process (PID=27755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:03,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:03,259] {logging_mixin.py:95} INFO - [2019-09-12 14:32:03,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:03,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:03,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:03,641] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:03,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 14:32:03,712] {scheduler_job.py:146} INFO - Started process (PID=27760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:08,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:08,719] {logging_mixin.py:95} INFO - [2019-09-12 14:32:08,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:09,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:09,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:09,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:09,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:32:09,177] {scheduler_job.py:146} INFO - Started process (PID=27761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:14,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:14,184] {logging_mixin.py:95} INFO - [2019-09-12 14:32:14,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:14,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:14,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:14,566] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:14,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:32:14,644] {scheduler_job.py:146} INFO - Started process (PID=27762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:19,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:19,653] {logging_mixin.py:95} INFO - [2019-09-12 14:32:19,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:20,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:20,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:20,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:20,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:32:20,109] {scheduler_job.py:146} INFO - Started process (PID=27764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:25,115] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:25,116] {logging_mixin.py:95} INFO - [2019-09-12 14:32:25,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:25,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:25,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:25,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:25,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 14:32:25,560] {scheduler_job.py:146} INFO - Started process (PID=27768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:30,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:30,567] {logging_mixin.py:95} INFO - [2019-09-12 14:32:30,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:30,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:30,931] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:30,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:30,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 14:32:31,019] {scheduler_job.py:146} INFO - Started process (PID=27770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:36,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:36,038] {logging_mixin.py:95} INFO - [2019-09-12 14:32:36,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:36,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:36,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:36,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:36,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 14:32:36,478] {scheduler_job.py:146} INFO - Started process (PID=27774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:41,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:41,484] {logging_mixin.py:95} INFO - [2019-09-12 14:32:41,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:41,828] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:41,853] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:41,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:41,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 14:32:41,941] {scheduler_job.py:146} INFO - Started process (PID=27776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:46,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:46,950] {logging_mixin.py:95} INFO - [2019-09-12 14:32:46,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:47,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:47,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:47,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:47,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:32:47,403] {scheduler_job.py:146} INFO - Started process (PID=27778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:52,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:52,414] {logging_mixin.py:95} INFO - [2019-09-12 14:32:52,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:52,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:52,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:52,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:52,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:32:52,862] {scheduler_job.py:146} INFO - Started process (PID=27779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:57,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:32:57,871] {logging_mixin.py:95} INFO - [2019-09-12 14:32:57,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:58,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:32:58,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:32:58,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:32:58,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 14:32:58,324] {scheduler_job.py:146} INFO - Started process (PID=27783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:03,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:03,333] {logging_mixin.py:95} INFO - [2019-09-12 14:33:03,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:03,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:03,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:03,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:03,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:33:03,787] {scheduler_job.py:146} INFO - Started process (PID=27785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:08,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:08,793] {logging_mixin.py:95} INFO - [2019-09-12 14:33:08,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:09,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:09,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:09,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:09,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:33:09,248] {scheduler_job.py:146} INFO - Started process (PID=27786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:14,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:14,256] {logging_mixin.py:95} INFO - [2019-09-12 14:33:14,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:14,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:14,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:14,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:14,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:33:14,711] {scheduler_job.py:146} INFO - Started process (PID=27790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:19,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:19,717] {logging_mixin.py:95} INFO - [2019-09-12 14:33:19,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:20,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:20,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:20,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:20,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-12 14:33:20,172] {scheduler_job.py:146} INFO - Started process (PID=27792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:25,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:25,179] {logging_mixin.py:95} INFO - [2019-09-12 14:33:25,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:25,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:25,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:25,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:25,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:33:25,629] {scheduler_job.py:146} INFO - Started process (PID=27796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:30,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:30,639] {logging_mixin.py:95} INFO - [2019-09-12 14:33:30,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:30,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:31,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:31,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:31,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 14:33:31,088] {scheduler_job.py:146} INFO - Started process (PID=27798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:36,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:36,095] {logging_mixin.py:95} INFO - [2019-09-12 14:33:36,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:36,440] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:36,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:36,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:36,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:33:36,549] {scheduler_job.py:146} INFO - Started process (PID=27799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:41,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:41,557] {logging_mixin.py:95} INFO - [2019-09-12 14:33:41,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:41,901] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:41,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:41,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:41,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:33:42,011] {scheduler_job.py:146} INFO - Started process (PID=27801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:47,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:47,022] {logging_mixin.py:95} INFO - [2019-09-12 14:33:47,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:47,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:47,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:47,404] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:47,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:33:47,472] {scheduler_job.py:146} INFO - Started process (PID=27806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:52,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:52,482] {logging_mixin.py:95} INFO - [2019-09-12 14:33:52,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:52,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:52,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:52,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:52,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:33:52,934] {scheduler_job.py:146} INFO - Started process (PID=27807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:57,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:33:57,943] {logging_mixin.py:95} INFO - [2019-09-12 14:33:57,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:58,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:33:58,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:33:58,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:33:58,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:33:58,397] {scheduler_job.py:146} INFO - Started process (PID=27811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:03,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:03,405] {logging_mixin.py:95} INFO - [2019-09-12 14:34:03,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:03,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:03,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:03,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:03,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:34:03,860] {scheduler_job.py:146} INFO - Started process (PID=27813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:08,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:08,871] {logging_mixin.py:95} INFO - [2019-09-12 14:34:08,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:09,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:09,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:09,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:09,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:34:09,322] {scheduler_job.py:146} INFO - Started process (PID=27814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:14,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:14,331] {logging_mixin.py:95} INFO - [2019-09-12 14:34:14,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:14,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:14,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:14,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:14,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 14:34:14,783] {scheduler_job.py:146} INFO - Started process (PID=27816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:19,788] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:19,789] {logging_mixin.py:95} INFO - [2019-09-12 14:34:19,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:20,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:20,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:20,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:20,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 14:34:20,249] {scheduler_job.py:146} INFO - Started process (PID=27820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:25,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:25,255] {logging_mixin.py:95} INFO - [2019-09-12 14:34:25,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:25,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:25,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:25,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:25,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 14:34:25,729] {scheduler_job.py:146} INFO - Started process (PID=27825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:30,739] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:30,740] {logging_mixin.py:95} INFO - [2019-09-12 14:34:30,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:31,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:31,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:31,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:31,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 14:34:31,222] {scheduler_job.py:146} INFO - Started process (PID=27827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:36,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:36,241] {logging_mixin.py:95} INFO - [2019-09-12 14:34:36,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:36,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:36,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:36,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:36,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 14:34:36,712] {scheduler_job.py:146} INFO - Started process (PID=27828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:41,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:41,720] {logging_mixin.py:95} INFO - [2019-09-12 14:34:41,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:42,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:42,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:42,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:42,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:34:42,201] {scheduler_job.py:146} INFO - Started process (PID=27830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:47,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:47,215] {logging_mixin.py:95} INFO - [2019-09-12 14:34:47,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:47,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:47,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:47,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:47,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:34:47,692] {scheduler_job.py:146} INFO - Started process (PID=27835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:52,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:52,699] {logging_mixin.py:95} INFO - [2019-09-12 14:34:52,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:53,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:53,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:53,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:53,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 14:34:53,189] {scheduler_job.py:146} INFO - Started process (PID=27836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:58,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:34:58,198] {logging_mixin.py:95} INFO - [2019-09-12 14:34:58,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:58,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:34:58,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:34:58,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:34:58,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:34:58,682] {scheduler_job.py:146} INFO - Started process (PID=27837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:03,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:03,694] {logging_mixin.py:95} INFO - [2019-09-12 14:35:03,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:04,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:04,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:04,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:04,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:35:04,174] {scheduler_job.py:146} INFO - Started process (PID=27839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:09,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:09,187] {logging_mixin.py:95} INFO - [2019-09-12 14:35:09,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:09,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:09,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:09,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:09,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 14:35:09,664] {scheduler_job.py:146} INFO - Started process (PID=27843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:14,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:14,672] {logging_mixin.py:95} INFO - [2019-09-12 14:35:14,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:15,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:15,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:15,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:15,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:35:15,158] {scheduler_job.py:146} INFO - Started process (PID=27844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:20,164] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:20,165] {logging_mixin.py:95} INFO - [2019-09-12 14:35:20,165] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:20,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:20,535] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:20,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:20,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:35:20,656] {scheduler_job.py:146} INFO - Started process (PID=27846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:25,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:25,664] {logging_mixin.py:95} INFO - [2019-09-12 14:35:25,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:26,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:26,035] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:26,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:26,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:35:26,155] {scheduler_job.py:146} INFO - Started process (PID=27850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:31,164] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:31,165] {logging_mixin.py:95} INFO - [2019-09-12 14:35:31,165] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:31,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:31,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:31,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:31,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 14:35:31,634] {scheduler_job.py:146} INFO - Started process (PID=27852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:36,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:36,662] {logging_mixin.py:95} INFO - [2019-09-12 14:35:36,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:37,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:37,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:37,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:37,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 14:35:37,124] {scheduler_job.py:146} INFO - Started process (PID=27853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:42,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:42,134] {logging_mixin.py:95} INFO - [2019-09-12 14:35:42,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:42,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:42,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:42,512] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:42,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:35:42,617] {scheduler_job.py:146} INFO - Started process (PID=27855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:47,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:47,624] {logging_mixin.py:95} INFO - [2019-09-12 14:35:47,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:47,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:48,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:48,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:48,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 14:35:48,108] {scheduler_job.py:146} INFO - Started process (PID=27860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:53,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:53,115] {logging_mixin.py:95} INFO - [2019-09-12 14:35:53,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:53,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:53,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:53,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:53,498] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:35:53,606] {scheduler_job.py:146} INFO - Started process (PID=27861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:58,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:35:58,619] {logging_mixin.py:95} INFO - [2019-09-12 14:35:58,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:58,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:35:58,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:35:58,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:35:59,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:35:59,098] {scheduler_job.py:146} INFO - Started process (PID=27862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:04,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:04,111] {logging_mixin.py:95} INFO - [2019-09-12 14:36:04,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:04,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:04,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:04,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:04,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 14:36:04,591] {scheduler_job.py:146} INFO - Started process (PID=27864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:09,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:09,598] {logging_mixin.py:95} INFO - [2019-09-12 14:36:09,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:09,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:09,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:09,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:09,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:36:10,085] {scheduler_job.py:146} INFO - Started process (PID=27868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:15,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:15,093] {logging_mixin.py:95} INFO - [2019-09-12 14:36:15,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:15,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:15,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:15,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:15,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:36:15,578] {scheduler_job.py:146} INFO - Started process (PID=27869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:20,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:20,585] {logging_mixin.py:95} INFO - [2019-09-12 14:36:20,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:20,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:20,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:20,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:20,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:36:21,078] {scheduler_job.py:146} INFO - Started process (PID=27871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:26,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:26,094] {logging_mixin.py:95} INFO - [2019-09-12 14:36:26,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:26,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:26,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:26,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:26,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 14:36:26,571] {scheduler_job.py:146} INFO - Started process (PID=27875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:31,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:31,581] {logging_mixin.py:95} INFO - [2019-09-12 14:36:31,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:31,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:31,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:31,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:31,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:36:32,061] {scheduler_job.py:146} INFO - Started process (PID=27877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:37,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:37,077] {logging_mixin.py:95} INFO - [2019-09-12 14:36:37,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:37,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:37,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:37,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:37,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 14:36:37,558] {scheduler_job.py:146} INFO - Started process (PID=27878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:42,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:42,564] {logging_mixin.py:95} INFO - [2019-09-12 14:36:42,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:42,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:42,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:42,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:42,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:36:43,055] {scheduler_job.py:146} INFO - Started process (PID=27880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:48,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:48,069] {logging_mixin.py:95} INFO - [2019-09-12 14:36:48,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:48,417] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:48,440] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:48,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:48,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 14:36:48,554] {scheduler_job.py:146} INFO - Started process (PID=27885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:53,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:53,564] {logging_mixin.py:95} INFO - [2019-09-12 14:36:53,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:53,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:53,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:53,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:53,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:36:54,057] {scheduler_job.py:146} INFO - Started process (PID=27886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:59,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:36:59,064] {logging_mixin.py:95} INFO - [2019-09-12 14:36:59,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:59,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:36:59,436] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:36:59,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:36:59,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:36:59,558] {scheduler_job.py:146} INFO - Started process (PID=27887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:04,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:04,583] {logging_mixin.py:95} INFO - [2019-09-12 14:37:04,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:04,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:04,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:04,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:04,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 14:37:05,057] {scheduler_job.py:146} INFO - Started process (PID=27889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:10,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:10,064] {logging_mixin.py:95} INFO - [2019-09-12 14:37:10,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:10,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:10,435] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:10,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:10,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:37:10,555] {scheduler_job.py:146} INFO - Started process (PID=27893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:15,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:15,567] {logging_mixin.py:95} INFO - [2019-09-12 14:37:15,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:15,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:15,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:15,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:15,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:37:16,050] {scheduler_job.py:146} INFO - Started process (PID=27894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:21,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:21,063] {logging_mixin.py:95} INFO - [2019-09-12 14:37:21,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:21,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:21,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:21,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:21,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 14:37:21,540] {scheduler_job.py:146} INFO - Started process (PID=27896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:26,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:26,547] {logging_mixin.py:95} INFO - [2019-09-12 14:37:26,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:26,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:26,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:26,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:26,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:37:27,028] {scheduler_job.py:146} INFO - Started process (PID=27900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:32,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:32,034] {logging_mixin.py:95} INFO - [2019-09-12 14:37:32,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:32,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:32,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:32,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:32,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-12 14:37:32,428] {scheduler_job.py:146} INFO - Started process (PID=27902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:37,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:37,451] {logging_mixin.py:95} INFO - [2019-09-12 14:37:37,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:37,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:37,823] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:37,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:37,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 14:37:37,921] {scheduler_job.py:146} INFO - Started process (PID=27903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:42,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:42,930] {logging_mixin.py:95} INFO - [2019-09-12 14:37:42,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:43,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:43,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:43,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:43,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:37:43,421] {scheduler_job.py:146} INFO - Started process (PID=27905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:48,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:48,427] {logging_mixin.py:95} INFO - [2019-09-12 14:37:48,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:48,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:48,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:48,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:48,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:37:48,916] {scheduler_job.py:146} INFO - Started process (PID=27910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:53,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:53,925] {logging_mixin.py:95} INFO - [2019-09-12 14:37:53,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:54,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:54,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:54,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:54,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 14:37:54,405] {scheduler_job.py:146} INFO - Started process (PID=27911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:59,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:37:59,418] {logging_mixin.py:95} INFO - [2019-09-12 14:37:59,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:59,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:37:59,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:37:59,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:37:59,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 14:37:59,909] {scheduler_job.py:146} INFO - Started process (PID=27912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:04,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:04,920] {logging_mixin.py:95} INFO - [2019-09-12 14:38:04,919] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:05,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:05,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:05,303] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:05,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:38:05,408] {scheduler_job.py:146} INFO - Started process (PID=27914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:10,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:10,424] {logging_mixin.py:95} INFO - [2019-09-12 14:38:10,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:10,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:10,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:10,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:10,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 14:38:10,899] {scheduler_job.py:146} INFO - Started process (PID=27918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:15,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:15,908] {logging_mixin.py:95} INFO - [2019-09-12 14:38:15,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:16,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:16,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:16,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:16,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 14:38:16,392] {scheduler_job.py:146} INFO - Started process (PID=27920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:21,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:21,408] {logging_mixin.py:95} INFO - [2019-09-12 14:38:21,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:21,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:21,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:21,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:21,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 14:38:21,894] {scheduler_job.py:146} INFO - Started process (PID=27921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:26,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:26,905] {logging_mixin.py:95} INFO - [2019-09-12 14:38:26,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:27,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:27,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:27,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:27,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 14:38:27,383] {scheduler_job.py:146} INFO - Started process (PID=27925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:32,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:32,395] {logging_mixin.py:95} INFO - [2019-09-12 14:38:32,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:32,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:32,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:32,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:32,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:38:32,885] {scheduler_job.py:146} INFO - Started process (PID=27927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:37,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:37,896] {logging_mixin.py:95} INFO - [2019-09-12 14:38:37,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:38,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:38,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:38,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:38,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:38:38,373] {scheduler_job.py:146} INFO - Started process (PID=27928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:43,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:43,382] {logging_mixin.py:95} INFO - [2019-09-12 14:38:43,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:43,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:43,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:43,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:43,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:38:43,873] {scheduler_job.py:146} INFO - Started process (PID=27930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:48,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:48,885] {logging_mixin.py:95} INFO - [2019-09-12 14:38:48,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:49,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:49,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:49,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:49,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 14:38:49,366] {scheduler_job.py:146} INFO - Started process (PID=27935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:54,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:54,376] {logging_mixin.py:95} INFO - [2019-09-12 14:38:54,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:54,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:54,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:38:54,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:38:54,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 14:38:54,870] {scheduler_job.py:146} INFO - Started process (PID=27936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:38:59,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:38:59,879] {logging_mixin.py:95} INFO - [2019-09-12 14:38:59,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:00,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:00,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:00,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:00,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 14:39:00,364] {scheduler_job.py:146} INFO - Started process (PID=27937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:05,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:05,383] {logging_mixin.py:95} INFO - [2019-09-12 14:39:05,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:05,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:05,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:05,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:05,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 14:39:05,870] {scheduler_job.py:146} INFO - Started process (PID=27939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:10,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:10,879] {logging_mixin.py:95} INFO - [2019-09-12 14:39:10,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:11,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:11,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:11,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:11,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 14:39:11,358] {scheduler_job.py:146} INFO - Started process (PID=27943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:16,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:16,370] {logging_mixin.py:95} INFO - [2019-09-12 14:39:16,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:16,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:16,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:16,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:16,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:39:16,855] {scheduler_job.py:146} INFO - Started process (PID=27946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:21,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:21,866] {logging_mixin.py:95} INFO - [2019-09-12 14:39:21,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:22,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:22,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:22,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:22,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 14:39:22,355] {scheduler_job.py:146} INFO - Started process (PID=27947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:27,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:27,365] {logging_mixin.py:95} INFO - [2019-09-12 14:39:27,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:27,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:27,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:27,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:27,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:39:27,840] {scheduler_job.py:146} INFO - Started process (PID=27951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:32,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:32,854] {logging_mixin.py:95} INFO - [2019-09-12 14:39:32,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:33,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:33,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:33,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:33,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:39:33,339] {scheduler_job.py:146} INFO - Started process (PID=27953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:38,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:38,350] {logging_mixin.py:95} INFO - [2019-09-12 14:39:38,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:38,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:38,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:38,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:38,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 14:39:38,826] {scheduler_job.py:146} INFO - Started process (PID=27957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:43,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:43,834] {logging_mixin.py:95} INFO - [2019-09-12 14:39:43,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:44,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:44,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:44,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:44,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 14:39:44,324] {scheduler_job.py:146} INFO - Started process (PID=27959) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:49,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:49,330] {logging_mixin.py:95} INFO - [2019-09-12 14:39:49,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:49,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:49,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:49,713] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:49,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 14:39:49,822] {scheduler_job.py:146} INFO - Started process (PID=27961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:54,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:39:54,836] {logging_mixin.py:95} INFO - [2019-09-12 14:39:54,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:55,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:39:55,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:39:55,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:39:55,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 14:39:55,316] {scheduler_job.py:146} INFO - Started process (PID=27962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:00,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:00,326] {logging_mixin.py:95} INFO - [2019-09-12 14:40:00,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:00,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:00,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:00,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:00,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 14:40:00,805] {scheduler_job.py:146} INFO - Started process (PID=27966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:05,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:05,812] {logging_mixin.py:95} INFO - [2019-09-12 14:40:05,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:06,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:06,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:06,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:06,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 14:40:06,304] {scheduler_job.py:146} INFO - Started process (PID=27968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:11,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:11,317] {logging_mixin.py:95} INFO - [2019-09-12 14:40:11,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:11,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:11,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:11,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:11,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:40:11,804] {scheduler_job.py:146} INFO - Started process (PID=27972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:16,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:16,809] {logging_mixin.py:95} INFO - [2019-09-12 14:40:16,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:17,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:17,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:17,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:17,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 14:40:17,306] {scheduler_job.py:146} INFO - Started process (PID=27974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:22,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:22,319] {logging_mixin.py:95} INFO - [2019-09-12 14:40:22,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:22,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:22,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:22,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:22,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 14:40:22,805] {scheduler_job.py:146} INFO - Started process (PID=27975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:27,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:27,811] {logging_mixin.py:95} INFO - [2019-09-12 14:40:27,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:28,155] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:28,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:28,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:28,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 14:40:28,306] {scheduler_job.py:146} INFO - Started process (PID=27976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:33,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 14:40:33,313] {logging_mixin.py:95} INFO - [2019-09-12 14:40:33,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:33,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 14:40:33,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 14:40:33,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 14:40:33,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 14:40:33,798] {scheduler_job.py:146} INFO - Started process (PID=27981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:30,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:30,483] {logging_mixin.py:95} INFO - [2019-09-12 15:25:30,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:30,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:30,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:30,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:30,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2697.163 seconds
[2019-09-12 15:25:31,033] {scheduler_job.py:146} INFO - Started process (PID=27986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:36,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:36,600] {logging_mixin.py:95} INFO - [2019-09-12 15:25:36,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:36,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:36,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:36,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:36,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.943 seconds
[2019-09-12 15:25:37,031] {scheduler_job.py:146} INFO - Started process (PID=27991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:42,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:42,039] {logging_mixin.py:95} INFO - [2019-09-12 15:25:42,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:42,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:42,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:42,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:42,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:25:42,479] {scheduler_job.py:146} INFO - Started process (PID=27993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:47,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:47,485] {logging_mixin.py:95} INFO - [2019-09-12 15:25:47,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:47,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:47,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:47,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:47,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:25:47,930] {scheduler_job.py:146} INFO - Started process (PID=28000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:52,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:52,940] {logging_mixin.py:95} INFO - [2019-09-12 15:25:52,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:53,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:53,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:53,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:53,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:25:53,379] {scheduler_job.py:146} INFO - Started process (PID=28001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:58,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:25:58,395] {logging_mixin.py:95} INFO - [2019-09-12 15:25:58,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:58,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:25:58,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:25:58,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:25:58,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:25:58,834] {scheduler_job.py:146} INFO - Started process (PID=28003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:03,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:03,842] {logging_mixin.py:95} INFO - [2019-09-12 15:26:03,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:04,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:04,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:04,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:04,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 15:26:04,291] {scheduler_job.py:146} INFO - Started process (PID=28009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:09,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:09,299] {logging_mixin.py:95} INFO - [2019-09-12 15:26:09,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:09,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:09,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:09,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:09,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:26:09,734] {scheduler_job.py:146} INFO - Started process (PID=28011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:14,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:14,741] {logging_mixin.py:95} INFO - [2019-09-12 15:26:14,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:15,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:15,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:15,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:15,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:26:15,175] {scheduler_job.py:146} INFO - Started process (PID=28016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:20,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:20,184] {logging_mixin.py:95} INFO - [2019-09-12 15:26:20,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:20,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:20,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:20,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:20,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 15:26:20,619] {scheduler_job.py:146} INFO - Started process (PID=28020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:25,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:25,627] {logging_mixin.py:95} INFO - [2019-09-12 15:26:25,626] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:25,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:26,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:26,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:26,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:26:26,063] {scheduler_job.py:146} INFO - Started process (PID=28023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:31,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:31,072] {logging_mixin.py:95} INFO - [2019-09-12 15:26:31,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:31,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:31,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:31,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:31,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:26:31,512] {scheduler_job.py:146} INFO - Started process (PID=28027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:36,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:36,518] {logging_mixin.py:95} INFO - [2019-09-12 15:26:36,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:36,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:36,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:36,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:36,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:26:36,960] {scheduler_job.py:146} INFO - Started process (PID=28029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:41,968] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:41,969] {logging_mixin.py:95} INFO - [2019-09-12 15:26:41,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:42,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:42,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:42,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:42,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:26:42,409] {scheduler_job.py:146} INFO - Started process (PID=28031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:47,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:47,416] {logging_mixin.py:95} INFO - [2019-09-12 15:26:47,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:47,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:47,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:47,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:47,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 15:26:47,954] {scheduler_job.py:146} INFO - Started process (PID=28036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:52,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:52,960] {logging_mixin.py:95} INFO - [2019-09-12 15:26:52,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:53,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:53,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:53,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:53,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:26:53,389] {scheduler_job.py:146} INFO - Started process (PID=28037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:58,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:26:58,395] {logging_mixin.py:95} INFO - [2019-09-12 15:26:58,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:58,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:26:58,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:26:58,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:26:58,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:26:58,834] {scheduler_job.py:146} INFO - Started process (PID=28039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:03,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:03,844] {logging_mixin.py:95} INFO - [2019-09-12 15:27:03,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:04,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:04,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:04,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:04,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:27:04,280] {scheduler_job.py:146} INFO - Started process (PID=28040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:09,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:09,287] {logging_mixin.py:95} INFO - [2019-09-12 15:27:09,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:09,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:09,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:09,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:09,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-12 15:27:09,729] {scheduler_job.py:146} INFO - Started process (PID=28045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:14,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:14,735] {logging_mixin.py:95} INFO - [2019-09-12 15:27:14,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:15,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:15,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:15,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:15,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 15:27:15,179] {scheduler_job.py:146} INFO - Started process (PID=28046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:20,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:20,185] {logging_mixin.py:95} INFO - [2019-09-12 15:27:20,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:20,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:20,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:20,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:20,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 15:27:20,633] {scheduler_job.py:146} INFO - Started process (PID=28047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:25,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:25,642] {logging_mixin.py:95} INFO - [2019-09-12 15:27:25,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:25,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:26,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:26,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:26,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:27:26,084] {scheduler_job.py:146} INFO - Started process (PID=28049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:31,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:31,093] {logging_mixin.py:95} INFO - [2019-09-12 15:27:31,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:31,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:31,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:31,471] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:31,476] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:27:31,528] {scheduler_job.py:146} INFO - Started process (PID=28053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:36,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:36,534] {logging_mixin.py:95} INFO - [2019-09-12 15:27:36,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:36,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:36,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:36,904] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:36,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-12 15:27:36,988] {scheduler_job.py:146} INFO - Started process (PID=28055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:41,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:41,994] {logging_mixin.py:95} INFO - [2019-09-12 15:27:41,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:42,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:42,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:42,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:42,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.541 seconds
[2019-09-12 15:27:42,642] {scheduler_job.py:146} INFO - Started process (PID=28066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:47,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:47,651] {logging_mixin.py:95} INFO - [2019-09-12 15:27:47,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:48,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:48,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:48,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:48,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-12 15:27:48,186] {scheduler_job.py:146} INFO - Started process (PID=28067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:53,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:53,193] {logging_mixin.py:95} INFO - [2019-09-12 15:27:53,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:53,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:53,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:53,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:53,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-12 15:27:53,729] {scheduler_job.py:146} INFO - Started process (PID=28072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:58,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:27:58,739] {logging_mixin.py:95} INFO - [2019-09-12 15:27:58,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:59,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:27:59,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:27:59,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:27:59,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:27:59,172] {scheduler_job.py:146} INFO - Started process (PID=28079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:04,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:04,178] {logging_mixin.py:95} INFO - [2019-09-12 15:28:04,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:04,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:04,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:04,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:04,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 15:28:04,617] {scheduler_job.py:146} INFO - Started process (PID=28080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:09,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:09,625] {logging_mixin.py:95} INFO - [2019-09-12 15:28:09,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:09,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:09,992] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:10,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:10,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:28:10,071] {scheduler_job.py:146} INFO - Started process (PID=28082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:15,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:15,077] {logging_mixin.py:95} INFO - [2019-09-12 15:28:15,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:15,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:15,457] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:15,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:15,473] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:28:15,517] {scheduler_job.py:146} INFO - Started process (PID=28086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:20,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:20,523] {logging_mixin.py:95} INFO - [2019-09-12 15:28:20,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:20,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:20,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:20,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:20,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-12 15:28:20,966] {scheduler_job.py:146} INFO - Started process (PID=28087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:25,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:25,972] {logging_mixin.py:95} INFO - [2019-09-12 15:28:25,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:26,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:26,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:26,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:26,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 15:28:26,521] {scheduler_job.py:146} INFO - Started process (PID=28089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:31,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:31,526] {logging_mixin.py:95} INFO - [2019-09-12 15:28:31,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:31,914] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:31,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:31,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:31,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-12 15:28:32,069] {scheduler_job.py:146} INFO - Started process (PID=28093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:37,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:37,077] {logging_mixin.py:95} INFO - [2019-09-12 15:28:37,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:37,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:37,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:37,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:37,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:28:37,510] {scheduler_job.py:146} INFO - Started process (PID=28095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:42,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:42,520] {logging_mixin.py:95} INFO - [2019-09-12 15:28:42,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:42,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:42,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:42,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:42,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 15:28:42,958] {scheduler_job.py:146} INFO - Started process (PID=28100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:47,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:47,963] {logging_mixin.py:95} INFO - [2019-09-12 15:28:47,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:48,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:48,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:48,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:48,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:28:48,413] {scheduler_job.py:146} INFO - Started process (PID=28110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:53,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:53,425] {logging_mixin.py:95} INFO - [2019-09-12 15:28:53,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:53,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:53,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:53,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:53,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:28:53,873] {scheduler_job.py:146} INFO - Started process (PID=28115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:58,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:28:58,880] {logging_mixin.py:95} INFO - [2019-09-12 15:28:58,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:59,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:28:59,328] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:28:59,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:28:59,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-12 15:28:59,414] {scheduler_job.py:146} INFO - Started process (PID=28126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:04,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:04,423] {logging_mixin.py:95} INFO - [2019-09-12 15:29:04,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:04,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:04,823] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:04,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:04,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:29:04,860] {scheduler_job.py:146} INFO - Started process (PID=28128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:09,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:09,866] {logging_mixin.py:95} INFO - [2019-09-12 15:29:09,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:10,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:10,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:10,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:10,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-12 15:29:10,307] {scheduler_job.py:146} INFO - Started process (PID=28131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:15,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:15,317] {logging_mixin.py:95} INFO - [2019-09-12 15:29:15,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:15,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:15,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:15,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:15,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:29:15,770] {scheduler_job.py:146} INFO - Started process (PID=28133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:20,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:20,784] {logging_mixin.py:95} INFO - [2019-09-12 15:29:20,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:21,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:21,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:21,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:21,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-12 15:29:21,329] {scheduler_job.py:146} INFO - Started process (PID=28138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:26,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:26,345] {logging_mixin.py:95} INFO - [2019-09-12 15:29:26,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:26,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:26,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:26,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:26,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-12 15:29:26,876] {scheduler_job.py:146} INFO - Started process (PID=28140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:31,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:31,885] {logging_mixin.py:95} INFO - [2019-09-12 15:29:31,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:32,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:32,293] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:32,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:32,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 15:29:32,334] {scheduler_job.py:146} INFO - Started process (PID=28144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:37,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:37,343] {logging_mixin.py:95} INFO - [2019-09-12 15:29:37,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:37,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:37,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:37,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:37,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 15:29:37,882] {scheduler_job.py:146} INFO - Started process (PID=28146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:42,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:42,891] {logging_mixin.py:95} INFO - [2019-09-12 15:29:42,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:43,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:43,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:43,285] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:43,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:29:43,329] {scheduler_job.py:146} INFO - Started process (PID=28148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:48,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:48,335] {logging_mixin.py:95} INFO - [2019-09-12 15:29:48,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:48,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:48,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:48,754] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:48,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-12 15:29:48,783] {scheduler_job.py:146} INFO - Started process (PID=28149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:53,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:53,793] {logging_mixin.py:95} INFO - [2019-09-12 15:29:53,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:54,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:54,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:54,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:54,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 15:29:54,331] {scheduler_job.py:146} INFO - Started process (PID=28156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:59,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:29:59,341] {logging_mixin.py:95} INFO - [2019-09-12 15:29:59,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:59,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:29:59,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:29:59,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:29:59,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:29:59,785] {scheduler_job.py:146} INFO - Started process (PID=28157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:04,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:04,791] {logging_mixin.py:95} INFO - [2019-09-12 15:30:04,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:05,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:05,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:05,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:05,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 15:30:05,233] {scheduler_job.py:146} INFO - Started process (PID=28162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:10,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:10,239] {logging_mixin.py:95} INFO - [2019-09-12 15:30:10,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:10,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:10,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:10,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:10,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:30:10,684] {scheduler_job.py:146} INFO - Started process (PID=28164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:15,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:15,693] {logging_mixin.py:95} INFO - [2019-09-12 15:30:15,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:16,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:16,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:16,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:16,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:30:16,142] {scheduler_job.py:146} INFO - Started process (PID=28165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:21,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:21,150] {logging_mixin.py:95} INFO - [2019-09-12 15:30:21,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:21,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:21,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:21,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:21,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:30:21,585] {scheduler_job.py:146} INFO - Started process (PID=28174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:26,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:26,599] {logging_mixin.py:95} INFO - [2019-09-12 15:30:26,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:26,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:26,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:26,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:26,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:30:27,034] {scheduler_job.py:146} INFO - Started process (PID=28178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:32,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:32,042] {logging_mixin.py:95} INFO - [2019-09-12 15:30:32,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:32,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:32,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:32,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:32,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:30:32,488] {scheduler_job.py:146} INFO - Started process (PID=28182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:37,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:37,499] {logging_mixin.py:95} INFO - [2019-09-12 15:30:37,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:37,863] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:37,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:37,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:37,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 15:30:37,943] {scheduler_job.py:146} INFO - Started process (PID=28185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:42,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:42,950] {logging_mixin.py:95} INFO - [2019-09-12 15:30:42,949] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:43,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:43,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:43,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:43,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:30:43,398] {scheduler_job.py:146} INFO - Started process (PID=28187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:48,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:48,404] {logging_mixin.py:95} INFO - [2019-09-12 15:30:48,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:48,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:48,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:48,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:48,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:30:48,851] {scheduler_job.py:146} INFO - Started process (PID=28188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:53,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:53,860] {logging_mixin.py:95} INFO - [2019-09-12 15:30:53,860] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:54,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:54,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:54,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:54,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 15:30:54,398] {scheduler_job.py:146} INFO - Started process (PID=28194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:59,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:30:59,404] {logging_mixin.py:95} INFO - [2019-09-12 15:30:59,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:59,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:30:59,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:30:59,785] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:30:59,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:30:59,860] {scheduler_job.py:146} INFO - Started process (PID=28195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:04,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:04,867] {logging_mixin.py:95} INFO - [2019-09-12 15:31:04,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:05,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:05,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:05,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:05,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 15:31:05,410] {scheduler_job.py:146} INFO - Started process (PID=28199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:10,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:10,422] {logging_mixin.py:95} INFO - [2019-09-12 15:31:10,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:10,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:10,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:10,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:10,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 15:31:10,960] {scheduler_job.py:146} INFO - Started process (PID=28201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:15,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:15,968] {logging_mixin.py:95} INFO - [2019-09-12 15:31:15,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:16,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:16,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:16,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:16,370] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:31:16,404] {scheduler_job.py:146} INFO - Started process (PID=28202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:21,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:21,411] {logging_mixin.py:95} INFO - [2019-09-12 15:31:21,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:21,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:21,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:21,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:21,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:31:21,860] {scheduler_job.py:146} INFO - Started process (PID=28206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:26,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:26,878] {logging_mixin.py:95} INFO - [2019-09-12 15:31:26,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:27,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:27,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:27,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:27,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-09-12 15:31:27,412] {scheduler_job.py:146} INFO - Started process (PID=28209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:32,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:32,421] {logging_mixin.py:95} INFO - [2019-09-12 15:31:32,420] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:32,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:32,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:32,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:32,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:31:32,871] {scheduler_job.py:146} INFO - Started process (PID=28210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:37,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:37,889] {logging_mixin.py:95} INFO - [2019-09-12 15:31:37,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:38,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:38,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:38,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:38,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:31:38,332] {scheduler_job.py:146} INFO - Started process (PID=28215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:43,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:43,340] {logging_mixin.py:95} INFO - [2019-09-12 15:31:43,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:43,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:43,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:43,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:43,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:31:43,787] {scheduler_job.py:146} INFO - Started process (PID=28217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:48,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:48,794] {logging_mixin.py:95} INFO - [2019-09-12 15:31:48,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:49,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:49,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:49,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:49,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:31:49,240] {scheduler_job.py:146} INFO - Started process (PID=28218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:54,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:54,248] {logging_mixin.py:95} INFO - [2019-09-12 15:31:54,248] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:54,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:54,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:31:54,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:31:54,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:31:54,700] {scheduler_job.py:146} INFO - Started process (PID=28220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:31:59,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:31:59,711] {logging_mixin.py:95} INFO - [2019-09-12 15:31:59,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:00,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:00,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:00,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:00,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:32:00,158] {scheduler_job.py:146} INFO - Started process (PID=28224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:05,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:05,166] {logging_mixin.py:95} INFO - [2019-09-12 15:32:05,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:05,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:05,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:05,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:05,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 15:32:05,713] {scheduler_job.py:146} INFO - Started process (PID=28226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:10,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:10,720] {logging_mixin.py:95} INFO - [2019-09-12 15:32:10,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:11,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:11,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:11,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:11,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:32:11,169] {scheduler_job.py:146} INFO - Started process (PID=28231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:16,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:16,178] {logging_mixin.py:95} INFO - [2019-09-12 15:32:16,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:16,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:16,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:16,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:16,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 15:32:16,627] {scheduler_job.py:146} INFO - Started process (PID=28232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:21,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:21,634] {logging_mixin.py:95} INFO - [2019-09-12 15:32:21,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:21,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:22,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:22,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:22,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:32:22,079] {scheduler_job.py:146} INFO - Started process (PID=28233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:27,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:27,089] {logging_mixin.py:95} INFO - [2019-09-12 15:32:27,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:27,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:27,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:27,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:27,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 15:32:27,535] {scheduler_job.py:146} INFO - Started process (PID=28239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:32,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:32,543] {logging_mixin.py:95} INFO - [2019-09-12 15:32:32,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:32,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:32,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:32,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:32,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:32:32,991] {scheduler_job.py:146} INFO - Started process (PID=28241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:37,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:38,005] {logging_mixin.py:95} INFO - [2019-09-12 15:32:38,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:38,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:38,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:38,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:38,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:32:38,451] {scheduler_job.py:146} INFO - Started process (PID=28245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:43,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:43,463] {logging_mixin.py:95} INFO - [2019-09-12 15:32:43,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:43,803] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:43,825] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:43,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:43,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 15:32:43,909] {scheduler_job.py:146} INFO - Started process (PID=28250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:48,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:48,917] {logging_mixin.py:95} INFO - [2019-09-12 15:32:48,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:49,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:49,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:49,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:49,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:32:49,365] {scheduler_job.py:146} INFO - Started process (PID=28251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:54,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:54,372] {logging_mixin.py:95} INFO - [2019-09-12 15:32:54,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:54,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:54,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:32:54,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:32:54,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 15:32:54,817] {scheduler_job.py:146} INFO - Started process (PID=28253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:32:59,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:32:59,825] {logging_mixin.py:95} INFO - [2019-09-12 15:32:59,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:00,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:00,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:00,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:00,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 15:33:00,364] {scheduler_job.py:146} INFO - Started process (PID=28257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:05,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:05,373] {logging_mixin.py:95} INFO - [2019-09-12 15:33:05,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:05,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:05,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:05,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:05,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.520 seconds
[2019-09-12 15:33:05,908] {scheduler_job.py:146} INFO - Started process (PID=28262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:10,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:10,915] {logging_mixin.py:95} INFO - [2019-09-12 15:33:10,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:11,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:11,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:11,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:11,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-12 15:33:11,460] {scheduler_job.py:146} INFO - Started process (PID=28264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:16,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:16,467] {logging_mixin.py:95} INFO - [2019-09-12 15:33:16,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:16,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:16,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:16,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:16,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:33:16,911] {scheduler_job.py:146} INFO - Started process (PID=28268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:21,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:21,921] {logging_mixin.py:95} INFO - [2019-09-12 15:33:21,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:22,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:22,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:22,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:22,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:33:22,364] {scheduler_job.py:146} INFO - Started process (PID=28269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:27,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:27,371] {logging_mixin.py:95} INFO - [2019-09-12 15:33:27,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:27,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:27,754] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:27,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:27,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:33:27,811] {scheduler_job.py:146} INFO - Started process (PID=28274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:32,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:32,822] {logging_mixin.py:95} INFO - [2019-09-12 15:33:32,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:33,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:33,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:33,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:33,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:33:33,268] {scheduler_job.py:146} INFO - Started process (PID=28275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:38,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:38,273] {logging_mixin.py:95} INFO - [2019-09-12 15:33:38,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:38,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:38,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:38,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:38,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-12 15:33:38,816] {scheduler_job.py:146} INFO - Started process (PID=28284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:43,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:43,823] {logging_mixin.py:95} INFO - [2019-09-12 15:33:43,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:44,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:44,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:44,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:44,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 15:33:44,280] {scheduler_job.py:146} INFO - Started process (PID=28287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:49,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:49,288] {logging_mixin.py:95} INFO - [2019-09-12 15:33:49,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:49,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:49,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:49,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:49,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 15:33:49,720] {scheduler_job.py:146} INFO - Started process (PID=28288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:54,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:33:54,730] {logging_mixin.py:95} INFO - [2019-09-12 15:33:54,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:55,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:33:55,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:33:55,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:33:55,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:33:55,172] {scheduler_job.py:146} INFO - Started process (PID=28293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:00,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:00,180] {logging_mixin.py:95} INFO - [2019-09-12 15:34:00,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:00,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:00,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:00,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:00,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:34:00,627] {scheduler_job.py:146} INFO - Started process (PID=28295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:05,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:05,634] {logging_mixin.py:95} INFO - [2019-09-12 15:34:05,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:06,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:06,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:06,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:06,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 15:34:06,083] {scheduler_job.py:146} INFO - Started process (PID=28299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:11,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:11,090] {logging_mixin.py:95} INFO - [2019-09-12 15:34:11,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:11,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:11,459] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:11,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:11,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:34:11,535] {scheduler_job.py:146} INFO - Started process (PID=28302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:16,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:16,545] {logging_mixin.py:95} INFO - [2019-09-12 15:34:16,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:16,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:16,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:16,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:17,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-12 15:34:17,080] {scheduler_job.py:146} INFO - Started process (PID=28304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:22,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:22,086] {logging_mixin.py:95} INFO - [2019-09-12 15:34:22,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:22,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:22,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:22,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:22,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-12 15:34:22,624] {scheduler_job.py:146} INFO - Started process (PID=28308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:27,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:27,642] {logging_mixin.py:95} INFO - [2019-09-12 15:34:27,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:28,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:28,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:28,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:28,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 15:34:28,068] {scheduler_job.py:146} INFO - Started process (PID=28310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:33,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:33,075] {logging_mixin.py:95} INFO - [2019-09-12 15:34:33,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:33,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:33,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:33,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:33,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:34:33,519] {scheduler_job.py:146} INFO - Started process (PID=28311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:38,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:38,534] {logging_mixin.py:95} INFO - [2019-09-12 15:34:38,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:38,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:38,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:38,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:39,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-12 15:34:39,066] {scheduler_job.py:146} INFO - Started process (PID=28318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:44,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:44,074] {logging_mixin.py:95} INFO - [2019-09-12 15:34:44,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:44,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:44,454] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:44,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:44,470] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:34:44,504] {scheduler_job.py:146} INFO - Started process (PID=28319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:49,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:49,513] {logging_mixin.py:95} INFO - [2019-09-12 15:34:49,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:49,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:49,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:49,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:49,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:34:49,955] {scheduler_job.py:146} INFO - Started process (PID=28320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:54,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:34:54,964] {logging_mixin.py:95} INFO - [2019-09-12 15:34:54,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:55,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:34:55,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:34:55,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:34:55,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:34:55,402] {scheduler_job.py:146} INFO - Started process (PID=28325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:00,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:00,409] {logging_mixin.py:95} INFO - [2019-09-12 15:35:00,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:00,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:00,794] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:00,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:00,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:35:00,860] {scheduler_job.py:146} INFO - Started process (PID=28326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:05,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:05,869] {logging_mixin.py:95} INFO - [2019-09-12 15:35:05,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:06,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:06,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:06,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:06,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.586 seconds
[2019-09-12 15:35:06,504] {scheduler_job.py:146} INFO - Started process (PID=28332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:11,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:11,513] {logging_mixin.py:95} INFO - [2019-09-12 15:35:11,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:11,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:11,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:11,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:11,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 15:35:12,051] {scheduler_job.py:146} INFO - Started process (PID=28336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:17,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:17,063] {logging_mixin.py:95} INFO - [2019-09-12 15:35:17,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:17,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:17,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:17,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:17,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-12 15:35:17,595] {scheduler_job.py:146} INFO - Started process (PID=28338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:22,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:22,604] {logging_mixin.py:95} INFO - [2019-09-12 15:35:22,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:23,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:23,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:23,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:23,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-12 15:35:23,139] {scheduler_job.py:146} INFO - Started process (PID=28339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:28,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:28,146] {logging_mixin.py:95} INFO - [2019-09-12 15:35:28,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:28,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:28,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:28,535] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:28,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:35:28,585] {scheduler_job.py:146} INFO - Started process (PID=28344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:33,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:33,593] {logging_mixin.py:95} INFO - [2019-09-12 15:35:33,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:33,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:33,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:33,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:33,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:35:34,045] {scheduler_job.py:146} INFO - Started process (PID=28345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:39,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:39,052] {logging_mixin.py:95} INFO - [2019-09-12 15:35:39,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:39,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:39,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:39,481] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:39,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 15:35:39,597] {scheduler_job.py:146} INFO - Started process (PID=28352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:44,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:44,604] {logging_mixin.py:95} INFO - [2019-09-12 15:35:44,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:44,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:45,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:45,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:45,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:35:45,042] {scheduler_job.py:146} INFO - Started process (PID=28355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:50,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:50,049] {logging_mixin.py:95} INFO - [2019-09-12 15:35:50,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:50,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:50,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:50,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:50,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:35:50,487] {scheduler_job.py:146} INFO - Started process (PID=28356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:55,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:35:55,493] {logging_mixin.py:95} INFO - [2019-09-12 15:35:55,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:55,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:35:55,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:35:55,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:35:55,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:35:55,941] {scheduler_job.py:146} INFO - Started process (PID=28358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:00,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:00,951] {logging_mixin.py:95} INFO - [2019-09-12 15:36:00,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:01,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:01,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:01,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:01,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:36:01,403] {scheduler_job.py:146} INFO - Started process (PID=28362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:06,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:06,412] {logging_mixin.py:95} INFO - [2019-09-12 15:36:06,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:06,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:06,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:06,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:06,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:36:06,856] {scheduler_job.py:146} INFO - Started process (PID=28363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:11,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:11,864] {logging_mixin.py:95} INFO - [2019-09-12 15:36:11,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:12,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:12,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:12,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:12,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:36:12,315] {scheduler_job.py:146} INFO - Started process (PID=28368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:17,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:17,320] {logging_mixin.py:95} INFO - [2019-09-12 15:36:17,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:17,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:17,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:17,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:17,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:36:17,765] {scheduler_job.py:146} INFO - Started process (PID=28370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:22,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:22,773] {logging_mixin.py:95} INFO - [2019-09-12 15:36:22,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:23,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:23,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:23,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:23,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 15:36:23,218] {scheduler_job.py:146} INFO - Started process (PID=28371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:28,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:28,226] {logging_mixin.py:95} INFO - [2019-09-12 15:36:28,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:28,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:28,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:28,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:28,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:36:28,680] {scheduler_job.py:146} INFO - Started process (PID=28376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:33,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:33,691] {logging_mixin.py:95} INFO - [2019-09-12 15:36:33,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:34,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:34,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:34,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:34,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:36:34,127] {scheduler_job.py:146} INFO - Started process (PID=28377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:39,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:39,134] {logging_mixin.py:95} INFO - [2019-09-12 15:36:39,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:39,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:39,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:39,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:39,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:36:39,573] {scheduler_job.py:146} INFO - Started process (PID=28381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:44,581] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:44,582] {logging_mixin.py:95} INFO - [2019-09-12 15:36:44,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:44,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:44,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:44,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:45,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 15:36:45,020] {scheduler_job.py:146} INFO - Started process (PID=28385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:50,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:50,028] {logging_mixin.py:95} INFO - [2019-09-12 15:36:50,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:50,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:50,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:50,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:50,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 15:36:50,458] {scheduler_job.py:146} INFO - Started process (PID=28386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:55,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:36:55,465] {logging_mixin.py:95} INFO - [2019-09-12 15:36:55,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:55,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:36:55,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:36:55,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:36:55,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:36:55,911] {scheduler_job.py:146} INFO - Started process (PID=28388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:00,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:00,923] {logging_mixin.py:95} INFO - [2019-09-12 15:37:00,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:01,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:01,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:01,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:01,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:37:01,367] {scheduler_job.py:146} INFO - Started process (PID=28392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:06,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:06,376] {logging_mixin.py:95} INFO - [2019-09-12 15:37:06,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:06,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:06,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:06,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:06,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:37:06,827] {scheduler_job.py:146} INFO - Started process (PID=28393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:11,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:11,834] {logging_mixin.py:95} INFO - [2019-09-12 15:37:11,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:12,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:12,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:12,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:12,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:37:12,283] {scheduler_job.py:146} INFO - Started process (PID=28398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:17,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:17,293] {logging_mixin.py:95} INFO - [2019-09-12 15:37:17,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:17,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:17,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:17,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:17,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-12 15:37:17,839] {scheduler_job.py:146} INFO - Started process (PID=28400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:22,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:22,845] {logging_mixin.py:95} INFO - [2019-09-12 15:37:22,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:23,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:23,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:23,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:23,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:37:23,300] {scheduler_job.py:146} INFO - Started process (PID=28401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:28,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:28,307] {logging_mixin.py:95} INFO - [2019-09-12 15:37:28,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:28,698] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:28,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:28,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:28,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 15:37:28,759] {scheduler_job.py:146} INFO - Started process (PID=28403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:33,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:33,770] {logging_mixin.py:95} INFO - [2019-09-12 15:37:33,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:34,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:34,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:34,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:34,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:37:34,218] {scheduler_job.py:146} INFO - Started process (PID=28407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:39,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:39,227] {logging_mixin.py:95} INFO - [2019-09-12 15:37:39,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:39,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:39,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:39,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:39,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:37:39,676] {scheduler_job.py:146} INFO - Started process (PID=28410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:44,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:44,692] {logging_mixin.py:95} INFO - [2019-09-12 15:37:44,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:45,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:45,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:45,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:45,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 15:37:45,133] {scheduler_job.py:146} INFO - Started process (PID=28414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:50,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:50,142] {logging_mixin.py:95} INFO - [2019-09-12 15:37:50,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:50,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:50,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:50,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:50,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 15:37:50,591] {scheduler_job.py:146} INFO - Started process (PID=28416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:55,599] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:37:55,600] {logging_mixin.py:95} INFO - [2019-09-12 15:37:55,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:55,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:37:55,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:37:55,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:37:55,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:37:56,045] {scheduler_job.py:146} INFO - Started process (PID=28418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:01,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:01,056] {logging_mixin.py:95} INFO - [2019-09-12 15:38:01,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:01,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:01,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:01,404] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:01,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-12 15:38:01,502] {scheduler_job.py:146} INFO - Started process (PID=28422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:06,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:06,511] {logging_mixin.py:95} INFO - [2019-09-12 15:38:06,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:06,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:06,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:06,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:06,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-12 15:38:06,967] {scheduler_job.py:146} INFO - Started process (PID=28423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:11,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:11,977] {logging_mixin.py:95} INFO - [2019-09-12 15:38:11,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:12,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:12,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:12,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:12,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:38:12,427] {scheduler_job.py:146} INFO - Started process (PID=28425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:17,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:17,438] {logging_mixin.py:95} INFO - [2019-09-12 15:38:17,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:17,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:17,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:17,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:17,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:38:17,887] {scheduler_job.py:146} INFO - Started process (PID=28426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:22,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:22,900] {logging_mixin.py:95} INFO - [2019-09-12 15:38:22,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:23,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:23,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:23,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:23,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:38:23,345] {scheduler_job.py:146} INFO - Started process (PID=28431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:28,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:28,366] {logging_mixin.py:95} INFO - [2019-09-12 15:38:28,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:28,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:28,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:28,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:28,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 15:38:28,803] {scheduler_job.py:146} INFO - Started process (PID=28433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:33,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:33,810] {logging_mixin.py:95} INFO - [2019-09-12 15:38:33,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:34,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:34,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:34,190] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:34,196] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:38:34,265] {scheduler_job.py:146} INFO - Started process (PID=28434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:39,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:39,274] {logging_mixin.py:95} INFO - [2019-09-12 15:38:39,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:39,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:39,678] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:39,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:39,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-12 15:38:39,718] {scheduler_job.py:146} INFO - Started process (PID=28440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:44,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:44,726] {logging_mixin.py:95} INFO - [2019-09-12 15:38:44,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:45,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:45,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:45,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:45,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:38:45,173] {scheduler_job.py:146} INFO - Started process (PID=28441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:50,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:50,182] {logging_mixin.py:95} INFO - [2019-09-12 15:38:50,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:50,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:50,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:50,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:50,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 15:38:50,632] {scheduler_job.py:146} INFO - Started process (PID=28446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:55,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:38:55,640] {logging_mixin.py:95} INFO - [2019-09-12 15:38:55,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:55,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:38:56,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:38:56,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:38:56,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:38:56,087] {scheduler_job.py:146} INFO - Started process (PID=28448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:01,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:01,097] {logging_mixin.py:95} INFO - [2019-09-12 15:39:01,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:01,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:01,532] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:01,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:01,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-12 15:39:01,645] {scheduler_job.py:146} INFO - Started process (PID=28449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:06,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:06,655] {logging_mixin.py:95} INFO - [2019-09-12 15:39:06,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:07,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:07,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:07,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:07,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 15:39:07,095] {scheduler_job.py:146} INFO - Started process (PID=28450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:12,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:12,105] {logging_mixin.py:95} INFO - [2019-09-12 15:39:12,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:12,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:12,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:12,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:12,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:39:12,548] {scheduler_job.py:146} INFO - Started process (PID=28455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:17,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:17,554] {logging_mixin.py:95} INFO - [2019-09-12 15:39:17,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:17,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:17,931] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:17,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:17,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:39:18,007] {scheduler_job.py:146} INFO - Started process (PID=28456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:23,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:23,012] {logging_mixin.py:95} INFO - [2019-09-12 15:39:23,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:23,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:23,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:23,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:23,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:39:23,464] {scheduler_job.py:146} INFO - Started process (PID=28458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:28,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:28,471] {logging_mixin.py:95} INFO - [2019-09-12 15:39:28,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:28,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:28,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:28,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:28,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-12 15:39:28,919] {scheduler_job.py:146} INFO - Started process (PID=28463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:33,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:33,924] {logging_mixin.py:95} INFO - [2019-09-12 15:39:33,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:34,275] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:34,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:34,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:34,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:39:34,377] {scheduler_job.py:146} INFO - Started process (PID=28464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:39,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:39,385] {logging_mixin.py:95} INFO - [2019-09-12 15:39:39,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:39,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:39,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:39,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:39,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:39:39,832] {scheduler_job.py:146} INFO - Started process (PID=28467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:44,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:44,842] {logging_mixin.py:95} INFO - [2019-09-12 15:39:44,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:45,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:45,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:45,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:45,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:39:45,300] {scheduler_job.py:146} INFO - Started process (PID=28471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:50,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:50,309] {logging_mixin.py:95} INFO - [2019-09-12 15:39:50,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:50,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:50,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:50,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:50,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:39:50,760] {scheduler_job.py:146} INFO - Started process (PID=28472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:55,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:39:55,772] {logging_mixin.py:95} INFO - [2019-09-12 15:39:55,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:56,149] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:39:56,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:39:56,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:39:56,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 15:39:56,211] {scheduler_job.py:146} INFO - Started process (PID=28475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:01,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:01,218] {logging_mixin.py:95} INFO - [2019-09-12 15:40:01,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:01,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:01,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:01,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:01,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:40:01,665] {scheduler_job.py:146} INFO - Started process (PID=28479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:06,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:06,674] {logging_mixin.py:95} INFO - [2019-09-12 15:40:06,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:07,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:07,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:07,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:07,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:40:07,122] {scheduler_job.py:146} INFO - Started process (PID=28480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:12,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:12,132] {logging_mixin.py:95} INFO - [2019-09-12 15:40:12,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:12,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:12,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:12,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:12,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:40:12,583] {scheduler_job.py:146} INFO - Started process (PID=28485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:17,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:17,590] {logging_mixin.py:95} INFO - [2019-09-12 15:40:17,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:17,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:17,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:17,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:17,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:40:18,038] {scheduler_job.py:146} INFO - Started process (PID=28486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:23,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:23,050] {logging_mixin.py:95} INFO - [2019-09-12 15:40:23,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:23,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:23,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:23,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:23,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:40:23,493] {scheduler_job.py:146} INFO - Started process (PID=28487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:28,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:28,509] {logging_mixin.py:95} INFO - [2019-09-12 15:40:28,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:28,863] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:28,881] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:28,890] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:28,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:40:28,942] {scheduler_job.py:146} INFO - Started process (PID=28493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:33,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:33,953] {logging_mixin.py:95} INFO - [2019-09-12 15:40:33,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:34,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:34,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:34,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:34,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:40:34,408] {scheduler_job.py:146} INFO - Started process (PID=28494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:39,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:39,416] {logging_mixin.py:95} INFO - [2019-09-12 15:40:39,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:39,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:39,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:39,799] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:39,805] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:40:39,867] {scheduler_job.py:146} INFO - Started process (PID=28498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:44,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:44,875] {logging_mixin.py:95} INFO - [2019-09-12 15:40:44,875] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:45,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:45,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:45,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:45,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:40:45,327] {scheduler_job.py:146} INFO - Started process (PID=28501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:50,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:50,336] {logging_mixin.py:95} INFO - [2019-09-12 15:40:50,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:50,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:50,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:50,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:50,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:40:50,791] {scheduler_job.py:146} INFO - Started process (PID=28502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:55,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:40:55,801] {logging_mixin.py:95} INFO - [2019-09-12 15:40:55,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:56,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:40:56,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:40:56,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:40:56,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:40:56,250] {scheduler_job.py:146} INFO - Started process (PID=28505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:01,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:01,259] {logging_mixin.py:95} INFO - [2019-09-12 15:41:01,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:01,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:01,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:01,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:01,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 15:41:01,704] {scheduler_job.py:146} INFO - Started process (PID=28509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:06,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:06,713] {logging_mixin.py:95} INFO - [2019-09-12 15:41:06,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:07,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:07,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:07,095] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:07,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:41:07,162] {scheduler_job.py:146} INFO - Started process (PID=28510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:12,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:12,169] {logging_mixin.py:95} INFO - [2019-09-12 15:41:12,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:12,578] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:12,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:12,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:12,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 15:41:12,708] {scheduler_job.py:146} INFO - Started process (PID=28515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:17,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:17,717] {logging_mixin.py:95} INFO - [2019-09-12 15:41:17,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:18,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:18,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:18,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:18,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 15:41:18,157] {scheduler_job.py:146} INFO - Started process (PID=28522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:23,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:23,168] {logging_mixin.py:95} INFO - [2019-09-12 15:41:23,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:23,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:23,547] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:23,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:23,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:41:23,604] {scheduler_job.py:146} INFO - Started process (PID=28523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:28,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:28,612] {logging_mixin.py:95} INFO - [2019-09-12 15:41:28,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:29,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:29,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:29,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:29,058] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-12 15:41:29,149] {scheduler_job.py:146} INFO - Started process (PID=28532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:34,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:34,158] {logging_mixin.py:95} INFO - [2019-09-12 15:41:34,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:34,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:34,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:34,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:34,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:41:34,596] {scheduler_job.py:146} INFO - Started process (PID=28533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:39,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:39,603] {logging_mixin.py:95} INFO - [2019-09-12 15:41:39,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:39,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:39,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:39,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:39,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:41:40,046] {scheduler_job.py:146} INFO - Started process (PID=28536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:45,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:45,055] {logging_mixin.py:95} INFO - [2019-09-12 15:41:45,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:45,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:45,459] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:45,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:45,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-12 15:41:45,494] {scheduler_job.py:146} INFO - Started process (PID=28541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:50,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:50,500] {logging_mixin.py:95} INFO - [2019-09-12 15:41:50,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:50,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:50,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:50,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:50,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:41:50,955] {scheduler_job.py:146} INFO - Started process (PID=28542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:55,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:41:55,967] {logging_mixin.py:95} INFO - [2019-09-12 15:41:55,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:56,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:41:56,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:41:56,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:41:56,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:41:56,415] {scheduler_job.py:146} INFO - Started process (PID=28544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:01,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:01,424] {logging_mixin.py:95} INFO - [2019-09-12 15:42:01,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:01,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:01,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:01,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:01,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:42:01,870] {scheduler_job.py:146} INFO - Started process (PID=28549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:06,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:06,880] {logging_mixin.py:95} INFO - [2019-09-12 15:42:06,880] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:07,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:07,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:07,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:07,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:42:07,328] {scheduler_job.py:146} INFO - Started process (PID=28550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:12,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:12,338] {logging_mixin.py:95} INFO - [2019-09-12 15:42:12,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:12,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:12,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:12,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:12,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:42:12,772] {scheduler_job.py:146} INFO - Started process (PID=28552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:17,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:17,780] {logging_mixin.py:95} INFO - [2019-09-12 15:42:17,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:18,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:18,158] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:18,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:18,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:42:18,228] {scheduler_job.py:146} INFO - Started process (PID=28556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:23,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:23,239] {logging_mixin.py:95} INFO - [2019-09-12 15:42:23,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:23,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:23,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:23,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:23,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:42:23,684] {scheduler_job.py:146} INFO - Started process (PID=28557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:28,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:28,694] {logging_mixin.py:95} INFO - [2019-09-12 15:42:28,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:29,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:29,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:29,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:29,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:42:29,138] {scheduler_job.py:146} INFO - Started process (PID=28559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:34,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:34,146] {logging_mixin.py:95} INFO - [2019-09-12 15:42:34,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:34,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:34,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:34,530] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:34,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:42:34,596] {scheduler_job.py:146} INFO - Started process (PID=28561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:39,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:39,601] {logging_mixin.py:95} INFO - [2019-09-12 15:42:39,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:39,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:40,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:40,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:40,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 15:42:40,152] {scheduler_job.py:146} INFO - Started process (PID=28567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:45,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:45,163] {logging_mixin.py:95} INFO - [2019-09-12 15:42:45,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:45,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:45,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:45,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:45,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:42:45,601] {scheduler_job.py:146} INFO - Started process (PID=28568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:50,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:50,607] {logging_mixin.py:95} INFO - [2019-09-12 15:42:50,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:50,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:50,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:50,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:51,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:42:51,051] {scheduler_job.py:146} INFO - Started process (PID=28569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:56,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:42:56,060] {logging_mixin.py:95} INFO - [2019-09-12 15:42:56,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:56,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:42:56,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:42:56,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:42:56,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 15:42:56,596] {scheduler_job.py:146} INFO - Started process (PID=28574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:01,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:01,611] {logging_mixin.py:95} INFO - [2019-09-12 15:43:01,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:02,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:02,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:02,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:02,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 15:43:02,142] {scheduler_job.py:146} INFO - Started process (PID=28576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:07,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:07,151] {logging_mixin.py:95} INFO - [2019-09-12 15:43:07,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:07,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:07,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:07,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:07,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:43:07,587] {scheduler_job.py:146} INFO - Started process (PID=28577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:12,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:12,594] {logging_mixin.py:95} INFO - [2019-09-12 15:43:12,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:12,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:12,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:12,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:13,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 15:43:13,034] {scheduler_job.py:146} INFO - Started process (PID=28582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:18,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:18,044] {logging_mixin.py:95} INFO - [2019-09-12 15:43:18,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:18,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:18,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:18,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:18,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 15:43:18,580] {scheduler_job.py:146} INFO - Started process (PID=28583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:23,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:23,586] {logging_mixin.py:95} INFO - [2019-09-12 15:43:23,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:23,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:23,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:23,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:24,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 15:43:24,023] {scheduler_job.py:146} INFO - Started process (PID=28587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:29,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:29,035] {logging_mixin.py:95} INFO - [2019-09-12 15:43:29,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:29,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:29,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:29,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:29,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.962 seconds
[2019-09-12 15:43:30,072] {scheduler_job.py:146} INFO - Started process (PID=28594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:35,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:35,080] {logging_mixin.py:95} INFO - [2019-09-12 15:43:35,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:35,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:35,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:35,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:35,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 15:43:35,515] {scheduler_job.py:146} INFO - Started process (PID=28596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:40,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:40,526] {logging_mixin.py:95} INFO - [2019-09-12 15:43:40,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:40,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:40,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:41,000] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:41,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-12 15:43:41,056] {scheduler_job.py:146} INFO - Started process (PID=28602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:46,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:46,068] {logging_mixin.py:95} INFO - [2019-09-12 15:43:46,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:46,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:46,454] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:46,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:46,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:43:46,504] {scheduler_job.py:146} INFO - Started process (PID=28603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:51,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:51,512] {logging_mixin.py:95} INFO - [2019-09-12 15:43:51,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:51,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:51,895] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:51,904] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:51,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:43:51,951] {scheduler_job.py:146} INFO - Started process (PID=28604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:56,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:43:56,982] {logging_mixin.py:95} INFO - [2019-09-12 15:43:56,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:57,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:43:57,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:43:57,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:43:57,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 15:43:57,501] {scheduler_job.py:146} INFO - Started process (PID=28609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:02,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:02,508] {logging_mixin.py:95} INFO - [2019-09-12 15:44:02,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:02,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:02,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:02,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:02,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 15:44:02,947] {scheduler_job.py:146} INFO - Started process (PID=28610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:07,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:07,954] {logging_mixin.py:95} INFO - [2019-09-12 15:44:07,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:08,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:08,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:08,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:08,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:44:08,392] {scheduler_job.py:146} INFO - Started process (PID=28612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:13,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:13,404] {logging_mixin.py:95} INFO - [2019-09-12 15:44:13,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:13,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:13,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:13,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:13,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:44:13,841] {scheduler_job.py:146} INFO - Started process (PID=28614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:18,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:18,851] {logging_mixin.py:95} INFO - [2019-09-12 15:44:18,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:19,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:19,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:19,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:19,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:44:19,292] {scheduler_job.py:146} INFO - Started process (PID=28618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:24,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:24,301] {logging_mixin.py:95} INFO - [2019-09-12 15:44:24,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:24,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:24,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:24,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:24,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 15:44:24,736] {scheduler_job.py:146} INFO - Started process (PID=28620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:29,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:29,743] {logging_mixin.py:95} INFO - [2019-09-12 15:44:29,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:30,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:30,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:30,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:30,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:44:30,180] {scheduler_job.py:146} INFO - Started process (PID=28624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:35,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:35,191] {logging_mixin.py:95} INFO - [2019-09-12 15:44:35,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:35,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:35,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:35,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:35,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 15:44:35,626] {scheduler_job.py:146} INFO - Started process (PID=28625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:40,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:40,634] {logging_mixin.py:95} INFO - [2019-09-12 15:44:40,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:40,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:41,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:41,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:41,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:44:41,073] {scheduler_job.py:146} INFO - Started process (PID=28633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:46,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:46,083] {logging_mixin.py:95} INFO - [2019-09-12 15:44:46,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:46,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:46,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:46,481] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:46,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:44:46,521] {scheduler_job.py:146} INFO - Started process (PID=28634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:51,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:51,531] {logging_mixin.py:95} INFO - [2019-09-12 15:44:51,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:51,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:51,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:51,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:51,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:44:51,979] {scheduler_job.py:146} INFO - Started process (PID=28635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:56,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:44:56,988] {logging_mixin.py:95} INFO - [2019-09-12 15:44:56,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:57,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:44:57,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:44:57,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:44:57,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 15:44:57,427] {scheduler_job.py:146} INFO - Started process (PID=28637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:02,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:02,433] {logging_mixin.py:95} INFO - [2019-09-12 15:45:02,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:02,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:02,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:02,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:02,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:45:02,873] {scheduler_job.py:146} INFO - Started process (PID=28641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:07,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:07,880] {logging_mixin.py:95} INFO - [2019-09-12 15:45:07,880] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:08,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:08,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:08,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:08,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 15:45:08,315] {scheduler_job.py:146} INFO - Started process (PID=28643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:13,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:13,321] {logging_mixin.py:95} INFO - [2019-09-12 15:45:13,321] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:13,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:13,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:13,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:13,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:45:13,770] {scheduler_job.py:146} INFO - Started process (PID=28645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:18,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:18,777] {logging_mixin.py:95} INFO - [2019-09-12 15:45:18,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:19,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:19,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:19,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:19,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:45:19,218] {scheduler_job.py:146} INFO - Started process (PID=28650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:24,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:24,227] {logging_mixin.py:95} INFO - [2019-09-12 15:45:24,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:24,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:24,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:24,627] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:24,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 15:45:24,665] {scheduler_job.py:146} INFO - Started process (PID=28653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:29,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:29,677] {logging_mixin.py:95} INFO - [2019-09-12 15:45:29,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:30,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:30,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:30,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:30,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:45:30,110] {scheduler_job.py:146} INFO - Started process (PID=28657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:35,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:35,121] {logging_mixin.py:95} INFO - [2019-09-12 15:45:35,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:35,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:35,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:35,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:35,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:45:35,571] {scheduler_job.py:146} INFO - Started process (PID=28658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:40,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:40,581] {logging_mixin.py:95} INFO - [2019-09-12 15:45:40,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:41,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:41,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:41,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:41,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-12 15:45:41,123] {scheduler_job.py:146} INFO - Started process (PID=28664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:46,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:46,134] {logging_mixin.py:95} INFO - [2019-09-12 15:45:46,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:46,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:46,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:46,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:46,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 15:45:46,575] {scheduler_job.py:146} INFO - Started process (PID=28668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:51,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:51,585] {logging_mixin.py:95} INFO - [2019-09-12 15:45:51,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:51,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:51,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:51,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:51,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 15:45:52,023] {scheduler_job.py:146} INFO - Started process (PID=28672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:57,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:45:57,031] {logging_mixin.py:95} INFO - [2019-09-12 15:45:57,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:57,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:45:57,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:45:57,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:45:57,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 15:45:57,464] {scheduler_job.py:146} INFO - Started process (PID=28674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:02,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:02,471] {logging_mixin.py:95} INFO - [2019-09-12 15:46:02,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:02,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:02,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:02,890] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:02,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 15:46:03,006] {scheduler_job.py:146} INFO - Started process (PID=28675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:08,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:08,017] {logging_mixin.py:95} INFO - [2019-09-12 15:46:08,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:08,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:08,389] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:08,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:08,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:46:08,456] {scheduler_job.py:146} INFO - Started process (PID=28679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:13,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:13,468] {logging_mixin.py:95} INFO - [2019-09-12 15:46:13,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:13,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:13,848] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:13,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:13,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:46:13,899] {scheduler_job.py:146} INFO - Started process (PID=28681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:18,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:18,907] {logging_mixin.py:95} INFO - [2019-09-12 15:46:18,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:19,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:19,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:19,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:19,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 15:46:19,349] {scheduler_job.py:146} INFO - Started process (PID=28688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:24,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:24,356] {logging_mixin.py:95} INFO - [2019-09-12 15:46:24,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:24,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:24,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:24,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:24,754] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:46:24,803] {scheduler_job.py:146} INFO - Started process (PID=28690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:29,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:29,815] {logging_mixin.py:95} INFO - [2019-09-12 15:46:29,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:30,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:30,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:30,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:30,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:46:30,258] {scheduler_job.py:146} INFO - Started process (PID=28691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:35,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:35,268] {logging_mixin.py:95} INFO - [2019-09-12 15:46:35,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:35,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:35,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:35,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:35,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:46:35,708] {scheduler_job.py:146} INFO - Started process (PID=28692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:40,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:40,718] {logging_mixin.py:95} INFO - [2019-09-12 15:46:40,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:41,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:41,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:41,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:41,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:46:41,167] {scheduler_job.py:146} INFO - Started process (PID=28695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:46,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:46,174] {logging_mixin.py:95} INFO - [2019-09-12 15:46:46,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:46,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:46,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:46,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:46,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:46:46,621] {scheduler_job.py:146} INFO - Started process (PID=28699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:51,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:51,628] {logging_mixin.py:95} INFO - [2019-09-12 15:46:51,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:51,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:52,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:52,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:52,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:46:52,082] {scheduler_job.py:146} INFO - Started process (PID=28700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:57,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:46:57,090] {logging_mixin.py:95} INFO - [2019-09-12 15:46:57,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:57,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:46:57,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:46:57,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:46:57,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-12 15:46:57,540] {scheduler_job.py:146} INFO - Started process (PID=28705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:02,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:02,549] {logging_mixin.py:95} INFO - [2019-09-12 15:47:02,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:02,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:02,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:02,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:02,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:47:02,994] {scheduler_job.py:146} INFO - Started process (PID=28706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:08,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:08,005] {logging_mixin.py:95} INFO - [2019-09-12 15:47:08,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:08,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:08,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:08,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:08,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:47:08,446] {scheduler_job.py:146} INFO - Started process (PID=28710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:13,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:13,454] {logging_mixin.py:95} INFO - [2019-09-12 15:47:13,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:13,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:13,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:13,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:13,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:47:13,904] {scheduler_job.py:146} INFO - Started process (PID=28712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:18,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:18,913] {logging_mixin.py:95} INFO - [2019-09-12 15:47:18,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:19,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:19,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:19,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:19,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:47:19,355] {scheduler_job.py:146} INFO - Started process (PID=28713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:24,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:24,362] {logging_mixin.py:95} INFO - [2019-09-12 15:47:24,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:24,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:24,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:24,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:24,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:47:24,812] {scheduler_job.py:146} INFO - Started process (PID=28715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:29,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:29,821] {logging_mixin.py:95} INFO - [2019-09-12 15:47:29,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:30,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:30,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:30,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:30,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:47:30,264] {scheduler_job.py:146} INFO - Started process (PID=28719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:35,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:35,271] {logging_mixin.py:95} INFO - [2019-09-12 15:47:35,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:35,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:35,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:35,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:35,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:47:35,713] {scheduler_job.py:146} INFO - Started process (PID=28720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:40,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:40,724] {logging_mixin.py:95} INFO - [2019-09-12 15:47:40,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:41,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:41,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:41,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:41,123] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:47:41,170] {scheduler_job.py:146} INFO - Started process (PID=28726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:46,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:46,180] {logging_mixin.py:95} INFO - [2019-09-12 15:47:46,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:46,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:46,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:46,576] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:46,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 15:47:46,619] {scheduler_job.py:146} INFO - Started process (PID=28727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:51,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:51,629] {logging_mixin.py:95} INFO - [2019-09-12 15:47:51,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:51,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:52,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:52,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:52,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:47:52,070] {scheduler_job.py:146} INFO - Started process (PID=28728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:57,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:47:57,096] {logging_mixin.py:95} INFO - [2019-09-12 15:47:57,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:57,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:47:57,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:47:57,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:47:57,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:47:57,524] {scheduler_job.py:146} INFO - Started process (PID=28733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:02,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:02,532] {logging_mixin.py:95} INFO - [2019-09-12 15:48:02,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:02,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:02,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:02,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:02,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:48:02,976] {scheduler_job.py:146} INFO - Started process (PID=28734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:07,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:07,988] {logging_mixin.py:95} INFO - [2019-09-12 15:48:07,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:08,347] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:08,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:08,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:08,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:48:08,431] {scheduler_job.py:146} INFO - Started process (PID=28737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:13,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:13,442] {logging_mixin.py:95} INFO - [2019-09-12 15:48:13,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:13,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:13,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:13,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:13,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-12 15:48:13,881] {scheduler_job.py:146} INFO - Started process (PID=28742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:18,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:18,890] {logging_mixin.py:95} INFO - [2019-09-12 15:48:18,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:19,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:19,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:19,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:19,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:48:19,328] {scheduler_job.py:146} INFO - Started process (PID=28743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:24,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:24,335] {logging_mixin.py:95} INFO - [2019-09-12 15:48:24,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:24,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:24,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:24,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:24,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:48:24,783] {scheduler_job.py:146} INFO - Started process (PID=28745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:29,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:29,793] {logging_mixin.py:95} INFO - [2019-09-12 15:48:29,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:30,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:30,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:30,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:30,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 15:48:30,336] {scheduler_job.py:146} INFO - Started process (PID=28746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:35,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:35,344] {logging_mixin.py:95} INFO - [2019-09-12 15:48:35,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:35,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:35,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:35,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:35,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:48:35,779] {scheduler_job.py:146} INFO - Started process (PID=28750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:40,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:40,787] {logging_mixin.py:95} INFO - [2019-09-12 15:48:40,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:41,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:41,175] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:41,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:41,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:48:41,224] {scheduler_job.py:146} INFO - Started process (PID=28756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:46,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:46,233] {logging_mixin.py:95} INFO - [2019-09-12 15:48:46,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:46,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:46,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:46,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:46,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:48:46,680] {scheduler_job.py:146} INFO - Started process (PID=28757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:51,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:51,691] {logging_mixin.py:95} INFO - [2019-09-12 15:48:51,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:52,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:52,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:52,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:52,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:48:52,126] {scheduler_job.py:146} INFO - Started process (PID=28758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:57,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:48:57,133] {logging_mixin.py:95} INFO - [2019-09-12 15:48:57,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:57,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:48:57,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:48:57,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:48:57,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 15:48:57,579] {scheduler_job.py:146} INFO - Started process (PID=28760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:02,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:02,589] {logging_mixin.py:95} INFO - [2019-09-12 15:49:02,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:02,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:02,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:02,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:02,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:49:03,031] {scheduler_job.py:146} INFO - Started process (PID=28764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:08,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:08,038] {logging_mixin.py:95} INFO - [2019-09-12 15:49:08,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:08,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:08,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:08,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:08,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 15:49:08,479] {scheduler_job.py:146} INFO - Started process (PID=28765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:13,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:13,487] {logging_mixin.py:95} INFO - [2019-09-12 15:49:13,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:13,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:13,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:13,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:13,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:49:13,927] {scheduler_job.py:146} INFO - Started process (PID=28770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:18,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:18,935] {logging_mixin.py:95} INFO - [2019-09-12 15:49:18,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:19,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:19,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:19,321] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:19,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:49:19,382] {scheduler_job.py:146} INFO - Started process (PID=28771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:24,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:24,391] {logging_mixin.py:95} INFO - [2019-09-12 15:49:24,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:24,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:24,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:24,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:24,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:49:24,834] {scheduler_job.py:146} INFO - Started process (PID=28773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:29,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:29,845] {logging_mixin.py:95} INFO - [2019-09-12 15:49:29,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:30,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:30,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:30,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:30,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:49:30,284] {scheduler_job.py:146} INFO - Started process (PID=28774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:35,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:35,295] {logging_mixin.py:95} INFO - [2019-09-12 15:49:35,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:35,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:35,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:35,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:35,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:49:35,740] {scheduler_job.py:146} INFO - Started process (PID=28778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:40,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:40,751] {logging_mixin.py:95} INFO - [2019-09-12 15:49:40,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:41,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:41,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:41,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:41,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:49:41,197] {scheduler_job.py:146} INFO - Started process (PID=28781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:46,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:46,207] {logging_mixin.py:95} INFO - [2019-09-12 15:49:46,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:46,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:46,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:46,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:46,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:49:46,645] {scheduler_job.py:146} INFO - Started process (PID=28782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:51,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:51,657] {logging_mixin.py:95} INFO - [2019-09-12 15:49:51,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:52,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:52,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:52,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:52,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:49:52,104] {scheduler_job.py:146} INFO - Started process (PID=28783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:57,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:49:57,124] {logging_mixin.py:95} INFO - [2019-09-12 15:49:57,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:57,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:49:57,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:49:57,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:49:57,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-12 15:49:57,649] {scheduler_job.py:146} INFO - Started process (PID=28788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:02,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:02,661] {logging_mixin.py:95} INFO - [2019-09-12 15:50:02,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:03,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:03,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:03,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:03,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:50:03,094] {scheduler_job.py:146} INFO - Started process (PID=28792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:08,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:08,106] {logging_mixin.py:95} INFO - [2019-09-12 15:50:08,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:08,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:08,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:08,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:08,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-12 15:50:08,636] {scheduler_job.py:146} INFO - Started process (PID=28798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:13,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:13,644] {logging_mixin.py:95} INFO - [2019-09-12 15:50:13,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:14,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:14,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:14,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:14,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 15:50:14,087] {scheduler_job.py:146} INFO - Started process (PID=28800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:19,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:19,094] {logging_mixin.py:95} INFO - [2019-09-12 15:50:19,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:19,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:19,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:19,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:19,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-12 15:50:19,626] {scheduler_job.py:146} INFO - Started process (PID=28812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:24,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:24,634] {logging_mixin.py:95} INFO - [2019-09-12 15:50:24,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:24,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:25,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:25,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:25,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:50:25,080] {scheduler_job.py:146} INFO - Started process (PID=28815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:30,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:30,087] {logging_mixin.py:95} INFO - [2019-09-12 15:50:30,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:30,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:30,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:30,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:30,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 15:50:30,530] {scheduler_job.py:146} INFO - Started process (PID=28818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:35,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:35,540] {logging_mixin.py:95} INFO - [2019-09-12 15:50:35,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:35,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:35,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:35,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:35,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 15:50:36,081] {scheduler_job.py:146} INFO - Started process (PID=28834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:41,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:41,088] {logging_mixin.py:95} INFO - [2019-09-12 15:50:41,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:41,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:41,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:41,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:41,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:50:41,529] {scheduler_job.py:146} INFO - Started process (PID=28838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:46,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:46,535] {logging_mixin.py:95} INFO - [2019-09-12 15:50:46,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:46,897] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:46,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:46,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:46,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:50:46,979] {scheduler_job.py:146} INFO - Started process (PID=28839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:51,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:51,986] {logging_mixin.py:95} INFO - [2019-09-12 15:50:51,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:52,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:52,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:52,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:52,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-12 15:50:52,435] {scheduler_job.py:146} INFO - Started process (PID=28843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:57,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:50:57,445] {logging_mixin.py:95} INFO - [2019-09-12 15:50:57,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:57,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:50:57,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:50:57,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:50:57,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 15:50:57,886] {scheduler_job.py:146} INFO - Started process (PID=28845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:02,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:02,894] {logging_mixin.py:95} INFO - [2019-09-12 15:51:02,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:03,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:03,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:03,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:03,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 15:51:03,426] {scheduler_job.py:146} INFO - Started process (PID=28848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:08,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:08,433] {logging_mixin.py:95} INFO - [2019-09-12 15:51:08,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:08,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:08,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:08,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:08,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:51:08,876] {scheduler_job.py:146} INFO - Started process (PID=28851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:13,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:13,881] {logging_mixin.py:95} INFO - [2019-09-12 15:51:13,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:14,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:14,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:14,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:14,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 15:51:14,427] {scheduler_job.py:146} INFO - Started process (PID=28854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:19,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:19,438] {logging_mixin.py:95} INFO - [2019-09-12 15:51:19,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:19,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:19,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:19,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:19,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:51:19,882] {scheduler_job.py:146} INFO - Started process (PID=28855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:24,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:24,892] {logging_mixin.py:95} INFO - [2019-09-12 15:51:24,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:25,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:25,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:25,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:25,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 15:51:25,338] {scheduler_job.py:146} INFO - Started process (PID=28857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:30,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:30,348] {logging_mixin.py:95} INFO - [2019-09-12 15:51:30,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:30,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:30,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:30,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:30,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:51:30,793] {scheduler_job.py:146} INFO - Started process (PID=28861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:35,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:35,800] {logging_mixin.py:95} INFO - [2019-09-12 15:51:35,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:36,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:36,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:36,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:36,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-12 15:51:36,255] {scheduler_job.py:146} INFO - Started process (PID=28862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:41,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:41,262] {logging_mixin.py:95} INFO - [2019-09-12 15:51:41,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:41,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:41,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:41,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:41,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:51:41,711] {scheduler_job.py:146} INFO - Started process (PID=28868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:46,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:46,718] {logging_mixin.py:95} INFO - [2019-09-12 15:51:46,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:47,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:47,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:47,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:47,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:51:47,169] {scheduler_job.py:146} INFO - Started process (PID=28869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:52,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:52,178] {logging_mixin.py:95} INFO - [2019-09-12 15:51:52,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:52,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:52,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:52,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:52,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:51:52,627] {scheduler_job.py:146} INFO - Started process (PID=28870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:57,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:51:57,647] {logging_mixin.py:95} INFO - [2019-09-12 15:51:57,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:57,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:51:58,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:51:58,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:51:58,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 15:51:58,085] {scheduler_job.py:146} INFO - Started process (PID=28872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:03,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:03,094] {logging_mixin.py:95} INFO - [2019-09-12 15:52:03,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:03,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:03,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:03,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:03,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:52:03,538] {scheduler_job.py:146} INFO - Started process (PID=28876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:08,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:08,546] {logging_mixin.py:95} INFO - [2019-09-12 15:52:08,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:08,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:08,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:08,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:08,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:52:08,991] {scheduler_job.py:146} INFO - Started process (PID=28877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:13,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:13,998] {logging_mixin.py:95} INFO - [2019-09-12 15:52:13,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:14,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:14,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:14,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:14,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:52:14,443] {scheduler_job.py:146} INFO - Started process (PID=28882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:19,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:19,450] {logging_mixin.py:95} INFO - [2019-09-12 15:52:19,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:19,803] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:19,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:19,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:19,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:52:19,895] {scheduler_job.py:146} INFO - Started process (PID=28883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:24,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:24,903] {logging_mixin.py:95} INFO - [2019-09-12 15:52:24,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:25,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:25,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:25,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:25,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:52:25,348] {scheduler_job.py:146} INFO - Started process (PID=28888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:30,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:30,357] {logging_mixin.py:95} INFO - [2019-09-12 15:52:30,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:30,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:30,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:30,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:30,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 15:52:30,803] {scheduler_job.py:146} INFO - Started process (PID=28889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:35,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:35,808] {logging_mixin.py:95} INFO - [2019-09-12 15:52:35,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:36,158] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:36,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:36,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:36,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:52:36,259] {scheduler_job.py:146} INFO - Started process (PID=28890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:41,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:41,267] {logging_mixin.py:95} INFO - [2019-09-12 15:52:41,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:41,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:41,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:41,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:41,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:52:41,713] {scheduler_job.py:146} INFO - Started process (PID=28893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:46,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:46,719] {logging_mixin.py:95} INFO - [2019-09-12 15:52:46,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:47,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:47,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:47,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:47,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:52:47,168] {scheduler_job.py:146} INFO - Started process (PID=28897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:52,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:52,175] {logging_mixin.py:95} INFO - [2019-09-12 15:52:52,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:52,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:52,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:52,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:52,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:52:52,625] {scheduler_job.py:146} INFO - Started process (PID=28898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:57,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:52:57,631] {logging_mixin.py:95} INFO - [2019-09-12 15:52:57,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:57,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:52:58,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:52:58,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:52:58,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:52:58,082] {scheduler_job.py:146} INFO - Started process (PID=28900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:03,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:03,089] {logging_mixin.py:95} INFO - [2019-09-12 15:53:03,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:03,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:03,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:03,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:03,477] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:53:03,540] {scheduler_job.py:146} INFO - Started process (PID=28904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:08,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:08,551] {logging_mixin.py:95} INFO - [2019-09-12 15:53:08,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:08,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:08,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:08,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:08,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:53:09,001] {scheduler_job.py:146} INFO - Started process (PID=28905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:14,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:14,011] {logging_mixin.py:95} INFO - [2019-09-12 15:53:14,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:14,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:14,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:14,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:14,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:53:14,458] {scheduler_job.py:146} INFO - Started process (PID=28907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:19,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:19,466] {logging_mixin.py:95} INFO - [2019-09-12 15:53:19,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:19,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:19,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:19,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:19,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:53:19,906] {scheduler_job.py:146} INFO - Started process (PID=28911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:24,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:24,913] {logging_mixin.py:95} INFO - [2019-09-12 15:53:24,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:25,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:25,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:25,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:25,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:53:25,361] {scheduler_job.py:146} INFO - Started process (PID=28913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:30,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:30,372] {logging_mixin.py:95} INFO - [2019-09-12 15:53:30,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:30,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:30,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:30,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:30,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-12 15:53:30,821] {scheduler_job.py:146} INFO - Started process (PID=28914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:35,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:35,830] {logging_mixin.py:95} INFO - [2019-09-12 15:53:35,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:36,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:36,172] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:36,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:36,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-12 15:53:36,277] {scheduler_job.py:146} INFO - Started process (PID=28918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:41,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:41,284] {logging_mixin.py:95} INFO - [2019-09-12 15:53:41,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:41,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:41,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:41,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:41,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:53:41,736] {scheduler_job.py:146} INFO - Started process (PID=28921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:46,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:46,747] {logging_mixin.py:95} INFO - [2019-09-12 15:53:46,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:47,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:47,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:47,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:47,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:53:47,194] {scheduler_job.py:146} INFO - Started process (PID=28925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:52,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:52,200] {logging_mixin.py:95} INFO - [2019-09-12 15:53:52,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:52,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:52,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:52,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:52,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 15:53:52,747] {scheduler_job.py:146} INFO - Started process (PID=28926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:57,758] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:53:57,759] {logging_mixin.py:95} INFO - [2019-09-12 15:53:57,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:58,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:53:58,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:53:58,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:53:58,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:53:58,208] {scheduler_job.py:146} INFO - Started process (PID=28928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:03,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:03,215] {logging_mixin.py:95} INFO - [2019-09-12 15:54:03,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:03,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:03,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:03,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:03,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:54:03,669] {scheduler_job.py:146} INFO - Started process (PID=28929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:08,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:08,680] {logging_mixin.py:95} INFO - [2019-09-12 15:54:08,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:09,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:09,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:09,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:09,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:54:09,133] {scheduler_job.py:146} INFO - Started process (PID=28933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:14,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:14,141] {logging_mixin.py:95} INFO - [2019-09-12 15:54:14,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:14,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:14,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:14,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:14,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:54:14,591] {scheduler_job.py:146} INFO - Started process (PID=28935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:19,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:19,601] {logging_mixin.py:95} INFO - [2019-09-12 15:54:19,600] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:19,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:19,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:19,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:19,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:54:20,050] {scheduler_job.py:146} INFO - Started process (PID=28936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:25,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:25,060] {logging_mixin.py:95} INFO - [2019-09-12 15:54:25,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:25,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:25,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:25,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:25,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:54:25,501] {scheduler_job.py:146} INFO - Started process (PID=28941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:30,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:30,511] {logging_mixin.py:95} INFO - [2019-09-12 15:54:30,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:30,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:30,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:30,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:30,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:54:30,966] {scheduler_job.py:146} INFO - Started process (PID=28942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:35,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:35,973] {logging_mixin.py:95} INFO - [2019-09-12 15:54:35,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:36,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:36,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:36,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:36,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:54:36,422] {scheduler_job.py:146} INFO - Started process (PID=28946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:41,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:41,429] {logging_mixin.py:95} INFO - [2019-09-12 15:54:41,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:41,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:41,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:41,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:41,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:54:41,880] {scheduler_job.py:146} INFO - Started process (PID=28949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:46,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:46,899] {logging_mixin.py:95} INFO - [2019-09-12 15:54:46,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:47,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:47,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:47,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:47,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:54:47,339] {scheduler_job.py:146} INFO - Started process (PID=28950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:52,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:52,348] {logging_mixin.py:95} INFO - [2019-09-12 15:54:52,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:52,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:52,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:52,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:52,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:54:52,799] {scheduler_job.py:146} INFO - Started process (PID=28954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:57,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:54:57,810] {logging_mixin.py:95} INFO - [2019-09-12 15:54:57,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:58,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:54:58,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:54:58,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:54:58,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:54:58,258] {scheduler_job.py:146} INFO - Started process (PID=28956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:03,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:03,267] {logging_mixin.py:95} INFO - [2019-09-12 15:55:03,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:03,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:03,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:03,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:03,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:55:03,723] {scheduler_job.py:146} INFO - Started process (PID=28957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:08,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:08,730] {logging_mixin.py:95} INFO - [2019-09-12 15:55:08,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:09,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:09,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:09,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:09,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 15:55:09,185] {scheduler_job.py:146} INFO - Started process (PID=28961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:14,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:14,196] {logging_mixin.py:95} INFO - [2019-09-12 15:55:14,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:14,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:14,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:14,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:14,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:55:14,645] {scheduler_job.py:146} INFO - Started process (PID=28963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:19,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:19,657] {logging_mixin.py:95} INFO - [2019-09-12 15:55:19,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:20,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:20,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:20,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:20,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 15:55:20,109] {scheduler_job.py:146} INFO - Started process (PID=28964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:25,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:25,115] {logging_mixin.py:95} INFO - [2019-09-12 15:55:25,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:25,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:25,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:25,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:25,486] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-12 15:55:25,567] {scheduler_job.py:146} INFO - Started process (PID=28969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:30,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:30,576] {logging_mixin.py:95} INFO - [2019-09-12 15:55:30,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:30,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:30,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:30,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:30,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:55:31,023] {scheduler_job.py:146} INFO - Started process (PID=28970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:36,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:36,031] {logging_mixin.py:95} INFO - [2019-09-12 15:55:36,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:36,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:36,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:36,414] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:36,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:55:36,487] {scheduler_job.py:146} INFO - Started process (PID=28971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:41,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:41,497] {logging_mixin.py:95} INFO - [2019-09-12 15:55:41,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:41,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:41,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:41,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:41,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:55:41,950] {scheduler_job.py:146} INFO - Started process (PID=28977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:46,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:46,961] {logging_mixin.py:95} INFO - [2019-09-12 15:55:46,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:47,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:47,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:47,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:47,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 15:55:47,403] {scheduler_job.py:146} INFO - Started process (PID=28978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:52,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:52,412] {logging_mixin.py:95} INFO - [2019-09-12 15:55:52,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:52,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:52,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:52,803] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:52,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:55:52,865] {scheduler_job.py:146} INFO - Started process (PID=28982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:57,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:55:57,871] {logging_mixin.py:95} INFO - [2019-09-12 15:55:57,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:58,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:55:58,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:55:58,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:55:58,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:55:58,321] {scheduler_job.py:146} INFO - Started process (PID=28984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:03,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:03,328] {logging_mixin.py:95} INFO - [2019-09-12 15:56:03,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:03,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:03,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:03,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:03,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 15:56:03,782] {scheduler_job.py:146} INFO - Started process (PID=28985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:08,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:08,792] {logging_mixin.py:95} INFO - [2019-09-12 15:56:08,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:09,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:09,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:09,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:09,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:56:09,235] {scheduler_job.py:146} INFO - Started process (PID=28986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:14,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:14,244] {logging_mixin.py:95} INFO - [2019-09-12 15:56:14,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:14,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:14,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:14,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:14,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 15:56:14,691] {scheduler_job.py:146} INFO - Started process (PID=28991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:19,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:19,697] {logging_mixin.py:95} INFO - [2019-09-12 15:56:19,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:20,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:20,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:20,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:20,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:56:20,146] {scheduler_job.py:146} INFO - Started process (PID=28992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:25,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:25,155] {logging_mixin.py:95} INFO - [2019-09-12 15:56:25,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:25,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:25,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:25,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:25,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:56:25,603] {scheduler_job.py:146} INFO - Started process (PID=28994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:30,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:30,611] {logging_mixin.py:95} INFO - [2019-09-12 15:56:30,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:30,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:30,982] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:30,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:30,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:56:31,062] {scheduler_job.py:146} INFO - Started process (PID=28995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:36,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:36,068] {logging_mixin.py:95} INFO - [2019-09-12 15:56:36,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:36,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:36,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:36,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:36,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:56:36,523] {scheduler_job.py:146} INFO - Started process (PID=28999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:41,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:41,532] {logging_mixin.py:95} INFO - [2019-09-12 15:56:41,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:41,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:41,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:41,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:41,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 15:56:41,985] {scheduler_job.py:146} INFO - Started process (PID=29005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:46,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:46,992] {logging_mixin.py:95} INFO - [2019-09-12 15:56:46,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:47,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:47,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:47,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:47,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:56:47,452] {scheduler_job.py:146} INFO - Started process (PID=29006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:52,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:52,461] {logging_mixin.py:95} INFO - [2019-09-12 15:56:52,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:52,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:52,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:52,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:52,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:56:52,916] {scheduler_job.py:146} INFO - Started process (PID=29007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:57,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:56:57,927] {logging_mixin.py:95} INFO - [2019-09-12 15:56:57,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:58,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:56:58,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:56:58,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:56:58,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:56:58,373] {scheduler_job.py:146} INFO - Started process (PID=29009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:03,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:03,381] {logging_mixin.py:95} INFO - [2019-09-12 15:57:03,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:03,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:03,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:03,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:03,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:57:03,835] {scheduler_job.py:146} INFO - Started process (PID=29013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:08,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:08,845] {logging_mixin.py:95} INFO - [2019-09-12 15:57:08,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:09,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:09,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:09,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:09,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 15:57:09,300] {scheduler_job.py:146} INFO - Started process (PID=29014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:14,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:14,310] {logging_mixin.py:95} INFO - [2019-09-12 15:57:14,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:14,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:14,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:14,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:14,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 15:57:14,762] {scheduler_job.py:146} INFO - Started process (PID=29016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:19,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:19,768] {logging_mixin.py:95} INFO - [2019-09-12 15:57:19,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:20,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:20,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:20,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:20,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 15:57:20,223] {scheduler_job.py:146} INFO - Started process (PID=29017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:25,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:25,230] {logging_mixin.py:95} INFO - [2019-09-12 15:57:25,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:25,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:25,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:25,627] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:25,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:57:25,678] {scheduler_job.py:146} INFO - Started process (PID=29022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:30,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:30,690] {logging_mixin.py:95} INFO - [2019-09-12 15:57:30,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:31,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:31,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:31,070] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:31,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:57:31,131] {scheduler_job.py:146} INFO - Started process (PID=29026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:36,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:36,142] {logging_mixin.py:95} INFO - [2019-09-12 15:57:36,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:36,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:36,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:36,519] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:36,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:57:36,594] {scheduler_job.py:146} INFO - Started process (PID=29027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:41,604] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:41,605] {logging_mixin.py:95} INFO - [2019-09-12 15:57:41,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:41,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:41,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:41,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:41,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 15:57:42,058] {scheduler_job.py:146} INFO - Started process (PID=29030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:47,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:47,068] {logging_mixin.py:95} INFO - [2019-09-12 15:57:47,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:47,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:47,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:47,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:47,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-12 15:57:47,518] {scheduler_job.py:146} INFO - Started process (PID=29034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:52,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:52,526] {logging_mixin.py:95} INFO - [2019-09-12 15:57:52,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:52,870] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:52,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:52,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:52,909] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 15:57:52,982] {scheduler_job.py:146} INFO - Started process (PID=29035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:57,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:57:57,991] {logging_mixin.py:95} INFO - [2019-09-12 15:57:57,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:58,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:57:58,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:57:58,414] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:57:58,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 15:57:58,534] {scheduler_job.py:146} INFO - Started process (PID=29037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:03,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:03,540] {logging_mixin.py:95} INFO - [2019-09-12 15:58:03,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:03,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:03,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:03,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:03,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:58:03,987] {scheduler_job.py:146} INFO - Started process (PID=29041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:08,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:08,995] {logging_mixin.py:95} INFO - [2019-09-12 15:58:08,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:09,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:09,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:09,379] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:09,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 15:58:09,439] {scheduler_job.py:146} INFO - Started process (PID=29042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:14,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:14,449] {logging_mixin.py:95} INFO - [2019-09-12 15:58:14,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:14,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:14,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:14,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:14,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 15:58:14,903] {scheduler_job.py:146} INFO - Started process (PID=29044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:19,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:19,910] {logging_mixin.py:95} INFO - [2019-09-12 15:58:19,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:20,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:20,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:20,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:20,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 15:58:20,371] {scheduler_job.py:146} INFO - Started process (PID=29048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:25,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:25,377] {logging_mixin.py:95} INFO - [2019-09-12 15:58:25,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:25,737] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:25,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:25,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:25,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:58:25,824] {scheduler_job.py:146} INFO - Started process (PID=29050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:30,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:30,834] {logging_mixin.py:95} INFO - [2019-09-12 15:58:30,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:31,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:31,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:31,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:31,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-12 15:58:31,364] {scheduler_job.py:146} INFO - Started process (PID=29052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:36,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:36,375] {logging_mixin.py:95} INFO - [2019-09-12 15:58:36,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:36,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:36,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:36,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:36,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.518 seconds
[2019-09-12 15:58:36,914] {scheduler_job.py:146} INFO - Started process (PID=29062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:41,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:41,923] {logging_mixin.py:95} INFO - [2019-09-12 15:58:41,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:42,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:42,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:42,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:42,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 15:58:42,453] {scheduler_job.py:146} INFO - Started process (PID=29065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:47,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:47,464] {logging_mixin.py:95} INFO - [2019-09-12 15:58:47,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:47,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:47,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:47,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:47,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 15:58:48,003] {scheduler_job.py:146} INFO - Started process (PID=29069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:53,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:53,009] {logging_mixin.py:95} INFO - [2019-09-12 15:58:53,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:53,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:53,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:53,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:53,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-12 15:58:53,545] {scheduler_job.py:146} INFO - Started process (PID=29072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:58,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:58:58,551] {logging_mixin.py:95} INFO - [2019-09-12 15:58:58,551] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:58,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:58:58,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:58:58,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:58:58,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 15:58:59,087] {scheduler_job.py:146} INFO - Started process (PID=29074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:04,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:04,094] {logging_mixin.py:95} INFO - [2019-09-12 15:59:04,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:04,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:04,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:04,487] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:04,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 15:59:04,535] {scheduler_job.py:146} INFO - Started process (PID=29075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:09,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:09,543] {logging_mixin.py:95} INFO - [2019-09-12 15:59:09,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:09,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:09,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:09,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:09,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:59:09,987] {scheduler_job.py:146} INFO - Started process (PID=29076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:14,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:14,995] {logging_mixin.py:95} INFO - [2019-09-12 15:59:14,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:15,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:15,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:15,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:15,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 15:59:15,436] {scheduler_job.py:146} INFO - Started process (PID=29081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:20,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:20,443] {logging_mixin.py:95} INFO - [2019-09-12 15:59:20,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:20,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:20,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:20,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:20,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 15:59:20,881] {scheduler_job.py:146} INFO - Started process (PID=29082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:25,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:25,889] {logging_mixin.py:95} INFO - [2019-09-12 15:59:25,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:26,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:26,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:26,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:26,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 15:59:26,331] {scheduler_job.py:146} INFO - Started process (PID=29084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:31,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:31,342] {logging_mixin.py:95} INFO - [2019-09-12 15:59:31,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:31,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:31,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:31,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:31,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 15:59:31,779] {scheduler_job.py:146} INFO - Started process (PID=29088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:36,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:36,785] {logging_mixin.py:95} INFO - [2019-09-12 15:59:36,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:37,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:37,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:37,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:37,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 15:59:37,230] {scheduler_job.py:146} INFO - Started process (PID=29093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:42,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:42,241] {logging_mixin.py:95} INFO - [2019-09-12 15:59:42,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:42,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:42,623] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:42,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:42,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 15:59:42,682] {scheduler_job.py:146} INFO - Started process (PID=29095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:47,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:47,693] {logging_mixin.py:95} INFO - [2019-09-12 15:59:47,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:48,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:48,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:48,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:48,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 15:59:48,132] {scheduler_job.py:146} INFO - Started process (PID=29096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:53,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:53,142] {logging_mixin.py:95} INFO - [2019-09-12 15:59:53,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:53,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:53,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:53,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:53,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 15:59:53,681] {scheduler_job.py:146} INFO - Started process (PID=29100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:58,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 15:59:58,688] {logging_mixin.py:95} INFO - [2019-09-12 15:59:58,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:59,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 15:59:59,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 15:59:59,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 15:59:59,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 15:59:59,227] {scheduler_job.py:146} INFO - Started process (PID=29102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:04,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:04,239] {logging_mixin.py:95} INFO - [2019-09-12 16:00:04,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:04,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:04,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:04,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:04,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 16:00:04,778] {scheduler_job.py:146} INFO - Started process (PID=29103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:09,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:09,787] {logging_mixin.py:95} INFO - [2019-09-12 16:00:09,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:10,140] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:10,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:10,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:10,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:00:10,233] {scheduler_job.py:146} INFO - Started process (PID=29104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:15,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:15,244] {logging_mixin.py:95} INFO - [2019-09-12 16:00:15,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:15,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:15,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:15,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:15,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 16:00:15,678] {scheduler_job.py:146} INFO - Started process (PID=29109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:20,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:20,688] {logging_mixin.py:95} INFO - [2019-09-12 16:00:20,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:21,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:21,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:21,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:21,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:00:21,131] {scheduler_job.py:146} INFO - Started process (PID=29110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:26,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:26,138] {logging_mixin.py:95} INFO - [2019-09-12 16:00:26,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:26,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:26,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:26,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:26,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:00:26,688] {scheduler_job.py:146} INFO - Started process (PID=29112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:31,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:31,694] {logging_mixin.py:95} INFO - [2019-09-12 16:00:31,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:32,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:32,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:32,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:32,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 16:00:32,147] {scheduler_job.py:146} INFO - Started process (PID=29116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:37,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:37,156] {logging_mixin.py:95} INFO - [2019-09-12 16:00:37,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:37,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:37,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:37,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:37,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-12 16:00:37,607] {scheduler_job.py:146} INFO - Started process (PID=29118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:42,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:42,615] {logging_mixin.py:95} INFO - [2019-09-12 16:00:42,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:42,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:42,992] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:43,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:43,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:00:43,060] {scheduler_job.py:146} INFO - Started process (PID=29120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:48,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:48,069] {logging_mixin.py:95} INFO - [2019-09-12 16:00:48,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:48,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:48,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:48,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:48,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:00:48,519] {scheduler_job.py:146} INFO - Started process (PID=29124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:53,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:53,526] {logging_mixin.py:95} INFO - [2019-09-12 16:00:53,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:53,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:53,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:53,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:53,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 16:00:53,979] {scheduler_job.py:146} INFO - Started process (PID=29125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:58,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:00:58,987] {logging_mixin.py:95} INFO - [2019-09-12 16:00:58,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:59,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:00:59,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:00:59,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:00:59,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:00:59,433] {scheduler_job.py:146} INFO - Started process (PID=29130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:04,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:04,442] {logging_mixin.py:95} INFO - [2019-09-12 16:01:04,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:04,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:04,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:04,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:04,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:01:04,893] {scheduler_job.py:146} INFO - Started process (PID=29131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:09,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:09,900] {logging_mixin.py:95} INFO - [2019-09-12 16:01:09,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:10,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:10,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:10,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:10,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:01:10,352] {scheduler_job.py:146} INFO - Started process (PID=29132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:15,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:15,359] {logging_mixin.py:95} INFO - [2019-09-12 16:01:15,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:15,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:15,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:15,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:15,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:01:15,813] {scheduler_job.py:146} INFO - Started process (PID=29134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:20,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:20,819] {logging_mixin.py:95} INFO - [2019-09-12 16:01:20,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:21,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:21,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:21,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:21,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 16:01:21,266] {scheduler_job.py:146} INFO - Started process (PID=29138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:26,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:26,275] {logging_mixin.py:95} INFO - [2019-09-12 16:01:26,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:26,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:26,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:26,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:26,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:01:26,724] {scheduler_job.py:146} INFO - Started process (PID=29140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:31,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:31,731] {logging_mixin.py:95} INFO - [2019-09-12 16:01:31,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:32,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:32,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:32,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:32,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 16:01:32,175] {scheduler_job.py:146} INFO - Started process (PID=29141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:37,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:37,182] {logging_mixin.py:95} INFO - [2019-09-12 16:01:37,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:37,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:37,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:37,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:37,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:01:37,624] {scheduler_job.py:146} INFO - Started process (PID=29146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:42,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:42,633] {logging_mixin.py:95} INFO - [2019-09-12 16:01:42,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:42,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:43,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:43,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:43,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:01:43,082] {scheduler_job.py:146} INFO - Started process (PID=29148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:48,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:48,092] {logging_mixin.py:95} INFO - [2019-09-12 16:01:48,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:48,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:48,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:48,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:48,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:01:48,540] {scheduler_job.py:146} INFO - Started process (PID=29152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:53,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:53,549] {logging_mixin.py:95} INFO - [2019-09-12 16:01:53,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:53,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:53,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:53,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:53,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:01:53,988] {scheduler_job.py:146} INFO - Started process (PID=29153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:58,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:01:58,998] {logging_mixin.py:95} INFO - [2019-09-12 16:01:58,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:59,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:01:59,383] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:01:59,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:01:59,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:01:59,444] {scheduler_job.py:146} INFO - Started process (PID=29155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:04,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:04,453] {logging_mixin.py:95} INFO - [2019-09-12 16:02:04,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:04,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:04,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:04,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:04,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:02:04,895] {scheduler_job.py:146} INFO - Started process (PID=29159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:09,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:09,904] {logging_mixin.py:95} INFO - [2019-09-12 16:02:09,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:10,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:10,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:10,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:10,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 16:02:10,451] {scheduler_job.py:146} INFO - Started process (PID=29161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:15,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:15,458] {logging_mixin.py:95} INFO - [2019-09-12 16:02:15,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:15,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:15,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:15,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:15,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:02:15,895] {scheduler_job.py:146} INFO - Started process (PID=29162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:20,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:20,905] {logging_mixin.py:95} INFO - [2019-09-12 16:02:20,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:21,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:21,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:21,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:21,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 16:02:21,352] {scheduler_job.py:146} INFO - Started process (PID=29166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:26,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:26,359] {logging_mixin.py:95} INFO - [2019-09-12 16:02:26,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:26,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:26,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:26,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:26,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-12 16:02:26,900] {scheduler_job.py:146} INFO - Started process (PID=29168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:31,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:31,912] {logging_mixin.py:95} INFO - [2019-09-12 16:02:31,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:32,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:32,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:32,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:32,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:02:32,348] {scheduler_job.py:146} INFO - Started process (PID=29172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:37,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:37,357] {logging_mixin.py:95} INFO - [2019-09-12 16:02:37,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:37,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:37,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:37,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:37,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:02:37,793] {scheduler_job.py:146} INFO - Started process (PID=29174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:42,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:42,803] {logging_mixin.py:95} INFO - [2019-09-12 16:02:42,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:43,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:43,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:43,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:43,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:02:43,243] {scheduler_job.py:146} INFO - Started process (PID=29176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:48,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:48,251] {logging_mixin.py:95} INFO - [2019-09-12 16:02:48,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:48,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:48,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:48,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:48,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:02:48,698] {scheduler_job.py:146} INFO - Started process (PID=29177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:53,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:53,704] {logging_mixin.py:95} INFO - [2019-09-12 16:02:53,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:54,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:54,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:54,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:54,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-12 16:02:54,151] {scheduler_job.py:146} INFO - Started process (PID=29178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:59,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:02:59,160] {logging_mixin.py:95} INFO - [2019-09-12 16:02:59,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:59,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:02:59,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:02:59,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:02:59,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:02:59,611] {scheduler_job.py:146} INFO - Started process (PID=29183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:04,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:04,622] {logging_mixin.py:95} INFO - [2019-09-12 16:03:04,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:04,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:05,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:05,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:05,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:03:05,063] {scheduler_job.py:146} INFO - Started process (PID=29187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:10,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:10,070] {logging_mixin.py:95} INFO - [2019-09-12 16:03:10,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:10,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:10,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:10,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:10,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:03:10,523] {scheduler_job.py:146} INFO - Started process (PID=29189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:15,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:15,531] {logging_mixin.py:95} INFO - [2019-09-12 16:03:15,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:15,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:15,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:15,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:15,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:03:15,975] {scheduler_job.py:146} INFO - Started process (PID=29190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:20,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:20,985] {logging_mixin.py:95} INFO - [2019-09-12 16:03:20,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:21,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:21,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:21,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:21,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:03:21,430] {scheduler_job.py:146} INFO - Started process (PID=29192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:26,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:26,447] {logging_mixin.py:95} INFO - [2019-09-12 16:03:26,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:26,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:26,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:26,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:26,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 16:03:26,895] {scheduler_job.py:146} INFO - Started process (PID=29196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:31,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:31,905] {logging_mixin.py:95} INFO - [2019-09-12 16:03:31,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:32,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:32,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:32,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:32,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:03:32,346] {scheduler_job.py:146} INFO - Started process (PID=29197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:37,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:37,355] {logging_mixin.py:95} INFO - [2019-09-12 16:03:37,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:37,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:37,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:37,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:37,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:03:37,796] {scheduler_job.py:146} INFO - Started process (PID=29199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:42,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:42,804] {logging_mixin.py:95} INFO - [2019-09-12 16:03:42,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:43,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:43,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:43,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:43,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 16:03:43,254] {scheduler_job.py:146} INFO - Started process (PID=29204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:48,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:48,259] {logging_mixin.py:95} INFO - [2019-09-12 16:03:48,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:48,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:48,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:48,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:48,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 16:03:48,718] {scheduler_job.py:146} INFO - Started process (PID=29205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:53,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:53,725] {logging_mixin.py:95} INFO - [2019-09-12 16:03:53,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:54,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:54,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:54,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:54,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 16:03:54,178] {scheduler_job.py:146} INFO - Started process (PID=29209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:59,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:03:59,186] {logging_mixin.py:95} INFO - [2019-09-12 16:03:59,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:59,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:03:59,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:03:59,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:03:59,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:03:59,632] {scheduler_job.py:146} INFO - Started process (PID=29211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:04,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:04,642] {logging_mixin.py:95} INFO - [2019-09-12 16:04:04,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:04,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:05,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:05,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:05,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:04:05,093] {scheduler_job.py:146} INFO - Started process (PID=29212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:10,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:10,103] {logging_mixin.py:95} INFO - [2019-09-12 16:04:10,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:10,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:10,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:10,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:10,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:04:10,550] {scheduler_job.py:146} INFO - Started process (PID=29214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:15,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:15,560] {logging_mixin.py:95} INFO - [2019-09-12 16:04:15,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:15,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:15,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:15,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:15,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:04:16,005] {scheduler_job.py:146} INFO - Started process (PID=29218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:21,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:21,014] {logging_mixin.py:95} INFO - [2019-09-12 16:04:21,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:21,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:21,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:21,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:21,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:04:21,462] {scheduler_job.py:146} INFO - Started process (PID=29219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:26,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:26,471] {logging_mixin.py:95} INFO - [2019-09-12 16:04:26,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:26,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:26,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:26,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:26,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:04:26,917] {scheduler_job.py:146} INFO - Started process (PID=29221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:31,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:31,927] {logging_mixin.py:95} INFO - [2019-09-12 16:04:31,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:32,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:32,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:32,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:32,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:04:32,376] {scheduler_job.py:146} INFO - Started process (PID=29223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:37,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:37,387] {logging_mixin.py:95} INFO - [2019-09-12 16:04:37,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:37,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:37,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:37,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:37,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:04:37,833] {scheduler_job.py:146} INFO - Started process (PID=29227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:42,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:42,843] {logging_mixin.py:95} INFO - [2019-09-12 16:04:42,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:43,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:43,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:43,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:43,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:04:43,282] {scheduler_job.py:146} INFO - Started process (PID=29233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:48,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:48,290] {logging_mixin.py:95} INFO - [2019-09-12 16:04:48,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:48,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:48,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:48,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:48,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:04:48,734] {scheduler_job.py:146} INFO - Started process (PID=29235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:53,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:53,743] {logging_mixin.py:95} INFO - [2019-09-12 16:04:53,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:54,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:54,168] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:54,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:54,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-12 16:04:54,286] {scheduler_job.py:146} INFO - Started process (PID=29236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:59,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:04:59,295] {logging_mixin.py:95} INFO - [2019-09-12 16:04:59,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:59,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:04:59,690] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:04:59,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:04:59,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 16:04:59,731] {scheduler_job.py:146} INFO - Started process (PID=29241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:04,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:04,743] {logging_mixin.py:95} INFO - [2019-09-12 16:05:04,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:05,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:05,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:05,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:05,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:05:05,181] {scheduler_job.py:146} INFO - Started process (PID=29242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:10,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:10,189] {logging_mixin.py:95} INFO - [2019-09-12 16:05:10,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:10,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:10,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:10,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:10,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 16:05:10,633] {scheduler_job.py:146} INFO - Started process (PID=29244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:15,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:15,641] {logging_mixin.py:95} INFO - [2019-09-12 16:05:15,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:16,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:16,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:16,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:16,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:05:16,086] {scheduler_job.py:146} INFO - Started process (PID=29245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:21,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:21,097] {logging_mixin.py:95} INFO - [2019-09-12 16:05:21,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:21,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:21,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:21,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:21,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:05:21,540] {scheduler_job.py:146} INFO - Started process (PID=29249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:26,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:26,556] {logging_mixin.py:95} INFO - [2019-09-12 16:05:26,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:26,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:26,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:26,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:26,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:05:26,999] {scheduler_job.py:146} INFO - Started process (PID=29251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:32,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:32,009] {logging_mixin.py:95} INFO - [2019-09-12 16:05:32,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:32,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:32,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:32,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:32,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:05:32,455] {scheduler_job.py:146} INFO - Started process (PID=29255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:37,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:37,466] {logging_mixin.py:95} INFO - [2019-09-12 16:05:37,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:37,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:37,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:37,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:37,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:05:37,919] {scheduler_job.py:146} INFO - Started process (PID=29257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:42,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:42,928] {logging_mixin.py:95} INFO - [2019-09-12 16:05:42,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:43,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:43,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:43,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:43,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 16:05:43,375] {scheduler_job.py:146} INFO - Started process (PID=29259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:48,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:48,383] {logging_mixin.py:95} INFO - [2019-09-12 16:05:48,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:48,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:48,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:48,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:48,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:05:48,829] {scheduler_job.py:146} INFO - Started process (PID=29260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:53,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:53,837] {logging_mixin.py:95} INFO - [2019-09-12 16:05:53,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:54,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:54,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:54,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:54,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:05:54,284] {scheduler_job.py:146} INFO - Started process (PID=29264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:59,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:05:59,294] {logging_mixin.py:95} INFO - [2019-09-12 16:05:59,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:59,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:05:59,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:05:59,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:05:59,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:05:59,737] {scheduler_job.py:146} INFO - Started process (PID=29266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:04,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:04,747] {logging_mixin.py:95} INFO - [2019-09-12 16:06:04,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:05,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:05,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:05,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:05,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:06:05,195] {scheduler_job.py:146} INFO - Started process (PID=29270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:10,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:10,205] {logging_mixin.py:95} INFO - [2019-09-12 16:06:10,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:10,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:10,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:10,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:10,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:06:10,653] {scheduler_job.py:146} INFO - Started process (PID=29272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:15,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:15,664] {logging_mixin.py:95} INFO - [2019-09-12 16:06:15,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:16,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:16,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:16,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:16,052] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:06:16,114] {scheduler_job.py:146} INFO - Started process (PID=29273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:21,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:21,121] {logging_mixin.py:95} INFO - [2019-09-12 16:06:21,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:21,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:21,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:21,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:21,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:06:21,565] {scheduler_job.py:146} INFO - Started process (PID=29274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:26,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:26,575] {logging_mixin.py:95} INFO - [2019-09-12 16:06:26,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:26,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:26,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:26,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:26,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 16:06:27,010] {scheduler_job.py:146} INFO - Started process (PID=29279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:32,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:32,020] {logging_mixin.py:95} INFO - [2019-09-12 16:06:32,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:32,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:32,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:32,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:32,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:06:32,462] {scheduler_job.py:146} INFO - Started process (PID=29281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:37,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:37,472] {logging_mixin.py:95} INFO - [2019-09-12 16:06:37,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:37,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:37,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:37,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:37,866] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:06:37,921] {scheduler_job.py:146} INFO - Started process (PID=29285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:42,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:42,926] {logging_mixin.py:95} INFO - [2019-09-12 16:06:42,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:43,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:43,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:43,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:43,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:06:43,368] {scheduler_job.py:146} INFO - Started process (PID=29291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:48,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:48,374] {logging_mixin.py:95} INFO - [2019-09-12 16:06:48,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:48,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:48,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:48,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:48,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 16:06:48,913] {scheduler_job.py:146} INFO - Started process (PID=29295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:53,918] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:53,919] {logging_mixin.py:95} INFO - [2019-09-12 16:06:53,919] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:54,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:54,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:54,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:54,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:06:54,365] {scheduler_job.py:146} INFO - Started process (PID=29296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:59,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:06:59,373] {logging_mixin.py:95} INFO - [2019-09-12 16:06:59,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:59,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:06:59,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:06:59,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:06:59,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-12 16:06:59,899] {scheduler_job.py:146} INFO - Started process (PID=29300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:04,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:04,909] {logging_mixin.py:95} INFO - [2019-09-12 16:07:04,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:05,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:05,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:05,406] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:05,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.514 seconds
[2019-09-12 16:07:05,443] {scheduler_job.py:146} INFO - Started process (PID=29308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:10,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:10,453] {logging_mixin.py:95} INFO - [2019-09-12 16:07:10,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:10,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:10,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:10,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:10,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-12 16:07:10,973] {scheduler_job.py:146} INFO - Started process (PID=29310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:15,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:15,981] {logging_mixin.py:95} INFO - [2019-09-12 16:07:15,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:16,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:16,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:16,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:16,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 16:07:16,513] {scheduler_job.py:146} INFO - Started process (PID=29311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:21,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:21,524] {logging_mixin.py:95} INFO - [2019-09-12 16:07:21,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:21,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:21,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:21,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:21,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-12 16:07:22,051] {scheduler_job.py:146} INFO - Started process (PID=29315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:27,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:27,085] {logging_mixin.py:95} INFO - [2019-09-12 16:07:27,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:27,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:27,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:27,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:27,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-12 16:07:27,589] {scheduler_job.py:146} INFO - Started process (PID=29317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:32,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:32,598] {logging_mixin.py:95} INFO - [2019-09-12 16:07:32,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:32,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:33,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:33,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:33,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:07:33,136] {scheduler_job.py:146} INFO - Started process (PID=29318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:38,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:38,144] {logging_mixin.py:95} INFO - [2019-09-12 16:07:38,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:38,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:38,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:38,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:38,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 16:07:38,681] {scheduler_job.py:146} INFO - Started process (PID=29320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:43,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:43,689] {logging_mixin.py:95} INFO - [2019-09-12 16:07:43,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:44,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:44,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:44,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:44,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 16:07:44,216] {scheduler_job.py:146} INFO - Started process (PID=29322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:49,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:49,227] {logging_mixin.py:95} INFO - [2019-09-12 16:07:49,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:49,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:49,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:49,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:49,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 16:07:49,757] {scheduler_job.py:146} INFO - Started process (PID=29326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:54,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:07:54,762] {logging_mixin.py:95} INFO - [2019-09-12 16:07:54,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:55,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:07:55,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:07:55,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:07:55,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-12 16:07:55,298] {scheduler_job.py:146} INFO - Started process (PID=29330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:00,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:00,305] {logging_mixin.py:95} INFO - [2019-09-12 16:08:00,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:00,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:00,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:00,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:00,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 16:08:00,835] {scheduler_job.py:146} INFO - Started process (PID=29332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:05,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:05,842] {logging_mixin.py:95} INFO - [2019-09-12 16:08:05,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:06,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:06,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:06,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:06,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-12 16:08:06,373] {scheduler_job.py:146} INFO - Started process (PID=29333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:11,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:11,381] {logging_mixin.py:95} INFO - [2019-09-12 16:08:11,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:11,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:11,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:11,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:11,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 16:08:11,906] {scheduler_job.py:146} INFO - Started process (PID=29338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:16,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:16,914] {logging_mixin.py:95} INFO - [2019-09-12 16:08:16,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:17,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:17,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:17,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:17,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-09-12 16:08:17,451] {scheduler_job.py:146} INFO - Started process (PID=29339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:22,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:22,460] {logging_mixin.py:95} INFO - [2019-09-12 16:08:22,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:22,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:22,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:22,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:22,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 16:08:22,986] {scheduler_job.py:146} INFO - Started process (PID=29340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:27,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:27,996] {logging_mixin.py:95} INFO - [2019-09-12 16:08:27,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:28,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:28,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:28,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:28,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-12 16:08:28,526] {scheduler_job.py:146} INFO - Started process (PID=29345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:33,536] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:33,537] {logging_mixin.py:95} INFO - [2019-09-12 16:08:33,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:33,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:33,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:33,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:33,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 16:08:34,068] {scheduler_job.py:146} INFO - Started process (PID=29346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:39,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:39,077] {logging_mixin.py:95} INFO - [2019-09-12 16:08:39,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:39,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:39,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:39,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:39,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 16:08:39,609] {scheduler_job.py:146} INFO - Started process (PID=29348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:44,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:44,620] {logging_mixin.py:95} INFO - [2019-09-12 16:08:44,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:45,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:45,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:45,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:45,058] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 16:08:45,149] {scheduler_job.py:146} INFO - Started process (PID=29350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:50,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:50,158] {logging_mixin.py:95} INFO - [2019-09-12 16:08:50,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:50,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:50,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:50,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:50,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 16:08:50,693] {scheduler_job.py:146} INFO - Started process (PID=29354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:55,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:08:55,699] {logging_mixin.py:95} INFO - [2019-09-12 16:08:55,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:56,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:08:56,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:08:56,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:08:56,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:08:56,232] {scheduler_job.py:146} INFO - Started process (PID=29356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:01,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:01,241] {logging_mixin.py:95} INFO - [2019-09-12 16:09:01,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:01,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:01,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:01,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:01,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 16:09:01,771] {scheduler_job.py:146} INFO - Started process (PID=29360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:06,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:06,778] {logging_mixin.py:95} INFO - [2019-09-12 16:09:06,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:07,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:07,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:07,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:07,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-12 16:09:07,310] {scheduler_job.py:146} INFO - Started process (PID=29361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:12,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:12,318] {logging_mixin.py:95} INFO - [2019-09-12 16:09:12,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:12,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:12,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:12,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:12,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:09:12,849] {scheduler_job.py:146} INFO - Started process (PID=29363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:17,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:17,859] {logging_mixin.py:95} INFO - [2019-09-12 16:09:17,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:18,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:18,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:18,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:18,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-12 16:09:18,393] {scheduler_job.py:146} INFO - Started process (PID=29368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:23,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:23,403] {logging_mixin.py:95} INFO - [2019-09-12 16:09:23,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:23,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:23,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:23,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:23,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 16:09:23,931] {scheduler_job.py:146} INFO - Started process (PID=29369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:28,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:28,937] {logging_mixin.py:95} INFO - [2019-09-12 16:09:28,937] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:29,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:29,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:29,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:29,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:09:29,473] {scheduler_job.py:146} INFO - Started process (PID=29371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:34,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:34,481] {logging_mixin.py:95} INFO - [2019-09-12 16:09:34,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:34,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:34,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:34,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:34,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:09:35,014] {scheduler_job.py:146} INFO - Started process (PID=29376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:40,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:40,024] {logging_mixin.py:95} INFO - [2019-09-12 16:09:40,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:40,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:40,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:40,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:40,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:09:40,451] {scheduler_job.py:146} INFO - Started process (PID=29378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:45,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:45,458] {logging_mixin.py:95} INFO - [2019-09-12 16:09:45,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:45,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:45,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:45,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:45,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 16:09:45,894] {scheduler_job.py:146} INFO - Started process (PID=29380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:50,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:50,905] {logging_mixin.py:95} INFO - [2019-09-12 16:09:50,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:51,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:51,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:51,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:51,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-12 16:09:51,440] {scheduler_job.py:146} INFO - Started process (PID=29384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:56,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:09:56,451] {logging_mixin.py:95} INFO - [2019-09-12 16:09:56,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:56,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:09:56,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:09:56,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:09:56,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-12 16:09:56,986] {scheduler_job.py:146} INFO - Started process (PID=29386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:01,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:01,996] {logging_mixin.py:95} INFO - [2019-09-12 16:10:01,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:02,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:02,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:02,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:02,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:10:02,527] {scheduler_job.py:146} INFO - Started process (PID=29387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:07,536] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:07,537] {logging_mixin.py:95} INFO - [2019-09-12 16:10:07,537] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:07,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:07,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:07,962] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:07,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 16:10:08,066] {scheduler_job.py:146} INFO - Started process (PID=29389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:13,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:13,075] {logging_mixin.py:95} INFO - [2019-09-12 16:10:13,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:13,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:13,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:13,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:13,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:10:13,609] {scheduler_job.py:146} INFO - Started process (PID=29393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:18,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:18,617] {logging_mixin.py:95} INFO - [2019-09-12 16:10:18,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:19,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:19,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:19,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:19,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 16:10:19,152] {scheduler_job.py:146} INFO - Started process (PID=29397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:24,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:24,162] {logging_mixin.py:95} INFO - [2019-09-12 16:10:24,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:24,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:24,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:24,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:24,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-12 16:10:24,696] {scheduler_job.py:146} INFO - Started process (PID=29398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:29,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:29,702] {logging_mixin.py:95} INFO - [2019-09-12 16:10:29,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:30,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:30,115] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:30,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:30,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:10:30,234] {scheduler_job.py:146} INFO - Started process (PID=29400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:35,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:35,244] {logging_mixin.py:95} INFO - [2019-09-12 16:10:35,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:35,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:35,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:35,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:35,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 16:10:35,776] {scheduler_job.py:146} INFO - Started process (PID=29401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:40,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:40,793] {logging_mixin.py:95} INFO - [2019-09-12 16:10:40,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:41,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:41,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:41,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:41,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:10:41,324] {scheduler_job.py:146} INFO - Started process (PID=29407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:46,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:46,333] {logging_mixin.py:95} INFO - [2019-09-12 16:10:46,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:46,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:46,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:46,763] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:46,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-12 16:10:46,866] {scheduler_job.py:146} INFO - Started process (PID=29408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:51,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:51,875] {logging_mixin.py:95} INFO - [2019-09-12 16:10:51,875] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:52,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:52,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:52,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:52,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 16:10:52,403] {scheduler_job.py:146} INFO - Started process (PID=29409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:57,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:10:57,414] {logging_mixin.py:95} INFO - [2019-09-12 16:10:57,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:57,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:10:57,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:10:57,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:10:57,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-12 16:10:57,943] {scheduler_job.py:146} INFO - Started process (PID=29414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:02,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:02,951] {logging_mixin.py:95} INFO - [2019-09-12 16:11:02,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:03,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:03,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:03,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:03,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-12 16:11:03,478] {scheduler_job.py:146} INFO - Started process (PID=29415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:08,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:08,484] {logging_mixin.py:95} INFO - [2019-09-12 16:11:08,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:08,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:08,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:08,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:08,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.496 seconds
[2019-09-12 16:11:09,011] {scheduler_job.py:146} INFO - Started process (PID=29419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:14,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:14,021] {logging_mixin.py:95} INFO - [2019-09-12 16:11:14,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:14,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:14,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:14,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:14,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-12 16:11:14,551] {scheduler_job.py:146} INFO - Started process (PID=29421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:19,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:19,562] {logging_mixin.py:95} INFO - [2019-09-12 16:11:19,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:19,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:19,977] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:19,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:19,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:11:20,088] {scheduler_job.py:146} INFO - Started process (PID=29422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:25,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:25,096] {logging_mixin.py:95} INFO - [2019-09-12 16:11:25,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:25,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:25,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:25,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:25,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-12 16:11:25,630] {scheduler_job.py:146} INFO - Started process (PID=29426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:30,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:30,640] {logging_mixin.py:95} INFO - [2019-09-12 16:11:30,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:31,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:31,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:31,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:31,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 16:11:31,176] {scheduler_job.py:146} INFO - Started process (PID=29428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:36,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:36,187] {logging_mixin.py:95} INFO - [2019-09-12 16:11:36,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:36,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:36,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:36,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:36,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 16:11:36,717] {scheduler_job.py:146} INFO - Started process (PID=29429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:41,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:41,727] {logging_mixin.py:95} INFO - [2019-09-12 16:11:41,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:42,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:42,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:42,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:42,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 16:11:42,256] {scheduler_job.py:146} INFO - Started process (PID=29435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:47,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:47,266] {logging_mixin.py:95} INFO - [2019-09-12 16:11:47,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:47,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:47,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:47,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:47,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:11:47,798] {scheduler_job.py:146} INFO - Started process (PID=29436) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:52,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:52,807] {logging_mixin.py:95} INFO - [2019-09-12 16:11:52,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:53,195] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:53,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:53,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:53,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-12 16:11:53,339] {scheduler_job.py:146} INFO - Started process (PID=29437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:58,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:11:58,348] {logging_mixin.py:95} INFO - [2019-09-12 16:11:58,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:58,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:11:58,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:11:58,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:11:58,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-12 16:11:58,875] {scheduler_job.py:146} INFO - Started process (PID=29442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:03,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:03,881] {logging_mixin.py:95} INFO - [2019-09-12 16:12:03,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:04,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:04,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:04,321] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:04,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-12 16:12:04,413] {scheduler_job.py:146} INFO - Started process (PID=29443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:09,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:09,422] {logging_mixin.py:95} INFO - [2019-09-12 16:12:09,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:09,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:09,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:09,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:09,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.523 seconds
[2019-09-12 16:12:10,049] {scheduler_job.py:146} INFO - Started process (PID=29447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:15,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:15,056] {logging_mixin.py:95} INFO - [2019-09-12 16:12:15,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:15,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:15,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:15,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:15,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-12 16:12:15,578] {scheduler_job.py:146} INFO - Started process (PID=29449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:20,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:20,589] {logging_mixin.py:95} INFO - [2019-09-12 16:12:20,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:20,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:20,988] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:21,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:21,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 16:12:21,118] {scheduler_job.py:146} INFO - Started process (PID=29450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:26,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:26,125] {logging_mixin.py:95} INFO - [2019-09-12 16:12:26,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:26,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:26,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:26,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:26,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-12 16:12:26,648] {scheduler_job.py:146} INFO - Started process (PID=29452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:31,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:31,658] {logging_mixin.py:95} INFO - [2019-09-12 16:12:31,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:32,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:32,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:32,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:32,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-12 16:12:32,186] {scheduler_job.py:146} INFO - Started process (PID=29453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:37,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:37,193] {logging_mixin.py:95} INFO - [2019-09-12 16:12:37,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:37,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:37,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:37,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:37,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:12:37,725] {scheduler_job.py:146} INFO - Started process (PID=29458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:42,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:42,734] {logging_mixin.py:95} INFO - [2019-09-12 16:12:42,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:43,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:43,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:43,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:43,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:12:43,268] {scheduler_job.py:146} INFO - Started process (PID=29460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:48,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:48,279] {logging_mixin.py:95} INFO - [2019-09-12 16:12:48,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:48,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:48,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:48,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:48,725] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-12 16:12:48,806] {scheduler_job.py:146} INFO - Started process (PID=29464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:53,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:53,816] {logging_mixin.py:95} INFO - [2019-09-12 16:12:53,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:54,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:54,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:54,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:54,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:12:54,345] {scheduler_job.py:146} INFO - Started process (PID=29465) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:59,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:12:59,353] {logging_mixin.py:95} INFO - [2019-09-12 16:12:59,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:59,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:12:59,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:12:59,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:12:59,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:12:59,889] {scheduler_job.py:146} INFO - Started process (PID=29467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:04,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:04,898] {logging_mixin.py:95} INFO - [2019-09-12 16:13:04,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:05,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:05,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:05,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:05,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 16:13:05,429] {scheduler_job.py:146} INFO - Started process (PID=29471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:10,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:10,440] {logging_mixin.py:95} INFO - [2019-09-12 16:13:10,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:10,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:10,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:10,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:10,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 16:13:10,969] {scheduler_job.py:146} INFO - Started process (PID=29473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:15,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:15,975] {logging_mixin.py:95} INFO - [2019-09-12 16:13:15,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:16,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:16,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:16,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:16,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-12 16:13:16,510] {scheduler_job.py:146} INFO - Started process (PID=29477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:21,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:21,518] {logging_mixin.py:95} INFO - [2019-09-12 16:13:21,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:21,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:21,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:21,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:21,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 16:13:22,044] {scheduler_job.py:146} INFO - Started process (PID=29478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:27,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:27,054] {logging_mixin.py:95} INFO - [2019-09-12 16:13:27,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:27,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:27,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:27,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:27,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:13:27,583] {scheduler_job.py:146} INFO - Started process (PID=29480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:32,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:32,590] {logging_mixin.py:95} INFO - [2019-09-12 16:13:32,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:32,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:33,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:33,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:33,050] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-12 16:13:33,119] {scheduler_job.py:146} INFO - Started process (PID=29484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:38,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:38,128] {logging_mixin.py:95} INFO - [2019-09-12 16:13:38,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:38,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:38,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:38,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:38,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.550 seconds
[2019-09-12 16:13:38,752] {scheduler_job.py:146} INFO - Started process (PID=29486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:43,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:43,761] {logging_mixin.py:95} INFO - [2019-09-12 16:13:43,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:44,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:44,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:44,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:44,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:13:44,285] {scheduler_job.py:146} INFO - Started process (PID=29488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:49,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:49,292] {logging_mixin.py:95} INFO - [2019-09-12 16:13:49,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:49,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:49,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:49,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:49,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:13:49,737] {scheduler_job.py:146} INFO - Started process (PID=29489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:54,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:13:54,746] {logging_mixin.py:95} INFO - [2019-09-12 16:13:54,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:55,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:13:55,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:13:55,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:13:55,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 16:13:55,186] {scheduler_job.py:146} INFO - Started process (PID=29493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:00,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:00,197] {logging_mixin.py:95} INFO - [2019-09-12 16:14:00,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:00,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:00,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:00,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:00,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:14:00,634] {scheduler_job.py:146} INFO - Started process (PID=29495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:05,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:05,643] {logging_mixin.py:95} INFO - [2019-09-12 16:14:05,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:05,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:06,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:06,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:06,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:14:06,086] {scheduler_job.py:146} INFO - Started process (PID=29499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:11,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:11,096] {logging_mixin.py:95} INFO - [2019-09-12 16:14:11,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:11,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:11,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:11,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:11,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:14:11,536] {scheduler_job.py:146} INFO - Started process (PID=29501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:16,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:16,544] {logging_mixin.py:95} INFO - [2019-09-12 16:14:16,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:16,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:16,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:16,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:16,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:14:16,991] {scheduler_job.py:146} INFO - Started process (PID=29502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:21,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:22,001] {logging_mixin.py:95} INFO - [2019-09-12 16:14:22,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:22,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:22,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:22,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:22,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:14:22,445] {scheduler_job.py:146} INFO - Started process (PID=29506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:27,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:27,452] {logging_mixin.py:95} INFO - [2019-09-12 16:14:27,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:27,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:27,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:27,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:27,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:14:27,901] {scheduler_job.py:146} INFO - Started process (PID=29508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:32,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:32,912] {logging_mixin.py:95} INFO - [2019-09-12 16:14:32,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:33,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:33,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:33,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:33,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:14:33,356] {scheduler_job.py:146} INFO - Started process (PID=29512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:38,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:38,362] {logging_mixin.py:95} INFO - [2019-09-12 16:14:38,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:38,720] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:38,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:38,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:38,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:14:38,810] {scheduler_job.py:146} INFO - Started process (PID=29514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:43,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:43,820] {logging_mixin.py:95} INFO - [2019-09-12 16:14:43,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:44,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:44,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:44,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:44,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:14:44,259] {scheduler_job.py:146} INFO - Started process (PID=29516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:49,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:49,268] {logging_mixin.py:95} INFO - [2019-09-12 16:14:49,267] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:49,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:49,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:49,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:49,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:14:49,715] {scheduler_job.py:146} INFO - Started process (PID=29517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:54,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:14:54,724] {logging_mixin.py:95} INFO - [2019-09-12 16:14:54,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:55,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:14:55,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:14:55,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:14:55,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:14:55,163] {scheduler_job.py:146} INFO - Started process (PID=29521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:00,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:00,175] {logging_mixin.py:95} INFO - [2019-09-12 16:15:00,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:00,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:00,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:00,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:00,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:15:00,608] {scheduler_job.py:146} INFO - Started process (PID=29523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:05,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:05,615] {logging_mixin.py:95} INFO - [2019-09-12 16:15:05,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:05,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:06,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:06,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:06,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:15:06,060] {scheduler_job.py:146} INFO - Started process (PID=29524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:11,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:11,068] {logging_mixin.py:95} INFO - [2019-09-12 16:15:11,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:11,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:11,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:11,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:11,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:15:11,509] {scheduler_job.py:146} INFO - Started process (PID=29526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:16,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:16,520] {logging_mixin.py:95} INFO - [2019-09-12 16:15:16,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:16,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:16,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:16,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:16,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:15:16,960] {scheduler_job.py:146} INFO - Started process (PID=29530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:21,968] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:21,969] {logging_mixin.py:95} INFO - [2019-09-12 16:15:21,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:22,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:22,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:22,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:22,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:15:22,411] {scheduler_job.py:146} INFO - Started process (PID=29531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:27,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:27,422] {logging_mixin.py:95} INFO - [2019-09-12 16:15:27,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:27,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:27,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:27,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:27,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:15:27,859] {scheduler_job.py:146} INFO - Started process (PID=29536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:32,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:32,869] {logging_mixin.py:95} INFO - [2019-09-12 16:15:32,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:33,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:33,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:33,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:33,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:15:33,310] {scheduler_job.py:146} INFO - Started process (PID=29537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:38,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:38,320] {logging_mixin.py:95} INFO - [2019-09-12 16:15:38,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:38,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:38,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:38,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:38,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:15:38,760] {scheduler_job.py:146} INFO - Started process (PID=29539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:43,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:43,770] {logging_mixin.py:95} INFO - [2019-09-12 16:15:43,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:44,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:44,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:44,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:44,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:15:44,218] {scheduler_job.py:146} INFO - Started process (PID=29544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:49,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:49,225] {logging_mixin.py:95} INFO - [2019-09-12 16:15:49,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:49,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:49,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:49,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:49,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:15:49,669] {scheduler_job.py:146} INFO - Started process (PID=29545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:54,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:15:54,677] {logging_mixin.py:95} INFO - [2019-09-12 16:15:54,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:55,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:15:55,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:15:55,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:15:55,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:15:55,125] {scheduler_job.py:146} INFO - Started process (PID=29549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:00,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:00,135] {logging_mixin.py:95} INFO - [2019-09-12 16:16:00,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:00,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:00,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:00,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:00,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:16:00,567] {scheduler_job.py:146} INFO - Started process (PID=29551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:05,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:05,576] {logging_mixin.py:95} INFO - [2019-09-12 16:16:05,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:05,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:05,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:05,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:05,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:16:06,016] {scheduler_job.py:146} INFO - Started process (PID=29552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:11,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:11,025] {logging_mixin.py:95} INFO - [2019-09-12 16:16:11,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:11,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:11,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:11,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:11,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:16:11,472] {scheduler_job.py:146} INFO - Started process (PID=29554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:16,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:16,481] {logging_mixin.py:95} INFO - [2019-09-12 16:16:16,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:16,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:16,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:16,869] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:16,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:16:16,924] {scheduler_job.py:146} INFO - Started process (PID=29558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:21,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:21,935] {logging_mixin.py:95} INFO - [2019-09-12 16:16:21,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:22,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:22,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:22,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:22,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:16:22,376] {scheduler_job.py:146} INFO - Started process (PID=29559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:27,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:27,385] {logging_mixin.py:95} INFO - [2019-09-12 16:16:27,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:27,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:27,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:27,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:27,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:16:27,828] {scheduler_job.py:146} INFO - Started process (PID=29564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:32,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:32,838] {logging_mixin.py:95} INFO - [2019-09-12 16:16:32,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:33,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:33,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:33,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:33,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:16:33,379] {scheduler_job.py:146} INFO - Started process (PID=29565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:38,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:38,386] {logging_mixin.py:95} INFO - [2019-09-12 16:16:38,386] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:38,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:38,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:38,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:38,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 16:16:38,923] {scheduler_job.py:146} INFO - Started process (PID=29567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:43,931] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:43,933] {logging_mixin.py:95} INFO - [2019-09-12 16:16:43,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:44,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:44,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:44,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:44,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:16:44,462] {scheduler_job.py:146} INFO - Started process (PID=29569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:49,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:49,473] {logging_mixin.py:95} INFO - [2019-09-12 16:16:49,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:49,862] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:49,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:49,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:49,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:16:49,998] {scheduler_job.py:146} INFO - Started process (PID=29573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:55,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:16:55,005] {logging_mixin.py:95} INFO - [2019-09-12 16:16:55,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:55,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:16:55,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:16:55,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:16:55,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 16:16:55,538] {scheduler_job.py:146} INFO - Started process (PID=29574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:00,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:00,547] {logging_mixin.py:95} INFO - [2019-09-12 16:17:00,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:00,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:00,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:00,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:00,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 16:17:00,987] {scheduler_job.py:146} INFO - Started process (PID=29576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:05,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:05,993] {logging_mixin.py:95} INFO - [2019-09-12 16:17:05,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:06,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:06,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:06,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:06,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 16:17:06,528] {scheduler_job.py:146} INFO - Started process (PID=29580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:11,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:11,539] {logging_mixin.py:95} INFO - [2019-09-12 16:17:11,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:11,925] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:11,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:11,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:11,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:17:12,067] {scheduler_job.py:146} INFO - Started process (PID=29582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:17,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:17,077] {logging_mixin.py:95} INFO - [2019-09-12 16:17:17,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:17,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:17,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:17,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:17,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-12 16:17:17,607] {scheduler_job.py:146} INFO - Started process (PID=29586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:22,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:22,617] {logging_mixin.py:95} INFO - [2019-09-12 16:17:22,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:23,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:23,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:23,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:23,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:17:23,148] {scheduler_job.py:146} INFO - Started process (PID=29587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:28,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:28,158] {logging_mixin.py:95} INFO - [2019-09-12 16:17:28,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:28,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:28,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:28,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:28,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-09-12 16:17:28,695] {scheduler_job.py:146} INFO - Started process (PID=29592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:33,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:33,705] {logging_mixin.py:95} INFO - [2019-09-12 16:17:33,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:34,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:34,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:34,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:34,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 16:17:34,135] {scheduler_job.py:146} INFO - Started process (PID=29593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:39,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:39,144] {logging_mixin.py:95} INFO - [2019-09-12 16:17:39,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:39,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:39,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:39,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:39,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:17:39,588] {scheduler_job.py:146} INFO - Started process (PID=29595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:44,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:44,595] {logging_mixin.py:95} INFO - [2019-09-12 16:17:44,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:44,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:44,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:44,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:44,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:17:45,033] {scheduler_job.py:146} INFO - Started process (PID=29597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:50,041] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:50,042] {logging_mixin.py:95} INFO - [2019-09-12 16:17:50,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:50,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:50,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:50,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:50,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:17:50,566] {scheduler_job.py:146} INFO - Started process (PID=29601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:55,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:17:55,576] {logging_mixin.py:95} INFO - [2019-09-12 16:17:55,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:55,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:17:55,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:17:56,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:17:56,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:17:56,105] {scheduler_job.py:146} INFO - Started process (PID=29602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:01,111] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:01,112] {logging_mixin.py:95} INFO - [2019-09-12 16:18:01,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:01,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:01,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:01,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:01,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:18:01,645] {scheduler_job.py:146} INFO - Started process (PID=29604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:06,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:06,653] {logging_mixin.py:95} INFO - [2019-09-12 16:18:06,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:07,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:07,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:07,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:07,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:18:07,182] {scheduler_job.py:146} INFO - Started process (PID=29608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:12,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:12,189] {logging_mixin.py:95} INFO - [2019-09-12 16:18:12,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:12,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:12,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:12,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:12,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:18:12,720] {scheduler_job.py:146} INFO - Started process (PID=29610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:17,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:17,727] {logging_mixin.py:95} INFO - [2019-09-12 16:18:17,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:18,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:18,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:18,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:18,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:18:18,260] {scheduler_job.py:146} INFO - Started process (PID=29614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:23,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:23,269] {logging_mixin.py:95} INFO - [2019-09-12 16:18:23,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:23,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:23,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:23,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:23,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:18:23,807] {scheduler_job.py:146} INFO - Started process (PID=29615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:28,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:28,827] {logging_mixin.py:95} INFO - [2019-09-12 16:18:28,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:29,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:29,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:29,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:29,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-12 16:18:29,345] {scheduler_job.py:146} INFO - Started process (PID=29617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:34,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:34,354] {logging_mixin.py:95} INFO - [2019-09-12 16:18:34,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:34,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:34,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:34,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:34,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-12 16:18:34,881] {scheduler_job.py:146} INFO - Started process (PID=29618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:39,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:39,891] {logging_mixin.py:95} INFO - [2019-09-12 16:18:39,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:40,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:40,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:40,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:40,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:18:40,424] {scheduler_job.py:146} INFO - Started process (PID=29623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:45,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:45,433] {logging_mixin.py:95} INFO - [2019-09-12 16:18:45,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:45,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:45,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:45,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:45,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:18:45,963] {scheduler_job.py:146} INFO - Started process (PID=29625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:50,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:50,970] {logging_mixin.py:95} INFO - [2019-09-12 16:18:50,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:51,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:51,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:51,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:51,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:18:51,500] {scheduler_job.py:146} INFO - Started process (PID=29626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:56,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:18:56,511] {logging_mixin.py:95} INFO - [2019-09-12 16:18:56,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:56,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:18:56,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:18:56,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:18:56,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-12 16:18:57,040] {scheduler_job.py:146} INFO - Started process (PID=29631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:02,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:02,051] {logging_mixin.py:95} INFO - [2019-09-12 16:19:02,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:02,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:02,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:02,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:02,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-12 16:19:02,579] {scheduler_job.py:146} INFO - Started process (PID=29632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:07,586] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:07,587] {logging_mixin.py:95} INFO - [2019-09-12 16:19:07,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:07,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:08,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:08,014] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:08,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 16:19:08,115] {scheduler_job.py:146} INFO - Started process (PID=29636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:13,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:13,124] {logging_mixin.py:95} INFO - [2019-09-12 16:19:13,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:13,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:13,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:13,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:13,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:19:13,655] {scheduler_job.py:146} INFO - Started process (PID=29638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:18,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:18,666] {logging_mixin.py:95} INFO - [2019-09-12 16:19:18,665] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:19,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:19,078] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:19,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:19,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:19:19,194] {scheduler_job.py:146} INFO - Started process (PID=29639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:24,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:24,204] {logging_mixin.py:95} INFO - [2019-09-12 16:19:24,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:24,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:24,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:24,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:24,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:19:24,733] {scheduler_job.py:146} INFO - Started process (PID=29640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:29,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:29,742] {logging_mixin.py:95} INFO - [2019-09-12 16:19:29,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:30,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:30,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:30,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:30,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:19:30,275] {scheduler_job.py:146} INFO - Started process (PID=29645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:35,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:35,284] {logging_mixin.py:95} INFO - [2019-09-12 16:19:35,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:35,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:35,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:35,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:35,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 16:19:35,812] {scheduler_job.py:146} INFO - Started process (PID=29646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:40,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:40,822] {logging_mixin.py:95} INFO - [2019-09-12 16:19:40,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:41,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:41,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:41,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:41,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:19:41,262] {scheduler_job.py:146} INFO - Started process (PID=29651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:46,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:46,270] {logging_mixin.py:95} INFO - [2019-09-12 16:19:46,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:46,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:46,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:46,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:46,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:19:46,713] {scheduler_job.py:146} INFO - Started process (PID=29653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:51,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:51,724] {logging_mixin.py:95} INFO - [2019-09-12 16:19:51,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:52,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:52,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:52,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:52,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:19:52,167] {scheduler_job.py:146} INFO - Started process (PID=29654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:57,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:19:57,177] {logging_mixin.py:95} INFO - [2019-09-12 16:19:57,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:57,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:19:57,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:19:57,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:19:57,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:19:57,624] {scheduler_job.py:146} INFO - Started process (PID=29656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:02,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:02,633] {logging_mixin.py:95} INFO - [2019-09-12 16:20:02,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:02,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:03,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:03,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:03,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:20:03,076] {scheduler_job.py:146} INFO - Started process (PID=29660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:08,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:08,086] {logging_mixin.py:95} INFO - [2019-09-12 16:20:08,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:08,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:08,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:08,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:08,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:20:08,527] {scheduler_job.py:146} INFO - Started process (PID=29664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:13,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:13,535] {logging_mixin.py:95} INFO - [2019-09-12 16:20:13,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:13,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:13,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:13,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:13,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:20:13,984] {scheduler_job.py:146} INFO - Started process (PID=29666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:18,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:18,993] {logging_mixin.py:95} INFO - [2019-09-12 16:20:18,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:19,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:19,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:19,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:19,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:20:19,441] {scheduler_job.py:146} INFO - Started process (PID=29667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:24,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:24,448] {logging_mixin.py:95} INFO - [2019-09-12 16:20:24,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:24,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:24,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:24,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:24,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:20:24,899] {scheduler_job.py:146} INFO - Started process (PID=29668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:29,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:29,907] {logging_mixin.py:95} INFO - [2019-09-12 16:20:29,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:30,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:30,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:30,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:30,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:20:30,353] {scheduler_job.py:146} INFO - Started process (PID=29673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:35,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:35,362] {logging_mixin.py:95} INFO - [2019-09-12 16:20:35,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:35,718] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:35,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:35,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:35,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:20:35,809] {scheduler_job.py:146} INFO - Started process (PID=29674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:40,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:40,816] {logging_mixin.py:95} INFO - [2019-09-12 16:20:40,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:41,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:41,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:41,207] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:41,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:20:41,262] {scheduler_job.py:146} INFO - Started process (PID=29676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:46,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:46,272] {logging_mixin.py:95} INFO - [2019-09-12 16:20:46,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:46,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:46,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:46,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:46,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:20:46,724] {scheduler_job.py:146} INFO - Started process (PID=29678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:51,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:51,735] {logging_mixin.py:95} INFO - [2019-09-12 16:20:51,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:52,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:52,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:52,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:52,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:20:52,184] {scheduler_job.py:146} INFO - Started process (PID=29682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:57,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:20:57,195] {logging_mixin.py:95} INFO - [2019-09-12 16:20:57,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:57,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:20:57,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:20:57,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:20:57,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:20:57,642] {scheduler_job.py:146} INFO - Started process (PID=29684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:02,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:02,650] {logging_mixin.py:95} INFO - [2019-09-12 16:21:02,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:03,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:03,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:03,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:03,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:21:03,095] {scheduler_job.py:146} INFO - Started process (PID=29688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:08,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:08,104] {logging_mixin.py:95} INFO - [2019-09-12 16:21:08,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:08,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:08,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:08,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:08,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:21:08,546] {scheduler_job.py:146} INFO - Started process (PID=29689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:13,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:13,554] {logging_mixin.py:95} INFO - [2019-09-12 16:21:13,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:13,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:13,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:13,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:13,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:21:14,001] {scheduler_job.py:146} INFO - Started process (PID=29691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:19,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:19,010] {logging_mixin.py:95} INFO - [2019-09-12 16:21:19,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:19,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:19,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:19,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:19,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:21:19,452] {scheduler_job.py:146} INFO - Started process (PID=29693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:24,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:24,463] {logging_mixin.py:95} INFO - [2019-09-12 16:21:24,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:24,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:24,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:24,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:24,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:21:24,911] {scheduler_job.py:146} INFO - Started process (PID=29696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:29,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:29,921] {logging_mixin.py:95} INFO - [2019-09-12 16:21:29,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:30,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:30,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:30,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:30,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:21:30,364] {scheduler_job.py:146} INFO - Started process (PID=29701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:35,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:35,371] {logging_mixin.py:95} INFO - [2019-09-12 16:21:35,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:35,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:35,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:35,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:35,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:21:35,815] {scheduler_job.py:146} INFO - Started process (PID=29702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:40,824] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:40,826] {logging_mixin.py:95} INFO - [2019-09-12 16:21:40,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:41,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:41,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:41,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:41,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:21:41,274] {scheduler_job.py:146} INFO - Started process (PID=29704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:46,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:46,281] {logging_mixin.py:95} INFO - [2019-09-12 16:21:46,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:46,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:46,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:46,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:46,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:21:46,724] {scheduler_job.py:146} INFO - Started process (PID=29706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:51,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:51,734] {logging_mixin.py:95} INFO - [2019-09-12 16:21:51,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:52,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:52,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:52,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:52,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:21:52,180] {scheduler_job.py:146} INFO - Started process (PID=29710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:57,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:21:57,197] {logging_mixin.py:95} INFO - [2019-09-12 16:21:57,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:57,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:21:57,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:21:57,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:21:57,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:21:57,634] {scheduler_job.py:146} INFO - Started process (PID=29712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:02,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:02,645] {logging_mixin.py:95} INFO - [2019-09-12 16:22:02,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:03,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:03,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:03,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:03,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:22:03,087] {scheduler_job.py:146} INFO - Started process (PID=29716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:08,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:08,097] {logging_mixin.py:95} INFO - [2019-09-12 16:22:08,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:08,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:08,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:08,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:08,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:22:08,544] {scheduler_job.py:146} INFO - Started process (PID=29717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:13,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:13,554] {logging_mixin.py:95} INFO - [2019-09-12 16:22:13,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:13,907] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:13,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:13,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:13,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:22:13,996] {scheduler_job.py:146} INFO - Started process (PID=29719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:19,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:19,006] {logging_mixin.py:95} INFO - [2019-09-12 16:22:19,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:19,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:19,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:19,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:19,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:22:19,452] {scheduler_job.py:146} INFO - Started process (PID=29720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:24,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:24,460] {logging_mixin.py:95} INFO - [2019-09-12 16:22:24,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:24,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:24,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:24,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:24,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:22:24,911] {scheduler_job.py:146} INFO - Started process (PID=29724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:29,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:29,934] {logging_mixin.py:95} INFO - [2019-09-12 16:22:29,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:30,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:30,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:30,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:30,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 16:22:30,368] {scheduler_job.py:146} INFO - Started process (PID=29726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:35,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:35,375] {logging_mixin.py:95} INFO - [2019-09-12 16:22:35,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:35,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:35,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:35,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:35,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:22:35,823] {scheduler_job.py:146} INFO - Started process (PID=29727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:40,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:40,831] {logging_mixin.py:95} INFO - [2019-09-12 16:22:40,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:41,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:41,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:41,226] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:41,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:22:41,279] {scheduler_job.py:146} INFO - Started process (PID=29732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:46,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:46,289] {logging_mixin.py:95} INFO - [2019-09-12 16:22:46,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:46,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:46,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:46,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:46,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:22:46,734] {scheduler_job.py:146} INFO - Started process (PID=29734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:51,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:51,741] {logging_mixin.py:95} INFO - [2019-09-12 16:22:51,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:52,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:52,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:52,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:52,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:22:52,190] {scheduler_job.py:146} INFO - Started process (PID=29738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:57,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:22:57,197] {logging_mixin.py:95} INFO - [2019-09-12 16:22:57,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:57,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:22:57,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:22:57,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:22:57,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:22:57,648] {scheduler_job.py:146} INFO - Started process (PID=29740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:02,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:02,659] {logging_mixin.py:95} INFO - [2019-09-12 16:23:02,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:03,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:03,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:03,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:03,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:23:03,106] {scheduler_job.py:146} INFO - Started process (PID=29741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:08,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:08,113] {logging_mixin.py:95} INFO - [2019-09-12 16:23:08,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:08,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:08,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:08,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:08,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:23:08,565] {scheduler_job.py:146} INFO - Started process (PID=29742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:13,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:13,574] {logging_mixin.py:95} INFO - [2019-09-12 16:23:13,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:13,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:13,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:13,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:13,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:23:14,020] {scheduler_job.py:146} INFO - Started process (PID=29747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:19,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:19,028] {logging_mixin.py:95} INFO - [2019-09-12 16:23:19,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:19,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:19,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:19,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:19,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:23:19,474] {scheduler_job.py:146} INFO - Started process (PID=29748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:24,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:24,483] {logging_mixin.py:95} INFO - [2019-09-12 16:23:24,483] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:24,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:24,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:24,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:24,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:23:24,927] {scheduler_job.py:146} INFO - Started process (PID=29752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:29,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:29,950] {logging_mixin.py:95} INFO - [2019-09-12 16:23:29,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:30,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:30,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:30,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:30,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 16:23:30,384] {scheduler_job.py:146} INFO - Started process (PID=29754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:35,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:35,391] {logging_mixin.py:95} INFO - [2019-09-12 16:23:35,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:35,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:35,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:35,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:35,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:23:35,847] {scheduler_job.py:146} INFO - Started process (PID=29755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:40,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:40,857] {logging_mixin.py:95} INFO - [2019-09-12 16:23:40,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:41,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:41,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:41,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:41,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:23:41,302] {scheduler_job.py:146} INFO - Started process (PID=29757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:46,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:46,311] {logging_mixin.py:95} INFO - [2019-09-12 16:23:46,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:46,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:46,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:46,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:46,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:23:46,761] {scheduler_job.py:146} INFO - Started process (PID=29762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:51,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:51,769] {logging_mixin.py:95} INFO - [2019-09-12 16:23:51,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:52,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:52,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:52,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:52,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:23:52,212] {scheduler_job.py:146} INFO - Started process (PID=29766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:57,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:23:57,230] {logging_mixin.py:95} INFO - [2019-09-12 16:23:57,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:57,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:23:57,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:23:57,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:23:57,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:23:57,669] {scheduler_job.py:146} INFO - Started process (PID=29768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:02,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:02,676] {logging_mixin.py:95} INFO - [2019-09-12 16:24:02,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:03,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:03,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:03,070] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:03,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:24:03,126] {scheduler_job.py:146} INFO - Started process (PID=29769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:08,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:08,134] {logging_mixin.py:95} INFO - [2019-09-12 16:24:08,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:08,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:08,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:08,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:08,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:24:08,583] {scheduler_job.py:146} INFO - Started process (PID=29770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:13,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:13,589] {logging_mixin.py:95} INFO - [2019-09-12 16:24:13,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:13,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:13,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:13,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:13,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 16:24:14,039] {scheduler_job.py:146} INFO - Started process (PID=29775) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:19,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:19,047] {logging_mixin.py:95} INFO - [2019-09-12 16:24:19,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:19,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:19,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:19,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:19,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:24:19,497] {scheduler_job.py:146} INFO - Started process (PID=29776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:24,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:24,508] {logging_mixin.py:95} INFO - [2019-09-12 16:24:24,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:24,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:24,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:24,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:24,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:24:24,950] {scheduler_job.py:146} INFO - Started process (PID=29777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:29,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:29,967] {logging_mixin.py:95} INFO - [2019-09-12 16:24:29,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:30,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:30,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:30,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:30,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:24:30,408] {scheduler_job.py:146} INFO - Started process (PID=29779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:35,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:35,418] {logging_mixin.py:95} INFO - [2019-09-12 16:24:35,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:35,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:35,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:35,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:35,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:24:35,863] {scheduler_job.py:146} INFO - Started process (PID=29783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:40,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:40,873] {logging_mixin.py:95} INFO - [2019-09-12 16:24:40,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:41,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:41,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:41,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:41,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:24:41,320] {scheduler_job.py:146} INFO - Started process (PID=29785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:46,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:46,330] {logging_mixin.py:95} INFO - [2019-09-12 16:24:46,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:46,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:46,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:46,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:46,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:24:46,783] {scheduler_job.py:146} INFO - Started process (PID=29790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:51,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:51,790] {logging_mixin.py:95} INFO - [2019-09-12 16:24:51,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:52,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:52,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:52,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:52,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:24:52,278] {scheduler_job.py:146} INFO - Started process (PID=29796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:57,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:24:57,292] {logging_mixin.py:95} INFO - [2019-09-12 16:24:57,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:57,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:24:57,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:24:57,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:24:57,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:24:57,758] {scheduler_job.py:146} INFO - Started process (PID=29798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:02,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:02,771] {logging_mixin.py:95} INFO - [2019-09-12 16:25:02,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:03,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:03,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:03,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:03,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:25:03,246] {scheduler_job.py:146} INFO - Started process (PID=29803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:08,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:08,259] {logging_mixin.py:95} INFO - [2019-09-12 16:25:08,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:08,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:08,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:08,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:08,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:25:08,734] {scheduler_job.py:146} INFO - Started process (PID=29804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:13,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:13,747] {logging_mixin.py:95} INFO - [2019-09-12 16:25:13,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:14,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:14,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:14,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:14,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:25:14,218] {scheduler_job.py:146} INFO - Started process (PID=29806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:19,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:19,229] {logging_mixin.py:95} INFO - [2019-09-12 16:25:19,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:19,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:19,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:19,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:19,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:25:19,689] {scheduler_job.py:146} INFO - Started process (PID=29807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:24,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:24,702] {logging_mixin.py:95} INFO - [2019-09-12 16:25:24,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:25,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:25,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:25,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:25,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:25:25,168] {scheduler_job.py:146} INFO - Started process (PID=29811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:30,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:30,181] {logging_mixin.py:95} INFO - [2019-09-12 16:25:30,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:30,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:30,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:30,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:30,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:25:30,653] {scheduler_job.py:146} INFO - Started process (PID=29813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:35,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:35,662] {logging_mixin.py:95} INFO - [2019-09-12 16:25:35,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:36,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:36,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:36,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:36,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:25:36,138] {scheduler_job.py:146} INFO - Started process (PID=29814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:41,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:41,147] {logging_mixin.py:95} INFO - [2019-09-12 16:25:41,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:41,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:41,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:41,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:41,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:25:41,622] {scheduler_job.py:146} INFO - Started process (PID=29817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:46,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:46,635] {logging_mixin.py:95} INFO - [2019-09-12 16:25:46,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:46,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:47,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:47,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:47,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:25:47,110] {scheduler_job.py:146} INFO - Started process (PID=29824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:52,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:52,122] {logging_mixin.py:95} INFO - [2019-09-12 16:25:52,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:52,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:52,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:52,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:52,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:25:52,597] {scheduler_job.py:146} INFO - Started process (PID=29825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:57,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:25:57,612] {logging_mixin.py:95} INFO - [2019-09-12 16:25:57,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:57,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:25:57,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:25:58,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:25:58,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:25:58,091] {scheduler_job.py:146} INFO - Started process (PID=29827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:03,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:03,099] {logging_mixin.py:95} INFO - [2019-09-12 16:26:03,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:03,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:03,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:03,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:03,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:26:03,582] {scheduler_job.py:146} INFO - Started process (PID=29828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:08,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:08,591] {logging_mixin.py:95} INFO - [2019-09-12 16:26:08,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:08,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:08,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:08,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:08,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:26:09,067] {scheduler_job.py:146} INFO - Started process (PID=29832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:14,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:14,082] {logging_mixin.py:95} INFO - [2019-09-12 16:26:14,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:14,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:14,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:14,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:14,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:26:14,550] {scheduler_job.py:146} INFO - Started process (PID=29834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:19,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:19,557] {logging_mixin.py:95} INFO - [2019-09-12 16:26:19,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:19,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:19,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:19,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:19,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:26:20,034] {scheduler_job.py:146} INFO - Started process (PID=29835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:25,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:25,049] {logging_mixin.py:95} INFO - [2019-09-12 16:26:25,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:25,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:25,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:25,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:25,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:26:25,516] {scheduler_job.py:146} INFO - Started process (PID=29836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:30,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:30,525] {logging_mixin.py:95} INFO - [2019-09-12 16:26:30,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:30,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:30,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:30,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:30,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:26:30,997] {scheduler_job.py:146} INFO - Started process (PID=29841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:36,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:36,005] {logging_mixin.py:95} INFO - [2019-09-12 16:26:36,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:36,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:36,383] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:36,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:36,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:26:36,488] {scheduler_job.py:146} INFO - Started process (PID=29842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:41,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:41,503] {logging_mixin.py:95} INFO - [2019-09-12 16:26:41,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:41,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:41,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:41,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:41,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:26:41,968] {scheduler_job.py:146} INFO - Started process (PID=29845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:46,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:46,983] {logging_mixin.py:95} INFO - [2019-09-12 16:26:46,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:47,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:47,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:47,373] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:47,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:26:47,451] {scheduler_job.py:146} INFO - Started process (PID=29846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:52,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:52,465] {logging_mixin.py:95} INFO - [2019-09-12 16:26:52,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:52,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:52,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:52,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:52,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:26:52,944] {scheduler_job.py:146} INFO - Started process (PID=29850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:57,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:26:57,956] {logging_mixin.py:95} INFO - [2019-09-12 16:26:57,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:58,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:26:58,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:26:58,346] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:26:58,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:26:58,429] {scheduler_job.py:146} INFO - Started process (PID=29852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:03,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:03,440] {logging_mixin.py:95} INFO - [2019-09-12 16:27:03,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:03,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:03,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:03,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:03,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:27:03,914] {scheduler_job.py:146} INFO - Started process (PID=29853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:08,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:08,924] {logging_mixin.py:95} INFO - [2019-09-12 16:27:08,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:09,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:09,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:09,317] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:09,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:27:09,410] {scheduler_job.py:146} INFO - Started process (PID=29857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:14,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:14,423] {logging_mixin.py:95} INFO - [2019-09-12 16:27:14,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:14,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:14,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:14,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:14,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:27:14,898] {scheduler_job.py:146} INFO - Started process (PID=29859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:19,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:19,909] {logging_mixin.py:95} INFO - [2019-09-12 16:27:19,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:20,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:20,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:20,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:20,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:27:20,376] {scheduler_job.py:146} INFO - Started process (PID=29860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:25,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:25,388] {logging_mixin.py:95} INFO - [2019-09-12 16:27:25,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:25,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:25,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:25,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:25,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:27:25,864] {scheduler_job.py:146} INFO - Started process (PID=29861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:30,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:30,880] {logging_mixin.py:95} INFO - [2019-09-12 16:27:30,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:31,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:31,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:31,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:31,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:27:31,349] {scheduler_job.py:146} INFO - Started process (PID=29866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:36,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:36,358] {logging_mixin.py:95} INFO - [2019-09-12 16:27:36,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:36,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:36,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:36,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:36,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:27:36,831] {scheduler_job.py:146} INFO - Started process (PID=29867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:41,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:41,838] {logging_mixin.py:95} INFO - [2019-09-12 16:27:41,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:42,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:42,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:42,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:42,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:27:42,319] {scheduler_job.py:146} INFO - Started process (PID=29870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:47,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:47,337] {logging_mixin.py:95} INFO - [2019-09-12 16:27:47,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:47,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:47,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:47,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:47,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:27:47,806] {scheduler_job.py:146} INFO - Started process (PID=29871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:52,816] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:52,817] {logging_mixin.py:95} INFO - [2019-09-12 16:27:52,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:53,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:53,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:53,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:53,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:27:53,282] {scheduler_job.py:146} INFO - Started process (PID=29875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:58,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:27:58,296] {logging_mixin.py:95} INFO - [2019-09-12 16:27:58,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:58,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:27:58,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:27:58,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:27:58,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:27:58,773] {scheduler_job.py:146} INFO - Started process (PID=29877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:03,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:03,787] {logging_mixin.py:95} INFO - [2019-09-12 16:28:03,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:04,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:04,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:04,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:04,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:28:04,249] {scheduler_job.py:146} INFO - Started process (PID=29878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:09,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:09,261] {logging_mixin.py:95} INFO - [2019-09-12 16:28:09,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:09,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:09,645] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:09,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:09,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:28:09,735] {scheduler_job.py:146} INFO - Started process (PID=29882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:14,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:14,749] {logging_mixin.py:95} INFO - [2019-09-12 16:28:14,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:15,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:15,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:15,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:15,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:28:15,216] {scheduler_job.py:146} INFO - Started process (PID=29884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:20,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:20,232] {logging_mixin.py:95} INFO - [2019-09-12 16:28:20,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:20,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:20,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:20,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:20,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:28:20,697] {scheduler_job.py:146} INFO - Started process (PID=29885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:25,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:25,712] {logging_mixin.py:95} INFO - [2019-09-12 16:28:25,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:26,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:26,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:26,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:26,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:28:26,170] {scheduler_job.py:146} INFO - Started process (PID=29886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:31,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:31,185] {logging_mixin.py:95} INFO - [2019-09-12 16:28:31,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:31,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:31,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:31,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:31,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:28:31,652] {scheduler_job.py:146} INFO - Started process (PID=29891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:36,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:36,667] {logging_mixin.py:95} INFO - [2019-09-12 16:28:36,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:37,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:37,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:37,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:37,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:28:37,144] {scheduler_job.py:146} INFO - Started process (PID=29892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:42,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:42,160] {logging_mixin.py:95} INFO - [2019-09-12 16:28:42,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:42,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:42,556] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:42,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:42,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 16:28:42,630] {scheduler_job.py:146} INFO - Started process (PID=29895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:47,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:47,640] {logging_mixin.py:95} INFO - [2019-09-12 16:28:47,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:47,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:48,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:48,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:48,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:28:48,115] {scheduler_job.py:146} INFO - Started process (PID=29896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:53,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:53,129] {logging_mixin.py:95} INFO - [2019-09-12 16:28:53,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:53,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:53,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:53,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:53,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:28:53,589] {scheduler_job.py:146} INFO - Started process (PID=29900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:58,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:28:58,601] {logging_mixin.py:95} INFO - [2019-09-12 16:28:58,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:58,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:28:58,979] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:28:58,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:28:58,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:28:59,072] {scheduler_job.py:146} INFO - Started process (PID=29902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:04,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:04,086] {logging_mixin.py:95} INFO - [2019-09-12 16:29:04,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:04,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:04,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:04,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:04,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:29:04,559] {scheduler_job.py:146} INFO - Started process (PID=29903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:09,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:09,572] {logging_mixin.py:95} INFO - [2019-09-12 16:29:09,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:09,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:09,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:09,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:09,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:29:10,049] {scheduler_job.py:146} INFO - Started process (PID=29907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:15,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:15,055] {logging_mixin.py:95} INFO - [2019-09-12 16:29:15,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:15,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:15,434] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:15,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:15,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:29:15,530] {scheduler_job.py:146} INFO - Started process (PID=29909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:20,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:20,546] {logging_mixin.py:95} INFO - [2019-09-12 16:29:20,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:20,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:20,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:20,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:20,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:29:21,010] {scheduler_job.py:146} INFO - Started process (PID=29910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:26,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:26,023] {logging_mixin.py:95} INFO - [2019-09-12 16:29:26,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:26,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:26,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:26,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:26,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:29:26,487] {scheduler_job.py:146} INFO - Started process (PID=29911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:31,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:31,502] {logging_mixin.py:95} INFO - [2019-09-12 16:29:31,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:31,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:31,881] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:31,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:31,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:29:31,962] {scheduler_job.py:146} INFO - Started process (PID=29917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:36,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:36,970] {logging_mixin.py:95} INFO - [2019-09-12 16:29:36,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:37,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:37,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:37,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:37,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 16:29:37,441] {scheduler_job.py:146} INFO - Started process (PID=29921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:42,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:42,451] {logging_mixin.py:95} INFO - [2019-09-12 16:29:42,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:42,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:42,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:42,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:42,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-12 16:29:42,979] {scheduler_job.py:146} INFO - Started process (PID=29924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:47,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:47,991] {logging_mixin.py:95} INFO - [2019-09-12 16:29:47,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:48,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:48,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:48,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:48,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 16:29:48,514] {scheduler_job.py:146} INFO - Started process (PID=29925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:53,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:53,524] {logging_mixin.py:95} INFO - [2019-09-12 16:29:53,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:53,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:54,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:54,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:54,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.514 seconds
[2019-09-12 16:29:54,052] {scheduler_job.py:146} INFO - Started process (PID=29929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:59,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:29:59,060] {logging_mixin.py:95} INFO - [2019-09-12 16:29:59,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:59,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:29:59,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:29:59,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:29:59,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:29:59,589] {scheduler_job.py:146} INFO - Started process (PID=29931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:04,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:04,597] {logging_mixin.py:95} INFO - [2019-09-12 16:30:04,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:04,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:04,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:04,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:04,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:30:05,044] {scheduler_job.py:146} INFO - Started process (PID=29933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:10,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:10,055] {logging_mixin.py:95} INFO - [2019-09-12 16:30:10,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:10,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:10,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:10,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:10,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:30:10,498] {scheduler_job.py:146} INFO - Started process (PID=29937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:15,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:15,508] {logging_mixin.py:95} INFO - [2019-09-12 16:30:15,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:15,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:15,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:15,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:15,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:30:15,954] {scheduler_job.py:146} INFO - Started process (PID=29939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:20,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:20,964] {logging_mixin.py:95} INFO - [2019-09-12 16:30:20,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:21,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:21,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:21,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:21,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:30:21,412] {scheduler_job.py:146} INFO - Started process (PID=29943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:26,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:26,422] {logging_mixin.py:95} INFO - [2019-09-12 16:30:26,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:26,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:26,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:26,846] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:26,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:30:26,956] {scheduler_job.py:146} INFO - Started process (PID=29947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:31,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:31,963] {logging_mixin.py:95} INFO - [2019-09-12 16:30:31,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:32,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:32,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:32,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:32,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-12 16:30:32,410] {scheduler_job.py:146} INFO - Started process (PID=29948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:37,419] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:37,420] {logging_mixin.py:95} INFO - [2019-09-12 16:30:37,420] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:37,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:37,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:37,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:37,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:30:37,857] {scheduler_job.py:146} INFO - Started process (PID=29952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:42,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:42,864] {logging_mixin.py:95} INFO - [2019-09-12 16:30:42,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:43,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:43,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:43,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:43,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:30:43,311] {scheduler_job.py:146} INFO - Started process (PID=29955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:48,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:48,321] {logging_mixin.py:95} INFO - [2019-09-12 16:30:48,321] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:48,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:48,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:48,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:48,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:30:48,773] {scheduler_job.py:146} INFO - Started process (PID=29956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:53,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:53,780] {logging_mixin.py:95} INFO - [2019-09-12 16:30:53,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:54,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:54,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:54,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:54,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:30:54,234] {scheduler_job.py:146} INFO - Started process (PID=29957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:59,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:30:59,245] {logging_mixin.py:95} INFO - [2019-09-12 16:30:59,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:59,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:30:59,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:30:59,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:30:59,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:30:59,688] {scheduler_job.py:146} INFO - Started process (PID=29962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:04,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:04,696] {logging_mixin.py:95} INFO - [2019-09-12 16:31:04,696] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:05,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:05,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:05,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:05,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:31:05,138] {scheduler_job.py:146} INFO - Started process (PID=29966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:10,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:10,150] {logging_mixin.py:95} INFO - [2019-09-12 16:31:10,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:10,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:10,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:10,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:10,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 16:31:10,585] {scheduler_job.py:146} INFO - Started process (PID=29967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:15,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:15,594] {logging_mixin.py:95} INFO - [2019-09-12 16:31:15,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:15,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:15,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:15,990] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:15,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:31:16,038] {scheduler_job.py:146} INFO - Started process (PID=29969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:21,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:21,047] {logging_mixin.py:95} INFO - [2019-09-12 16:31:21,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:21,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:21,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:21,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:21,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:31:21,488] {scheduler_job.py:146} INFO - Started process (PID=29970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:26,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:26,495] {logging_mixin.py:95} INFO - [2019-09-12 16:31:26,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:26,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:26,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:26,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:26,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 16:31:26,937] {scheduler_job.py:146} INFO - Started process (PID=29975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:31,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:31,944] {logging_mixin.py:95} INFO - [2019-09-12 16:31:31,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:32,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:32,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:32,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:32,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:31:32,391] {scheduler_job.py:146} INFO - Started process (PID=29976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:37,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:37,403] {logging_mixin.py:95} INFO - [2019-09-12 16:31:37,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:37,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:37,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:37,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:37,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:31:37,841] {scheduler_job.py:146} INFO - Started process (PID=29977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:42,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:42,860] {logging_mixin.py:95} INFO - [2019-09-12 16:31:42,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:43,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:43,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:43,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:43,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 16:31:43,289] {scheduler_job.py:146} INFO - Started process (PID=29983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:48,297] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:48,298] {logging_mixin.py:95} INFO - [2019-09-12 16:31:48,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:48,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:48,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:48,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:48,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:31:48,741] {scheduler_job.py:146} INFO - Started process (PID=29986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:53,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:53,752] {logging_mixin.py:95} INFO - [2019-09-12 16:31:53,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:54,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:54,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:54,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:54,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:31:54,198] {scheduler_job.py:146} INFO - Started process (PID=29987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:59,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:31:59,206] {logging_mixin.py:95} INFO - [2019-09-12 16:31:59,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:59,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:31:59,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:31:59,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:31:59,636] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-12 16:31:59,656] {scheduler_job.py:146} INFO - Started process (PID=29992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:04,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:04,666] {logging_mixin.py:95} INFO - [2019-09-12 16:32:04,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:05,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:05,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:05,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:05,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 16:32:05,115] {scheduler_job.py:146} INFO - Started process (PID=29993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:10,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:10,128] {logging_mixin.py:95} INFO - [2019-09-12 16:32:10,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:10,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:10,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:10,519] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:10,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:32:10,577] {scheduler_job.py:146} INFO - Started process (PID=29994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:15,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:15,585] {logging_mixin.py:95} INFO - [2019-09-12 16:32:15,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:15,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:15,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:16,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:16,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:32:16,035] {scheduler_job.py:146} INFO - Started process (PID=29996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:21,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:21,043] {logging_mixin.py:95} INFO - [2019-09-12 16:32:21,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:21,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:21,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:21,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:21,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 16:32:21,496] {scheduler_job.py:146} INFO - Started process (PID=30000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:26,505] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:26,506] {logging_mixin.py:95} INFO - [2019-09-12 16:32:26,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:26,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:26,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:26,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:26,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:32:26,958] {scheduler_job.py:146} INFO - Started process (PID=30001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:31,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:31,966] {logging_mixin.py:95} INFO - [2019-09-12 16:32:31,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:32,348] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:32,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:32,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:32,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 16:32:32,414] {scheduler_job.py:146} INFO - Started process (PID=30006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:37,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:37,424] {logging_mixin.py:95} INFO - [2019-09-12 16:32:37,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:37,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:37,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:37,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:37,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-12 16:32:37,871] {scheduler_job.py:146} INFO - Started process (PID=30007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:42,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:42,891] {logging_mixin.py:95} INFO - [2019-09-12 16:32:42,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:43,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:43,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:43,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:43,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:32:43,327] {scheduler_job.py:146} INFO - Started process (PID=30013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:48,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:48,335] {logging_mixin.py:95} INFO - [2019-09-12 16:32:48,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:48,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:48,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:48,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:48,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:32:48,785] {scheduler_job.py:146} INFO - Started process (PID=30014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:53,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:53,797] {logging_mixin.py:95} INFO - [2019-09-12 16:32:53,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:54,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:54,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:54,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:54,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:32:54,246] {scheduler_job.py:146} INFO - Started process (PID=30015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:59,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:32:59,255] {logging_mixin.py:95} INFO - [2019-09-12 16:32:59,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:59,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:32:59,628] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:32:59,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:32:59,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:32:59,705] {scheduler_job.py:146} INFO - Started process (PID=30017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:04,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:04,714] {logging_mixin.py:95} INFO - [2019-09-12 16:33:04,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:05,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:05,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:05,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:05,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:33:05,158] {scheduler_job.py:146} INFO - Started process (PID=30021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:10,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:10,169] {logging_mixin.py:95} INFO - [2019-09-12 16:33:10,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:10,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:10,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:10,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:10,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:33:10,616] {scheduler_job.py:146} INFO - Started process (PID=30022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:15,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:15,624] {logging_mixin.py:95} INFO - [2019-09-12 16:33:15,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:15,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:15,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:16,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:16,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 16:33:16,070] {scheduler_job.py:146} INFO - Started process (PID=30027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:21,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:21,081] {logging_mixin.py:95} INFO - [2019-09-12 16:33:21,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:21,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:21,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:21,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:21,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:33:21,526] {scheduler_job.py:146} INFO - Started process (PID=30028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:26,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:26,534] {logging_mixin.py:95} INFO - [2019-09-12 16:33:26,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:26,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:26,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:26,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:26,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:33:26,986] {scheduler_job.py:146} INFO - Started process (PID=30029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:31,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:31,997] {logging_mixin.py:95} INFO - [2019-09-12 16:33:31,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:32,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:32,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:32,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:32,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:33:32,441] {scheduler_job.py:146} INFO - Started process (PID=30034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:37,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:37,451] {logging_mixin.py:95} INFO - [2019-09-12 16:33:37,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:37,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:37,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:37,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:37,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 16:33:37,894] {scheduler_job.py:146} INFO - Started process (PID=30035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:42,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:42,914] {logging_mixin.py:95} INFO - [2019-09-12 16:33:42,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:43,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:43,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:43,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:43,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 16:33:43,448] {scheduler_job.py:146} INFO - Started process (PID=30038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:48,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:48,457] {logging_mixin.py:95} INFO - [2019-09-12 16:33:48,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:48,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:48,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:48,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:48,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:33:48,903] {scheduler_job.py:146} INFO - Started process (PID=30042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:53,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:53,912] {logging_mixin.py:95} INFO - [2019-09-12 16:33:53,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:54,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:54,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:54,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:54,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 16:33:54,362] {scheduler_job.py:146} INFO - Started process (PID=30043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:59,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:33:59,374] {logging_mixin.py:95} INFO - [2019-09-12 16:33:59,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:59,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:33:59,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:33:59,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:33:59,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:33:59,818] {scheduler_job.py:146} INFO - Started process (PID=30045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:04,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:04,827] {logging_mixin.py:95} INFO - [2019-09-12 16:34:04,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:05,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:05,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:05,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:05,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 16:34:05,275] {scheduler_job.py:146} INFO - Started process (PID=30047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:10,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:10,285] {logging_mixin.py:95} INFO - [2019-09-12 16:34:10,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:10,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:10,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:10,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:10,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:34:10,725] {scheduler_job.py:146} INFO - Started process (PID=30050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:15,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:15,735] {logging_mixin.py:95} INFO - [2019-09-12 16:34:15,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:16,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:16,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:16,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:16,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:34:16,187] {scheduler_job.py:146} INFO - Started process (PID=30052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:21,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:21,198] {logging_mixin.py:95} INFO - [2019-09-12 16:34:21,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:21,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:21,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:21,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:21,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 16:34:21,644] {scheduler_job.py:146} INFO - Started process (PID=30053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:26,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:26,665] {logging_mixin.py:95} INFO - [2019-09-12 16:34:26,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:27,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:27,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:27,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:27,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:34:27,099] {scheduler_job.py:146} INFO - Started process (PID=30057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:32,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:32,109] {logging_mixin.py:95} INFO - [2019-09-12 16:34:32,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:32,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:32,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:32,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:32,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:34:32,561] {scheduler_job.py:146} INFO - Started process (PID=30059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:37,568] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:37,569] {logging_mixin.py:95} INFO - [2019-09-12 16:34:37,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:37,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:37,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:37,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:37,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:34:38,015] {scheduler_job.py:146} INFO - Started process (PID=30063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:43,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:43,034] {logging_mixin.py:95} INFO - [2019-09-12 16:34:43,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:43,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:43,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:43,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:43,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:34:43,470] {scheduler_job.py:146} INFO - Started process (PID=30066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:48,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:48,478] {logging_mixin.py:95} INFO - [2019-09-12 16:34:48,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:48,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:48,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:48,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:48,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-12 16:34:49,030] {scheduler_job.py:146} INFO - Started process (PID=30067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:54,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:54,041] {logging_mixin.py:95} INFO - [2019-09-12 16:34:54,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:54,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:54,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:54,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:54,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 16:34:54,481] {scheduler_job.py:146} INFO - Started process (PID=30071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:59,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:34:59,489] {logging_mixin.py:95} INFO - [2019-09-12 16:34:59,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:59,863] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:34:59,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:34:59,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:34:59,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:34:59,941] {scheduler_job.py:146} INFO - Started process (PID=30074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:04,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:04,950] {logging_mixin.py:95} INFO - [2019-09-12 16:35:04,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:05,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:05,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:05,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:05,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-12 16:35:05,489] {scheduler_job.py:146} INFO - Started process (PID=30077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:10,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:10,499] {logging_mixin.py:95} INFO - [2019-09-12 16:35:10,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:10,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:10,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:10,890] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:10,895] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:35:10,944] {scheduler_job.py:146} INFO - Started process (PID=30078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:15,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:15,956] {logging_mixin.py:95} INFO - [2019-09-12 16:35:15,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:16,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:16,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:16,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:16,366] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 16:35:16,399] {scheduler_job.py:146} INFO - Started process (PID=30083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:21,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:21,407] {logging_mixin.py:95} INFO - [2019-09-12 16:35:21,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:21,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:21,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:21,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:21,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-12 16:35:21,956] {scheduler_job.py:146} INFO - Started process (PID=30087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:26,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:26,965] {logging_mixin.py:95} INFO - [2019-09-12 16:35:26,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:27,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:27,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:27,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:27,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:35:27,418] {scheduler_job.py:146} INFO - Started process (PID=30089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:32,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:32,428] {logging_mixin.py:95} INFO - [2019-09-12 16:35:32,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:32,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:32,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:32,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:32,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:35:32,972] {scheduler_job.py:146} INFO - Started process (PID=30090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:37,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:37,982] {logging_mixin.py:95} INFO - [2019-09-12 16:35:37,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:38,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:38,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:38,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:38,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 16:35:38,429] {scheduler_job.py:146} INFO - Started process (PID=30091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:43,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:43,437] {logging_mixin.py:95} INFO - [2019-09-12 16:35:43,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:43,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:43,809] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:43,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:43,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:35:43,880] {scheduler_job.py:146} INFO - Started process (PID=30097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:48,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:48,892] {logging_mixin.py:95} INFO - [2019-09-12 16:35:48,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:49,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:49,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:49,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:49,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 16:35:49,346] {scheduler_job.py:146} INFO - Started process (PID=30098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:54,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:54,355] {logging_mixin.py:95} INFO - [2019-09-12 16:35:54,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:54,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:54,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:35:54,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:35:54,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:35:54,798] {scheduler_job.py:146} INFO - Started process (PID=30102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:35:59,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:35:59,808] {logging_mixin.py:95} INFO - [2019-09-12 16:35:59,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:00,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:00,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:00,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:00,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:36:00,256] {scheduler_job.py:146} INFO - Started process (PID=30104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:05,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:05,266] {logging_mixin.py:95} INFO - [2019-09-12 16:36:05,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:05,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:05,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:05,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:05,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 16:36:05,811] {scheduler_job.py:146} INFO - Started process (PID=30105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:10,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:10,822] {logging_mixin.py:95} INFO - [2019-09-12 16:36:10,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:11,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:11,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:11,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:11,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:36:11,265] {scheduler_job.py:146} INFO - Started process (PID=30109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:16,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:16,278] {logging_mixin.py:95} INFO - [2019-09-12 16:36:16,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:16,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:16,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:16,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:16,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:36:16,719] {scheduler_job.py:146} INFO - Started process (PID=30111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:21,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:21,732] {logging_mixin.py:95} INFO - [2019-09-12 16:36:21,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:22,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:22,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:22,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:22,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 16:36:22,269] {scheduler_job.py:146} INFO - Started process (PID=30112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:27,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:27,279] {logging_mixin.py:95} INFO - [2019-09-12 16:36:27,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:27,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:27,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:27,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:27,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:36:27,716] {scheduler_job.py:146} INFO - Started process (PID=30117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:32,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:32,723] {logging_mixin.py:95} INFO - [2019-09-12 16:36:32,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:33,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:33,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:33,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:33,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:36:33,171] {scheduler_job.py:146} INFO - Started process (PID=30118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:38,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:38,182] {logging_mixin.py:95} INFO - [2019-09-12 16:36:38,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:38,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:38,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:38,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:38,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:36:38,616] {scheduler_job.py:146} INFO - Started process (PID=30119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:43,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:43,624] {logging_mixin.py:95} INFO - [2019-09-12 16:36:43,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:44,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:44,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:44,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:44,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 16:36:44,166] {scheduler_job.py:146} INFO - Started process (PID=30125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:49,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:49,177] {logging_mixin.py:95} INFO - [2019-09-12 16:36:49,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:49,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:49,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:49,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:49,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:36:49,612] {scheduler_job.py:146} INFO - Started process (PID=30126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:54,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:36:54,624] {logging_mixin.py:95} INFO - [2019-09-12 16:36:54,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:54,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:36:55,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:36:55,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:36:55,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:36:55,063] {scheduler_job.py:146} INFO - Started process (PID=30127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:00,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:00,074] {logging_mixin.py:95} INFO - [2019-09-12 16:37:00,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:00,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:00,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:00,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:00,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:37:00,515] {scheduler_job.py:146} INFO - Started process (PID=30129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:05,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:05,525] {logging_mixin.py:95} INFO - [2019-09-12 16:37:05,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:05,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:05,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:05,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:05,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:37:05,972] {scheduler_job.py:146} INFO - Started process (PID=30133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:10,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:10,981] {logging_mixin.py:95} INFO - [2019-09-12 16:37:10,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:11,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:11,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:11,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:11,370] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:37:11,430] {scheduler_job.py:146} INFO - Started process (PID=30134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:16,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:16,441] {logging_mixin.py:95} INFO - [2019-09-12 16:37:16,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:16,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:16,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:16,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:16,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:37:16,889] {scheduler_job.py:146} INFO - Started process (PID=30136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:21,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:21,895] {logging_mixin.py:95} INFO - [2019-09-12 16:37:21,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:22,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:22,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:22,285] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:22,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:37:22,343] {scheduler_job.py:146} INFO - Started process (PID=30140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:27,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:27,351] {logging_mixin.py:95} INFO - [2019-09-12 16:37:27,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:27,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:27,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:27,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:27,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:37:27,797] {scheduler_job.py:146} INFO - Started process (PID=30142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:32,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:32,809] {logging_mixin.py:95} INFO - [2019-09-12 16:37:32,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:33,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:33,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:33,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:33,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:37:33,248] {scheduler_job.py:146} INFO - Started process (PID=30146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:38,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:38,256] {logging_mixin.py:95} INFO - [2019-09-12 16:37:38,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:38,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:38,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:38,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:38,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:37:38,706] {scheduler_job.py:146} INFO - Started process (PID=30147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:43,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:43,728] {logging_mixin.py:95} INFO - [2019-09-12 16:37:43,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:44,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:44,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:44,129] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:44,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 16:37:44,159] {scheduler_job.py:146} INFO - Started process (PID=30150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:49,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:49,168] {logging_mixin.py:95} INFO - [2019-09-12 16:37:49,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:49,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:49,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:49,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:49,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:37:49,601] {scheduler_job.py:146} INFO - Started process (PID=30154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:54,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:37:54,613] {logging_mixin.py:95} INFO - [2019-09-12 16:37:54,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:54,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:37:54,991] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:37:55,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:37:55,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:37:55,051] {scheduler_job.py:146} INFO - Started process (PID=30155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:00,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:00,060] {logging_mixin.py:95} INFO - [2019-09-12 16:38:00,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:00,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:00,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:00,439] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:00,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 16:38:00,504] {scheduler_job.py:146} INFO - Started process (PID=30157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:05,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:05,515] {logging_mixin.py:95} INFO - [2019-09-12 16:38:05,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:05,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:05,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:05,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:05,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:38:05,962] {scheduler_job.py:146} INFO - Started process (PID=30161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:10,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:10,970] {logging_mixin.py:95} INFO - [2019-09-12 16:38:10,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:11,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:11,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:11,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:11,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:38:11,418] {scheduler_job.py:146} INFO - Started process (PID=30162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:16,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:16,427] {logging_mixin.py:95} INFO - [2019-09-12 16:38:16,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:16,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:16,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:16,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:16,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:38:16,873] {scheduler_job.py:146} INFO - Started process (PID=30164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:21,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:21,884] {logging_mixin.py:95} INFO - [2019-09-12 16:38:21,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:22,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:22,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:22,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:22,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:38:22,333] {scheduler_job.py:146} INFO - Started process (PID=30168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:27,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:27,357] {logging_mixin.py:95} INFO - [2019-09-12 16:38:27,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:27,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:27,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:27,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:27,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:38:27,785] {scheduler_job.py:146} INFO - Started process (PID=30170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:32,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:32,797] {logging_mixin.py:95} INFO - [2019-09-12 16:38:32,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:33,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:33,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:33,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:33,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:38:33,239] {scheduler_job.py:146} INFO - Started process (PID=30171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:38,249] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:38,250] {logging_mixin.py:95} INFO - [2019-09-12 16:38:38,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:38,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:38,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:38,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:38,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:38:38,694] {scheduler_job.py:146} INFO - Started process (PID=30172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:43,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:43,715] {logging_mixin.py:95} INFO - [2019-09-12 16:38:43,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:44,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:44,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:44,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:44,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 16:38:44,145] {scheduler_job.py:146} INFO - Started process (PID=30178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:49,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:49,155] {logging_mixin.py:95} INFO - [2019-09-12 16:38:49,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:49,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:49,532] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:49,543] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:49,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:38:49,590] {scheduler_job.py:146} INFO - Started process (PID=30179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:54,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:38:54,601] {logging_mixin.py:95} INFO - [2019-09-12 16:38:54,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:54,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:38:54,986] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:38:54,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:38:55,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:38:55,040] {scheduler_job.py:146} INFO - Started process (PID=30183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:00,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:00,053] {logging_mixin.py:95} INFO - [2019-09-12 16:39:00,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:00,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:00,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:00,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:00,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 16:39:00,490] {scheduler_job.py:146} INFO - Started process (PID=30185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:05,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:05,500] {logging_mixin.py:95} INFO - [2019-09-12 16:39:05,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:05,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:05,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:05,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:05,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 16:39:05,941] {scheduler_job.py:146} INFO - Started process (PID=30186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:10,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:10,951] {logging_mixin.py:95} INFO - [2019-09-12 16:39:10,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:11,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:11,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:11,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:11,350] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:39:11,391] {scheduler_job.py:146} INFO - Started process (PID=30187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:16,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:16,403] {logging_mixin.py:95} INFO - [2019-09-12 16:39:16,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:16,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:16,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:16,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:16,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:39:16,842] {scheduler_job.py:146} INFO - Started process (PID=30192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:21,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:21,852] {logging_mixin.py:95} INFO - [2019-09-12 16:39:21,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:22,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:22,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:22,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:22,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 16:39:22,292] {scheduler_job.py:146} INFO - Started process (PID=30196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:27,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:27,317] {logging_mixin.py:95} INFO - [2019-09-12 16:39:27,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:27,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:27,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:27,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:27,708] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:39:27,743] {scheduler_job.py:146} INFO - Started process (PID=30198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:32,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:32,753] {logging_mixin.py:95} INFO - [2019-09-12 16:39:32,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:33,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:33,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:33,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:33,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:39:33,199] {scheduler_job.py:146} INFO - Started process (PID=30199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:38,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:38,210] {logging_mixin.py:95} INFO - [2019-09-12 16:39:38,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:38,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:38,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:38,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:38,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:39:38,657] {scheduler_job.py:146} INFO - Started process (PID=30200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:43,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:43,677] {logging_mixin.py:95} INFO - [2019-09-12 16:39:43,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:44,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:44,054] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:44,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:44,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:39:44,107] {scheduler_job.py:146} INFO - Started process (PID=30203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:49,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:49,115] {logging_mixin.py:95} INFO - [2019-09-12 16:39:49,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:49,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:49,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:49,495] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:49,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 16:39:49,557] {scheduler_job.py:146} INFO - Started process (PID=30207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:54,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:39:54,566] {logging_mixin.py:95} INFO - [2019-09-12 16:39:54,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:54,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:39:54,977] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:39:54,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:39:54,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 16:39:55,107] {scheduler_job.py:146} INFO - Started process (PID=30211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:00,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:00,120] {logging_mixin.py:95} INFO - [2019-09-12 16:40:00,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:00,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:00,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:00,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:00,510] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:40:00,563] {scheduler_job.py:146} INFO - Started process (PID=30213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:05,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:05,572] {logging_mixin.py:95} INFO - [2019-09-12 16:40:05,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:05,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:05,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:05,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:05,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:40:06,023] {scheduler_job.py:146} INFO - Started process (PID=30214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:11,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:11,032] {logging_mixin.py:95} INFO - [2019-09-12 16:40:11,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:11,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:11,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:11,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:11,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:40:11,481] {scheduler_job.py:146} INFO - Started process (PID=30215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:16,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:16,492] {logging_mixin.py:95} INFO - [2019-09-12 16:40:16,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:16,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:16,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:16,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:16,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:40:16,932] {scheduler_job.py:146} INFO - Started process (PID=30217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:21,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:21,942] {logging_mixin.py:95} INFO - [2019-09-12 16:40:21,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:22,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:22,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:22,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:22,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:40:22,386] {scheduler_job.py:146} INFO - Started process (PID=30221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:27,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:27,394] {logging_mixin.py:95} INFO - [2019-09-12 16:40:27,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:27,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:27,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:27,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:27,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:40:27,837] {scheduler_job.py:146} INFO - Started process (PID=30223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:32,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:32,849] {logging_mixin.py:95} INFO - [2019-09-12 16:40:32,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:33,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:33,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:33,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:33,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:40:33,295] {scheduler_job.py:146} INFO - Started process (PID=30227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:38,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:38,304] {logging_mixin.py:95} INFO - [2019-09-12 16:40:38,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:38,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:38,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:38,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:38,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:40:38,753] {scheduler_job.py:146} INFO - Started process (PID=30228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:43,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:43,776] {logging_mixin.py:95} INFO - [2019-09-12 16:40:43,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:44,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:44,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:44,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:44,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 16:40:44,207] {scheduler_job.py:146} INFO - Started process (PID=30231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:49,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:49,215] {logging_mixin.py:95} INFO - [2019-09-12 16:40:49,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:49,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:49,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:49,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:49,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:40:49,668] {scheduler_job.py:146} INFO - Started process (PID=30235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:54,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:40:54,675] {logging_mixin.py:95} INFO - [2019-09-12 16:40:54,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:55,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:40:55,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:40:55,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:40:55,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:40:55,124] {scheduler_job.py:146} INFO - Started process (PID=30236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:00,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:00,135] {logging_mixin.py:95} INFO - [2019-09-12 16:41:00,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:00,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:00,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:00,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:00,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:41:00,577] {scheduler_job.py:146} INFO - Started process (PID=30241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:05,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:05,585] {logging_mixin.py:95} INFO - [2019-09-12 16:41:05,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:05,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:05,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:05,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:05,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:41:06,028] {scheduler_job.py:146} INFO - Started process (PID=30242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:11,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:11,037] {logging_mixin.py:95} INFO - [2019-09-12 16:41:11,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:11,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:11,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:11,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:11,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:41:11,483] {scheduler_job.py:146} INFO - Started process (PID=30243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:16,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:16,492] {logging_mixin.py:95} INFO - [2019-09-12 16:41:16,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:16,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:16,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:16,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:16,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:41:16,940] {scheduler_job.py:146} INFO - Started process (PID=30245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:21,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:21,947] {logging_mixin.py:95} INFO - [2019-09-12 16:41:21,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:22,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:22,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:22,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:22,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:41:22,398] {scheduler_job.py:146} INFO - Started process (PID=30249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:27,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:27,421] {logging_mixin.py:95} INFO - [2019-09-12 16:41:27,420] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:27,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:27,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:27,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:27,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 16:41:27,854] {scheduler_job.py:146} INFO - Started process (PID=30251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:32,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:32,862] {logging_mixin.py:95} INFO - [2019-09-12 16:41:32,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:33,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:33,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:33,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:33,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:41:33,309] {scheduler_job.py:146} INFO - Started process (PID=30255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:38,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:38,317] {logging_mixin.py:95} INFO - [2019-09-12 16:41:38,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:38,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:38,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:38,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:38,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:41:38,769] {scheduler_job.py:146} INFO - Started process (PID=30256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:43,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:43,788] {logging_mixin.py:95} INFO - [2019-09-12 16:41:43,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:44,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:44,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:44,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:44,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 16:41:44,319] {scheduler_job.py:146} INFO - Started process (PID=30259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:49,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:49,329] {logging_mixin.py:95} INFO - [2019-09-12 16:41:49,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:49,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:49,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:49,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:49,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:41:49,768] {scheduler_job.py:146} INFO - Started process (PID=30263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:54,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:41:54,778] {logging_mixin.py:95} INFO - [2019-09-12 16:41:54,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:55,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:41:55,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:41:55,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:41:55,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:41:55,218] {scheduler_job.py:146} INFO - Started process (PID=30264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:00,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:00,225] {logging_mixin.py:95} INFO - [2019-09-12 16:42:00,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:00,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:00,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:00,612] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:00,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:42:00,672] {scheduler_job.py:146} INFO - Started process (PID=30266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:05,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:05,678] {logging_mixin.py:95} INFO - [2019-09-12 16:42:05,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:06,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:06,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:06,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:06,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:42:06,125] {scheduler_job.py:146} INFO - Started process (PID=30267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:11,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:11,136] {logging_mixin.py:95} INFO - [2019-09-12 16:42:11,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:11,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:11,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:11,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:11,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:42:11,586] {scheduler_job.py:146} INFO - Started process (PID=30271) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:16,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:16,596] {logging_mixin.py:95} INFO - [2019-09-12 16:42:16,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:16,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:16,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:16,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:16,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:42:17,046] {scheduler_job.py:146} INFO - Started process (PID=30273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:22,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:22,056] {logging_mixin.py:95} INFO - [2019-09-12 16:42:22,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:22,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:22,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:22,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:22,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:42:22,502] {scheduler_job.py:146} INFO - Started process (PID=30277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:27,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:27,523] {logging_mixin.py:95} INFO - [2019-09-12 16:42:27,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:27,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:27,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:27,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:27,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:42:27,958] {scheduler_job.py:146} INFO - Started process (PID=30279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:32,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:32,968] {logging_mixin.py:95} INFO - [2019-09-12 16:42:32,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:33,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:33,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:33,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:33,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:42:33,413] {scheduler_job.py:146} INFO - Started process (PID=30280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:38,424] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:38,425] {logging_mixin.py:95} INFO - [2019-09-12 16:42:38,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:38,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:38,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:38,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:38,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:42:38,865] {scheduler_job.py:146} INFO - Started process (PID=30281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:43,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:43,885] {logging_mixin.py:95} INFO - [2019-09-12 16:42:43,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:44,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:44,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:44,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:44,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:42:44,323] {scheduler_job.py:146} INFO - Started process (PID=30287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:49,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:49,330] {logging_mixin.py:95} INFO - [2019-09-12 16:42:49,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:49,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:49,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:49,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:49,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:42:49,769] {scheduler_job.py:146} INFO - Started process (PID=30288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:54,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:42:54,779] {logging_mixin.py:95} INFO - [2019-09-12 16:42:54,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:55,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:42:55,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:42:55,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:42:55,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 16:42:55,223] {scheduler_job.py:146} INFO - Started process (PID=30292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:00,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:00,233] {logging_mixin.py:95} INFO - [2019-09-12 16:43:00,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:00,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:00,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:00,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:00,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:43:00,681] {scheduler_job.py:146} INFO - Started process (PID=30294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:05,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:05,690] {logging_mixin.py:95} INFO - [2019-09-12 16:43:05,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:06,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:06,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:06,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:06,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:43:06,137] {scheduler_job.py:146} INFO - Started process (PID=30295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:11,144] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:11,145] {logging_mixin.py:95} INFO - [2019-09-12 16:43:11,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:11,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:11,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:11,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:11,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:43:11,591] {scheduler_job.py:146} INFO - Started process (PID=30299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:16,599] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:16,600] {logging_mixin.py:95} INFO - [2019-09-12 16:43:16,600] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:16,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:17,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:17,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:17,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 16:43:17,141] {scheduler_job.py:146} INFO - Started process (PID=30301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:22,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:22,151] {logging_mixin.py:95} INFO - [2019-09-12 16:43:22,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:22,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:22,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:22,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:22,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 16:43:22,687] {scheduler_job.py:146} INFO - Started process (PID=30302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:27,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:27,696] {logging_mixin.py:95} INFO - [2019-09-12 16:43:27,696] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:28,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:28,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:28,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:28,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:43:28,133] {scheduler_job.py:146} INFO - Started process (PID=30307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:33,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:33,143] {logging_mixin.py:95} INFO - [2019-09-12 16:43:33,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:33,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:33,526] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:33,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:33,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:43:33,589] {scheduler_job.py:146} INFO - Started process (PID=30308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:38,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:38,599] {logging_mixin.py:95} INFO - [2019-09-12 16:43:38,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:38,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:38,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:38,990] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:38,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 16:43:39,045] {scheduler_job.py:146} INFO - Started process (PID=30309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:44,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:44,055] {logging_mixin.py:95} INFO - [2019-09-12 16:43:44,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:44,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:44,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:44,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:44,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:43:44,497] {scheduler_job.py:146} INFO - Started process (PID=30315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:49,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:49,508] {logging_mixin.py:95} INFO - [2019-09-12 16:43:49,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:49,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:49,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:49,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:49,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:43:49,951] {scheduler_job.py:146} INFO - Started process (PID=30318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:54,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:43:54,961] {logging_mixin.py:95} INFO - [2019-09-12 16:43:54,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:55,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:43:55,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:43:55,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:43:55,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:43:55,401] {scheduler_job.py:146} INFO - Started process (PID=30320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:00,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:00,410] {logging_mixin.py:95} INFO - [2019-09-12 16:44:00,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:00,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:00,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:00,798] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:00,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 16:44:00,856] {scheduler_job.py:146} INFO - Started process (PID=30325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:05,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:05,867] {logging_mixin.py:95} INFO - [2019-09-12 16:44:05,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:06,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:06,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:06,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:06,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:44:06,314] {scheduler_job.py:146} INFO - Started process (PID=30326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:11,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:11,324] {logging_mixin.py:95} INFO - [2019-09-12 16:44:11,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:11,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:11,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:11,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:11,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:44:11,769] {scheduler_job.py:146} INFO - Started process (PID=30330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:16,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:16,778] {logging_mixin.py:95} INFO - [2019-09-12 16:44:16,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:17,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:17,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:17,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:17,182] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 16:44:17,222] {scheduler_job.py:146} INFO - Started process (PID=30332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:22,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:22,230] {logging_mixin.py:95} INFO - [2019-09-12 16:44:22,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:22,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:22,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:22,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:22,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:44:22,678] {scheduler_job.py:146} INFO - Started process (PID=30333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:27,683] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:27,684] {logging_mixin.py:95} INFO - [2019-09-12 16:44:27,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:28,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:28,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:28,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:28,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:44:28,129] {scheduler_job.py:146} INFO - Started process (PID=30338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:33,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:33,136] {logging_mixin.py:95} INFO - [2019-09-12 16:44:33,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:33,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:33,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:33,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:33,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:44:33,578] {scheduler_job.py:146} INFO - Started process (PID=30339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:38,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:38,585] {logging_mixin.py:95} INFO - [2019-09-12 16:44:38,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:38,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:38,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:38,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:38,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:44:39,031] {scheduler_job.py:146} INFO - Started process (PID=30340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:44,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:44,052] {logging_mixin.py:95} INFO - [2019-09-12 16:44:44,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:44,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:44,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:44,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:44,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 16:44:44,479] {scheduler_job.py:146} INFO - Started process (PID=30343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:49,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:49,488] {logging_mixin.py:95} INFO - [2019-09-12 16:44:49,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:49,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:49,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:49,904] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:49,909] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 16:44:49,935] {scheduler_job.py:146} INFO - Started process (PID=30347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:54,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:44:54,943] {logging_mixin.py:95} INFO - [2019-09-12 16:44:54,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:55,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:44:55,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:44:55,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:44:55,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 16:44:55,488] {scheduler_job.py:146} INFO - Started process (PID=30348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:00,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:00,498] {logging_mixin.py:95} INFO - [2019-09-12 16:45:00,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:00,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:00,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:00,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:00,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 16:45:00,932] {scheduler_job.py:146} INFO - Started process (PID=30353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:05,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:05,939] {logging_mixin.py:95} INFO - [2019-09-12 16:45:05,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:06,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:06,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:06,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:06,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:45:06,382] {scheduler_job.py:146} INFO - Started process (PID=30354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:11,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:11,392] {logging_mixin.py:95} INFO - [2019-09-12 16:45:11,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:11,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:11,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:11,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:11,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-12 16:45:11,839] {scheduler_job.py:146} INFO - Started process (PID=30355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:16,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:16,847] {logging_mixin.py:95} INFO - [2019-09-12 16:45:16,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:17,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:17,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:17,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:17,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:45:17,296] {scheduler_job.py:146} INFO - Started process (PID=30360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:22,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:22,306] {logging_mixin.py:95} INFO - [2019-09-12 16:45:22,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:22,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:22,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:22,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:22,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:45:22,749] {scheduler_job.py:146} INFO - Started process (PID=30362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:27,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:27,756] {logging_mixin.py:95} INFO - [2019-09-12 16:45:27,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:28,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:28,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:28,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:28,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:45:28,207] {scheduler_job.py:146} INFO - Started process (PID=30364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:33,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:33,213] {logging_mixin.py:95} INFO - [2019-09-12 16:45:33,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:33,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:33,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:33,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:33,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:45:33,661] {scheduler_job.py:146} INFO - Started process (PID=30365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:38,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:38,671] {logging_mixin.py:95} INFO - [2019-09-12 16:45:38,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:39,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:39,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:39,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:39,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:45:39,116] {scheduler_job.py:146} INFO - Started process (PID=30369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:44,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:44,135] {logging_mixin.py:95} INFO - [2019-09-12 16:45:44,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:44,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:44,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:44,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:44,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:45:44,570] {scheduler_job.py:146} INFO - Started process (PID=30372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:49,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:49,579] {logging_mixin.py:95} INFO - [2019-09-12 16:45:49,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:49,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:49,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:49,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:49,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:45:50,028] {scheduler_job.py:146} INFO - Started process (PID=30376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:55,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:45:55,037] {logging_mixin.py:95} INFO - [2019-09-12 16:45:55,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:55,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:45:55,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:45:55,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:45:55,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:45:55,483] {scheduler_job.py:146} INFO - Started process (PID=30377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:00,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:00,492] {logging_mixin.py:95} INFO - [2019-09-12 16:46:00,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:00,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:00,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:00,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:00,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:46:00,930] {scheduler_job.py:146} INFO - Started process (PID=30379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:05,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:05,939] {logging_mixin.py:95} INFO - [2019-09-12 16:46:05,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:06,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:06,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:06,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:06,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:46:06,388] {scheduler_job.py:146} INFO - Started process (PID=30380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:11,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:11,398] {logging_mixin.py:95} INFO - [2019-09-12 16:46:11,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:11,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:11,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:11,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:11,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:46:11,847] {scheduler_job.py:146} INFO - Started process (PID=30384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:16,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:16,857] {logging_mixin.py:95} INFO - [2019-09-12 16:46:16,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:17,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:17,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:17,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:17,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:46:17,298] {scheduler_job.py:146} INFO - Started process (PID=30389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:22,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:22,308] {logging_mixin.py:95} INFO - [2019-09-12 16:46:22,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:22,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:22,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:22,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:22,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:46:22,753] {scheduler_job.py:146} INFO - Started process (PID=30390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:27,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:27,760] {logging_mixin.py:95} INFO - [2019-09-12 16:46:27,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:28,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:28,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:28,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:28,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:46:28,209] {scheduler_job.py:146} INFO - Started process (PID=30392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:33,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:33,220] {logging_mixin.py:95} INFO - [2019-09-12 16:46:33,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:33,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:33,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:33,608] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:33,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 16:46:33,669] {scheduler_job.py:146} INFO - Started process (PID=30393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:38,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:38,677] {logging_mixin.py:95} INFO - [2019-09-12 16:46:38,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:39,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:39,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:39,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:39,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 16:46:39,124] {scheduler_job.py:146} INFO - Started process (PID=30397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:44,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:44,144] {logging_mixin.py:95} INFO - [2019-09-12 16:46:44,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:44,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:44,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:44,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:44,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:46:44,566] {scheduler_job.py:146} INFO - Started process (PID=30418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:49,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:49,576] {logging_mixin.py:95} INFO - [2019-09-12 16:46:49,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:49,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:49,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:49,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:49,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 16:46:50,024] {scheduler_job.py:146} INFO - Started process (PID=30419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:55,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:46:55,034] {logging_mixin.py:95} INFO - [2019-09-12 16:46:55,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:55,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:46:55,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:46:55,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:46:55,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:46:55,481] {scheduler_job.py:146} INFO - Started process (PID=30420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:00,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:00,488] {logging_mixin.py:95} INFO - [2019-09-12 16:47:00,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:00,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:00,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:00,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:00,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 16:47:00,936] {scheduler_job.py:146} INFO - Started process (PID=30425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:05,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:05,945] {logging_mixin.py:95} INFO - [2019-09-12 16:47:05,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:06,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:06,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:06,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:06,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:47:06,393] {scheduler_job.py:146} INFO - Started process (PID=30426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:11,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:11,403] {logging_mixin.py:95} INFO - [2019-09-12 16:47:11,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:11,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:11,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:11,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:11,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 16:47:11,846] {scheduler_job.py:146} INFO - Started process (PID=30430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:16,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:16,858] {logging_mixin.py:95} INFO - [2019-09-12 16:47:16,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:17,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:17,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:17,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:17,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 16:47:17,301] {scheduler_job.py:146} INFO - Started process (PID=30432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:22,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:22,312] {logging_mixin.py:95} INFO - [2019-09-12 16:47:22,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:22,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:22,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:22,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:22,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:47:22,763] {scheduler_job.py:146} INFO - Started process (PID=30433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:27,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:27,785] {logging_mixin.py:95} INFO - [2019-09-12 16:47:27,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:28,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:28,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:28,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:28,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 16:47:28,219] {scheduler_job.py:146} INFO - Started process (PID=30435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:33,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:33,230] {logging_mixin.py:95} INFO - [2019-09-12 16:47:33,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:33,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:33,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:33,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:33,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:47:33,671] {scheduler_job.py:146} INFO - Started process (PID=30439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:38,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:38,681] {logging_mixin.py:95} INFO - [2019-09-12 16:47:38,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:39,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:39,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:39,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:39,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:47:39,127] {scheduler_job.py:146} INFO - Started process (PID=30440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:44,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:44,148] {logging_mixin.py:95} INFO - [2019-09-12 16:47:44,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:44,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:44,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:44,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:44,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 16:47:44,579] {scheduler_job.py:146} INFO - Started process (PID=30446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:49,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:49,591] {logging_mixin.py:95} INFO - [2019-09-12 16:47:49,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:49,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:49,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:49,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:49,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 16:47:50,054] {scheduler_job.py:146} INFO - Started process (PID=30447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:55,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:47:55,060] {logging_mixin.py:95} INFO - [2019-09-12 16:47:55,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:55,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:47:55,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:47:55,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:47:55,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 16:47:55,543] {scheduler_job.py:146} INFO - Started process (PID=30451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:00,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:48:00,557] {logging_mixin.py:95} INFO - [2019-09-12 16:48:00,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:00,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:00,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:48:00,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:48:00,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:48:01,033] {scheduler_job.py:146} INFO - Started process (PID=30453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:06,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:48:06,047] {logging_mixin.py:95} INFO - [2019-09-12 16:48:06,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:06,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:48:06,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:48:06,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:48:06,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:48:06,527] {scheduler_job.py:146} INFO - Started process (PID=30454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:57:55,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:57:55,225] {logging_mixin.py:95} INFO - [2019-09-12 16:57:55,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:57:55,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:57:55,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:57:55,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:57:55,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 589.100 seconds
[2019-09-12 16:57:55,709] {scheduler_job.py:146} INFO - Started process (PID=30462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:00,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:00,721] {logging_mixin.py:95} INFO - [2019-09-12 16:58:00,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:01,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:01,143] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:01,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:01,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 16:58:01,258] {scheduler_job.py:146} INFO - Started process (PID=30471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:06,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:06,265] {logging_mixin.py:95} INFO - [2019-09-12 16:58:06,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:06,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:06,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:06,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:06,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 16:58:06,706] {scheduler_job.py:146} INFO - Started process (PID=30474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:11,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:11,719] {logging_mixin.py:95} INFO - [2019-09-12 16:58:11,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:12,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:12,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:12,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:12,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 16:58:12,253] {scheduler_job.py:146} INFO - Started process (PID=30479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:17,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:17,263] {logging_mixin.py:95} INFO - [2019-09-12 16:58:17,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:17,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:17,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:17,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:17,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 16:58:17,704] {scheduler_job.py:146} INFO - Started process (PID=30480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:22,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:22,713] {logging_mixin.py:95} INFO - [2019-09-12 16:58:22,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:23,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:23,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:23,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:23,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 16:58:23,155] {scheduler_job.py:146} INFO - Started process (PID=30481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:28,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:28,171] {logging_mixin.py:95} INFO - [2019-09-12 16:58:28,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:28,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:28,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:28,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:28,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 16:58:28,610] {scheduler_job.py:146} INFO - Started process (PID=30487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:33,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:33,618] {logging_mixin.py:95} INFO - [2019-09-12 16:58:33,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:33,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:33,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:34,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:34,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 16:58:34,064] {scheduler_job.py:146} INFO - Started process (PID=30489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:39,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:39,075] {logging_mixin.py:95} INFO - [2019-09-12 16:58:39,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:39,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:39,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:39,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:39,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 16:58:39,519] {scheduler_job.py:146} INFO - Started process (PID=30490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:44,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:44,527] {logging_mixin.py:95} INFO - [2019-09-12 16:58:44,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:44,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:44,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:44,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:44,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 16:58:44,973] {scheduler_job.py:146} INFO - Started process (PID=30495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:49,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:49,979] {logging_mixin.py:95} INFO - [2019-09-12 16:58:49,979] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:50,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:50,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:50,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:50,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 16:58:50,425] {scheduler_job.py:146} INFO - Started process (PID=30496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:55,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:58:55,434] {logging_mixin.py:95} INFO - [2019-09-12 16:58:55,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:55,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:58:55,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:58:55,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:58:55,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-12 16:58:55,972] {scheduler_job.py:146} INFO - Started process (PID=30497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:00,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:00,981] {logging_mixin.py:95} INFO - [2019-09-12 16:59:00,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:01,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:01,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:01,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:01,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:59:01,424] {scheduler_job.py:146} INFO - Started process (PID=30502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:06,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:06,431] {logging_mixin.py:95} INFO - [2019-09-12 16:59:06,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:06,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:06,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:06,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:06,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 16:59:06,879] {scheduler_job.py:146} INFO - Started process (PID=30503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:11,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:11,888] {logging_mixin.py:95} INFO - [2019-09-12 16:59:11,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:12,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:12,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:12,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:12,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 16:59:12,333] {scheduler_job.py:146} INFO - Started process (PID=30505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:17,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:17,340] {logging_mixin.py:95} INFO - [2019-09-12 16:59:17,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:17,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:17,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:17,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:17,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 16:59:17,785] {scheduler_job.py:146} INFO - Started process (PID=30509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:22,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:22,796] {logging_mixin.py:95} INFO - [2019-09-12 16:59:22,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:23,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:23,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:23,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:23,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 16:59:23,240] {scheduler_job.py:146} INFO - Started process (PID=30510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:28,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:28,256] {logging_mixin.py:95} INFO - [2019-09-12 16:59:28,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:28,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:28,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:28,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:28,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 16:59:28,695] {scheduler_job.py:146} INFO - Started process (PID=30513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:33,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:33,704] {logging_mixin.py:95} INFO - [2019-09-12 16:59:33,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:34,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:34,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:34,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:34,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 16:59:34,144] {scheduler_job.py:146} INFO - Started process (PID=30517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:39,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:39,155] {logging_mixin.py:95} INFO - [2019-09-12 16:59:39,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:39,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:39,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:39,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:39,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 16:59:39,606] {scheduler_job.py:146} INFO - Started process (PID=30518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:44,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:44,616] {logging_mixin.py:95} INFO - [2019-09-12 16:59:44,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:44,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:44,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:45,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:45,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 16:59:45,068] {scheduler_job.py:146} INFO - Started process (PID=30520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:50,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:50,079] {logging_mixin.py:95} INFO - [2019-09-12 16:59:50,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:50,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:50,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:50,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:50,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 16:59:50,524] {scheduler_job.py:146} INFO - Started process (PID=30521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:55,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 16:59:55,530] {logging_mixin.py:95} INFO - [2019-09-12 16:59:55,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:55,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 16:59:55,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 16:59:55,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 16:59:55,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-12 16:59:55,982] {scheduler_job.py:146} INFO - Started process (PID=30525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:00,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:00,990] {logging_mixin.py:95} INFO - [2019-09-12 17:00:00,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:01,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:01,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:01,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:01,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:00:01,437] {scheduler_job.py:146} INFO - Started process (PID=30527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:06,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:06,445] {logging_mixin.py:95} INFO - [2019-09-12 17:00:06,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:06,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:06,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:06,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:06,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:00:06,894] {scheduler_job.py:146} INFO - Started process (PID=30531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:11,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:11,902] {logging_mixin.py:95} INFO - [2019-09-12 17:00:11,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:12,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:12,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:12,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:12,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:00:12,355] {scheduler_job.py:146} INFO - Started process (PID=30533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:17,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:17,366] {logging_mixin.py:95} INFO - [2019-09-12 17:00:17,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:17,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:17,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:17,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:17,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:00:17,812] {scheduler_job.py:146} INFO - Started process (PID=30534) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:22,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:22,823] {logging_mixin.py:95} INFO - [2019-09-12 17:00:22,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:23,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:23,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:23,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:23,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:00:23,273] {scheduler_job.py:146} INFO - Started process (PID=30535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:28,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:28,293] {logging_mixin.py:95} INFO - [2019-09-12 17:00:28,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:28,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:28,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:28,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:28,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-12 17:00:28,733] {scheduler_job.py:146} INFO - Started process (PID=30541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:33,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:33,741] {logging_mixin.py:95} INFO - [2019-09-12 17:00:33,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:34,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:34,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:34,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:34,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:00:34,189] {scheduler_job.py:146} INFO - Started process (PID=30542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:39,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:39,195] {logging_mixin.py:95} INFO - [2019-09-12 17:00:39,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:39,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:39,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:39,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:39,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:00:39,648] {scheduler_job.py:146} INFO - Started process (PID=30546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:44,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:44,659] {logging_mixin.py:95} INFO - [2019-09-12 17:00:44,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:45,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:45,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:45,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:45,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:00:45,107] {scheduler_job.py:146} INFO - Started process (PID=30548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:50,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:50,114] {logging_mixin.py:95} INFO - [2019-09-12 17:00:50,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:50,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:50,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:50,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:50,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:00:50,567] {scheduler_job.py:146} INFO - Started process (PID=30549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:55,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:00:55,578] {logging_mixin.py:95} INFO - [2019-09-12 17:00:55,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:55,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:00:55,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:00:55,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:00:55,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:00:56,022] {scheduler_job.py:146} INFO - Started process (PID=30553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:01,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:01,028] {logging_mixin.py:95} INFO - [2019-09-12 17:01:01,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:01,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:01,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:01,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:01,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:01:01,474] {scheduler_job.py:146} INFO - Started process (PID=30555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:06,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:06,482] {logging_mixin.py:95} INFO - [2019-09-12 17:01:06,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:06,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:06,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:06,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:06,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:01:06,925] {scheduler_job.py:146} INFO - Started process (PID=30559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:11,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:11,933] {logging_mixin.py:95} INFO - [2019-09-12 17:01:11,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:12,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:12,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:12,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:12,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:01:12,386] {scheduler_job.py:146} INFO - Started process (PID=30561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:17,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:17,395] {logging_mixin.py:95} INFO - [2019-09-12 17:01:17,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:17,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:17,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:17,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:17,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:01:17,833] {scheduler_job.py:146} INFO - Started process (PID=30562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:22,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:22,840] {logging_mixin.py:95} INFO - [2019-09-12 17:01:22,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:23,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:23,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:23,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:23,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:01:23,282] {scheduler_job.py:146} INFO - Started process (PID=30563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:28,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:28,298] {logging_mixin.py:95} INFO - [2019-09-12 17:01:28,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:28,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:28,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:28,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:28,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-12 17:01:28,730] {scheduler_job.py:146} INFO - Started process (PID=30569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:33,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:33,742] {logging_mixin.py:95} INFO - [2019-09-12 17:01:33,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:34,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:34,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:34,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:34,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 17:01:34,180] {scheduler_job.py:146} INFO - Started process (PID=30570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:39,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:39,187] {logging_mixin.py:95} INFO - [2019-09-12 17:01:39,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:39,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:39,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:39,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:39,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:01:39,627] {scheduler_job.py:146} INFO - Started process (PID=30576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:44,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:44,640] {logging_mixin.py:95} INFO - [2019-09-12 17:01:44,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:45,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:45,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:45,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:45,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:01:45,077] {scheduler_job.py:146} INFO - Started process (PID=30580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:50,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:50,085] {logging_mixin.py:95} INFO - [2019-09-12 17:01:50,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:50,440] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:50,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:50,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:50,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:01:50,527] {scheduler_job.py:146} INFO - Started process (PID=30581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:55,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:01:55,536] {logging_mixin.py:95} INFO - [2019-09-12 17:01:55,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:55,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:01:55,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:01:55,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:01:55,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 17:01:55,987] {scheduler_job.py:146} INFO - Started process (PID=30586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:00,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:00,994] {logging_mixin.py:95} INFO - [2019-09-12 17:02:00,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:01,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:01,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:01,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:01,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-12 17:02:01,437] {scheduler_job.py:146} INFO - Started process (PID=30588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:06,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:06,446] {logging_mixin.py:95} INFO - [2019-09-12 17:02:06,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:06,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:06,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:06,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:06,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:02:06,890] {scheduler_job.py:146} INFO - Started process (PID=30589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:11,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:11,901] {logging_mixin.py:95} INFO - [2019-09-12 17:02:11,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:12,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:12,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:12,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:12,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 17:02:12,338] {scheduler_job.py:146} INFO - Started process (PID=30594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:17,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:17,349] {logging_mixin.py:95} INFO - [2019-09-12 17:02:17,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:17,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:17,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:17,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:17,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:02:17,792] {scheduler_job.py:146} INFO - Started process (PID=30595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:22,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:22,798] {logging_mixin.py:95} INFO - [2019-09-12 17:02:22,798] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:23,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:23,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:23,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:23,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 17:02:23,245] {scheduler_job.py:146} INFO - Started process (PID=30596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:28,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:28,266] {logging_mixin.py:95} INFO - [2019-09-12 17:02:28,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:28,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:28,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:28,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:28,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:02:28,697] {scheduler_job.py:146} INFO - Started process (PID=30602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:33,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:33,704] {logging_mixin.py:95} INFO - [2019-09-12 17:02:33,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:34,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:34,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:34,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:34,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-12 17:02:34,154] {scheduler_job.py:146} INFO - Started process (PID=30603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:39,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:39,159] {logging_mixin.py:95} INFO - [2019-09-12 17:02:39,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:39,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:39,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:39,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:39,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 17:02:39,601] {scheduler_job.py:146} INFO - Started process (PID=30604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:44,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:44,609] {logging_mixin.py:95} INFO - [2019-09-12 17:02:44,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:44,985] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:45,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:45,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:45,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:02:45,045] {scheduler_job.py:146} INFO - Started process (PID=31153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:50,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:50,054] {logging_mixin.py:95} INFO - [2019-09-12 17:02:50,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:50,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:50,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:50,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:50,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 17:02:50,483] {scheduler_job.py:146} INFO - Started process (PID=31999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:55,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:02:55,493] {logging_mixin.py:95} INFO - [2019-09-12 17:02:55,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:55,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:02:55,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:02:56,000] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:02:56,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.523 seconds
[2019-09-12 17:02:56,035] {scheduler_job.py:146} INFO - Started process (PID=32003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:01,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:01,043] {logging_mixin.py:95} INFO - [2019-09-12 17:03:01,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:01,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:01,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:01,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:01,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:03:01,498] {scheduler_job.py:146} INFO - Started process (PID=32008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:06,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:06,509] {logging_mixin.py:95} INFO - [2019-09-12 17:03:06,509] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:06,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:06,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:06,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:06,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:03:06,953] {scheduler_job.py:146} INFO - Started process (PID=32009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:11,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:11,962] {logging_mixin.py:95} INFO - [2019-09-12 17:03:11,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:12,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:12,332] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:12,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:12,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:03:12,410] {scheduler_job.py:146} INFO - Started process (PID=32014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:17,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:17,418] {logging_mixin.py:95} INFO - [2019-09-12 17:03:17,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:17,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:17,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:17,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:17,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:03:17,871] {scheduler_job.py:146} INFO - Started process (PID=32015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:22,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:22,878] {logging_mixin.py:95} INFO - [2019-09-12 17:03:22,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:23,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:23,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:23,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:23,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:03:23,333] {scheduler_job.py:146} INFO - Started process (PID=32016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:28,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:28,342] {logging_mixin.py:95} INFO - [2019-09-12 17:03:28,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:28,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:28,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:28,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:28,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 17:03:28,797] {scheduler_job.py:146} INFO - Started process (PID=32022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:33,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:33,809] {logging_mixin.py:95} INFO - [2019-09-12 17:03:33,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:34,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:34,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:34,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:34,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:03:34,249] {scheduler_job.py:146} INFO - Started process (PID=32023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:39,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:39,260] {logging_mixin.py:95} INFO - [2019-09-12 17:03:39,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:39,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:39,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:39,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:39,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:03:39,708] {scheduler_job.py:146} INFO - Started process (PID=32024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:44,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:44,718] {logging_mixin.py:95} INFO - [2019-09-12 17:03:44,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:45,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:45,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:45,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:45,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:03:45,167] {scheduler_job.py:146} INFO - Started process (PID=32029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:50,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:50,174] {logging_mixin.py:95} INFO - [2019-09-12 17:03:50,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:50,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:50,600] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:50,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:50,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-12 17:03:50,727] {scheduler_job.py:146} INFO - Started process (PID=32030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:55,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:03:55,735] {logging_mixin.py:95} INFO - [2019-09-12 17:03:55,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:56,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:03:56,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:03:56,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:03:56,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 17:03:56,174] {scheduler_job.py:146} INFO - Started process (PID=32031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:01,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:01,182] {logging_mixin.py:95} INFO - [2019-09-12 17:04:01,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:01,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:01,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:01,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:01,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:04:01,616] {scheduler_job.py:146} INFO - Started process (PID=32036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:06,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:06,623] {logging_mixin.py:95} INFO - [2019-09-12 17:04:06,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:07,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:07,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:07,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:07,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-12 17:04:07,165] {scheduler_job.py:146} INFO - Started process (PID=32037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:12,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:12,172] {logging_mixin.py:95} INFO - [2019-09-12 17:04:12,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:12,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:12,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:12,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:12,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:04:12,609] {scheduler_job.py:146} INFO - Started process (PID=32039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:17,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:17,615] {logging_mixin.py:95} INFO - [2019-09-12 17:04:17,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:17,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:17,988] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:17,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:18,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:04:18,067] {scheduler_job.py:146} INFO - Started process (PID=32040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:23,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:23,073] {logging_mixin.py:95} INFO - [2019-09-12 17:04:23,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:23,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:23,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:23,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:23,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:04:23,528] {scheduler_job.py:146} INFO - Started process (PID=32044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:28,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:28,539] {logging_mixin.py:95} INFO - [2019-09-12 17:04:28,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:28,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:28,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:28,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:28,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 17:04:29,078] {scheduler_job.py:146} INFO - Started process (PID=32047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:34,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:34,087] {logging_mixin.py:95} INFO - [2019-09-12 17:04:34,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:34,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:34,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:34,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:34,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:04:34,528] {scheduler_job.py:146} INFO - Started process (PID=32051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:39,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:39,532] {logging_mixin.py:95} INFO - [2019-09-12 17:04:39,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:39,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:39,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:39,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:39,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 17:04:40,072] {scheduler_job.py:146} INFO - Started process (PID=32052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:45,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:45,079] {logging_mixin.py:95} INFO - [2019-09-12 17:04:45,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:45,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:45,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:45,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:45,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-12 17:04:45,619] {scheduler_job.py:146} INFO - Started process (PID=32054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:50,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:50,627] {logging_mixin.py:95} INFO - [2019-09-12 17:04:50,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:50,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:51,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:51,014] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:51,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:04:51,064] {scheduler_job.py:146} INFO - Started process (PID=32055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:56,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:04:56,070] {logging_mixin.py:95} INFO - [2019-09-12 17:04:56,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:56,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:04:56,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:04:56,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:04:56,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-12 17:04:56,610] {scheduler_job.py:146} INFO - Started process (PID=32063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:01,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:01,616] {logging_mixin.py:95} INFO - [2019-09-12 17:05:01,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:02,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:02,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:02,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:02,052] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-12 17:05:02,156] {scheduler_job.py:146} INFO - Started process (PID=32068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:07,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:07,166] {logging_mixin.py:95} INFO - [2019-09-12 17:05:07,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:07,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:07,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:07,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:07,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:05:07,602] {scheduler_job.py:146} INFO - Started process (PID=32072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:12,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:12,610] {logging_mixin.py:95} INFO - [2019-09-12 17:05:12,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:13,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:13,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:13,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:13,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-12 17:05:13,158] {scheduler_job.py:146} INFO - Started process (PID=32074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:18,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:18,168] {logging_mixin.py:95} INFO - [2019-09-12 17:05:18,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:18,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:18,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:18,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:18,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:05:18,616] {scheduler_job.py:146} INFO - Started process (PID=32075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:23,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:23,624] {logging_mixin.py:95} INFO - [2019-09-12 17:05:23,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:23,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:24,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:24,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:24,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:05:24,069] {scheduler_job.py:146} INFO - Started process (PID=32079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:29,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:29,075] {logging_mixin.py:95} INFO - [2019-09-12 17:05:29,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:29,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:29,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:29,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:29,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:05:29,515] {scheduler_job.py:146} INFO - Started process (PID=32082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:34,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:34,525] {logging_mixin.py:95} INFO - [2019-09-12 17:05:34,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:34,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:34,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:34,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:34,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-12 17:05:35,071] {scheduler_job.py:146} INFO - Started process (PID=32083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:40,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:40,077] {logging_mixin.py:95} INFO - [2019-09-12 17:05:40,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:40,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:40,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:40,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:40,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-12 17:05:40,615] {scheduler_job.py:146} INFO - Started process (PID=32087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:45,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:45,621] {logging_mixin.py:95} INFO - [2019-09-12 17:05:45,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:45,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:46,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:46,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:46,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:05:46,058] {scheduler_job.py:146} INFO - Started process (PID=32090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:51,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:51,063] {logging_mixin.py:95} INFO - [2019-09-12 17:05:51,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:51,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:51,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:51,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:51,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-12 17:05:51,602] {scheduler_job.py:146} INFO - Started process (PID=32091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:56,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:05:56,608] {logging_mixin.py:95} INFO - [2019-09-12 17:05:56,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:56,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:05:56,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:05:56,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:05:56,968] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-12 17:05:57,053] {scheduler_job.py:146} INFO - Started process (PID=32097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:02,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:02,058] {logging_mixin.py:95} INFO - [2019-09-12 17:06:02,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:02,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:02,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:02,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:02,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:06:02,506] {scheduler_job.py:146} INFO - Started process (PID=32098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:07,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:07,515] {logging_mixin.py:95} INFO - [2019-09-12 17:06:07,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:07,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:07,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:07,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:07,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-12 17:06:07,960] {scheduler_job.py:146} INFO - Started process (PID=32099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:12,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:12,969] {logging_mixin.py:95} INFO - [2019-09-12 17:06:12,969] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:13,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:13,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:13,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:13,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:06:13,413] {scheduler_job.py:146} INFO - Started process (PID=32101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:18,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:18,422] {logging_mixin.py:95} INFO - [2019-09-12 17:06:18,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:18,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:18,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:18,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:18,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:06:18,869] {scheduler_job.py:146} INFO - Started process (PID=32105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:23,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:23,879] {logging_mixin.py:95} INFO - [2019-09-12 17:06:23,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:24,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:24,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:24,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:24,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-12 17:06:24,321] {scheduler_job.py:146} INFO - Started process (PID=32106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:29,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:29,326] {logging_mixin.py:95} INFO - [2019-09-12 17:06:29,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:29,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:29,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:29,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:29,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:06:29,774] {scheduler_job.py:146} INFO - Started process (PID=32112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:34,788] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:34,788] {logging_mixin.py:95} INFO - [2019-09-12 17:06:34,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:35,136] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:35,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:35,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:35,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 17:06:35,230] {scheduler_job.py:146} INFO - Started process (PID=32113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:40,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:40,236] {logging_mixin.py:95} INFO - [2019-09-12 17:06:40,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:40,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:40,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:40,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:40,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:06:40,688] {scheduler_job.py:146} INFO - Started process (PID=32114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:45,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:45,693] {logging_mixin.py:95} INFO - [2019-09-12 17:06:45,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:46,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:46,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:46,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:46,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-12 17:06:46,141] {scheduler_job.py:146} INFO - Started process (PID=32116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:51,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:51,146] {logging_mixin.py:95} INFO - [2019-09-12 17:06:51,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:51,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:51,547] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:51,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:51,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:06:51,596] {scheduler_job.py:146} INFO - Started process (PID=32120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:56,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:06:56,606] {logging_mixin.py:95} INFO - [2019-09-12 17:06:56,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:56,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:06:57,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:06:57,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:06:57,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-12 17:06:57,151] {scheduler_job.py:146} INFO - Started process (PID=32125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:02,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:02,159] {logging_mixin.py:95} INFO - [2019-09-12 17:07:02,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:02,535] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:02,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:02,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:02,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 17:07:02,596] {scheduler_job.py:146} INFO - Started process (PID=32126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:07,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:07,603] {logging_mixin.py:95} INFO - [2019-09-12 17:07:07,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:07,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:07,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:07,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:07,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-12 17:07:08,050] {scheduler_job.py:146} INFO - Started process (PID=32127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:13,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:13,055] {logging_mixin.py:95} INFO - [2019-09-12 17:07:13,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:13,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:13,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:13,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:13,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-12 17:07:13,504] {scheduler_job.py:146} INFO - Started process (PID=32129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:18,509] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:18,510] {logging_mixin.py:95} INFO - [2019-09-12 17:07:18,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:18,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:18,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:18,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:18,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:07:18,956] {scheduler_job.py:146} INFO - Started process (PID=32130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:23,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:23,963] {logging_mixin.py:95} INFO - [2019-09-12 17:07:23,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:24,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:24,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:24,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:24,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-12 17:07:24,411] {scheduler_job.py:146} INFO - Started process (PID=32134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:29,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:29,418] {logging_mixin.py:95} INFO - [2019-09-12 17:07:29,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:29,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:29,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:29,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:29,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:07:29,866] {scheduler_job.py:146} INFO - Started process (PID=32137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:34,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:34,874] {logging_mixin.py:95} INFO - [2019-09-12 17:07:34,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:35,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:35,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:35,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:35,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-12 17:07:35,316] {scheduler_job.py:146} INFO - Started process (PID=32141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:40,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:40,326] {logging_mixin.py:95} INFO - [2019-09-12 17:07:40,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:40,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:40,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:40,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:40,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-12 17:07:40,772] {scheduler_job.py:146} INFO - Started process (PID=32142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:45,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:45,779] {logging_mixin.py:95} INFO - [2019-09-12 17:07:45,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:46,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:46,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:46,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:46,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-12 17:07:46,227] {scheduler_job.py:146} INFO - Started process (PID=32147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:51,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:51,235] {logging_mixin.py:95} INFO - [2019-09-12 17:07:51,235] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:51,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:51,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:51,612] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:51,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 17:07:51,669] {scheduler_job.py:146} INFO - Started process (PID=32148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:56,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:07:56,674] {logging_mixin.py:95} INFO - [2019-09-12 17:07:56,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:57,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:07:57,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:07:57,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:07:57,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-12 17:07:57,130] {scheduler_job.py:146} INFO - Started process (PID=32150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:02,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:02,138] {logging_mixin.py:95} INFO - [2019-09-12 17:08:02,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:02,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:02,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:02,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:02,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 17:08:02,582] {scheduler_job.py:146} INFO - Started process (PID=32151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:07,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:07,588] {logging_mixin.py:95} INFO - [2019-09-12 17:08:07,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:07,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:07,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:07,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:07,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-12 17:08:08,032] {scheduler_job.py:146} INFO - Started process (PID=32152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:13,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:13,039] {logging_mixin.py:95} INFO - [2019-09-12 17:08:13,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:13,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:13,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:13,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:13,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-12 17:08:13,483] {scheduler_job.py:146} INFO - Started process (PID=32154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:18,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:18,492] {logging_mixin.py:95} INFO - [2019-09-12 17:08:18,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:18,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:18,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:18,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:18,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-12 17:08:18,938] {scheduler_job.py:146} INFO - Started process (PID=32155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:23,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:23,947] {logging_mixin.py:95} INFO - [2019-09-12 17:08:23,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:24,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:24,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:24,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:24,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-12 17:08:24,395] {scheduler_job.py:146} INFO - Started process (PID=32156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:29,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:29,401] {logging_mixin.py:95} INFO - [2019-09-12 17:08:29,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:29,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:29,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:29,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:29,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 17:08:29,846] {scheduler_job.py:146} INFO - Started process (PID=32159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:34,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:34,856] {logging_mixin.py:95} INFO - [2019-09-12 17:08:34,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:35,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:35,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:35,217] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:35,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-12 17:08:35,298] {scheduler_job.py:146} INFO - Started process (PID=32160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:40,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:40,307] {logging_mixin.py:95} INFO - [2019-09-12 17:08:40,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:40,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:40,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:40,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:40,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 17:08:40,751] {scheduler_job.py:146} INFO - Started process (PID=32161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:45,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:45,757] {logging_mixin.py:95} INFO - [2019-09-12 17:08:45,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:46,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:46,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:46,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:46,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-12 17:08:46,206] {scheduler_job.py:146} INFO - Started process (PID=32163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:51,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:51,214] {logging_mixin.py:95} INFO - [2019-09-12 17:08:51,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:51,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:51,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:51,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:51,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-12 17:08:51,660] {scheduler_job.py:146} INFO - Started process (PID=32164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:56,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:08:56,666] {logging_mixin.py:95} INFO - [2019-09-12 17:08:56,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:57,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:08:57,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:08:57,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:08:57,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:08:57,113] {scheduler_job.py:146} INFO - Started process (PID=32166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:02,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:02,119] {logging_mixin.py:95} INFO - [2019-09-12 17:09:02,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:02,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:02,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:02,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:02,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-12 17:09:02,565] {scheduler_job.py:146} INFO - Started process (PID=32167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:07,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:07,570] {logging_mixin.py:95} INFO - [2019-09-12 17:09:07,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:07,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:07,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:07,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:07,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-12 17:09:08,018] {scheduler_job.py:146} INFO - Started process (PID=32168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:13,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:13,027] {logging_mixin.py:95} INFO - [2019-09-12 17:09:13,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:13,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:13,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:13,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:13,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 17:09:13,469] {scheduler_job.py:146} INFO - Started process (PID=32170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:18,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:18,477] {logging_mixin.py:95} INFO - [2019-09-12 17:09:18,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:18,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:18,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:18,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:18,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-12 17:09:18,927] {scheduler_job.py:146} INFO - Started process (PID=32172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:23,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:23,935] {logging_mixin.py:95} INFO - [2019-09-12 17:09:23,935] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:24,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:24,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:24,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:24,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 17:09:24,383] {scheduler_job.py:146} INFO - Started process (PID=32173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:29,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:29,392] {logging_mixin.py:95} INFO - [2019-09-12 17:09:29,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:29,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:29,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:29,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:29,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-12 17:09:29,832] {scheduler_job.py:146} INFO - Started process (PID=32176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:34,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:34,837] {logging_mixin.py:95} INFO - [2019-09-12 17:09:34,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:35,182] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:35,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:35,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:35,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 17:09:35,292] {scheduler_job.py:146} INFO - Started process (PID=32177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:40,299] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:40,300] {logging_mixin.py:95} INFO - [2019-09-12 17:09:40,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:40,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:40,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:40,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:40,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:09:40,754] {scheduler_job.py:146} INFO - Started process (PID=32178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:45,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:45,760] {logging_mixin.py:95} INFO - [2019-09-12 17:09:45,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:46,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:46,131] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:46,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:46,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 17:09:46,209] {scheduler_job.py:146} INFO - Started process (PID=32180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:51,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:51,215] {logging_mixin.py:95} INFO - [2019-09-12 17:09:51,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:51,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:51,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:51,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:51,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:09:51,666] {scheduler_job.py:146} INFO - Started process (PID=32182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:56,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:09:56,673] {logging_mixin.py:95} INFO - [2019-09-12 17:09:56,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:57,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:09:57,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:09:57,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:09:57,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:09:57,128] {scheduler_job.py:146} INFO - Started process (PID=32184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:02,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:02,136] {logging_mixin.py:95} INFO - [2019-09-12 17:10:02,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:02,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:02,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:02,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:02,532] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:10:02,587] {scheduler_job.py:146} INFO - Started process (PID=32186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:07,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:07,597] {logging_mixin.py:95} INFO - [2019-09-12 17:10:07,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:07,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:07,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:07,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:07,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:10:08,043] {scheduler_job.py:146} INFO - Started process (PID=32187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:13,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:13,050] {logging_mixin.py:95} INFO - [2019-09-12 17:10:13,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:13,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:13,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:13,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:13,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:10:13,505] {scheduler_job.py:146} INFO - Started process (PID=32189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:18,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:18,515] {logging_mixin.py:95} INFO - [2019-09-12 17:10:18,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:18,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:18,886] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:18,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:18,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:10:18,970] {scheduler_job.py:146} INFO - Started process (PID=32190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:23,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:23,981] {logging_mixin.py:95} INFO - [2019-09-12 17:10:23,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:24,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:24,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:24,366] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:24,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:10:24,434] {scheduler_job.py:146} INFO - Started process (PID=32191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:29,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:29,440] {logging_mixin.py:95} INFO - [2019-09-12 17:10:29,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:29,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:29,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:29,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:29,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:10:29,900] {scheduler_job.py:146} INFO - Started process (PID=32194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:34,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:34,907] {logging_mixin.py:95} INFO - [2019-09-12 17:10:34,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:35,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:35,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:35,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:35,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:10:35,363] {scheduler_job.py:146} INFO - Started process (PID=32195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:40,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:40,380] {logging_mixin.py:95} INFO - [2019-09-12 17:10:40,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:40,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:40,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:40,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:40,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:10:40,828] {scheduler_job.py:146} INFO - Started process (PID=32196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:45,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:45,841] {logging_mixin.py:95} INFO - [2019-09-12 17:10:45,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:46,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:46,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:46,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:46,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:10:46,297] {scheduler_job.py:146} INFO - Started process (PID=32198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:51,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:51,308] {logging_mixin.py:95} INFO - [2019-09-12 17:10:51,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:51,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:51,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:51,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:51,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:10:51,786] {scheduler_job.py:146} INFO - Started process (PID=32199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:56,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:10:56,792] {logging_mixin.py:95} INFO - [2019-09-12 17:10:56,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:57,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:10:57,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:10:57,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:10:57,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:10:57,273] {scheduler_job.py:146} INFO - Started process (PID=32201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:02,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:02,285] {logging_mixin.py:95} INFO - [2019-09-12 17:11:02,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:02,640] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:02,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:02,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:02,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:11:02,765] {scheduler_job.py:146} INFO - Started process (PID=32202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:07,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:07,776] {logging_mixin.py:95} INFO - [2019-09-12 17:11:07,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:08,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:08,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:08,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:08,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:11:08,260] {scheduler_job.py:146} INFO - Started process (PID=32203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:13,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:13,272] {logging_mixin.py:95} INFO - [2019-09-12 17:11:13,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:13,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:13,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:13,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:13,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:11:13,759] {scheduler_job.py:146} INFO - Started process (PID=32205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:18,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:18,773] {logging_mixin.py:95} INFO - [2019-09-12 17:11:18,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:19,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:19,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:19,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:19,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:11:19,241] {scheduler_job.py:146} INFO - Started process (PID=32206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:24,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:24,246] {logging_mixin.py:95} INFO - [2019-09-12 17:11:24,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:24,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:24,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:24,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:24,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-09-12 17:11:24,631] {scheduler_job.py:146} INFO - Started process (PID=32207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:29,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:29,642] {logging_mixin.py:95} INFO - [2019-09-12 17:11:29,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:29,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:30,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:30,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:30,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:11:30,127] {scheduler_job.py:146} INFO - Started process (PID=32210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:35,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:35,144] {logging_mixin.py:95} INFO - [2019-09-12 17:11:35,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:35,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:35,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:35,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:35,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:11:35,629] {scheduler_job.py:146} INFO - Started process (PID=32211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:40,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:40,646] {logging_mixin.py:95} INFO - [2019-09-12 17:11:40,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:40,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:41,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:41,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:41,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:11:41,120] {scheduler_job.py:146} INFO - Started process (PID=32212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:46,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:46,137] {logging_mixin.py:95} INFO - [2019-09-12 17:11:46,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:46,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:46,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:46,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:46,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:11:46,622] {scheduler_job.py:146} INFO - Started process (PID=32214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:51,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:51,628] {logging_mixin.py:95} INFO - [2019-09-12 17:11:51,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:51,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:51,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:52,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:52,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-12 17:11:52,107] {scheduler_job.py:146} INFO - Started process (PID=32215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:57,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:11:57,123] {logging_mixin.py:95} INFO - [2019-09-12 17:11:57,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:57,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:11:57,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:11:57,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:11:57,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:11:57,607] {scheduler_job.py:146} INFO - Started process (PID=32217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:02,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:02,620] {logging_mixin.py:95} INFO - [2019-09-12 17:12:02,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:02,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:02,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:03,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:03,011] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:12:03,104] {scheduler_job.py:146} INFO - Started process (PID=32218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:08,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:08,117] {logging_mixin.py:95} INFO - [2019-09-12 17:12:08,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:08,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:08,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:08,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:08,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:12:08,597] {scheduler_job.py:146} INFO - Started process (PID=32219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:13,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:13,610] {logging_mixin.py:95} INFO - [2019-09-12 17:12:13,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:13,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:13,982] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:13,990] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:13,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:12:14,088] {scheduler_job.py:146} INFO - Started process (PID=32221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:19,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:19,097] {logging_mixin.py:95} INFO - [2019-09-12 17:12:19,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:19,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:19,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:19,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:19,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:12:19,580] {scheduler_job.py:146} INFO - Started process (PID=32222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:24,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:24,589] {logging_mixin.py:95} INFO - [2019-09-12 17:12:24,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:24,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:24,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:24,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:24,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:12:25,071] {scheduler_job.py:146} INFO - Started process (PID=32223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:30,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:30,077] {logging_mixin.py:95} INFO - [2019-09-12 17:12:30,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:30,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:30,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:30,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:30,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:12:30,569] {scheduler_job.py:146} INFO - Started process (PID=32226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:35,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:35,575] {logging_mixin.py:95} INFO - [2019-09-12 17:12:35,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:35,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:35,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:35,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:35,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 17:12:36,064] {scheduler_job.py:146} INFO - Started process (PID=32227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:41,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:41,081] {logging_mixin.py:95} INFO - [2019-09-12 17:12:41,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:41,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:41,457] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:41,465] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:41,470] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:12:41,558] {scheduler_job.py:146} INFO - Started process (PID=32228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:46,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:46,564] {logging_mixin.py:95} INFO - [2019-09-12 17:12:46,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:46,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:46,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:46,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:46,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:12:47,041] {scheduler_job.py:146} INFO - Started process (PID=32230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:52,050] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:52,051] {logging_mixin.py:95} INFO - [2019-09-12 17:12:52,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:52,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:52,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:52,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:52,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 17:12:52,528] {scheduler_job.py:146} INFO - Started process (PID=32231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:57,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:12:57,543] {logging_mixin.py:95} INFO - [2019-09-12 17:12:57,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:57,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:12:57,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:12:57,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:12:57,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:12:58,026] {scheduler_job.py:146} INFO - Started process (PID=32233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:03,035] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:03,036] {logging_mixin.py:95} INFO - [2019-09-12 17:13:03,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:03,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:03,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:03,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:03,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:13:03,526] {scheduler_job.py:146} INFO - Started process (PID=32234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:08,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:08,536] {logging_mixin.py:95} INFO - [2019-09-12 17:13:08,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:08,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:08,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:08,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:08,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 17:13:09,030] {scheduler_job.py:146} INFO - Started process (PID=32235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:14,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:14,038] {logging_mixin.py:95} INFO - [2019-09-12 17:13:14,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:14,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:14,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:14,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:14,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:13:14,520] {scheduler_job.py:146} INFO - Started process (PID=32237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:19,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:19,535] {logging_mixin.py:95} INFO - [2019-09-12 17:13:19,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:19,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:19,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:19,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:19,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:13:20,015] {scheduler_job.py:146} INFO - Started process (PID=32238) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:25,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:25,032] {logging_mixin.py:95} INFO - [2019-09-12 17:13:25,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:25,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:25,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:25,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:25,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:13:25,514] {scheduler_job.py:146} INFO - Started process (PID=32239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:30,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:30,521] {logging_mixin.py:95} INFO - [2019-09-12 17:13:30,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:30,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:30,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:30,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:30,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 17:13:31,013] {scheduler_job.py:146} INFO - Started process (PID=32242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:36,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:36,023] {logging_mixin.py:95} INFO - [2019-09-12 17:13:36,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:36,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:36,399] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:36,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:36,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:13:36,513] {scheduler_job.py:146} INFO - Started process (PID=32243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:41,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:41,528] {logging_mixin.py:95} INFO - [2019-09-12 17:13:41,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:41,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:41,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:41,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:41,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:13:42,010] {scheduler_job.py:146} INFO - Started process (PID=32244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:47,018] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:47,019] {logging_mixin.py:95} INFO - [2019-09-12 17:13:47,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:47,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:47,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:47,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:47,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 17:13:47,418] {scheduler_job.py:146} INFO - Started process (PID=32246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:52,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:52,428] {logging_mixin.py:95} INFO - [2019-09-12 17:13:52,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:52,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:52,792] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:52,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:52,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 17:13:52,916] {scheduler_job.py:146} INFO - Started process (PID=32247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:57,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:13:57,928] {logging_mixin.py:95} INFO - [2019-09-12 17:13:57,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:58,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:13:58,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:13:58,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:13:58,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:13:58,413] {scheduler_job.py:146} INFO - Started process (PID=32249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:03,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:03,429] {logging_mixin.py:95} INFO - [2019-09-12 17:14:03,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:03,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:03,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:03,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:03,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:14:03,908] {scheduler_job.py:146} INFO - Started process (PID=32250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:08,918] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:08,919] {logging_mixin.py:95} INFO - [2019-09-12 17:14:08,918] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:09,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:09,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:09,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:09,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:14:09,398] {scheduler_job.py:146} INFO - Started process (PID=32251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:14,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:14,414] {logging_mixin.py:95} INFO - [2019-09-12 17:14:14,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:14,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:14,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:14,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:14,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:14:14,891] {scheduler_job.py:146} INFO - Started process (PID=32253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:19,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:19,900] {logging_mixin.py:95} INFO - [2019-09-12 17:14:19,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:20,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:20,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:20,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:20,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:14:20,392] {scheduler_job.py:146} INFO - Started process (PID=32254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:25,401] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:25,402] {logging_mixin.py:95} INFO - [2019-09-12 17:14:25,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:25,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:25,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:25,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:25,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:14:25,894] {scheduler_job.py:146} INFO - Started process (PID=32255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:30,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:30,902] {logging_mixin.py:95} INFO - [2019-09-12 17:14:30,902] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:31,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:31,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:31,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:31,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:14:31,396] {scheduler_job.py:146} INFO - Started process (PID=32258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:36,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:36,413] {logging_mixin.py:95} INFO - [2019-09-12 17:14:36,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:36,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:36,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:36,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:36,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:14:36,893] {scheduler_job.py:146} INFO - Started process (PID=32259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:41,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:41,902] {logging_mixin.py:95} INFO - [2019-09-12 17:14:41,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:42,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:42,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:42,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:42,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:14:42,386] {scheduler_job.py:146} INFO - Started process (PID=32260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:47,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:47,401] {logging_mixin.py:95} INFO - [2019-09-12 17:14:47,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:47,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:47,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:47,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:47,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:14:47,871] {scheduler_job.py:146} INFO - Started process (PID=32262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:52,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:52,882] {logging_mixin.py:95} INFO - [2019-09-12 17:14:52,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:53,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:53,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:53,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:53,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:14:53,373] {scheduler_job.py:146} INFO - Started process (PID=32263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:58,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:14:58,385] {logging_mixin.py:95} INFO - [2019-09-12 17:14:58,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:58,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:14:58,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:14:58,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:14:58,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:14:58,846] {scheduler_job.py:146} INFO - Started process (PID=32265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:03,859] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:03,860] {logging_mixin.py:95} INFO - [2019-09-12 17:15:03,860] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:04,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:04,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:04,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:04,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:15:04,343] {scheduler_job.py:146} INFO - Started process (PID=32266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:09,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:09,356] {logging_mixin.py:95} INFO - [2019-09-12 17:15:09,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:09,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:09,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:09,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:09,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:15:09,841] {scheduler_job.py:146} INFO - Started process (PID=32267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:14,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:14,851] {logging_mixin.py:95} INFO - [2019-09-12 17:15:14,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:15,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:15,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:15,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:15,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:15:15,345] {scheduler_job.py:146} INFO - Started process (PID=32269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:20,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:20,353] {logging_mixin.py:95} INFO - [2019-09-12 17:15:20,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:20,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:20,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:20,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:20,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:15:20,843] {scheduler_job.py:146} INFO - Started process (PID=32270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:25,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:25,851] {logging_mixin.py:95} INFO - [2019-09-12 17:15:25,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:26,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:26,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:26,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:26,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:15:26,335] {scheduler_job.py:146} INFO - Started process (PID=32272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:31,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:31,351] {logging_mixin.py:95} INFO - [2019-09-12 17:15:31,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:31,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:31,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:31,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:31,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:15:31,827] {scheduler_job.py:146} INFO - Started process (PID=32274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:36,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:36,834] {logging_mixin.py:95} INFO - [2019-09-12 17:15:36,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:37,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:37,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:37,217] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:37,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:15:37,312] {scheduler_job.py:146} INFO - Started process (PID=32275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:42,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:42,328] {logging_mixin.py:95} INFO - [2019-09-12 17:15:42,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:42,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:42,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:42,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:42,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:15:42,812] {scheduler_job.py:146} INFO - Started process (PID=32277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:47,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:47,827] {logging_mixin.py:95} INFO - [2019-09-12 17:15:47,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:48,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:48,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:48,207] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:48,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:15:48,294] {scheduler_job.py:146} INFO - Started process (PID=32278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:53,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:53,303] {logging_mixin.py:95} INFO - [2019-09-12 17:15:53,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:53,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:53,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:53,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:53,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:15:53,784] {scheduler_job.py:146} INFO - Started process (PID=32279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:58,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:15:58,800] {logging_mixin.py:95} INFO - [2019-09-12 17:15:58,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:59,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:15:59,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:15:59,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:15:59,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-12 17:15:59,269] {scheduler_job.py:146} INFO - Started process (PID=32281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:04,279] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:04,280] {logging_mixin.py:95} INFO - [2019-09-12 17:16:04,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:04,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:04,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:04,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:04,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 17:16:04,760] {scheduler_job.py:146} INFO - Started process (PID=32282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:09,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:09,772] {logging_mixin.py:95} INFO - [2019-09-12 17:16:09,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:10,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:10,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:10,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:10,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:16:10,253] {scheduler_job.py:146} INFO - Started process (PID=32283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:15,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:15,265] {logging_mixin.py:95} INFO - [2019-09-12 17:16:15,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:15,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:15,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:15,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:15,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:16:15,744] {scheduler_job.py:146} INFO - Started process (PID=32285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:20,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:20,753] {logging_mixin.py:95} INFO - [2019-09-12 17:16:20,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:21,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:21,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:21,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:21,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:16:21,241] {scheduler_job.py:146} INFO - Started process (PID=32286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:26,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:26,256] {logging_mixin.py:95} INFO - [2019-09-12 17:16:26,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:26,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:26,638] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:26,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:26,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:16:26,735] {scheduler_job.py:146} INFO - Started process (PID=32288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:31,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:31,745] {logging_mixin.py:95} INFO - [2019-09-12 17:16:31,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:32,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:32,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:32,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:32,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:16:32,217] {scheduler_job.py:146} INFO - Started process (PID=32290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:37,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:37,228] {logging_mixin.py:95} INFO - [2019-09-12 17:16:37,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:37,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:37,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:37,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:37,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:16:37,710] {scheduler_job.py:146} INFO - Started process (PID=32291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:42,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:42,717] {logging_mixin.py:95} INFO - [2019-09-12 17:16:42,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:43,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:43,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:43,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:43,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:16:43,205] {scheduler_job.py:146} INFO - Started process (PID=32293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:48,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:16:48,219] {logging_mixin.py:95} INFO - [2019-09-12 17:16:48,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:48,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:16:48,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:16:48,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:16:48,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:16:48,690] {scheduler_job.py:146} INFO - Started process (PID=32294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:53,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:18:53,643] {logging_mixin.py:95} INFO - [2019-09-12 17:18:53,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:54,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:54,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:18:54,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:18:54,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 125.398 seconds
[2019-09-12 17:18:54,143] {scheduler_job.py:146} INFO - Started process (PID=32301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:59,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:18:59,152] {logging_mixin.py:95} INFO - [2019-09-12 17:18:59,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:59,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:18:59,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:18:59,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:18:59,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 17:18:59,588] {scheduler_job.py:146} INFO - Started process (PID=32303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:04,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:04,595] {logging_mixin.py:95} INFO - [2019-09-12 17:19:04,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:04,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:04,975] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:04,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:04,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:19:05,029] {scheduler_job.py:146} INFO - Started process (PID=32308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:10,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:10,037] {logging_mixin.py:95} INFO - [2019-09-12 17:19:10,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:10,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:10,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:10,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:10,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-12 17:19:10,585] {scheduler_job.py:146} INFO - Started process (PID=32309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:15,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:15,602] {logging_mixin.py:95} INFO - [2019-09-12 17:19:15,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:16,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:16,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:16,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:16,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-12 17:19:16,132] {scheduler_job.py:146} INFO - Started process (PID=32311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:21,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:21,143] {logging_mixin.py:95} INFO - [2019-09-12 17:19:21,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:21,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:21,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:21,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:21,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:19:21,578] {scheduler_job.py:146} INFO - Started process (PID=32312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:26,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:26,588] {logging_mixin.py:95} INFO - [2019-09-12 17:19:26,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:26,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:26,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:26,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:26,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 17:19:27,043] {scheduler_job.py:146} INFO - Started process (PID=32314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:32,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:32,050] {logging_mixin.py:95} INFO - [2019-09-12 17:19:32,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:32,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:32,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:32,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:32,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 17:19:32,490] {scheduler_job.py:146} INFO - Started process (PID=32316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:37,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:37,499] {logging_mixin.py:95} INFO - [2019-09-12 17:19:37,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:37,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:37,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:37,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:37,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-12 17:19:38,042] {scheduler_job.py:146} INFO - Started process (PID=32319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:43,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:43,051] {logging_mixin.py:95} INFO - [2019-09-12 17:19:43,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:43,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:43,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:43,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:43,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:19:43,487] {scheduler_job.py:146} INFO - Started process (PID=32321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:48,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:48,496] {logging_mixin.py:95} INFO - [2019-09-12 17:19:48,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:48,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:48,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:48,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:48,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:19:48,935] {scheduler_job.py:146} INFO - Started process (PID=32322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:53,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:53,942] {logging_mixin.py:95} INFO - [2019-09-12 17:19:53,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:54,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:54,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:54,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:54,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-12 17:19:54,484] {scheduler_job.py:146} INFO - Started process (PID=32323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:59,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:19:59,497] {logging_mixin.py:95} INFO - [2019-09-12 17:19:59,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:59,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:19:59,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:19:59,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:19:59,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-12 17:19:59,932] {scheduler_job.py:146} INFO - Started process (PID=32325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:04,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:04,938] {logging_mixin.py:95} INFO - [2019-09-12 17:20:04,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:05,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:05,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:05,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:05,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-12 17:20:05,479] {scheduler_job.py:146} INFO - Started process (PID=32326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:10,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:10,497] {logging_mixin.py:95} INFO - [2019-09-12 17:20:10,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:10,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:10,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:10,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:10,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:20:10,935] {scheduler_job.py:146} INFO - Started process (PID=32327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:15,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:15,947] {logging_mixin.py:95} INFO - [2019-09-12 17:20:15,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:16,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:16,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:16,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:16,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:20:16,384] {scheduler_job.py:146} INFO - Started process (PID=32329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:21,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:21,396] {logging_mixin.py:95} INFO - [2019-09-12 17:20:21,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:21,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:21,776] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:21,785] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:21,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:20:21,842] {scheduler_job.py:146} INFO - Started process (PID=32330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:26,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:26,848] {logging_mixin.py:95} INFO - [2019-09-12 17:20:26,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:27,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:27,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:27,254] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:27,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 17:20:27,293] {scheduler_job.py:146} INFO - Started process (PID=32332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:32,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:32,301] {logging_mixin.py:95} INFO - [2019-09-12 17:20:32,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:32,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:32,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:32,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:32,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-12 17:20:32,843] {scheduler_job.py:146} INFO - Started process (PID=32334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:37,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:37,851] {logging_mixin.py:95} INFO - [2019-09-12 17:20:37,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:38,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:38,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:38,235] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:38,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:20:38,295] {scheduler_job.py:146} INFO - Started process (PID=32335) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:43,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:43,304] {logging_mixin.py:95} INFO - [2019-09-12 17:20:43,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:43,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:43,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:43,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:43,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:20:43,744] {scheduler_job.py:146} INFO - Started process (PID=32337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:48,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:48,756] {logging_mixin.py:95} INFO - [2019-09-12 17:20:48,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:49,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:49,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:49,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:49,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 17:20:49,199] {scheduler_job.py:146} INFO - Started process (PID=32338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:54,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:54,204] {logging_mixin.py:95} INFO - [2019-09-12 17:20:54,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:54,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:54,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:20:54,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:20:54,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:20:54,656] {scheduler_job.py:146} INFO - Started process (PID=32339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:20:59,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:20:59,665] {logging_mixin.py:95} INFO - [2019-09-12 17:20:59,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:00,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:00,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:00,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:00,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:21:00,120] {scheduler_job.py:146} INFO - Started process (PID=32341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:05,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:05,126] {logging_mixin.py:95} INFO - [2019-09-12 17:21:05,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:05,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:05,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:05,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:05,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:21:05,566] {scheduler_job.py:146} INFO - Started process (PID=32342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:10,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:10,572] {logging_mixin.py:95} INFO - [2019-09-12 17:21:10,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:10,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:10,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:10,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:10,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-12 17:21:11,024] {scheduler_job.py:146} INFO - Started process (PID=32343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:16,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:16,032] {logging_mixin.py:95} INFO - [2019-09-12 17:21:16,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:16,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:16,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:16,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:16,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:21:16,483] {scheduler_job.py:146} INFO - Started process (PID=32345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:21,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:21,494] {logging_mixin.py:95} INFO - [2019-09-12 17:21:21,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:21,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:21,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:21,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:21,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:21:21,947] {scheduler_job.py:146} INFO - Started process (PID=32346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:26,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:26,954] {logging_mixin.py:95} INFO - [2019-09-12 17:21:26,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:27,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:27,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:27,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:27,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:21:27,402] {scheduler_job.py:146} INFO - Started process (PID=32348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:32,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:32,410] {logging_mixin.py:95} INFO - [2019-09-12 17:21:32,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:32,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:32,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:32,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:32,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:21:32,851] {scheduler_job.py:146} INFO - Started process (PID=32350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:37,859] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:37,860] {logging_mixin.py:95} INFO - [2019-09-12 17:21:37,860] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:38,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:38,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:38,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:38,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:21:38,300] {scheduler_job.py:146} INFO - Started process (PID=32351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:43,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:43,310] {logging_mixin.py:95} INFO - [2019-09-12 17:21:43,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:43,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:43,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:43,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:43,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:21:43,753] {scheduler_job.py:146} INFO - Started process (PID=32353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:48,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:48,764] {logging_mixin.py:95} INFO - [2019-09-12 17:21:48,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:49,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:49,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:49,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:49,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 17:21:49,204] {scheduler_job.py:146} INFO - Started process (PID=32354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:54,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:54,210] {logging_mixin.py:95} INFO - [2019-09-12 17:21:54,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:54,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:54,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:21:54,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:21:54,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:21:54,661] {scheduler_job.py:146} INFO - Started process (PID=32355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:21:59,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:21:59,671] {logging_mixin.py:95} INFO - [2019-09-12 17:21:59,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:00,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:00,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:00,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:00,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:22:00,109] {scheduler_job.py:146} INFO - Started process (PID=32357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:05,115] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:05,116] {logging_mixin.py:95} INFO - [2019-09-12 17:22:05,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:05,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:05,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:05,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:05,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:22:05,563] {scheduler_job.py:146} INFO - Started process (PID=32358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:10,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:10,583] {logging_mixin.py:95} INFO - [2019-09-12 17:22:10,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:10,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:10,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:10,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:10,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:22:11,027] {scheduler_job.py:146} INFO - Started process (PID=32359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:16,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:16,035] {logging_mixin.py:95} INFO - [2019-09-12 17:22:16,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:16,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:16,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:16,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:16,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-12 17:22:16,485] {scheduler_job.py:146} INFO - Started process (PID=32361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:21,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:21,497] {logging_mixin.py:95} INFO - [2019-09-12 17:22:21,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:21,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:21,872] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:21,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:21,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:22:21,939] {scheduler_job.py:146} INFO - Started process (PID=32362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:26,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:26,946] {logging_mixin.py:95} INFO - [2019-09-12 17:22:26,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:27,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:27,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:27,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:27,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:22:27,400] {scheduler_job.py:146} INFO - Started process (PID=32364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:32,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:32,409] {logging_mixin.py:95} INFO - [2019-09-12 17:22:32,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:32,797] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:32,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:32,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:32,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 17:22:32,949] {scheduler_job.py:146} INFO - Started process (PID=32366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:37,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:37,959] {logging_mixin.py:95} INFO - [2019-09-12 17:22:37,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:38,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:38,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:38,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:38,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-12 17:22:38,402] {scheduler_job.py:146} INFO - Started process (PID=32367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:43,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:43,413] {logging_mixin.py:95} INFO - [2019-09-12 17:22:43,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:43,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:43,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:43,814] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:22:43,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:43,850] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:22:43,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-12 17:22:43,960] {scheduler_job.py:146} INFO - Started process (PID=32369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:48,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:48,972] {logging_mixin.py:95} INFO - [2019-09-12 17:22:48,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:49,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:49,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:49,361] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:22:49,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:49,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-12 17:22:49,513] {scheduler_job.py:146} INFO - Started process (PID=32371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:54,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:22:54,524] {logging_mixin.py:95} INFO - [2019-09-12 17:22:54,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:54,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:22:54,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:22:54,939] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:22:54,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:22:54,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-12 17:22:55,064] {scheduler_job.py:146} INFO - Started process (PID=32372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:00,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:00,072] {logging_mixin.py:95} INFO - [2019-09-12 17:23:00,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:00,422] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:00,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:00,456] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:00,487] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:00,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 17:23:00,521] {scheduler_job.py:146} INFO - Started process (PID=32374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:05,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:05,527] {logging_mixin.py:95} INFO - [2019-09-12 17:23:05,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:05,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:05,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:05,957] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:05,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:05,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-12 17:23:06,079] {scheduler_job.py:146} INFO - Started process (PID=32376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:11,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:11,096] {logging_mixin.py:95} INFO - [2019-09-12 17:23:11,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:11,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:11,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:11,493] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:11,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:11,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 17:23:11,632] {scheduler_job.py:146} INFO - Started process (PID=32377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:16,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:16,637] {logging_mixin.py:95} INFO - [2019-09-12 17:23:16,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:17,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:17,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:17,219] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:17,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:17,256] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:17,258] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:17,261] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:17,263] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:17,265] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:17,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.645 seconds
[2019-09-12 17:23:17,383] {scheduler_job.py:146} INFO - Started process (PID=32379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:22,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:22,393] {logging_mixin.py:95} INFO - [2019-09-12 17:23:22,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:22,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:22,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:22,784] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:22,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:22,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-12 17:23:22,835] {scheduler_job.py:146} INFO - Started process (PID=32381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:27,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:27,845] {logging_mixin.py:95} INFO - [2019-09-12 17:23:27,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:28,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:28,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:28,246] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:28,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:28,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-12 17:23:28,382] {scheduler_job.py:146} INFO - Started process (PID=32384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:33,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:33,391] {logging_mixin.py:95} INFO - [2019-09-12 17:23:33,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:33,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:33,792] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:33,801] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:33,826] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:33,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-12 17:23:33,927] {scheduler_job.py:146} INFO - Started process (PID=32385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:38,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:38,944] {logging_mixin.py:95} INFO - [2019-09-12 17:23:38,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:39,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:39,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:39,359] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:39,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:39,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-12 17:23:39,474] {scheduler_job.py:146} INFO - Started process (PID=32387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:44,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:44,480] {logging_mixin.py:95} INFO - [2019-09-12 17:23:44,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:44,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:44,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:44,879] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:44,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:44,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 17:23:44,929] {scheduler_job.py:146} INFO - Started process (PID=32389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:49,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:49,940] {logging_mixin.py:95} INFO - [2019-09-12 17:23:49,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:50,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:50,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:50,389] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:50,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:50,419] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_amzn_to_s3 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:23:50,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-12 17:23:50,485] {scheduler_job.py:146} INFO - Started process (PID=32395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:55,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:23:55,496] {logging_mixin.py:95} INFO - [2019-09-12 17:23:55,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:55,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:23:55,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:23:55,876] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:23:55,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:23:55,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 17:23:55,947] {scheduler_job.py:146} INFO - Started process (PID=32399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:00,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:00,956] {logging_mixin.py:95} INFO - [2019-09-12 17:24:00,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:01,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:01,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:01,332] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:01,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:01,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:24:01,404] {scheduler_job.py:146} INFO - Started process (PID=32401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:06,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:06,413] {logging_mixin.py:95} INFO - [2019-09-12 17:24:06,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:06,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:06,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:06,797] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:06,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:06,823] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:24:06,862] {scheduler_job.py:146} INFO - Started process (PID=32402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:11,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:11,873] {logging_mixin.py:95} INFO - [2019-09-12 17:24:11,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:12,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:12,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:12,274] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:12,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:12,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 17:24:12,324] {scheduler_job.py:146} INFO - Started process (PID=32404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:17,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:17,331] {logging_mixin.py:95} INFO - [2019-09-12 17:24:17,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:17,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:17,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:17,728] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:17,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:17,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 17:24:17,786] {scheduler_job.py:146} INFO - Started process (PID=32406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:22,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:22,792] {logging_mixin.py:95} INFO - [2019-09-12 17:24:22,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:23,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:23,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:23,162] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:23,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:23,187] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_msft_to_s3 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:24:23,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:24:23,246] {scheduler_job.py:146} INFO - Started process (PID=32409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:28,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:24:28,257] {logging_mixin.py:95} INFO - [2019-09-12 17:24:28,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:28,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:24:28,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:24:28,631] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:24:28,652] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:24:28,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:25:58,968] {scheduler_job.py:146} INFO - Started process (PID=32424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:03,975] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:03,976] {logging_mixin.py:95} INFO - [2019-09-12 17:26:03,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:04,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:04,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:04,361] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:04,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:04,383] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_fb_to_s3 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:26:04,386] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_aapl_to_s3 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:26:04,388] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_googl_to_s3 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:26:04,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 17:26:04,427] {scheduler_job.py:146} INFO - Started process (PID=32426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:09,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:09,438] {logging_mixin.py:95} INFO - [2019-09-12 17:26:09,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:09,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:09,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:09,819] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:09,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:09,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:26:09,887] {scheduler_job.py:146} INFO - Started process (PID=32427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:14,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:14,895] {logging_mixin.py:95} INFO - [2019-09-12 17:26:14,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:15,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:15,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:15,292] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:15,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:15,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-12 17:26:15,349] {scheduler_job.py:146} INFO - Started process (PID=32429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:20,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:20,361] {logging_mixin.py:95} INFO - [2019-09-12 17:26:20,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:20,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:20,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:20,738] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:20,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:20,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:26:20,799] {scheduler_job.py:146} INFO - Started process (PID=32431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:25,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:25,806] {logging_mixin.py:95} INFO - [2019-09-12 17:26:25,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:26,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:26,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:26,238] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:26,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:26,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-12 17:26:26,353] {scheduler_job.py:146} INFO - Started process (PID=32432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:31,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:31,362] {logging_mixin.py:95} INFO - [2019-09-12 17:26:31,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:31,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:31,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:31,727] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:31,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:31,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:26:31,812] {scheduler_job.py:146} INFO - Started process (PID=32438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:36,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:36,819] {logging_mixin.py:95} INFO - [2019-09-12 17:26:36,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:37,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:37,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:37,201] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:37,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:37,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-12 17:26:37,271] {scheduler_job.py:146} INFO - Started process (PID=32439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:42,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:42,288] {logging_mixin.py:95} INFO - [2019-09-12 17:26:42,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:42,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:42,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:42,669] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:42,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:42,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-12 17:26:42,733] {scheduler_job.py:146} INFO - Started process (PID=32440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:47,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:47,740] {logging_mixin.py:95} INFO - [2019-09-12 17:26:47,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:48,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:48,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:48,134] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:48,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:48,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:26:48,189] {scheduler_job.py:146} INFO - Started process (PID=32444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:53,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:53,195] {logging_mixin.py:95} INFO - [2019-09-12 17:26:53,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:53,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:53,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:53,625] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:53,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:53,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 17:26:53,739] {scheduler_job.py:146} INFO - Started process (PID=32449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:58,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:26:58,748] {logging_mixin.py:95} INFO - [2019-09-12 17:26:58,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:59,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:26:59,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:26:59,128] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:26:59,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:26:59,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:26:59,199] {scheduler_job.py:146} INFO - Started process (PID=32451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:04,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:04,228] {logging_mixin.py:95} INFO - [2019-09-12 17:27:04,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:04,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:04,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:04,607] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:04,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:04,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 17:27:04,663] {scheduler_job.py:146} INFO - Started process (PID=32454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:09,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:09,675] {logging_mixin.py:95} INFO - [2019-09-12 17:27:09,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:10,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:10,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:10,051] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:10,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:10,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:27:10,115] {scheduler_job.py:146} INFO - Started process (PID=32456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:15,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:15,123] {logging_mixin.py:95} INFO - [2019-09-12 17:27:15,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:15,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:15,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:15,505] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:15,519] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:15,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-12 17:27:15,576] {scheduler_job.py:146} INFO - Started process (PID=32458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:20,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:20,583] {logging_mixin.py:95} INFO - [2019-09-12 17:27:20,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:20,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:20,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:20,960] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:20,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:20,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:27:21,037] {scheduler_job.py:146} INFO - Started process (PID=32459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:26,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:26,046] {logging_mixin.py:95} INFO - [2019-09-12 17:27:26,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:26,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:26,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:26,452] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:26,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:26,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-12 17:27:26,496] {scheduler_job.py:146} INFO - Started process (PID=32461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:31,504] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:31,505] {logging_mixin.py:95} INFO - [2019-09-12 17:27:31,505] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:31,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:31,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:31,907] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:31,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:31,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-12 17:27:31,947] {scheduler_job.py:146} INFO - Started process (PID=32464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:36,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:36,953] {logging_mixin.py:95} INFO - [2019-09-12 17:27:36,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:37,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:37,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:37,325] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:37,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:37,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:27:37,405] {scheduler_job.py:146} INFO - Started process (PID=32468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:42,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:42,411] {logging_mixin.py:95} INFO - [2019-09-12 17:27:42,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:42,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:42,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:42,813] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:42,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:42,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-12 17:27:42,863] {scheduler_job.py:146} INFO - Started process (PID=32469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:47,869] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:47,870] {logging_mixin.py:95} INFO - [2019-09-12 17:27:47,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:48,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:48,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:48,273] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:48,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:48,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-12 17:27:48,322] {scheduler_job.py:146} INFO - Started process (PID=32471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:53,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:53,333] {logging_mixin.py:95} INFO - [2019-09-12 17:27:53,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:53,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:53,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:53,717] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:53,731] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:53,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 17:27:53,777] {scheduler_job.py:146} INFO - Started process (PID=32473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:58,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:27:58,785] {logging_mixin.py:95} INFO - [2019-09-12 17:27:58,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:59,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:27:59,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:27:59,184] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:27:59,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:27:59,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 17:27:59,233] {scheduler_job.py:146} INFO - Started process (PID=32475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:04,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:04,241] {logging_mixin.py:95} INFO - [2019-09-12 17:28:04,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:04,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:04,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:04,627] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:04,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:04,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:28:04,695] {scheduler_job.py:146} INFO - Started process (PID=32476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:09,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:09,702] {logging_mixin.py:95} INFO - [2019-09-12 17:28:09,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:10,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:10,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:10,160] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:10,178] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:10,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-12 17:28:10,253] {scheduler_job.py:146} INFO - Started process (PID=32480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:15,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:15,260] {logging_mixin.py:95} INFO - [2019-09-12 17:28:15,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:15,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:15,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:15,657] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:15,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:15,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 17:28:42,152] {scheduler_job.py:146} INFO - Started process (PID=32487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:47,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:47,160] {logging_mixin.py:95} INFO - [2019-09-12 17:28:47,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:47,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:47,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:47,732] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:47,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:47,747] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.end 2019-09-12 22:22:39.316294+00:00 [scheduled]> in ORM
[2019-09-12 17:28:47,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.606 seconds
[2019-09-12 17:28:47,814] {scheduler_job.py:146} INFO - Started process (PID=32489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:52,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:52,822] {logging_mixin.py:95} INFO - [2019-09-12 17:28:52,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:53,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:53,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:53,209] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:53,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:53,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:28:53,271] {scheduler_job.py:146} INFO - Started process (PID=32491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:58,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:28:58,282] {logging_mixin.py:95} INFO - [2019-09-12 17:28:58,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:58,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:58,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:28:58,667] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:28:58,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:28:58,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:28:58,738] {scheduler_job.py:146} INFO - Started process (PID=32493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:03,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:03,747] {logging_mixin.py:95} INFO - [2019-09-12 17:29:03,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:04,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:04,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:04,165] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:29:04,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:04,182] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 17:29:04,291] {scheduler_job.py:146} INFO - Started process (PID=32494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:09,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:09,302] {logging_mixin.py:95} INFO - [2019-09-12 17:29:09,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:09,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:09,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:09,715] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:29:09,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:09,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 17:29:09,841] {scheduler_job.py:146} INFO - Started process (PID=32496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:14,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:14,848] {logging_mixin.py:95} INFO - [2019-09-12 17:29:14,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:15,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:15,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:15,235] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:29:15,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:15,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:29:15,301] {scheduler_job.py:146} INFO - Started process (PID=32498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:20,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:20,311] {logging_mixin.py:95} INFO - [2019-09-12 17:29:20,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:20,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:20,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:20,690] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True>
[2019-09-12 17:29:20,697] {logging_mixin.py:95} INFO - [2019-09-12 17:29:20,696] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-09-12 22:22:39.316294+00:00: manual__2019-09-12T22:22:39.316294+00:00, externally triggered: True> successful
[2019-09-12 17:29:20,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:20,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:29:20,761] {scheduler_job.py:146} INFO - Started process (PID=32499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:25,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:25,775] {logging_mixin.py:95} INFO - [2019-09-12 17:29:25,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:26,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:26,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:26,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:26,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:29:26,220] {scheduler_job.py:146} INFO - Started process (PID=32500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:31,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:31,233] {logging_mixin.py:95} INFO - [2019-09-12 17:29:31,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:31,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:31,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:31,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:31,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-12 17:29:31,667] {scheduler_job.py:146} INFO - Started process (PID=32503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:36,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:36,683] {logging_mixin.py:95} INFO - [2019-09-12 17:29:36,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:37,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:37,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:37,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:37,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 17:29:37,122] {scheduler_job.py:146} INFO - Started process (PID=32504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:42,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:42,139] {logging_mixin.py:95} INFO - [2019-09-12 17:29:42,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:42,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:42,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:42,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:42,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:29:42,579] {scheduler_job.py:146} INFO - Started process (PID=32505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:47,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:47,594] {logging_mixin.py:95} INFO - [2019-09-12 17:29:47,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:47,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:47,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:47,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:47,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:29:48,043] {scheduler_job.py:146} INFO - Started process (PID=32507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:53,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:53,060] {logging_mixin.py:95} INFO - [2019-09-12 17:29:53,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:53,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:53,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:53,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:53,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:29:53,504] {scheduler_job.py:146} INFO - Started process (PID=32508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:58,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:29:58,521] {logging_mixin.py:95} INFO - [2019-09-12 17:29:58,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:58,857] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:29:58,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:29:58,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:29:58,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 17:29:58,968] {scheduler_job.py:146} INFO - Started process (PID=32510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:03,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:03,983] {logging_mixin.py:95} INFO - [2019-09-12 17:30:03,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:04,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:04,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:04,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:04,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:30:04,427] {scheduler_job.py:146} INFO - Started process (PID=32512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:09,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:09,441] {logging_mixin.py:95} INFO - [2019-09-12 17:30:09,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:09,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:09,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:09,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:09,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:30:09,888] {scheduler_job.py:146} INFO - Started process (PID=32513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:14,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:14,900] {logging_mixin.py:95} INFO - [2019-09-12 17:30:14,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:15,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:15,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:15,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:15,339] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-12 17:30:15,438] {scheduler_job.py:146} INFO - Started process (PID=32515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:20,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:20,451] {logging_mixin.py:95} INFO - [2019-09-12 17:30:20,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:20,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:20,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:20,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:20,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-12 17:30:20,893] {scheduler_job.py:146} INFO - Started process (PID=32516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:25,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:25,907] {logging_mixin.py:95} INFO - [2019-09-12 17:30:25,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:26,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:26,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:26,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:26,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:30:26,351] {scheduler_job.py:146} INFO - Started process (PID=32517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:31,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:31,364] {logging_mixin.py:95} INFO - [2019-09-12 17:30:31,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:31,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:31,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:31,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:31,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:30:31,811] {scheduler_job.py:146} INFO - Started process (PID=32520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:36,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:36,824] {logging_mixin.py:95} INFO - [2019-09-12 17:30:36,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:37,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:37,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:37,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:37,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 17:30:37,276] {scheduler_job.py:146} INFO - Started process (PID=32521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:42,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:42,290] {logging_mixin.py:95} INFO - [2019-09-12 17:30:42,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:42,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:42,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:42,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:42,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:30:42,736] {scheduler_job.py:146} INFO - Started process (PID=32522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:47,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:47,753] {logging_mixin.py:95} INFO - [2019-09-12 17:30:47,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:48,118] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:48,142] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:48,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:48,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-12 17:30:48,194] {scheduler_job.py:146} INFO - Started process (PID=32524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:53,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:53,214] {logging_mixin.py:95} INFO - [2019-09-12 17:30:53,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:53,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:53,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:53,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:53,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:30:53,654] {scheduler_job.py:146} INFO - Started process (PID=32525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:58,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:30:58,677] {logging_mixin.py:95} INFO - [2019-09-12 17:30:58,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:59,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:30:59,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:30:59,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:30:59,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-12 17:30:59,124] {scheduler_job.py:146} INFO - Started process (PID=32529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:04,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:04,139] {logging_mixin.py:95} INFO - [2019-09-12 17:31:04,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:04,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:04,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:04,635] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:04,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.520 seconds
[2019-09-12 17:31:04,688] {scheduler_job.py:146} INFO - Started process (PID=32530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:09,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:09,701] {logging_mixin.py:95} INFO - [2019-09-12 17:31:09,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:10,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:10,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:10,129] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:10,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-12 17:31:10,218] {scheduler_job.py:146} INFO - Started process (PID=32542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:15,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:15,239] {logging_mixin.py:95} INFO - [2019-09-12 17:31:15,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:15,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:15,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:15,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:15,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-12 17:31:15,673] {scheduler_job.py:146} INFO - Started process (PID=32544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:20,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:20,690] {logging_mixin.py:95} INFO - [2019-09-12 17:31:20,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:21,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:21,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:21,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:21,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:31:21,125] {scheduler_job.py:146} INFO - Started process (PID=32545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:26,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:26,136] {logging_mixin.py:95} INFO - [2019-09-12 17:31:26,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:26,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:26,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:26,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:26,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-12 17:31:26,666] {scheduler_job.py:146} INFO - Started process (PID=32546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:31,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:31,679] {logging_mixin.py:95} INFO - [2019-09-12 17:31:31,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:32,057] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:32,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:32,088] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:32,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 17:31:32,206] {scheduler_job.py:146} INFO - Started process (PID=32549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:37,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:37,218] {logging_mixin.py:95} INFO - [2019-09-12 17:31:37,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:37,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:37,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:37,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:37,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-12 17:31:37,656] {scheduler_job.py:146} INFO - Started process (PID=32550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:42,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:42,668] {logging_mixin.py:95} INFO - [2019-09-12 17:31:42,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:43,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:43,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:43,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:43,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:31:43,099] {scheduler_job.py:146} INFO - Started process (PID=32551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:48,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:48,114] {logging_mixin.py:95} INFO - [2019-09-12 17:31:48,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:48,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:48,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:48,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:48,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-12 17:31:48,639] {scheduler_job.py:146} INFO - Started process (PID=32558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:53,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:53,656] {logging_mixin.py:95} INFO - [2019-09-12 17:31:53,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:54,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:54,078] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:54,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:54,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-12 17:31:54,191] {scheduler_job.py:146} INFO - Started process (PID=32559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:59,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:31:59,207] {logging_mixin.py:95} INFO - [2019-09-12 17:31:59,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:59,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:31:59,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:31:59,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:31:59,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-12 17:31:59,748] {scheduler_job.py:146} INFO - Started process (PID=32561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:04,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:04,762] {logging_mixin.py:95} INFO - [2019-09-12 17:32:04,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:05,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:05,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:05,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:05,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 17:32:05,193] {scheduler_job.py:146} INFO - Started process (PID=32562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:10,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:10,207] {logging_mixin.py:95} INFO - [2019-09-12 17:32:10,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:10,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:10,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:10,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:10,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-12 17:32:10,636] {scheduler_job.py:146} INFO - Started process (PID=32563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:15,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:15,653] {logging_mixin.py:95} INFO - [2019-09-12 17:32:15,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:16,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:16,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:16,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:16,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:32:16,098] {scheduler_job.py:146} INFO - Started process (PID=32565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:21,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:21,111] {logging_mixin.py:95} INFO - [2019-09-12 17:32:21,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:21,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:21,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:21,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:21,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-12 17:32:21,647] {scheduler_job.py:146} INFO - Started process (PID=32567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:26,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:26,661] {logging_mixin.py:95} INFO - [2019-09-12 17:32:26,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:27,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:27,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:27,030] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:27,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-12 17:32:27,100] {scheduler_job.py:146} INFO - Started process (PID=32582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:32,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:32,122] {logging_mixin.py:95} INFO - [2019-09-12 17:32:32,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:32,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:32,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:32,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:32,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-12 17:32:32,552] {scheduler_job.py:146} INFO - Started process (PID=32590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:37,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:37,566] {logging_mixin.py:95} INFO - [2019-09-12 17:32:37,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:37,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:37,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:37,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:37,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-12 17:32:38,002] {scheduler_job.py:146} INFO - Started process (PID=32593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:43,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:43,013] {logging_mixin.py:95} INFO - [2019-09-12 17:32:43,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:43,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:43,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:43,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:43,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-12 17:32:43,551] {scheduler_job.py:146} INFO - Started process (PID=32595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:48,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:48,564] {logging_mixin.py:95} INFO - [2019-09-12 17:32:48,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:48,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:48,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:48,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:48,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-12 17:32:49,004] {scheduler_job.py:146} INFO - Started process (PID=32596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:54,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:54,014] {logging_mixin.py:95} INFO - [2019-09-12 17:32:54,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:54,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:54,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:54,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:54,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-12 17:32:54,445] {scheduler_job.py:146} INFO - Started process (PID=32597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:59,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:32:59,458] {logging_mixin.py:95} INFO - [2019-09-12 17:32:59,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:59,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:32:59,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:32:59,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:32:59,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-12 17:32:59,896] {scheduler_job.py:146} INFO - Started process (PID=32599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:04,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:04,910] {logging_mixin.py:95} INFO - [2019-09-12 17:33:04,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:05,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:05,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:05,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:05,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-12 17:33:05,352] {scheduler_job.py:146} INFO - Started process (PID=32600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:10,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:10,376] {logging_mixin.py:95} INFO - [2019-09-12 17:33:10,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:10,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:10,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:10,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:10,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:33:10,800] {scheduler_job.py:146} INFO - Started process (PID=32601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:15,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:15,813] {logging_mixin.py:95} INFO - [2019-09-12 17:33:15,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:16,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:16,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:16,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:16,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:33:16,262] {scheduler_job.py:146} INFO - Started process (PID=32603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:21,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:21,277] {logging_mixin.py:95} INFO - [2019-09-12 17:33:21,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:21,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:21,645] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:21,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:21,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-12 17:33:21,721] {scheduler_job.py:146} INFO - Started process (PID=32604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:26,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:26,735] {logging_mixin.py:95} INFO - [2019-09-12 17:33:26,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:27,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:27,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:27,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:27,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:33:27,183] {scheduler_job.py:146} INFO - Started process (PID=32605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:32,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:32,196] {logging_mixin.py:95} INFO - [2019-09-12 17:33:32,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:32,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:32,566] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:32,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:32,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-12 17:33:32,645] {scheduler_job.py:146} INFO - Started process (PID=32608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:37,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:37,659] {logging_mixin.py:95} INFO - [2019-09-12 17:33:37,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:38,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:38,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:38,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:38,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:33:38,104] {scheduler_job.py:146} INFO - Started process (PID=32609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:43,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:43,121] {logging_mixin.py:95} INFO - [2019-09-12 17:33:43,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:43,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:43,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:43,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:43,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:33:43,560] {scheduler_job.py:146} INFO - Started process (PID=32611) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:48,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:48,576] {logging_mixin.py:95} INFO - [2019-09-12 17:33:48,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:48,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:48,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:48,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:48,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-12 17:33:49,017] {scheduler_job.py:146} INFO - Started process (PID=32612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:54,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:54,034] {logging_mixin.py:95} INFO - [2019-09-12 17:33:54,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:54,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:54,399] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:54,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:54,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:33:54,480] {scheduler_job.py:146} INFO - Started process (PID=32613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:59,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:33:59,494] {logging_mixin.py:95} INFO - [2019-09-12 17:33:59,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:59,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:33:59,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:33:59,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:33:59,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-12 17:33:59,952] {scheduler_job.py:146} INFO - Started process (PID=32615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:04,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:04,968] {logging_mixin.py:95} INFO - [2019-09-12 17:34:04,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:05,314] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:05,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:05,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:05,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:34:05,416] {scheduler_job.py:146} INFO - Started process (PID=32616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:10,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:10,443] {logging_mixin.py:95} INFO - [2019-09-12 17:34:10,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:10,786] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:10,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:10,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:10,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-12 17:34:10,872] {scheduler_job.py:146} INFO - Started process (PID=32617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:15,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:15,887] {logging_mixin.py:95} INFO - [2019-09-12 17:34:15,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:16,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:16,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:16,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:16,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-12 17:34:16,332] {scheduler_job.py:146} INFO - Started process (PID=32619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:21,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:21,346] {logging_mixin.py:95} INFO - [2019-09-12 17:34:21,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:21,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:21,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:21,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:21,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-12 17:34:21,777] {scheduler_job.py:146} INFO - Started process (PID=32620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:26,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:26,791] {logging_mixin.py:95} INFO - [2019-09-12 17:34:26,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:27,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:27,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:27,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:27,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-12 17:34:27,230] {scheduler_job.py:146} INFO - Started process (PID=32621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:32,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:32,243] {logging_mixin.py:95} INFO - [2019-09-12 17:34:32,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:32,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:32,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:32,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:32,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-12 17:34:32,673] {scheduler_job.py:146} INFO - Started process (PID=32624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:37,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:37,690] {logging_mixin.py:95} INFO - [2019-09-12 17:34:37,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:38,057] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:38,078] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:38,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:38,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-12 17:34:38,126] {scheduler_job.py:146} INFO - Started process (PID=32625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:43,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:43,141] {logging_mixin.py:95} INFO - [2019-09-12 17:34:43,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:43,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:43,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:43,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:43,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-12 17:34:43,592] {scheduler_job.py:146} INFO - Started process (PID=32627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:48,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:48,609] {logging_mixin.py:95} INFO - [2019-09-12 17:34:48,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:48,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:48,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:48,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:48,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-12 17:34:49,051] {scheduler_job.py:146} INFO - Started process (PID=32628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:54,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:54,064] {logging_mixin.py:95} INFO - [2019-09-12 17:34:54,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:54,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:54,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:54,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:54,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-12 17:34:54,514] {scheduler_job.py:146} INFO - Started process (PID=32629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:59,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:34:59,527] {logging_mixin.py:95} INFO - [2019-09-12 17:34:59,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:59,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:34:59,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:34:59,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:34:59,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-12 17:34:59,976] {scheduler_job.py:146} INFO - Started process (PID=32631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:04,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:04,991] {logging_mixin.py:95} INFO - [2019-09-12 17:35:04,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:05,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:05,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:05,366] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:05,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 17:35:05,428] {scheduler_job.py:146} INFO - Started process (PID=32632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:10,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:10,454] {logging_mixin.py:95} INFO - [2019-09-12 17:35:10,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:10,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:10,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:10,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:10,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-12 17:35:10,884] {scheduler_job.py:146} INFO - Started process (PID=32633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:15,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:15,895] {logging_mixin.py:95} INFO - [2019-09-12 17:35:15,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:16,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:16,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:16,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:16,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-12 17:35:16,268] {scheduler_job.py:146} INFO - Started process (PID=32637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:21,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:21,287] {logging_mixin.py:95} INFO - [2019-09-12 17:35:21,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:21,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:21,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:21,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:21,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-12 17:35:21,760] {scheduler_job.py:146} INFO - Started process (PID=32638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:26,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:26,778] {logging_mixin.py:95} INFO - [2019-09-12 17:35:26,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:27,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:27,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-12 17:35:27,255] {scheduler_job.py:146} INFO - Started process (PID=32639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:27,266] {logging_mixin.py:95} INFO - [2019-09-12 17:35:27,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:27,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:27,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.388 seconds
[2019-09-12 17:35:27,663] {scheduler_job.py:146} INFO - Started process (PID=32640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:27,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:27,673] {logging_mixin.py:95} INFO - [2019-09-12 17:35:27,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,035] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:28,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:28,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.386 seconds
[2019-09-12 17:35:28,074] {scheduler_job.py:146} INFO - Started process (PID=32642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:28,083] {logging_mixin.py:95} INFO - [2019-09-12 17:35:28,083] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:28,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:28,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.385 seconds
[2019-09-12 17:35:28,479] {scheduler_job.py:146} INFO - Started process (PID=32644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:28,489] {logging_mixin.py:95} INFO - [2019-09-12 17:35:28,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,828] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,852] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:28,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:28,866] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.387 seconds
[2019-09-12 17:35:28,886] {scheduler_job.py:146} INFO - Started process (PID=32645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:28,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:28,895] {logging_mixin.py:95} INFO - [2019-09-12 17:35:28,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:29,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:29,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.385 seconds
[2019-09-12 17:35:29,295] {scheduler_job.py:146} INFO - Started process (PID=32646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:29,305] {logging_mixin.py:95} INFO - [2019-09-12 17:35:29,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,640] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:29,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:29,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.384 seconds
[2019-09-12 17:35:29,708] {scheduler_job.py:146} INFO - Started process (PID=32647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:29,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:29,719] {logging_mixin.py:95} INFO - [2019-09-12 17:35:29,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,078] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:30,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:30,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.384 seconds
[2019-09-12 17:35:30,115] {scheduler_job.py:146} INFO - Started process (PID=32648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:30,125] {logging_mixin.py:95} INFO - [2019-09-12 17:35:30,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:30,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:30,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.384 seconds
[2019-09-12 17:35:30,529] {scheduler_job.py:146} INFO - Started process (PID=32649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:30,538] {logging_mixin.py:95} INFO - [2019-09-12 17:35:30,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:30,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:30,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.377 seconds
[2019-09-12 17:35:30,941] {scheduler_job.py:146} INFO - Started process (PID=32650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:30,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:30,951] {logging_mixin.py:95} INFO - [2019-09-12 17:35:30,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:31,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:31,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-09-12 17:35:31,346] {scheduler_job.py:146} INFO - Started process (PID=32651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:31,355] {logging_mixin.py:95} INFO - [2019-09-12 17:35:31,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:31,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:31,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.405 seconds
[2019-09-12 17:35:31,855] {scheduler_job.py:146} INFO - Started process (PID=32652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:31,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:31,865] {logging_mixin.py:95} INFO - [2019-09-12 17:35:31,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:32,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:32,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-12 17:35:32,267] {scheduler_job.py:146} INFO - Started process (PID=32653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:32,276] {logging_mixin.py:95} INFO - [2019-09-12 17:35:32,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:32,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:32,640] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-12 17:35:32,678] {scheduler_job.py:146} INFO - Started process (PID=32654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:32,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:32,688] {logging_mixin.py:95} INFO - [2019-09-12 17:35:32,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:33,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:33,038] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 17:35:33,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 17:35:33,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-12 17:35:33,085] {scheduler_job.py:146} INFO - Started process (PID=32655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:35:33,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 17:35:33,095] {logging_mixin.py:95} INFO - [2019-09-12 17:35:33,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:47:49,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:47:49,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:47:49,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:47:49,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 4336.479 seconds
[2019-09-12 18:47:49,644] {scheduler_job.py:146} INFO - Started process (PID=32661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:47:54,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:47:54,657] {logging_mixin.py:95} INFO - [2019-09-12 18:47:54,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:47:55,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:47:55,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:47:55,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:47:55,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-12 18:47:55,110] {scheduler_job.py:146} INFO - Started process (PID=32666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:00,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:00,125] {logging_mixin.py:95} INFO - [2019-09-12 18:48:00,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:01,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:01,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:01,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:01,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.537 seconds
[2019-09-12 18:48:01,753] {scheduler_job.py:146} INFO - Started process (PID=32670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:06,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:06,775] {logging_mixin.py:95} INFO - [2019-09-12 18:48:06,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:08,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:08,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:08,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:08,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.473 seconds
[2019-09-12 18:48:08,368] {scheduler_job.py:146} INFO - Started process (PID=32671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:14,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:14,226] {logging_mixin.py:95} INFO - [2019-09-12 18:48:14,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:14,571] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:14,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:14,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:14,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.235 seconds
[2019-09-12 18:48:14,664] {scheduler_job.py:146} INFO - Started process (PID=32675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:19,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:19,670] {logging_mixin.py:95} INFO - [2019-09-12 18:48:19,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:20,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:20,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:20,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:20,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-12 18:48:20,155] {scheduler_job.py:146} INFO - Started process (PID=32678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:25,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:25,163] {logging_mixin.py:95} INFO - [2019-09-12 18:48:25,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:25,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:25,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:25,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:25,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-12 18:48:25,654] {scheduler_job.py:146} INFO - Started process (PID=32679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:25,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:25,659] {logging_mixin.py:95} INFO - [2019-09-12 18:48:25,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:25,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,018] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:26,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:26,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-12 18:48:26,066] {scheduler_job.py:146} INFO - Started process (PID=32680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:26,070] {logging_mixin.py:95} INFO - [2019-09-12 18:48:26,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:26,439] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:26,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-12 18:48:26,474] {scheduler_job.py:146} INFO - Started process (PID=32681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:26,479] {logging_mixin.py:95} INFO - [2019-09-12 18:48:26,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:26,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:26,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.385 seconds
[2019-09-12 18:48:26,883] {scheduler_job.py:146} INFO - Started process (PID=32682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:26,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:26,888] {logging_mixin.py:95} INFO - [2019-09-12 18:48:26,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:27,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:27,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 18:48:27,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 18:48:27,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-12 18:48:27,296] {scheduler_job.py:146} INFO - Started process (PID=32683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:27,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-12 18:48:27,301] {logging_mixin.py:95} INFO - [2019-09-12 18:48:27,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 18:48:27,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 19:24:33,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-12 19:24:33,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-12 19:24:33,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2165.852 seconds
