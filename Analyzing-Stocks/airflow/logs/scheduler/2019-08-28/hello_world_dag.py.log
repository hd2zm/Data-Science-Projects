[2019-08-27 19:21:20,437] {scheduler_job.py:146} INFO - Started process (PID=21048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:25,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:25,448] {logging_mixin.py:95} INFO - [2019-08-27 19:21:25,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:25,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:25,474] {logging_mixin.py:95} INFO - [2019-08-27 19:21:25,473] {dag.py:1303} INFO - Creating ORM DAG for hello_world
[2019-08-27 19:21:25,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:21:25,601] {scheduler_job.py:146} INFO - Started process (PID=21051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:30,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:30,609] {logging_mixin.py:95} INFO - [2019-08-27 19:21:30,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:30,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:30,641] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:21:30,752] {scheduler_job.py:146} INFO - Started process (PID=21052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:35,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:35,760] {logging_mixin.py:95} INFO - [2019-08-27 19:21:35,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:35,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:35,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.038 seconds
[2019-08-27 19:21:35,905] {scheduler_job.py:146} INFO - Started process (PID=21053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:40,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:40,914] {logging_mixin.py:95} INFO - [2019-08-27 19:21:40,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:40,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:40,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:21:41,063] {scheduler_job.py:146} INFO - Started process (PID=21055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:46,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:46,070] {logging_mixin.py:95} INFO - [2019-08-27 19:21:46,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:46,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:46,109] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:21:46,221] {scheduler_job.py:146} INFO - Started process (PID=21057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:51,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:51,232] {logging_mixin.py:95} INFO - [2019-08-27 19:21:51,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:51,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:51,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:21:51,371] {scheduler_job.py:146} INFO - Started process (PID=21058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:56,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:21:56,378] {logging_mixin.py:95} INFO - [2019-08-27 19:21:56,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:56,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:21:56,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:21:56,507] {scheduler_job.py:146} INFO - Started process (PID=21060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:01,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:01,513] {logging_mixin.py:95} INFO - [2019-08-27 19:22:01,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:01,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:01,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:22:01,644] {scheduler_job.py:146} INFO - Started process (PID=21061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:06,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:06,652] {logging_mixin.py:95} INFO - [2019-08-27 19:22:06,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:06,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:06,688] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:06,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:06,708] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:22:06,790] {scheduler_job.py:146} INFO - Started process (PID=21062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:11,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:11,801] {logging_mixin.py:95} INFO - [2019-08-27 19:22:11,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:11,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:11,829] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:11,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:11,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:22:11,937] {scheduler_job.py:146} INFO - Started process (PID=21064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:16,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:16,948] {logging_mixin.py:95} INFO - [2019-08-27 19:22:16,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:16,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:16,980] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:16,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:16,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:22:17,083] {scheduler_job.py:146} INFO - Started process (PID=21066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:22,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:22,094] {logging_mixin.py:95} INFO - [2019-08-27 19:22:22,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:22,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:22,123] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:22,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:22,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:22:22,238] {scheduler_job.py:146} INFO - Started process (PID=21067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:27,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:27,244] {logging_mixin.py:95} INFO - [2019-08-27 19:22:27,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:27,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:27,281] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:27,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:27,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:22:27,391] {scheduler_job.py:146} INFO - Started process (PID=21069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:32,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:32,399] {logging_mixin.py:95} INFO - [2019-08-27 19:22:32,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:32,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:32,437] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:32,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:32,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:22:32,540] {scheduler_job.py:146} INFO - Started process (PID=21070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:37,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:37,546] {logging_mixin.py:95} INFO - [2019-08-27 19:22:37,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:37,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:37,584] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:37,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:37,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.063 seconds
[2019-08-27 19:22:37,696] {scheduler_job.py:146} INFO - Started process (PID=21071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:42,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:42,703] {logging_mixin.py:95} INFO - [2019-08-27 19:22:42,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:42,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:42,735] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:42,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:42,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 19:22:42,838] {scheduler_job.py:146} INFO - Started process (PID=21073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:47,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:47,855] {logging_mixin.py:95} INFO - [2019-08-27 19:22:47,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:47,862] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:47,885] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:47,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:47,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.067 seconds
[2019-08-27 19:22:47,987] {scheduler_job.py:146} INFO - Started process (PID=21075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:52,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:52,993] {logging_mixin.py:95} INFO - [2019-08-27 19:22:52,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:52,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:53,029] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:53,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:53,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.066 seconds
[2019-08-27 19:22:53,136] {scheduler_job.py:146} INFO - Started process (PID=21076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:58,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:22:58,142] {logging_mixin.py:95} INFO - [2019-08-27 19:22:58,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:58,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:22:58,179] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:22:58,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:22:58,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:22:58,291] {scheduler_job.py:146} INFO - Started process (PID=21078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:03,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:03,297] {logging_mixin.py:95} INFO - [2019-08-27 19:23:03,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:03,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:03,334] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:23:03,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:23:03,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:23:03,435] {scheduler_job.py:146} INFO - Started process (PID=21079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:08,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:08,442] {logging_mixin.py:95} INFO - [2019-08-27 19:23:08,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:08,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:08,480] {scheduler_job.py:1228} INFO - Processing hello_world
[2019-08-27 19:23:08,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: hello_world> because no tasks in DAG have SLAs
[2019-08-27 19:23:08,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 19:23:08,587] {scheduler_job.py:146} INFO - Started process (PID=21080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:13,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:13,597] {logging_mixin.py:95} INFO - [2019-08-27 19:23:13,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:13,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:13,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:23:13,736] {scheduler_job.py:146} INFO - Started process (PID=21082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:18,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:18,747] {logging_mixin.py:95} INFO - [2019-08-27 19:23:18,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:18,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:18,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:23:18,895] {scheduler_job.py:146} INFO - Started process (PID=21084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:23,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:23,901] {logging_mixin.py:95} INFO - [2019-08-27 19:23:23,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:23,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:23,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.041 seconds
[2019-08-27 19:23:24,042] {scheduler_job.py:146} INFO - Started process (PID=21085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:29,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:29,053] {logging_mixin.py:95} INFO - [2019-08-27 19:23:29,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:29,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:29,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:23:29,185] {scheduler_job.py:146} INFO - Started process (PID=21088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:34,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:34,193] {logging_mixin.py:95} INFO - [2019-08-27 19:23:34,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:34,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:34,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 19:23:34,315] {scheduler_job.py:146} INFO - Started process (PID=21089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:39,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:39,325] {logging_mixin.py:95} INFO - [2019-08-27 19:23:39,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:39,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:39,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:23:39,460] {scheduler_job.py:146} INFO - Started process (PID=21090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:44,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:44,469] {logging_mixin.py:95} INFO - [2019-08-27 19:23:44,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:44,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:44,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:23:44,599] {scheduler_job.py:146} INFO - Started process (PID=21092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:49,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:49,608] {logging_mixin.py:95} INFO - [2019-08-27 19:23:49,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:49,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:49,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:23:49,736] {scheduler_job.py:146} INFO - Started process (PID=21094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:54,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:54,745] {logging_mixin.py:95} INFO - [2019-08-27 19:23:54,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:54,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:54,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:23:54,880] {scheduler_job.py:146} INFO - Started process (PID=21095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:59,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:23:59,886] {logging_mixin.py:95} INFO - [2019-08-27 19:23:59,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:59,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:23:59,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:24:00,030] {scheduler_job.py:146} INFO - Started process (PID=21097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:05,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:05,037] {logging_mixin.py:95} INFO - [2019-08-27 19:24:05,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:05,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:05,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.041 seconds
[2019-08-27 19:24:05,172] {scheduler_job.py:146} INFO - Started process (PID=21103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:10,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:10,182] {logging_mixin.py:95} INFO - [2019-08-27 19:24:10,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:10,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:10,211] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:24:10,315] {scheduler_job.py:146} INFO - Started process (PID=21105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:15,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:15,322] {logging_mixin.py:95} INFO - [2019-08-27 19:24:15,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:15,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:15,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:24:15,460] {scheduler_job.py:146} INFO - Started process (PID=21108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:20,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:20,472] {logging_mixin.py:95} INFO - [2019-08-27 19:24:20,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:20,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:20,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:24:20,602] {scheduler_job.py:146} INFO - Started process (PID=21110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:25,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:25,608] {logging_mixin.py:95} INFO - [2019-08-27 19:24:25,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:25,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:25,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:24:25,758] {scheduler_job.py:146} INFO - Started process (PID=21113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:30,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:30,771] {logging_mixin.py:95} INFO - [2019-08-27 19:24:30,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:30,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:30,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:24:30,908] {scheduler_job.py:146} INFO - Started process (PID=21116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:35,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:35,917] {logging_mixin.py:95} INFO - [2019-08-27 19:24:35,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:35,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:35,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.041 seconds
[2019-08-27 19:24:36,057] {scheduler_job.py:146} INFO - Started process (PID=21117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:41,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:41,067] {logging_mixin.py:95} INFO - [2019-08-27 19:24:41,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:41,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:41,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:24:41,211] {scheduler_job.py:146} INFO - Started process (PID=21119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:46,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:46,218] {logging_mixin.py:95} INFO - [2019-08-27 19:24:46,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:46,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:46,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:24:46,271] {scheduler_job.py:146} INFO - Started process (PID=21120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:51,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:51,280] {logging_mixin.py:95} INFO - [2019-08-27 19:24:51,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:51,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:51,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:24:51,411] {scheduler_job.py:146} INFO - Started process (PID=21122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:56,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:24:56,418] {logging_mixin.py:95} INFO - [2019-08-27 19:24:56,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:56,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:24:56,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:24:56,565] {scheduler_job.py:146} INFO - Started process (PID=21124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:01,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:01,573] {logging_mixin.py:95} INFO - [2019-08-27 19:25:01,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:01,578] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:01,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.038 seconds
[2019-08-27 19:25:01,720] {scheduler_job.py:146} INFO - Started process (PID=21125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:06,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:06,729] {logging_mixin.py:95} INFO - [2019-08-27 19:25:06,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:06,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:06,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:25:06,872] {scheduler_job.py:146} INFO - Started process (PID=21126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:11,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:11,883] {logging_mixin.py:95} INFO - [2019-08-27 19:25:11,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:11,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:11,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:25:12,019] {scheduler_job.py:146} INFO - Started process (PID=21128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:17,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:17,028] {logging_mixin.py:95} INFO - [2019-08-27 19:25:17,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:17,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:17,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:25:17,176] {scheduler_job.py:146} INFO - Started process (PID=21129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:22,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:22,186] {logging_mixin.py:95} INFO - [2019-08-27 19:25:22,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:22,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:22,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:25:22,328] {scheduler_job.py:146} INFO - Started process (PID=21131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:27,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:27,333] {logging_mixin.py:95} INFO - [2019-08-27 19:25:27,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:27,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:27,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.040 seconds
[2019-08-27 19:25:27,482] {scheduler_job.py:146} INFO - Started process (PID=21133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:32,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:32,490] {logging_mixin.py:95} INFO - [2019-08-27 19:25:32,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:32,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:32,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:25:32,631] {scheduler_job.py:146} INFO - Started process (PID=21134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:37,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:37,638] {logging_mixin.py:95} INFO - [2019-08-27 19:25:37,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:37,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:37,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:25:37,778] {scheduler_job.py:146} INFO - Started process (PID=21135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:42,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:42,785] {logging_mixin.py:95} INFO - [2019-08-27 19:25:42,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:42,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:42,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 19:25:42,931] {scheduler_job.py:146} INFO - Started process (PID=21137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:47,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:47,939] {logging_mixin.py:95} INFO - [2019-08-27 19:25:47,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:47,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:47,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:25:48,085] {scheduler_job.py:146} INFO - Started process (PID=21138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:53,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:53,093] {logging_mixin.py:95} INFO - [2019-08-27 19:25:53,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:53,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:53,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.041 seconds
[2019-08-27 19:25:53,230] {scheduler_job.py:146} INFO - Started process (PID=21139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:58,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:25:58,238] {logging_mixin.py:95} INFO - [2019-08-27 19:25:58,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:58,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:25:58,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:25:58,377] {scheduler_job.py:146} INFO - Started process (PID=21142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:03,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:03,385] {logging_mixin.py:95} INFO - [2019-08-27 19:26:03,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:03,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:03,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:26:03,530] {scheduler_job.py:146} INFO - Started process (PID=21143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:08,536] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:08,537] {logging_mixin.py:95} INFO - [2019-08-27 19:26:08,537] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:08,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:08,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:26:08,686] {scheduler_job.py:146} INFO - Started process (PID=21144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:13,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:13,697] {logging_mixin.py:95} INFO - [2019-08-27 19:26:13,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:13,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:13,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:26:13,840] {scheduler_job.py:146} INFO - Started process (PID=21146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:18,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:18,848] {logging_mixin.py:95} INFO - [2019-08-27 19:26:18,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:18,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:18,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:26:18,993] {scheduler_job.py:146} INFO - Started process (PID=21147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:23,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:24,000] {logging_mixin.py:95} INFO - [2019-08-27 19:26:23,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:24,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:24,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:26:24,159] {scheduler_job.py:146} INFO - Started process (PID=21148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:29,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:29,167] {logging_mixin.py:95} INFO - [2019-08-27 19:26:29,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:29,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:29,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:26:29,311] {scheduler_job.py:146} INFO - Started process (PID=21153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:34,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:34,322] {logging_mixin.py:95} INFO - [2019-08-27 19:26:34,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:34,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:34,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:26:34,466] {scheduler_job.py:146} INFO - Started process (PID=21154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:39,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:39,473] {logging_mixin.py:95} INFO - [2019-08-27 19:26:39,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:39,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:39,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 19:26:39,520] {scheduler_job.py:146} INFO - Started process (PID=21155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:44,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:44,532] {logging_mixin.py:95} INFO - [2019-08-27 19:26:44,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:44,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:44,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:26:44,678] {scheduler_job.py:146} INFO - Started process (PID=21157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:49,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:49,688] {logging_mixin.py:95} INFO - [2019-08-27 19:26:49,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:49,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:49,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.040 seconds
[2019-08-27 19:26:49,735] {scheduler_job.py:146} INFO - Started process (PID=21158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:54,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:54,744] {logging_mixin.py:95} INFO - [2019-08-27 19:26:54,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:54,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:54,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:26:54,884] {scheduler_job.py:146} INFO - Started process (PID=21159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:59,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:26:59,895] {logging_mixin.py:95} INFO - [2019-08-27 19:26:59,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:59,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:26:59,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:27:00,032] {scheduler_job.py:146} INFO - Started process (PID=21162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:05,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:05,043] {logging_mixin.py:95} INFO - [2019-08-27 19:27:05,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:05,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:05,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:27:05,194] {scheduler_job.py:146} INFO - Started process (PID=21163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:10,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:10,202] {logging_mixin.py:95} INFO - [2019-08-27 19:27:10,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:10,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:10,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 19:27:10,342] {scheduler_job.py:146} INFO - Started process (PID=21164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:15,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:15,352] {logging_mixin.py:95} INFO - [2019-08-27 19:27:15,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:15,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:15,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:27:15,495] {scheduler_job.py:146} INFO - Started process (PID=21166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:20,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:20,513] {logging_mixin.py:95} INFO - [2019-08-27 19:27:20,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:20,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:20,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:27:20,644] {scheduler_job.py:146} INFO - Started process (PID=21167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:25,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:25,656] {logging_mixin.py:95} INFO - [2019-08-27 19:27:25,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:25,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:25,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:27:25,800] {scheduler_job.py:146} INFO - Started process (PID=21169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:30,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:30,809] {logging_mixin.py:95} INFO - [2019-08-27 19:27:30,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:30,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:30,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:27:30,945] {scheduler_job.py:146} INFO - Started process (PID=21171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:35,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:35,954] {logging_mixin.py:95} INFO - [2019-08-27 19:27:35,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:35,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:35,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:27:36,097] {scheduler_job.py:146} INFO - Started process (PID=21172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:41,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:41,108] {logging_mixin.py:95} INFO - [2019-08-27 19:27:41,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:41,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:41,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:27:41,247] {scheduler_job.py:146} INFO - Started process (PID=21174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:46,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:46,259] {logging_mixin.py:95} INFO - [2019-08-27 19:27:46,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:46,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:46,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:27:46,409] {scheduler_job.py:146} INFO - Started process (PID=21175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:51,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:51,426] {logging_mixin.py:95} INFO - [2019-08-27 19:27:51,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:51,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:51,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:27:51,567] {scheduler_job.py:146} INFO - Started process (PID=21176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:56,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:27:56,576] {logging_mixin.py:95} INFO - [2019-08-27 19:27:56,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:56,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:27:56,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:27:56,726] {scheduler_job.py:146} INFO - Started process (PID=21178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:01,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:01,736] {logging_mixin.py:95} INFO - [2019-08-27 19:28:01,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:01,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['hello_world']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:01,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:28:01,877] {scheduler_job.py:146} INFO - Started process (PID=21183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:06,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:06,886] {logging_mixin.py:95} INFO - [2019-08-27 19:28:06,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:06,901] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:06,905] {logging_mixin.py:95} INFO - [2019-08-27 19:28:06,902] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:06,906] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:06,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:28:06,933] {scheduler_job.py:146} INFO - Started process (PID=21184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:11,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:11,941] {logging_mixin.py:95} INFO - [2019-08-27 19:28:11,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:11,947] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:11,949] {logging_mixin.py:95} INFO - [2019-08-27 19:28:11,948] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:11,949] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:11,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:28:11,989] {scheduler_job.py:146} INFO - Started process (PID=21186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:16,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:16,999] {logging_mixin.py:95} INFO - [2019-08-27 19:28:16,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:17,005] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:17,007] {logging_mixin.py:95} INFO - [2019-08-27 19:28:17,006] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:17,008] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:17,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 19:28:17,139] {scheduler_job.py:146} INFO - Started process (PID=21187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:22,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:22,151] {logging_mixin.py:95} INFO - [2019-08-27 19:28:22,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:22,157] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:22,159] {logging_mixin.py:95} INFO - [2019-08-27 19:28:22,158] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:22,160] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:22,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:28:22,192] {scheduler_job.py:146} INFO - Started process (PID=21188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:27,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:27,201] {logging_mixin.py:95} INFO - [2019-08-27 19:28:27,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:27,207] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:27,209] {logging_mixin.py:95} INFO - [2019-08-27 19:28:27,208] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:27,209] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:27,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:28:27,244] {scheduler_job.py:146} INFO - Started process (PID=21190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:32,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:32,257] {logging_mixin.py:95} INFO - [2019-08-27 19:28:32,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:32,263] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:32,265] {logging_mixin.py:95} INFO - [2019-08-27 19:28:32,264] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:32,266] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:32,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:28:32,392] {scheduler_job.py:146} INFO - Started process (PID=21192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:37,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:37,400] {logging_mixin.py:95} INFO - [2019-08-27 19:28:37,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:37,406] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:37,408] {logging_mixin.py:95} INFO - [2019-08-27 19:28:37,407] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:37,408] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:37,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:28:37,447] {scheduler_job.py:146} INFO - Started process (PID=21193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:42,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:42,457] {logging_mixin.py:95} INFO - [2019-08-27 19:28:42,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:42,463] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:42,465] {logging_mixin.py:95} INFO - [2019-08-27 19:28:42,464] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:42,465] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:42,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:28:42,593] {scheduler_job.py:146} INFO - Started process (PID=21195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:47,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:47,603] {logging_mixin.py:95} INFO - [2019-08-27 19:28:47,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:47,609] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:47,611] {logging_mixin.py:95} INFO - [2019-08-27 19:28:47,610] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:47,612] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:47,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:28:47,647] {scheduler_job.py:146} INFO - Started process (PID=21196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:52,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:52,658] {logging_mixin.py:95} INFO - [2019-08-27 19:28:52,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:52,664] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:52,666] {logging_mixin.py:95} INFO - [2019-08-27 19:28:52,665] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:52,667] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:52,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 19:28:52,706] {scheduler_job.py:146} INFO - Started process (PID=21197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:57,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:28:57,716] {logging_mixin.py:95} INFO - [2019-08-27 19:28:57,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:57,722] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:28:57,724] {logging_mixin.py:95} INFO - [2019-08-27 19:28:57,723] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:28:57,725] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:28:57,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:28:57,760] {scheduler_job.py:146} INFO - Started process (PID=21199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:02,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:02,768] {logging_mixin.py:95} INFO - [2019-08-27 19:29:02,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:02,774] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:02,777] {logging_mixin.py:95} INFO - [2019-08-27 19:29:02,775] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:02,777] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:02,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:29:02,911] {scheduler_job.py:146} INFO - Started process (PID=21201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:07,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:07,918] {logging_mixin.py:95} INFO - [2019-08-27 19:29:07,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:07,924] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:07,926] {logging_mixin.py:95} INFO - [2019-08-27 19:29:07,925] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:07,927] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:07,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:29:07,964] {scheduler_job.py:146} INFO - Started process (PID=21202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:12,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:12,972] {logging_mixin.py:95} INFO - [2019-08-27 19:29:12,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:12,978] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:12,981] {logging_mixin.py:95} INFO - [2019-08-27 19:29:12,980] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:12,981] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:12,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:29:13,023] {scheduler_job.py:146} INFO - Started process (PID=21204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:18,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:18,034] {logging_mixin.py:95} INFO - [2019-08-27 19:29:18,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:18,041] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:18,043] {logging_mixin.py:95} INFO - [2019-08-27 19:29:18,042] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:18,043] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:18,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 19:29:18,077] {scheduler_job.py:146} INFO - Started process (PID=21205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:23,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:23,087] {logging_mixin.py:95} INFO - [2019-08-27 19:29:23,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:23,093] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:23,095] {logging_mixin.py:95} INFO - [2019-08-27 19:29:23,094] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:23,096] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:23,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:29:23,130] {scheduler_job.py:146} INFO - Started process (PID=21206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:28,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:28,138] {logging_mixin.py:95} INFO - [2019-08-27 19:29:28,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:28,146] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:28,148] {logging_mixin.py:95} INFO - [2019-08-27 19:29:28,147] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:28,149] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:28,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:29:28,178] {scheduler_job.py:146} INFO - Started process (PID=21208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:33,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:33,186] {logging_mixin.py:95} INFO - [2019-08-27 19:29:33,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:33,192] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:33,194] {logging_mixin.py:95} INFO - [2019-08-27 19:29:33,193] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:33,195] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:33,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:29:33,229] {scheduler_job.py:146} INFO - Started process (PID=21209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:38,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:38,237] {logging_mixin.py:95} INFO - [2019-08-27 19:29:38,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:38,243] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:38,245] {logging_mixin.py:95} INFO - [2019-08-27 19:29:38,244] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:38,245] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:38,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:29:38,283] {scheduler_job.py:146} INFO - Started process (PID=21211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:43,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:43,293] {logging_mixin.py:95} INFO - [2019-08-27 19:29:43,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:43,299] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:43,301] {logging_mixin.py:95} INFO - [2019-08-27 19:29:43,300] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:43,301] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:43,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:29:43,337] {scheduler_job.py:146} INFO - Started process (PID=21213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:48,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:48,347] {logging_mixin.py:95} INFO - [2019-08-27 19:29:48,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:48,354] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:48,356] {logging_mixin.py:95} INFO - [2019-08-27 19:29:48,355] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:48,356] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:48,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:29:48,390] {scheduler_job.py:146} INFO - Started process (PID=21214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:53,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:53,399] {logging_mixin.py:95} INFO - [2019-08-27 19:29:53,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:53,405] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:29:53,407] {logging_mixin.py:95} INFO - [2019-08-27 19:29:53,406] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 27, in <module>
    python_callable=get_rates,
NameError: name 'get_rates' is not defined
[2019-08-27 19:29:53,408] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:53,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:29:53,444] {scheduler_job.py:146} INFO - Started process (PID=21215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:58,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:29:58,453] {logging_mixin.py:95} INFO - [2019-08-27 19:29:58,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:58,457] {logging_mixin.py:95} INFO - [2019-08-27 19:29:58,455] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:29:58,457] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:29:58,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:29:58,495] {scheduler_job.py:146} INFO - Started process (PID=21217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:03,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:03,508] {logging_mixin.py:95} INFO - [2019-08-27 19:30:03,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:03,511] {logging_mixin.py:95} INFO - [2019-08-27 19:30:03,510] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:03,512] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:03,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 19:30:03,544] {scheduler_job.py:146} INFO - Started process (PID=21219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:08,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:08,555] {logging_mixin.py:95} INFO - [2019-08-27 19:30:08,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:08,559] {logging_mixin.py:95} INFO - [2019-08-27 19:30:08,558] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:08,559] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:08,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:30:08,601] {scheduler_job.py:146} INFO - Started process (PID=21221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:13,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:13,612] {logging_mixin.py:95} INFO - [2019-08-27 19:30:13,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:13,616] {logging_mixin.py:95} INFO - [2019-08-27 19:30:13,615] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:13,616] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:13,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:30:13,651] {scheduler_job.py:146} INFO - Started process (PID=21223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:18,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:18,659] {logging_mixin.py:95} INFO - [2019-08-27 19:30:18,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:18,663] {logging_mixin.py:95} INFO - [2019-08-27 19:30:18,662] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:18,664] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:18,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:30:18,698] {scheduler_job.py:146} INFO - Started process (PID=21224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:23,706] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:23,707] {logging_mixin.py:95} INFO - [2019-08-27 19:30:23,707] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:23,711] {logging_mixin.py:95} INFO - [2019-08-27 19:30:23,710] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:23,712] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:23,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:30:23,836] {scheduler_job.py:146} INFO - Started process (PID=21225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:28,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:28,848] {logging_mixin.py:95} INFO - [2019-08-27 19:30:28,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:28,853] {logging_mixin.py:95} INFO - [2019-08-27 19:30:28,852] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:28,854] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:28,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:30:28,976] {scheduler_job.py:146} INFO - Started process (PID=21227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:33,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:33,985] {logging_mixin.py:95} INFO - [2019-08-27 19:30:33,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:33,989] {logging_mixin.py:95} INFO - [2019-08-27 19:30:33,988] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:33,989] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:34,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:30:34,116] {scheduler_job.py:146} INFO - Started process (PID=21228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:39,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:39,124] {logging_mixin.py:95} INFO - [2019-08-27 19:30:39,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:39,128] {logging_mixin.py:95} INFO - [2019-08-27 19:30:39,127] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:39,129] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:39,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.022 seconds
[2019-08-27 19:30:39,251] {scheduler_job.py:146} INFO - Started process (PID=21230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:44,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:44,261] {logging_mixin.py:95} INFO - [2019-08-27 19:30:44,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:44,267] {logging_mixin.py:95} INFO - [2019-08-27 19:30:44,265] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:44,267] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:44,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:30:44,387] {scheduler_job.py:146} INFO - Started process (PID=21232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:49,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:49,399] {logging_mixin.py:95} INFO - [2019-08-27 19:30:49,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:49,404] {logging_mixin.py:95} INFO - [2019-08-27 19:30:49,403] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:49,404] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:49,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:30:49,530] {scheduler_job.py:146} INFO - Started process (PID=21233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:54,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:54,541] {logging_mixin.py:95} INFO - [2019-08-27 19:30:54,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:54,545] {logging_mixin.py:95} INFO - [2019-08-27 19:30:54,544] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:54,546] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:54,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:30:54,587] {scheduler_job.py:146} INFO - Started process (PID=21234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:59,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:30:59,597] {logging_mixin.py:95} INFO - [2019-08-27 19:30:59,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:59,602] {logging_mixin.py:95} INFO - [2019-08-27 19:30:59,600] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:30:59,602] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:30:59,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:30:59,639] {scheduler_job.py:146} INFO - Started process (PID=21236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:04,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:04,648] {logging_mixin.py:95} INFO - [2019-08-27 19:31:04,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:04,652] {logging_mixin.py:95} INFO - [2019-08-27 19:31:04,651] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:04,652] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:04,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 19:31:04,689] {scheduler_job.py:146} INFO - Started process (PID=21237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:09,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:09,698] {logging_mixin.py:95} INFO - [2019-08-27 19:31:09,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:09,702] {logging_mixin.py:95} INFO - [2019-08-27 19:31:09,701] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:09,703] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:09,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:31:09,742] {scheduler_job.py:146} INFO - Started process (PID=21239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:14,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:14,751] {logging_mixin.py:95} INFO - [2019-08-27 19:31:14,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:14,755] {logging_mixin.py:95} INFO - [2019-08-27 19:31:14,754] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:14,756] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:14,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 19:31:14,797] {scheduler_job.py:146} INFO - Started process (PID=21241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:19,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:19,810] {logging_mixin.py:95} INFO - [2019-08-27 19:31:19,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:19,814] {logging_mixin.py:95} INFO - [2019-08-27 19:31:19,813] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:19,814] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:19,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:31:19,850] {scheduler_job.py:146} INFO - Started process (PID=21242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:24,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:24,864] {logging_mixin.py:95} INFO - [2019-08-27 19:31:24,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:24,869] {logging_mixin.py:95} INFO - [2019-08-27 19:31:24,868] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:24,870] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:24,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:31:24,920] {scheduler_job.py:146} INFO - Started process (PID=21243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:29,931] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:29,933] {logging_mixin.py:95} INFO - [2019-08-27 19:31:29,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:29,946] {logging_mixin.py:95} INFO - [2019-08-27 19:31:29,938] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:29,946] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:29,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:31:30,000] {scheduler_job.py:146} INFO - Started process (PID=21245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:35,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:35,013] {logging_mixin.py:95} INFO - [2019-08-27 19:31:35,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:35,018] {logging_mixin.py:95} INFO - [2019-08-27 19:31:35,016] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:35,018] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:35,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:31:35,055] {scheduler_job.py:146} INFO - Started process (PID=21246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:40,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:40,061] {logging_mixin.py:95} INFO - [2019-08-27 19:31:40,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:40,066] {logging_mixin.py:95} INFO - [2019-08-27 19:31:40,065] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:40,066] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:40,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:31:40,113] {scheduler_job.py:146} INFO - Started process (PID=21248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:45,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:45,124] {logging_mixin.py:95} INFO - [2019-08-27 19:31:45,123] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:45,128] {logging_mixin.py:95} INFO - [2019-08-27 19:31:45,127] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:45,129] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:45,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:31:45,168] {scheduler_job.py:146} INFO - Started process (PID=21250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:50,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:50,179] {logging_mixin.py:95} INFO - [2019-08-27 19:31:50,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:50,183] {logging_mixin.py:95} INFO - [2019-08-27 19:31:50,182] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:50,184] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:50,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:31:50,221] {scheduler_job.py:146} INFO - Started process (PID=21251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:55,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:31:55,230] {logging_mixin.py:95} INFO - [2019-08-27 19:31:55,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:55,235] {logging_mixin.py:95} INFO - [2019-08-27 19:31:55,233] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:31:55,235] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:31:55,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:31:55,280] {scheduler_job.py:146} INFO - Started process (PID=21252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:00,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:00,288] {logging_mixin.py:95} INFO - [2019-08-27 19:32:00,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:00,292] {logging_mixin.py:95} INFO - [2019-08-27 19:32:00,291] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:00,292] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:00,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:32:00,339] {scheduler_job.py:146} INFO - Started process (PID=21254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:05,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:05,346] {logging_mixin.py:95} INFO - [2019-08-27 19:32:05,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:05,352] {logging_mixin.py:95} INFO - [2019-08-27 19:32:05,351] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:05,353] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:05,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:32:05,396] {scheduler_job.py:146} INFO - Started process (PID=21255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:10,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:10,406] {logging_mixin.py:95} INFO - [2019-08-27 19:32:10,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:10,411] {logging_mixin.py:95} INFO - [2019-08-27 19:32:10,410] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:10,412] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:10,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:32:10,455] {scheduler_job.py:146} INFO - Started process (PID=21256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:15,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:15,463] {logging_mixin.py:95} INFO - [2019-08-27 19:32:15,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:15,468] {logging_mixin.py:95} INFO - [2019-08-27 19:32:15,466] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:15,468] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:15,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:32:15,514] {scheduler_job.py:146} INFO - Started process (PID=21259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:20,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:20,522] {logging_mixin.py:95} INFO - [2019-08-27 19:32:20,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:20,526] {logging_mixin.py:95} INFO - [2019-08-27 19:32:20,525] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:20,527] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:20,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:32:20,573] {scheduler_job.py:146} INFO - Started process (PID=21260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:25,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:25,579] {logging_mixin.py:95} INFO - [2019-08-27 19:32:25,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:25,583] {logging_mixin.py:95} INFO - [2019-08-27 19:32:25,582] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:25,584] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:25,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 19:32:25,627] {scheduler_job.py:146} INFO - Started process (PID=21261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:30,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:30,638] {logging_mixin.py:95} INFO - [2019-08-27 19:32:30,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:30,644] {logging_mixin.py:95} INFO - [2019-08-27 19:32:30,642] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:30,644] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:30,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:32:30,681] {scheduler_job.py:146} INFO - Started process (PID=21264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:35,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:35,690] {logging_mixin.py:95} INFO - [2019-08-27 19:32:35,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:35,695] {logging_mixin.py:95} INFO - [2019-08-27 19:32:35,694] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:35,695] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:35,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:32:35,737] {scheduler_job.py:146} INFO - Started process (PID=21265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:40,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:40,745] {logging_mixin.py:95} INFO - [2019-08-27 19:32:40,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:40,750] {logging_mixin.py:95} INFO - [2019-08-27 19:32:40,748] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:40,750] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:40,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:32:40,794] {scheduler_job.py:146} INFO - Started process (PID=21267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:45,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:45,807] {logging_mixin.py:95} INFO - [2019-08-27 19:32:45,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:45,812] {logging_mixin.py:95} INFO - [2019-08-27 19:32:45,811] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:45,812] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:45,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:32:45,847] {scheduler_job.py:146} INFO - Started process (PID=21269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:50,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:50,858] {logging_mixin.py:95} INFO - [2019-08-27 19:32:50,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:50,862] {logging_mixin.py:95} INFO - [2019-08-27 19:32:50,861] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:50,863] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:50,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:32:50,897] {scheduler_job.py:146} INFO - Started process (PID=21270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:55,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:32:55,908] {logging_mixin.py:95} INFO - [2019-08-27 19:32:55,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:55,913] {logging_mixin.py:95} INFO - [2019-08-27 19:32:55,912] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:32:55,913] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:32:55,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:32:55,957] {scheduler_job.py:146} INFO - Started process (PID=21272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:00,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:00,964] {logging_mixin.py:95} INFO - [2019-08-27 19:33:00,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:00,968] {logging_mixin.py:95} INFO - [2019-08-27 19:33:00,967] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:00,969] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:00,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:33:01,014] {scheduler_job.py:146} INFO - Started process (PID=21273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:06,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:06,021] {logging_mixin.py:95} INFO - [2019-08-27 19:33:06,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:06,026] {logging_mixin.py:95} INFO - [2019-08-27 19:33:06,024] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:06,026] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:06,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:33:06,073] {scheduler_job.py:146} INFO - Started process (PID=21274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:11,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:11,084] {logging_mixin.py:95} INFO - [2019-08-27 19:33:11,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:11,089] {logging_mixin.py:95} INFO - [2019-08-27 19:33:11,088] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:11,089] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:11,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:33:11,128] {scheduler_job.py:146} INFO - Started process (PID=21276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:16,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:16,134] {logging_mixin.py:95} INFO - [2019-08-27 19:33:16,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:16,138] {logging_mixin.py:95} INFO - [2019-08-27 19:33:16,137] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:16,138] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:16,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.021 seconds
[2019-08-27 19:33:16,180] {scheduler_job.py:146} INFO - Started process (PID=21278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:21,191] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:21,192] {logging_mixin.py:95} INFO - [2019-08-27 19:33:21,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:21,197] {logging_mixin.py:95} INFO - [2019-08-27 19:33:21,195] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:21,197] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:21,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:33:21,236] {scheduler_job.py:146} INFO - Started process (PID=21279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:26,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:26,243] {logging_mixin.py:95} INFO - [2019-08-27 19:33:26,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:26,248] {logging_mixin.py:95} INFO - [2019-08-27 19:33:26,247] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:26,248] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:26,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 19:33:26,291] {scheduler_job.py:146} INFO - Started process (PID=21281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:31,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:31,301] {logging_mixin.py:95} INFO - [2019-08-27 19:33:31,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:31,305] {logging_mixin.py:95} INFO - [2019-08-27 19:33:31,304] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:31,305] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:31,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 19:33:31,341] {scheduler_job.py:146} INFO - Started process (PID=21283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:36,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:36,352] {logging_mixin.py:95} INFO - [2019-08-27 19:33:36,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:36,357] {logging_mixin.py:95} INFO - [2019-08-27 19:33:36,355] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:36,357] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:36,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:33:36,395] {scheduler_job.py:146} INFO - Started process (PID=21284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:41,401] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:41,402] {logging_mixin.py:95} INFO - [2019-08-27 19:33:41,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:41,406] {logging_mixin.py:95} INFO - [2019-08-27 19:33:41,405] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:41,407] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:41,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:33:41,455] {scheduler_job.py:146} INFO - Started process (PID=21286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:46,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:46,469] {logging_mixin.py:95} INFO - [2019-08-27 19:33:46,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:46,474] {logging_mixin.py:95} INFO - [2019-08-27 19:33:46,473] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:46,474] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:46,486] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:33:46,508] {scheduler_job.py:146} INFO - Started process (PID=21288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:51,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:51,519] {logging_mixin.py:95} INFO - [2019-08-27 19:33:51,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:51,524] {logging_mixin.py:95} INFO - [2019-08-27 19:33:51,522] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:51,524] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:51,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:33:51,562] {scheduler_job.py:146} INFO - Started process (PID=21289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:56,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:33:56,570] {logging_mixin.py:95} INFO - [2019-08-27 19:33:56,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:56,574] {logging_mixin.py:95} INFO - [2019-08-27 19:33:56,573] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:33:56,575] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:33:56,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 19:33:56,619] {scheduler_job.py:146} INFO - Started process (PID=21291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:01,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:01,627] {logging_mixin.py:95} INFO - [2019-08-27 19:34:01,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:01,632] {logging_mixin.py:95} INFO - [2019-08-27 19:34:01,631] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:01,632] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:01,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:34:01,678] {scheduler_job.py:146} INFO - Started process (PID=21292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:06,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:06,686] {logging_mixin.py:95} INFO - [2019-08-27 19:34:06,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:06,691] {logging_mixin.py:95} INFO - [2019-08-27 19:34:06,690] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:06,692] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:06,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:34:06,740] {scheduler_job.py:146} INFO - Started process (PID=21293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:11,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:11,746] {logging_mixin.py:95} INFO - [2019-08-27 19:34:11,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:11,750] {logging_mixin.py:95} INFO - [2019-08-27 19:34:11,749] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:11,751] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:11,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 19:34:11,801] {scheduler_job.py:146} INFO - Started process (PID=21295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:16,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:16,810] {logging_mixin.py:95} INFO - [2019-08-27 19:34:16,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:16,814] {logging_mixin.py:95} INFO - [2019-08-27 19:34:16,813] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:16,815] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:16,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 19:34:16,857] {scheduler_job.py:146} INFO - Started process (PID=21297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:21,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:21,870] {logging_mixin.py:95} INFO - [2019-08-27 19:34:21,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:21,875] {logging_mixin.py:95} INFO - [2019-08-27 19:34:21,873] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:21,875] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:21,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:34:21,919] {scheduler_job.py:146} INFO - Started process (PID=21299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:26,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:26,927] {logging_mixin.py:95} INFO - [2019-08-27 19:34:26,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:26,932] {logging_mixin.py:95} INFO - [2019-08-27 19:34:26,931] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:26,932] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:26,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 19:34:26,978] {scheduler_job.py:146} INFO - Started process (PID=21301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:31,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:31,988] {logging_mixin.py:95} INFO - [2019-08-27 19:34:31,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:31,993] {logging_mixin.py:95} INFO - [2019-08-27 19:34:31,991] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:31,993] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:32,005] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 19:34:32,027] {scheduler_job.py:146} INFO - Started process (PID=21304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:37,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:37,037] {logging_mixin.py:95} INFO - [2019-08-27 19:34:37,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:37,042] {logging_mixin.py:95} INFO - [2019-08-27 19:34:37,040] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:37,042] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:37,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:34:37,083] {scheduler_job.py:146} INFO - Started process (PID=21305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:42,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:42,093] {logging_mixin.py:95} INFO - [2019-08-27 19:34:42,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:42,098] {logging_mixin.py:95} INFO - [2019-08-27 19:34:42,097] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:42,098] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:42,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:34:42,144] {scheduler_job.py:146} INFO - Started process (PID=21307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:47,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:47,154] {logging_mixin.py:95} INFO - [2019-08-27 19:34:47,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:47,159] {logging_mixin.py:95} INFO - [2019-08-27 19:34:47,158] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:47,160] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:47,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:34:47,204] {scheduler_job.py:146} INFO - Started process (PID=21308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:52,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:52,211] {logging_mixin.py:95} INFO - [2019-08-27 19:34:52,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:52,216] {logging_mixin.py:95} INFO - [2019-08-27 19:34:52,215] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:52,216] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:52,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:34:52,258] {scheduler_job.py:146} INFO - Started process (PID=21310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:57,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:34:57,267] {logging_mixin.py:95} INFO - [2019-08-27 19:34:57,267] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:57,272] {logging_mixin.py:95} INFO - [2019-08-27 19:34:57,270] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:34:57,272] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:34:57,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:34:57,408] {scheduler_job.py:146} INFO - Started process (PID=21312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:02,414] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:02,415] {logging_mixin.py:95} INFO - [2019-08-27 19:35:02,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:02,419] {logging_mixin.py:95} INFO - [2019-08-27 19:35:02,418] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:02,420] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:02,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:35:02,460] {scheduler_job.py:146} INFO - Started process (PID=21313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:07,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:07,470] {logging_mixin.py:95} INFO - [2019-08-27 19:35:07,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:07,474] {logging_mixin.py:95} INFO - [2019-08-27 19:35:07,473] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:07,475] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:07,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:35:07,519] {scheduler_job.py:146} INFO - Started process (PID=21314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:12,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:12,528] {logging_mixin.py:95} INFO - [2019-08-27 19:35:12,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:12,532] {logging_mixin.py:95} INFO - [2019-08-27 19:35:12,531] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:12,533] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:12,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:35:12,581] {scheduler_job.py:146} INFO - Started process (PID=21316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:17,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:17,593] {logging_mixin.py:95} INFO - [2019-08-27 19:35:17,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:17,597] {logging_mixin.py:95} INFO - [2019-08-27 19:35:17,596] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:17,597] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:17,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:35:17,631] {scheduler_job.py:146} INFO - Started process (PID=21317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:22,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:22,643] {logging_mixin.py:95} INFO - [2019-08-27 19:35:22,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:22,648] {logging_mixin.py:95} INFO - [2019-08-27 19:35:22,646] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:22,649] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:22,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:35:22,688] {scheduler_job.py:146} INFO - Started process (PID=21319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:27,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:27,697] {logging_mixin.py:95} INFO - [2019-08-27 19:35:27,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:27,701] {logging_mixin.py:95} INFO - [2019-08-27 19:35:27,700] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:27,702] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:27,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 19:35:27,733] {scheduler_job.py:146} INFO - Started process (PID=21322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:32,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:32,741] {logging_mixin.py:95} INFO - [2019-08-27 19:35:32,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:32,745] {logging_mixin.py:95} INFO - [2019-08-27 19:35:32,744] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:32,746] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:32,763] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:35:32,786] {scheduler_job.py:146} INFO - Started process (PID=21324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:37,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:37,796] {logging_mixin.py:95} INFO - [2019-08-27 19:35:37,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:37,800] {logging_mixin.py:95} INFO - [2019-08-27 19:35:37,799] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:37,800] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:37,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:35:37,845] {scheduler_job.py:146} INFO - Started process (PID=21325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:42,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:42,854] {logging_mixin.py:95} INFO - [2019-08-27 19:35:42,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:42,859] {logging_mixin.py:95} INFO - [2019-08-27 19:35:42,858] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:42,859] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:42,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:35:42,901] {scheduler_job.py:146} INFO - Started process (PID=21327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:47,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:47,910] {logging_mixin.py:95} INFO - [2019-08-27 19:35:47,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:47,914] {logging_mixin.py:95} INFO - [2019-08-27 19:35:47,913] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:47,915] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:47,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:35:47,953] {scheduler_job.py:146} INFO - Started process (PID=21328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:52,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:52,962] {logging_mixin.py:95} INFO - [2019-08-27 19:35:52,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:52,967] {logging_mixin.py:95} INFO - [2019-08-27 19:35:52,966] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:52,967] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:52,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 19:35:53,008] {scheduler_job.py:146} INFO - Started process (PID=21330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:58,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:35:58,016] {logging_mixin.py:95} INFO - [2019-08-27 19:35:58,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:58,020] {logging_mixin.py:95} INFO - [2019-08-27 19:35:58,019] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:35:58,020] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:35:58,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:35:58,061] {scheduler_job.py:146} INFO - Started process (PID=21332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:03,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:03,073] {logging_mixin.py:95} INFO - [2019-08-27 19:36:03,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:03,077] {logging_mixin.py:95} INFO - [2019-08-27 19:36:03,076] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:03,078] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:03,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:36:03,115] {scheduler_job.py:146} INFO - Started process (PID=21333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:08,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:08,122] {logging_mixin.py:95} INFO - [2019-08-27 19:36:08,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:08,127] {logging_mixin.py:95} INFO - [2019-08-27 19:36:08,125] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:08,127] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:08,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:36:08,175] {scheduler_job.py:146} INFO - Started process (PID=21334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:13,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:13,184] {logging_mixin.py:95} INFO - [2019-08-27 19:36:13,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:13,188] {logging_mixin.py:95} INFO - [2019-08-27 19:36:13,187] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:13,188] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:13,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:36:13,229] {scheduler_job.py:146} INFO - Started process (PID=21336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:18,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:18,236] {logging_mixin.py:95} INFO - [2019-08-27 19:36:18,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:18,241] {logging_mixin.py:95} INFO - [2019-08-27 19:36:18,240] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:18,242] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:18,260] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:36:18,284] {scheduler_job.py:146} INFO - Started process (PID=21337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:23,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:23,295] {logging_mixin.py:95} INFO - [2019-08-27 19:36:23,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:23,299] {logging_mixin.py:95} INFO - [2019-08-27 19:36:23,298] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:23,299] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:23,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:36:23,337] {scheduler_job.py:146} INFO - Started process (PID=21339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:28,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:28,343] {logging_mixin.py:95} INFO - [2019-08-27 19:36:28,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:28,347] {logging_mixin.py:95} INFO - [2019-08-27 19:36:28,346] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:28,347] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:28,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.021 seconds
[2019-08-27 19:36:28,390] {scheduler_job.py:146} INFO - Started process (PID=21341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:33,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:33,399] {logging_mixin.py:95} INFO - [2019-08-27 19:36:33,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:33,403] {logging_mixin.py:95} INFO - [2019-08-27 19:36:33,402] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:33,403] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:33,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:36:33,534] {scheduler_job.py:146} INFO - Started process (PID=21347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:38,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:38,542] {logging_mixin.py:95} INFO - [2019-08-27 19:36:38,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:38,547] {logging_mixin.py:95} INFO - [2019-08-27 19:36:38,546] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:38,547] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:38,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:36:38,587] {scheduler_job.py:146} INFO - Started process (PID=21348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:43,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:43,598] {logging_mixin.py:95} INFO - [2019-08-27 19:36:43,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:43,602] {logging_mixin.py:95} INFO - [2019-08-27 19:36:43,601] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:43,603] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:43,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:36:43,641] {scheduler_job.py:146} INFO - Started process (PID=21350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:48,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:48,650] {logging_mixin.py:95} INFO - [2019-08-27 19:36:48,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:48,655] {logging_mixin.py:95} INFO - [2019-08-27 19:36:48,654] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:48,655] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:48,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:36:48,700] {scheduler_job.py:146} INFO - Started process (PID=21351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:53,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:53,706] {logging_mixin.py:95} INFO - [2019-08-27 19:36:53,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:53,711] {logging_mixin.py:95} INFO - [2019-08-27 19:36:53,710] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:53,712] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:53,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.023 seconds
[2019-08-27 19:36:53,753] {scheduler_job.py:146} INFO - Started process (PID=21353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:58,758] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:36:58,759] {logging_mixin.py:95} INFO - [2019-08-27 19:36:58,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:58,764] {logging_mixin.py:95} INFO - [2019-08-27 19:36:58,762] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:36:58,764] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:36:58,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:36:58,810] {scheduler_job.py:146} INFO - Started process (PID=21355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:03,816] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:03,818] {logging_mixin.py:95} INFO - [2019-08-27 19:37:03,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:03,822] {logging_mixin.py:95} INFO - [2019-08-27 19:37:03,821] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:03,823] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:03,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:37:03,869] {scheduler_job.py:146} INFO - Started process (PID=21356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:08,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:08,877] {logging_mixin.py:95} INFO - [2019-08-27 19:37:08,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:08,882] {logging_mixin.py:95} INFO - [2019-08-27 19:37:08,880] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:08,882] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:08,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:37:08,924] {scheduler_job.py:146} INFO - Started process (PID=21357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:13,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:13,933] {logging_mixin.py:95} INFO - [2019-08-27 19:37:13,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:13,938] {logging_mixin.py:95} INFO - [2019-08-27 19:37:13,937] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:13,938] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:13,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:37:13,984] {scheduler_job.py:146} INFO - Started process (PID=21359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:18,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:18,994] {logging_mixin.py:95} INFO - [2019-08-27 19:37:18,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:18,999] {logging_mixin.py:95} INFO - [2019-08-27 19:37:18,998] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:19,000] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:19,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:37:19,046] {scheduler_job.py:146} INFO - Started process (PID=21360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:24,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:24,058] {logging_mixin.py:95} INFO - [2019-08-27 19:37:24,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:24,062] {logging_mixin.py:95} INFO - [2019-08-27 19:37:24,061] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:24,063] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:24,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:37:24,098] {scheduler_job.py:146} INFO - Started process (PID=21361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:29,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:29,108] {logging_mixin.py:95} INFO - [2019-08-27 19:37:29,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:29,120] {logging_mixin.py:95} INFO - [2019-08-27 19:37:29,112] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:29,121] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:29,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 19:37:29,152] {scheduler_job.py:146} INFO - Started process (PID=21364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:34,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:34,158] {logging_mixin.py:95} INFO - [2019-08-27 19:37:34,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:34,163] {logging_mixin.py:95} INFO - [2019-08-27 19:37:34,162] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:34,163] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:34,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:37:34,208] {scheduler_job.py:146} INFO - Started process (PID=21365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:39,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:39,217] {logging_mixin.py:95} INFO - [2019-08-27 19:37:39,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:39,221] {logging_mixin.py:95} INFO - [2019-08-27 19:37:39,220] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:39,222] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:39,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 19:37:39,269] {scheduler_job.py:146} INFO - Started process (PID=21366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:44,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:44,278] {logging_mixin.py:95} INFO - [2019-08-27 19:37:44,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:44,282] {logging_mixin.py:95} INFO - [2019-08-27 19:37:44,281] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:44,282] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:44,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 19:37:44,321] {scheduler_job.py:146} INFO - Started process (PID=21369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:49,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:49,339] {logging_mixin.py:95} INFO - [2019-08-27 19:37:49,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:49,344] {logging_mixin.py:95} INFO - [2019-08-27 19:37:49,343] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:49,345] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:49,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:37:49,381] {scheduler_job.py:146} INFO - Started process (PID=21370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:54,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:54,389] {logging_mixin.py:95} INFO - [2019-08-27 19:37:54,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:54,393] {logging_mixin.py:95} INFO - [2019-08-27 19:37:54,392] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:54,394] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:54,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:37:54,441] {scheduler_job.py:146} INFO - Started process (PID=21371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:59,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:37:59,449] {logging_mixin.py:95} INFO - [2019-08-27 19:37:59,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:59,453] {logging_mixin.py:95} INFO - [2019-08-27 19:37:59,452] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:37:59,453] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:37:59,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:37:59,501] {scheduler_job.py:146} INFO - Started process (PID=21374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:04,506] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:04,507] {logging_mixin.py:95} INFO - [2019-08-27 19:38:04,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:04,511] {logging_mixin.py:95} INFO - [2019-08-27 19:38:04,510] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:04,512] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:04,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:38:04,563] {scheduler_job.py:146} INFO - Started process (PID=21375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:09,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:09,571] {logging_mixin.py:95} INFO - [2019-08-27 19:38:09,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:09,575] {logging_mixin.py:95} INFO - [2019-08-27 19:38:09,574] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:09,575] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:09,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:38:09,621] {scheduler_job.py:146} INFO - Started process (PID=21376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:14,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:14,632] {logging_mixin.py:95} INFO - [2019-08-27 19:38:14,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:14,637] {logging_mixin.py:95} INFO - [2019-08-27 19:38:14,635] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:14,637] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:14,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:38:14,684] {scheduler_job.py:146} INFO - Started process (PID=21378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:19,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:19,701] {logging_mixin.py:95} INFO - [2019-08-27 19:38:19,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:19,706] {logging_mixin.py:95} INFO - [2019-08-27 19:38:19,704] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:19,706] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:19,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:38:19,742] {scheduler_job.py:146} INFO - Started process (PID=21379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:24,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:24,753] {logging_mixin.py:95} INFO - [2019-08-27 19:38:24,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:24,758] {logging_mixin.py:95} INFO - [2019-08-27 19:38:24,756] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:24,758] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:24,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:38:24,803] {scheduler_job.py:146} INFO - Started process (PID=21380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:29,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:29,812] {logging_mixin.py:95} INFO - [2019-08-27 19:38:29,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:29,818] {logging_mixin.py:95} INFO - [2019-08-27 19:38:29,815] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:29,818] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:29,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 19:38:29,860] {scheduler_job.py:146} INFO - Started process (PID=21384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:34,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:34,867] {logging_mixin.py:95} INFO - [2019-08-27 19:38:34,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:34,871] {logging_mixin.py:95} INFO - [2019-08-27 19:38:34,870] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:34,872] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:34,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:38:34,918] {scheduler_job.py:146} INFO - Started process (PID=21385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:39,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:39,924] {logging_mixin.py:95} INFO - [2019-08-27 19:38:39,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:39,929] {logging_mixin.py:95} INFO - [2019-08-27 19:38:39,927] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:39,929] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:39,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:38:39,977] {scheduler_job.py:146} INFO - Started process (PID=21386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:44,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:44,987] {logging_mixin.py:95} INFO - [2019-08-27 19:38:44,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:44,991] {logging_mixin.py:95} INFO - [2019-08-27 19:38:44,990] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:44,992] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:45,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:38:45,037] {scheduler_job.py:146} INFO - Started process (PID=21388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:50,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:50,048] {logging_mixin.py:95} INFO - [2019-08-27 19:38:50,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:50,053] {logging_mixin.py:95} INFO - [2019-08-27 19:38:50,052] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:50,053] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:50,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:38:50,094] {scheduler_job.py:146} INFO - Started process (PID=21389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:55,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:38:55,105] {logging_mixin.py:95} INFO - [2019-08-27 19:38:55,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:55,110] {logging_mixin.py:95} INFO - [2019-08-27 19:38:55,108] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:38:55,110] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:38:55,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:38:55,150] {scheduler_job.py:146} INFO - Started process (PID=21390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:00,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:00,156] {logging_mixin.py:95} INFO - [2019-08-27 19:39:00,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:00,161] {logging_mixin.py:95} INFO - [2019-08-27 19:39:00,159] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:00,162] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:00,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.023 seconds
[2019-08-27 19:39:00,208] {scheduler_job.py:146} INFO - Started process (PID=21393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:05,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:05,220] {logging_mixin.py:95} INFO - [2019-08-27 19:39:05,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:05,224] {logging_mixin.py:95} INFO - [2019-08-27 19:39:05,223] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:05,225] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:05,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:39:05,265] {scheduler_job.py:146} INFO - Started process (PID=21394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:10,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:10,275] {logging_mixin.py:95} INFO - [2019-08-27 19:39:10,274] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:10,279] {logging_mixin.py:95} INFO - [2019-08-27 19:39:10,278] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:10,280] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:10,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:39:10,324] {scheduler_job.py:146} INFO - Started process (PID=21395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:15,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:15,336] {logging_mixin.py:95} INFO - [2019-08-27 19:39:15,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:15,340] {logging_mixin.py:95} INFO - [2019-08-27 19:39:15,339] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:15,341] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:15,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:39:15,388] {scheduler_job.py:146} INFO - Started process (PID=21397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:20,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:20,403] {logging_mixin.py:95} INFO - [2019-08-27 19:39:20,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:20,408] {logging_mixin.py:95} INFO - [2019-08-27 19:39:20,406] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:20,408] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:20,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.038 seconds
[2019-08-27 19:39:20,448] {scheduler_job.py:146} INFO - Started process (PID=21398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:25,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:25,456] {logging_mixin.py:95} INFO - [2019-08-27 19:39:25,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:25,460] {logging_mixin.py:95} INFO - [2019-08-27 19:39:25,459] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:25,460] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:25,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:39:25,539] {scheduler_job.py:146} INFO - Started process (PID=21399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:30,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:30,545] {logging_mixin.py:95} INFO - [2019-08-27 19:39:30,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:30,548] {logging_mixin.py:95} INFO - [2019-08-27 19:39:30,548] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:30,549] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:30,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.021 seconds
[2019-08-27 19:39:30,619] {scheduler_job.py:146} INFO - Started process (PID=21402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:35,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:35,632] {logging_mixin.py:95} INFO - [2019-08-27 19:39:35,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:35,643] {logging_mixin.py:95} INFO - [2019-08-27 19:39:35,635] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:35,644] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:35,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 19:39:35,711] {scheduler_job.py:146} INFO - Started process (PID=21403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:40,727] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,730] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,729] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:40,730] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:39:40,795] {scheduler_job.py:146} INFO - Started process (PID=21404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:40,799] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,803] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,802] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:40,803] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.019 seconds
[2019-08-27 19:39:40,903] {scheduler_job.py:146} INFO - Started process (PID=21405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:40,908] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,912] {logging_mixin.py:95} INFO - [2019-08-27 19:39:40,911] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:40,912] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:40,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.027 seconds
[2019-08-27 19:39:41,008] {scheduler_job.py:146} INFO - Started process (PID=21406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,013] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,017] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,016] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,018] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.022 seconds
[2019-08-27 19:39:41,115] {scheduler_job.py:146} INFO - Started process (PID=21407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,120] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,124] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,123] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,124] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.021 seconds
[2019-08-27 19:39:41,219] {scheduler_job.py:146} INFO - Started process (PID=21409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,224] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,228] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,227] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,229] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.020 seconds
[2019-08-27 19:39:41,326] {scheduler_job.py:146} INFO - Started process (PID=21410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,331] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,335] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,334] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,336] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.023 seconds
[2019-08-27 19:39:41,431] {scheduler_job.py:146} INFO - Started process (PID=21411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,436] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,440] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,439] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,441] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.021 seconds
[2019-08-27 19:39:41,538] {scheduler_job.py:146} INFO - Started process (PID=21412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,543] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,548] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,546] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,548] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.023 seconds
[2019-08-27 19:39:41,645] {scheduler_job.py:146} INFO - Started process (PID=21413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,651] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,655] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,654] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,656] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.028 seconds
[2019-08-27 19:39:41,750] {scheduler_job.py:146} INFO - Started process (PID=21414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:39:41,757] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,761] {logging_mixin.py:95} INFO - [2019-08-27 19:39:41,760] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:39:41,762] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:39:41,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.025 seconds
[2019-08-27 19:41:54,003] {scheduler_job.py:146} INFO - Started process (PID=21415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,010] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,016] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,014] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,016] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.134 seconds
[2019-08-27 19:41:54,225] {scheduler_job.py:146} INFO - Started process (PID=21416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,230] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,233] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,232] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,233] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.018 seconds
[2019-08-27 19:41:54,327] {scheduler_job.py:146} INFO - Started process (PID=21417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,332] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,335] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,334] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,336] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.024 seconds
[2019-08-27 19:41:54,451] {scheduler_job.py:146} INFO - Started process (PID=21418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,461] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,468] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,466] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,469] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 19:41:54,560] {scheduler_job.py:146} INFO - Started process (PID=21419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,570] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,578] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,576] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,579] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.056 seconds
[2019-08-27 19:41:54,665] {scheduler_job.py:146} INFO - Started process (PID=21420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:54,671] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,677] {logging_mixin.py:95} INFO - [2019-08-27 19:41:54,675] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:54,677] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:54,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.026 seconds
[2019-08-27 19:41:54,769] {scheduler_job.py:146} INFO - Started process (PID=21424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:59,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:41:59,776] {logging_mixin.py:95} INFO - [2019-08-27 19:41:59,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:59,781] {logging_mixin.py:95} INFO - [2019-08-27 19:41:59,779] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:41:59,782] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:41:59,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 19:41:59,902] {scheduler_job.py:146} INFO - Started process (PID=21428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:04,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:04,910] {logging_mixin.py:95} INFO - [2019-08-27 19:42:04,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:04,914] {logging_mixin.py:95} INFO - [2019-08-27 19:42:04,913] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:04,915] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:04,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:42:04,951] {scheduler_job.py:146} INFO - Started process (PID=21433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:09,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:09,959] {logging_mixin.py:95} INFO - [2019-08-27 19:42:09,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:09,963] {logging_mixin.py:95} INFO - [2019-08-27 19:42:09,962] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:09,964] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:09,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 19:42:10,001] {scheduler_job.py:146} INFO - Started process (PID=21437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:15,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:15,009] {logging_mixin.py:95} INFO - [2019-08-27 19:42:15,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:15,013] {logging_mixin.py:95} INFO - [2019-08-27 19:42:15,012] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:15,014] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:15,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:42:15,052] {scheduler_job.py:146} INFO - Started process (PID=21439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:20,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:20,063] {logging_mixin.py:95} INFO - [2019-08-27 19:42:20,062] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:20,067] {logging_mixin.py:95} INFO - [2019-08-27 19:42:20,066] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:20,068] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:20,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 19:42:20,104] {scheduler_job.py:146} INFO - Started process (PID=21440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:25,111] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:25,112] {logging_mixin.py:95} INFO - [2019-08-27 19:42:25,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:25,116] {logging_mixin.py:95} INFO - [2019-08-27 19:42:25,115] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:25,117] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:25,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 19:42:25,166] {scheduler_job.py:146} INFO - Started process (PID=21442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:30,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:30,177] {logging_mixin.py:95} INFO - [2019-08-27 19:42:30,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:30,181] {logging_mixin.py:95} INFO - [2019-08-27 19:42:30,180] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:30,182] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:30,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 19:42:30,227] {scheduler_job.py:146} INFO - Started process (PID=21443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:35,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:35,238] {logging_mixin.py:95} INFO - [2019-08-27 19:42:35,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:35,242] {logging_mixin.py:95} INFO - [2019-08-27 19:42:35,241] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:35,243] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:35,260] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 19:42:35,288] {scheduler_job.py:146} INFO - Started process (PID=21444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:40,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:40,296] {logging_mixin.py:95} INFO - [2019-08-27 19:42:40,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:40,300] {logging_mixin.py:95} INFO - [2019-08-27 19:42:40,299] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:40,300] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:40,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 19:42:40,338] {scheduler_job.py:146} INFO - Started process (PID=21447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:45,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:45,344] {logging_mixin.py:95} INFO - [2019-08-27 19:42:45,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:45,348] {logging_mixin.py:95} INFO - [2019-08-27 19:42:45,346] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:45,348] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:45,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 19:42:45,392] {scheduler_job.py:146} INFO - Started process (PID=21449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:50,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:50,398] {logging_mixin.py:95} INFO - [2019-08-27 19:42:50,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:50,402] {logging_mixin.py:95} INFO - [2019-08-27 19:42:50,401] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:50,403] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:50,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 19:42:50,440] {scheduler_job.py:146} INFO - Started process (PID=21450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:55,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:42:55,448] {logging_mixin.py:95} INFO - [2019-08-27 19:42:55,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:55,453] {logging_mixin.py:95} INFO - [2019-08-27 19:42:55,451] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:42:55,453] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:42:55,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 19:42:55,491] {scheduler_job.py:146} INFO - Started process (PID=21452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:00,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:00,500] {logging_mixin.py:95} INFO - [2019-08-27 19:43:00,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:00,503] {logging_mixin.py:95} INFO - [2019-08-27 19:43:00,502] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:43:00,503] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:00,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 19:43:00,538] {scheduler_job.py:146} INFO - Started process (PID=21453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:05,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:05,548] {logging_mixin.py:95} INFO - [2019-08-27 19:43:05,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:05,552] {logging_mixin.py:95} INFO - [2019-08-27 19:43:05,551] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 18
    def send_to_s3(ds, **kwargs):
      ^
IndentationError: expected an indented block
[2019-08-27 19:43:05,552] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:05,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 19:43:05,590] {scheduler_job.py:146} INFO - Started process (PID=21454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:10,600] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:10,601] {logging_mixin.py:95} INFO - [2019-08-27 19:43:10,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:10,619] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:10,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:10,636] {logging_mixin.py:95} INFO - [2019-08-27 19:43:10,636] {dag.py:1303} INFO - Creating ORM DAG for stock_data
[2019-08-27 19:43:10,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.067 seconds
[2019-08-27 19:43:10,746] {scheduler_job.py:146} INFO - Started process (PID=21456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:15,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:15,753] {logging_mixin.py:95} INFO - [2019-08-27 19:43:15,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:15,760] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:15,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:15,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:43:15,899] {scheduler_job.py:146} INFO - Started process (PID=21457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:20,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:20,910] {logging_mixin.py:95} INFO - [2019-08-27 19:43:20,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:20,917] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:20,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:20,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:43:21,055] {scheduler_job.py:146} INFO - Started process (PID=21459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:26,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:26,064] {logging_mixin.py:95} INFO - [2019-08-27 19:43:26,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:26,070] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:26,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:26,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:43:26,212] {scheduler_job.py:146} INFO - Started process (PID=21461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:31,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:31,226] {logging_mixin.py:95} INFO - [2019-08-27 19:43:31,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:31,234] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:31,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:31,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:43:31,367] {scheduler_job.py:146} INFO - Started process (PID=21462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:36,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:36,374] {logging_mixin.py:95} INFO - [2019-08-27 19:43:36,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:36,380] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:36,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:36,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:43:36,523] {scheduler_job.py:146} INFO - Started process (PID=21463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:41,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:41,533] {logging_mixin.py:95} INFO - [2019-08-27 19:43:41,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:41,539] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:41,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:41,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:43:41,675] {scheduler_job.py:146} INFO - Started process (PID=21466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:46,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:46,685] {logging_mixin.py:95} INFO - [2019-08-27 19:43:46,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:46,694] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:46,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:46,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:43:46,819] {scheduler_job.py:146} INFO - Started process (PID=21479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:51,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:51,829] {logging_mixin.py:95} INFO - [2019-08-27 19:43:51,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:51,834] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:51,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:51,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:43:51,950] {scheduler_job.py:146} INFO - Started process (PID=21485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:56,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:43:56,959] {logging_mixin.py:95} INFO - [2019-08-27 19:43:56,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:56,966] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:43:56,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:43:56,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:43:57,097] {scheduler_job.py:146} INFO - Started process (PID=21487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:02,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:02,105] {logging_mixin.py:95} INFO - [2019-08-27 19:44:02,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:02,111] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:02,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:02,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:44:02,248] {scheduler_job.py:146} INFO - Started process (PID=21488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:07,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:07,257] {logging_mixin.py:95} INFO - [2019-08-27 19:44:07,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:07,264] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:07,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:07,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:44:07,403] {scheduler_job.py:146} INFO - Started process (PID=21489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:12,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:12,412] {logging_mixin.py:95} INFO - [2019-08-27 19:44:12,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:12,419] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:12,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:12,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 19:44:12,547] {scheduler_job.py:146} INFO - Started process (PID=21494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:17,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:17,554] {logging_mixin.py:95} INFO - [2019-08-27 19:44:17,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:17,560] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:17,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:17,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:44:17,693] {scheduler_job.py:146} INFO - Started process (PID=21496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:22,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:22,703] {logging_mixin.py:95} INFO - [2019-08-27 19:44:22,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:22,709] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:22,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:22,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:44:22,835] {scheduler_job.py:146} INFO - Started process (PID=21500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:27,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:27,845] {logging_mixin.py:95} INFO - [2019-08-27 19:44:27,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:27,851] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:27,857] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:27,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:44:27,980] {scheduler_job.py:146} INFO - Started process (PID=21503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:32,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:32,992] {logging_mixin.py:95} INFO - [2019-08-27 19:44:32,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:32,999] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:33,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:33,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:44:33,130] {scheduler_job.py:146} INFO - Started process (PID=21504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:38,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:38,138] {logging_mixin.py:95} INFO - [2019-08-27 19:44:38,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:38,145] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:38,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:38,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:44:38,274] {scheduler_job.py:146} INFO - Started process (PID=21506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:43,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:43,285] {logging_mixin.py:95} INFO - [2019-08-27 19:44:43,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:43,292] {logging_mixin.py:95} WARNING - /Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-08-27 19:44:43,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:43,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:44:43,417] {scheduler_job.py:146} INFO - Started process (PID=21509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:48,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:48,426] {logging_mixin.py:95} INFO - [2019-08-27 19:44:48,425] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:48,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:48,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:44:48,483] {scheduler_job.py:146} INFO - Started process (PID=21514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:53,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:53,491] {logging_mixin.py:95} INFO - [2019-08-27 19:44:53,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:53,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:53,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:44:53,631] {scheduler_job.py:146} INFO - Started process (PID=21518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:58,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:44:58,638] {logging_mixin.py:95} INFO - [2019-08-27 19:44:58,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:58,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:44:58,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:44:58,790] {scheduler_job.py:146} INFO - Started process (PID=21519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:03,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:03,802] {logging_mixin.py:95} INFO - [2019-08-27 19:45:03,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:03,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:03,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 19:45:03,939] {scheduler_job.py:146} INFO - Started process (PID=21520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:08,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:08,945] {logging_mixin.py:95} INFO - [2019-08-27 19:45:08,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:08,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:08,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:45:09,082] {scheduler_job.py:146} INFO - Started process (PID=21522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:14,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:14,094] {logging_mixin.py:95} INFO - [2019-08-27 19:45:14,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:14,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:14,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:45:14,229] {scheduler_job.py:146} INFO - Started process (PID=21523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:19,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:19,237] {logging_mixin.py:95} INFO - [2019-08-27 19:45:19,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:19,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:19,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:45:19,382] {scheduler_job.py:146} INFO - Started process (PID=21524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:24,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:24,389] {logging_mixin.py:95} INFO - [2019-08-27 19:45:24,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:24,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:24,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:45:24,532] {scheduler_job.py:146} INFO - Started process (PID=21527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:29,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:29,541] {logging_mixin.py:95} INFO - [2019-08-27 19:45:29,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:29,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:29,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:45:29,694] {scheduler_job.py:146} INFO - Started process (PID=21528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:34,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:34,701] {logging_mixin.py:95} INFO - [2019-08-27 19:45:34,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:34,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:34,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:45:34,846] {scheduler_job.py:146} INFO - Started process (PID=21532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:39,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:39,852] {logging_mixin.py:95} INFO - [2019-08-27 19:45:39,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:39,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:39,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.062 seconds
[2019-08-27 19:45:39,996] {scheduler_job.py:146} INFO - Started process (PID=21540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:45,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:45,005] {logging_mixin.py:95} INFO - [2019-08-27 19:45:45,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:45,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:45,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:45:45,147] {scheduler_job.py:146} INFO - Started process (PID=21541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:50,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:50,156] {logging_mixin.py:95} INFO - [2019-08-27 19:45:50,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:50,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:50,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:45:50,298] {scheduler_job.py:146} INFO - Started process (PID=21542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:55,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:45:55,305] {logging_mixin.py:95} INFO - [2019-08-27 19:45:55,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:55,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:45:55,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:45:55,446] {scheduler_job.py:146} INFO - Started process (PID=21545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:00,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:00,452] {logging_mixin.py:95} INFO - [2019-08-27 19:46:00,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:00,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:00,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:46:00,604] {scheduler_job.py:146} INFO - Started process (PID=21546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:05,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:05,615] {logging_mixin.py:95} INFO - [2019-08-27 19:46:05,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:05,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:05,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:46:05,759] {scheduler_job.py:146} INFO - Started process (PID=21547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:10,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:10,766] {logging_mixin.py:95} INFO - [2019-08-27 19:46:10,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:10,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:10,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:46:10,907] {scheduler_job.py:146} INFO - Started process (PID=21549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:15,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:15,916] {logging_mixin.py:95} INFO - [2019-08-27 19:46:15,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:15,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:15,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:46:16,063] {scheduler_job.py:146} INFO - Started process (PID=21550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:21,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:21,069] {logging_mixin.py:95} INFO - [2019-08-27 19:46:21,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:21,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:21,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:46:21,219] {scheduler_job.py:146} INFO - Started process (PID=21551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:26,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:26,227] {logging_mixin.py:95} INFO - [2019-08-27 19:46:26,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:26,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:26,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:46:26,374] {scheduler_job.py:146} INFO - Started process (PID=21554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:31,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:31,384] {logging_mixin.py:95} INFO - [2019-08-27 19:46:31,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:31,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:31,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:46:31,530] {scheduler_job.py:146} INFO - Started process (PID=21555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:36,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:36,539] {logging_mixin.py:95} INFO - [2019-08-27 19:46:36,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:36,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:36,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:46:36,681] {scheduler_job.py:146} INFO - Started process (PID=21556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:41,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:41,689] {logging_mixin.py:95} INFO - [2019-08-27 19:46:41,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:41,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:41,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:46:41,828] {scheduler_job.py:146} INFO - Started process (PID=21560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:46,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:46,836] {logging_mixin.py:95} INFO - [2019-08-27 19:46:46,835] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:46,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:46,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:46:46,974] {scheduler_job.py:146} INFO - Started process (PID=21563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:51,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:51,982] {logging_mixin.py:95} INFO - [2019-08-27 19:46:51,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:51,993] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:52,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:46:52,128] {scheduler_job.py:146} INFO - Started process (PID=21564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:57,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:46:57,138] {logging_mixin.py:95} INFO - [2019-08-27 19:46:57,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:57,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:46:57,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 19:46:57,294] {scheduler_job.py:146} INFO - Started process (PID=21567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:02,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:02,304] {logging_mixin.py:95} INFO - [2019-08-27 19:47:02,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:02,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:02,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:47:02,449] {scheduler_job.py:146} INFO - Started process (PID=21569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:07,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:07,455] {logging_mixin.py:95} INFO - [2019-08-27 19:47:07,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:07,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:07,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:47:07,585] {scheduler_job.py:146} INFO - Started process (PID=21570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:12,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:12,594] {logging_mixin.py:95} INFO - [2019-08-27 19:47:12,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:12,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:12,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:47:12,724] {scheduler_job.py:146} INFO - Started process (PID=21572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:17,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:17,734] {logging_mixin.py:95} INFO - [2019-08-27 19:47:17,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:17,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:17,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:47:17,865] {scheduler_job.py:146} INFO - Started process (PID=21573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:22,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:22,876] {logging_mixin.py:95} INFO - [2019-08-27 19:47:22,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:22,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:22,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:47:23,013] {scheduler_job.py:146} INFO - Started process (PID=21574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:28,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:28,021] {logging_mixin.py:95} INFO - [2019-08-27 19:47:28,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:28,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:28,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 19:47:28,152] {scheduler_job.py:146} INFO - Started process (PID=21577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:33,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:33,160] {logging_mixin.py:95} INFO - [2019-08-27 19:47:33,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:33,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:33,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:47:33,298] {scheduler_job.py:146} INFO - Started process (PID=21581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:38,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:38,304] {logging_mixin.py:95} INFO - [2019-08-27 19:47:38,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:38,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:38,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:47:38,443] {scheduler_job.py:146} INFO - Started process (PID=21583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:43,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:43,449] {logging_mixin.py:95} INFO - [2019-08-27 19:47:43,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:43,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:43,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:47:43,583] {scheduler_job.py:146} INFO - Started process (PID=21585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:48,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:48,590] {logging_mixin.py:95} INFO - [2019-08-27 19:47:48,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:48,599] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:48,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 19:47:48,726] {scheduler_job.py:146} INFO - Started process (PID=21587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:53,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:53,733] {logging_mixin.py:95} INFO - [2019-08-27 19:47:53,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:53,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:53,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:47:53,871] {scheduler_job.py:146} INFO - Started process (PID=21589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:58,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:47:58,878] {logging_mixin.py:95} INFO - [2019-08-27 19:47:58,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:58,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:47:58,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:47:59,011] {scheduler_job.py:146} INFO - Started process (PID=21591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:04,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:04,018] {logging_mixin.py:95} INFO - [2019-08-27 19:48:04,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:04,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:04,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:48:04,161] {scheduler_job.py:146} INFO - Started process (PID=21592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:09,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:09,170] {logging_mixin.py:95} INFO - [2019-08-27 19:48:09,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:09,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:09,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:48:09,311] {scheduler_job.py:146} INFO - Started process (PID=21594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:14,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:14,321] {logging_mixin.py:95} INFO - [2019-08-27 19:48:14,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:14,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:14,366] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:48:14,461] {scheduler_job.py:146} INFO - Started process (PID=21595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:19,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:19,472] {logging_mixin.py:95} INFO - [2019-08-27 19:48:19,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:19,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:19,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:48:19,616] {scheduler_job.py:146} INFO - Started process (PID=21596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:24,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:24,622] {logging_mixin.py:95} INFO - [2019-08-27 19:48:24,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:24,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:24,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:48:24,773] {scheduler_job.py:146} INFO - Started process (PID=21598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:29,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:29,781] {logging_mixin.py:95} INFO - [2019-08-27 19:48:29,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:29,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:29,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:48:29,921] {scheduler_job.py:146} INFO - Started process (PID=21599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:34,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:34,931] {logging_mixin.py:95} INFO - [2019-08-27 19:48:34,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:34,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:34,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:48:35,079] {scheduler_job.py:146} INFO - Started process (PID=21601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:40,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:40,085] {logging_mixin.py:95} INFO - [2019-08-27 19:48:40,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:40,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:40,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.085 seconds
[2019-08-27 19:48:40,239] {scheduler_job.py:146} INFO - Started process (PID=21607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:45,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:45,252] {logging_mixin.py:95} INFO - [2019-08-27 19:48:45,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:45,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:45,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 19:48:45,389] {scheduler_job.py:146} INFO - Started process (PID=21608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:50,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:50,400] {logging_mixin.py:95} INFO - [2019-08-27 19:48:50,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:50,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:50,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:48:50,550] {scheduler_job.py:146} INFO - Started process (PID=21609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:55,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:48:55,558] {logging_mixin.py:95} INFO - [2019-08-27 19:48:55,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:55,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:48:55,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:48:55,710] {scheduler_job.py:146} INFO - Started process (PID=21611) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:00,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:00,716] {logging_mixin.py:95} INFO - [2019-08-27 19:49:00,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:00,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:00,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:49:00,871] {scheduler_job.py:146} INFO - Started process (PID=21612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:05,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:05,882] {logging_mixin.py:95} INFO - [2019-08-27 19:49:05,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:05,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:05,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:49:06,028] {scheduler_job.py:146} INFO - Started process (PID=21614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:11,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:11,039] {logging_mixin.py:95} INFO - [2019-08-27 19:49:11,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:11,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:11,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:49:11,191] {scheduler_job.py:146} INFO - Started process (PID=21616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:16,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:16,199] {logging_mixin.py:95} INFO - [2019-08-27 19:49:16,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:16,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:16,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:49:16,346] {scheduler_job.py:146} INFO - Started process (PID=21617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:21,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:21,357] {logging_mixin.py:95} INFO - [2019-08-27 19:49:21,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:21,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:21,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:49:21,506] {scheduler_job.py:146} INFO - Started process (PID=21618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:26,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:26,512] {logging_mixin.py:95} INFO - [2019-08-27 19:49:26,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:26,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:26,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:49:26,668] {scheduler_job.py:146} INFO - Started process (PID=21620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:31,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:31,684] {logging_mixin.py:95} INFO - [2019-08-27 19:49:31,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:31,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:31,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:49:31,826] {scheduler_job.py:146} INFO - Started process (PID=21621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:36,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:36,842] {logging_mixin.py:95} INFO - [2019-08-27 19:49:36,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:36,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:36,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:49:36,991] {scheduler_job.py:146} INFO - Started process (PID=21623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:41,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:41,999] {logging_mixin.py:95} INFO - [2019-08-27 19:49:41,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:42,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:42,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:49:42,144] {scheduler_job.py:146} INFO - Started process (PID=21626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:47,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:47,155] {logging_mixin.py:95} INFO - [2019-08-27 19:49:47,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:47,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:47,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:49:47,305] {scheduler_job.py:146} INFO - Started process (PID=21627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:52,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:52,314] {logging_mixin.py:95} INFO - [2019-08-27 19:49:52,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:52,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:52,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:49:52,462] {scheduler_job.py:146} INFO - Started process (PID=21628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:57,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:49:57,473] {logging_mixin.py:95} INFO - [2019-08-27 19:49:57,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:57,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:49:57,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:49:57,621] {scheduler_job.py:146} INFO - Started process (PID=21630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:02,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:02,630] {logging_mixin.py:95} INFO - [2019-08-27 19:50:02,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:02,640] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:02,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:50:02,775] {scheduler_job.py:146} INFO - Started process (PID=21631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:07,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:07,788] {logging_mixin.py:95} INFO - [2019-08-27 19:50:07,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:07,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:07,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:50:07,942] {scheduler_job.py:146} INFO - Started process (PID=21633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:12,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:12,950] {logging_mixin.py:95} INFO - [2019-08-27 19:50:12,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:12,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:12,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:50:13,103] {scheduler_job.py:146} INFO - Started process (PID=21635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:18,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:18,114] {logging_mixin.py:95} INFO - [2019-08-27 19:50:18,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:18,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:18,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:50:18,261] {scheduler_job.py:146} INFO - Started process (PID=21636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:23,268] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:23,269] {logging_mixin.py:95} INFO - [2019-08-27 19:50:23,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:23,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:23,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:50:23,419] {scheduler_job.py:146} INFO - Started process (PID=21637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:28,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:28,431] {logging_mixin.py:95} INFO - [2019-08-27 19:50:28,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:28,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:28,477] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 19:50:28,581] {scheduler_job.py:146} INFO - Started process (PID=21639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:33,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:33,590] {logging_mixin.py:95} INFO - [2019-08-27 19:50:33,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:33,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:33,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:50:33,742] {scheduler_job.py:146} INFO - Started process (PID=21640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:38,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:38,757] {logging_mixin.py:95} INFO - [2019-08-27 19:50:38,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:38,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:38,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:50:38,903] {scheduler_job.py:146} INFO - Started process (PID=21643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:43,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:43,912] {logging_mixin.py:95} INFO - [2019-08-27 19:50:43,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:43,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:43,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:50:44,057] {scheduler_job.py:146} INFO - Started process (PID=21645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:49,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:49,065] {logging_mixin.py:95} INFO - [2019-08-27 19:50:49,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:49,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:49,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:50:49,216] {scheduler_job.py:146} INFO - Started process (PID=21646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:54,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:54,226] {logging_mixin.py:95} INFO - [2019-08-27 19:50:54,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:54,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:54,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:50:54,369] {scheduler_job.py:146} INFO - Started process (PID=21648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:59,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:50:59,378] {logging_mixin.py:95} INFO - [2019-08-27 19:50:59,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:59,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:50:59,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:50:59,531] {scheduler_job.py:146} INFO - Started process (PID=21649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:04,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:04,542] {logging_mixin.py:95} INFO - [2019-08-27 19:51:04,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:04,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:04,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:51:04,690] {scheduler_job.py:146} INFO - Started process (PID=21650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:09,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:09,698] {logging_mixin.py:95} INFO - [2019-08-27 19:51:09,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:09,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:09,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:51:09,855] {scheduler_job.py:146} INFO - Started process (PID=21653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:14,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:14,863] {logging_mixin.py:95} INFO - [2019-08-27 19:51:14,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:14,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:14,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:51:15,008] {scheduler_job.py:146} INFO - Started process (PID=21654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:20,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:20,018] {logging_mixin.py:95} INFO - [2019-08-27 19:51:20,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:20,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:20,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:51:20,163] {scheduler_job.py:146} INFO - Started process (PID=21655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:25,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:25,169] {logging_mixin.py:95} INFO - [2019-08-27 19:51:25,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:25,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:25,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:51:25,319] {scheduler_job.py:146} INFO - Started process (PID=21657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:30,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:30,328] {logging_mixin.py:95} INFO - [2019-08-27 19:51:30,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:30,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:30,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:51:30,480] {scheduler_job.py:146} INFO - Started process (PID=21658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:35,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:35,489] {logging_mixin.py:95} INFO - [2019-08-27 19:51:35,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:35,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:35,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:51:35,636] {scheduler_job.py:146} INFO - Started process (PID=21659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:40,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:40,643] {logging_mixin.py:95} INFO - [2019-08-27 19:51:40,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:40,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:40,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:51:40,790] {scheduler_job.py:146} INFO - Started process (PID=21667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:45,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:45,798] {logging_mixin.py:95} INFO - [2019-08-27 19:51:45,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:45,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:45,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:51:45,950] {scheduler_job.py:146} INFO - Started process (PID=21672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:50,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:50,961] {logging_mixin.py:95} INFO - [2019-08-27 19:51:50,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:50,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:51,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:51:51,110] {scheduler_job.py:146} INFO - Started process (PID=21673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:56,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:51:56,119] {logging_mixin.py:95} INFO - [2019-08-27 19:51:56,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:56,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:51:56,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:51:56,271] {scheduler_job.py:146} INFO - Started process (PID=21675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:01,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:01,293] {logging_mixin.py:95} INFO - [2019-08-27 19:52:01,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:01,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:01,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:52:01,449] {scheduler_job.py:146} INFO - Started process (PID=21676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:06,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:06,456] {logging_mixin.py:95} INFO - [2019-08-27 19:52:06,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:06,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:06,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:52:06,608] {scheduler_job.py:146} INFO - Started process (PID=21677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:11,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:11,619] {logging_mixin.py:95} INFO - [2019-08-27 19:52:11,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:11,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:11,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:52:11,770] {scheduler_job.py:146} INFO - Started process (PID=21680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:16,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:16,779] {logging_mixin.py:95} INFO - [2019-08-27 19:52:16,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:16,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:16,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:52:16,932] {scheduler_job.py:146} INFO - Started process (PID=21681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:21,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:21,939] {logging_mixin.py:95} INFO - [2019-08-27 19:52:21,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:21,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:21,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:52:22,089] {scheduler_job.py:146} INFO - Started process (PID=21682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:27,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:27,102] {logging_mixin.py:95} INFO - [2019-08-27 19:52:27,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:27,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:27,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:52:27,235] {scheduler_job.py:146} INFO - Started process (PID=21684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:32,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:32,247] {logging_mixin.py:95} INFO - [2019-08-27 19:52:32,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:32,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:32,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:52:32,390] {scheduler_job.py:146} INFO - Started process (PID=21685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:37,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:37,398] {logging_mixin.py:95} INFO - [2019-08-27 19:52:37,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:37,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:37,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:52:37,552] {scheduler_job.py:146} INFO - Started process (PID=21686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:42,562] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:42,563] {logging_mixin.py:95} INFO - [2019-08-27 19:52:42,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:42,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:42,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:52:42,702] {scheduler_job.py:146} INFO - Started process (PID=21692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:47,706] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:47,707] {logging_mixin.py:95} INFO - [2019-08-27 19:52:47,707] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:47,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:47,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:52:47,766] {scheduler_job.py:146} INFO - Started process (PID=21693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:52,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:52,777] {logging_mixin.py:95} INFO - [2019-08-27 19:52:52,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:52,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:52,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 19:52:52,923] {scheduler_job.py:146} INFO - Started process (PID=21694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:57,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:52:57,930] {logging_mixin.py:95} INFO - [2019-08-27 19:52:57,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:57,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:52:57,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:52:58,080] {scheduler_job.py:146} INFO - Started process (PID=21696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:03,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:03,100] {logging_mixin.py:95} INFO - [2019-08-27 19:53:03,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:03,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:03,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:53:03,230] {scheduler_job.py:146} INFO - Started process (PID=21697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:08,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:08,238] {logging_mixin.py:95} INFO - [2019-08-27 19:53:08,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:08,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:08,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:53:08,391] {scheduler_job.py:146} INFO - Started process (PID=21698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:13,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:13,400] {logging_mixin.py:95} INFO - [2019-08-27 19:53:13,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:13,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:13,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 19:53:13,546] {scheduler_job.py:146} INFO - Started process (PID=21701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:18,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:18,557] {logging_mixin.py:95} INFO - [2019-08-27 19:53:18,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:18,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:18,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:53:18,707] {scheduler_job.py:146} INFO - Started process (PID=21702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:23,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:23,717] {logging_mixin.py:95} INFO - [2019-08-27 19:53:23,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:23,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:23,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:53:23,860] {scheduler_job.py:146} INFO - Started process (PID=21704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:28,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:28,871] {logging_mixin.py:95} INFO - [2019-08-27 19:53:28,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:28,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:28,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:53:28,999] {scheduler_job.py:146} INFO - Started process (PID=21705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:34,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:34,010] {logging_mixin.py:95} INFO - [2019-08-27 19:53:34,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:34,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:34,058] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:53:34,142] {scheduler_job.py:146} INFO - Started process (PID=21706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:39,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:39,148] {logging_mixin.py:95} INFO - [2019-08-27 19:53:39,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:39,158] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:39,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:53:39,288] {scheduler_job.py:146} INFO - Started process (PID=21708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:44,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:44,298] {logging_mixin.py:95} INFO - [2019-08-27 19:53:44,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:44,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:44,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:53:44,430] {scheduler_job.py:146} INFO - Started process (PID=21711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:49,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:49,439] {logging_mixin.py:95} INFO - [2019-08-27 19:53:49,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:49,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:49,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:53:49,564] {scheduler_job.py:146} INFO - Started process (PID=21712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:54,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:54,573] {logging_mixin.py:95} INFO - [2019-08-27 19:53:54,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:54,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:54,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:53:54,705] {scheduler_job.py:146} INFO - Started process (PID=21717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:59,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:53:59,719] {logging_mixin.py:95} INFO - [2019-08-27 19:53:59,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:59,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:53:59,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:53:59,845] {scheduler_job.py:146} INFO - Started process (PID=21718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:04,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:04,856] {logging_mixin.py:95} INFO - [2019-08-27 19:54:04,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:04,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:04,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 19:54:04,986] {scheduler_job.py:146} INFO - Started process (PID=21719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:09,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:09,994] {logging_mixin.py:95} INFO - [2019-08-27 19:54:09,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:10,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:10,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:54:10,126] {scheduler_job.py:146} INFO - Started process (PID=21721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:15,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:15,136] {logging_mixin.py:95} INFO - [2019-08-27 19:54:15,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:15,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:15,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:54:15,269] {scheduler_job.py:146} INFO - Started process (PID=21722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:20,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:20,282] {logging_mixin.py:95} INFO - [2019-08-27 19:54:20,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:20,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:20,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:54:20,405] {scheduler_job.py:146} INFO - Started process (PID=21724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:25,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:25,414] {logging_mixin.py:95} INFO - [2019-08-27 19:54:25,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:25,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:25,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:54:25,540] {scheduler_job.py:146} INFO - Started process (PID=21726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:30,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:30,547] {logging_mixin.py:95} INFO - [2019-08-27 19:54:30,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:30,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:30,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:54:30,675] {scheduler_job.py:146} INFO - Started process (PID=21727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:35,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:35,686] {logging_mixin.py:95} INFO - [2019-08-27 19:54:35,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:35,698] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:35,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:54:35,814] {scheduler_job.py:146} INFO - Started process (PID=21728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:40,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:40,824] {logging_mixin.py:95} INFO - [2019-08-27 19:54:40,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:40,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:40,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:54:40,954] {scheduler_job.py:146} INFO - Started process (PID=21730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:45,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:45,963] {logging_mixin.py:95} INFO - [2019-08-27 19:54:45,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:45,974] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:46,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:54:46,092] {scheduler_job.py:146} INFO - Started process (PID=21731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:51,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:51,099] {logging_mixin.py:95} INFO - [2019-08-27 19:54:51,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:51,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:51,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:54:51,224] {scheduler_job.py:146} INFO - Started process (PID=21733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:56,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:54:56,232] {logging_mixin.py:95} INFO - [2019-08-27 19:54:56,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:56,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:54:56,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:54:56,363] {scheduler_job.py:146} INFO - Started process (PID=21735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:01,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:01,369] {logging_mixin.py:95} INFO - [2019-08-27 19:55:01,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:01,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:01,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:55:01,501] {scheduler_job.py:146} INFO - Started process (PID=21736) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:06,509] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:06,511] {logging_mixin.py:95} INFO - [2019-08-27 19:55:06,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:06,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:06,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:55:06,635] {scheduler_job.py:146} INFO - Started process (PID=21737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:11,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:11,646] {logging_mixin.py:95} INFO - [2019-08-27 19:55:11,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:11,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:11,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:55:11,770] {scheduler_job.py:146} INFO - Started process (PID=21739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:16,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:16,779] {logging_mixin.py:95} INFO - [2019-08-27 19:55:16,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:16,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:16,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:55:16,909] {scheduler_job.py:146} INFO - Started process (PID=21740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:21,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:21,916] {logging_mixin.py:95} INFO - [2019-08-27 19:55:21,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:21,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:21,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:55:22,047] {scheduler_job.py:146} INFO - Started process (PID=21742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:27,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:27,056] {logging_mixin.py:95} INFO - [2019-08-27 19:55:27,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:27,069] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:27,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:55:27,175] {scheduler_job.py:146} INFO - Started process (PID=21744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:32,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:32,183] {logging_mixin.py:95} INFO - [2019-08-27 19:55:32,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:32,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:32,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:55:32,305] {scheduler_job.py:146} INFO - Started process (PID=22609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:37,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:37,315] {logging_mixin.py:95} INFO - [2019-08-27 19:55:37,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:37,327] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:37,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:55:37,439] {scheduler_job.py:146} INFO - Started process (PID=23137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:42,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:42,446] {logging_mixin.py:95} INFO - [2019-08-27 19:55:42,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:42,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:42,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:55:42,578] {scheduler_job.py:146} INFO - Started process (PID=23140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:47,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:47,584] {logging_mixin.py:95} INFO - [2019-08-27 19:55:47,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:47,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:47,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:55:47,720] {scheduler_job.py:146} INFO - Started process (PID=23141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:52,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:52,729] {logging_mixin.py:95} INFO - [2019-08-27 19:55:52,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:52,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:52,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:55:52,860] {scheduler_job.py:146} INFO - Started process (PID=23143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:57,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:55:57,871] {logging_mixin.py:95} INFO - [2019-08-27 19:55:57,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:57,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:55:57,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:55:57,991] {scheduler_job.py:146} INFO - Started process (PID=23145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:02,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:02,999] {logging_mixin.py:95} INFO - [2019-08-27 19:56:02,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:03,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:03,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:56:03,122] {scheduler_job.py:146} INFO - Started process (PID=23146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:08,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:08,129] {logging_mixin.py:95} INFO - [2019-08-27 19:56:08,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:08,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:08,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:56:08,258] {scheduler_job.py:146} INFO - Started process (PID=23147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:13,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:13,265] {logging_mixin.py:95} INFO - [2019-08-27 19:56:13,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:13,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:13,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:56:13,393] {scheduler_job.py:146} INFO - Started process (PID=23149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:18,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:18,404] {logging_mixin.py:95} INFO - [2019-08-27 19:56:18,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:18,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:18,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 19:56:18,538] {scheduler_job.py:146} INFO - Started process (PID=23151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:23,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:23,553] {logging_mixin.py:95} INFO - [2019-08-27 19:56:23,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:23,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:23,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:56:23,684] {scheduler_job.py:146} INFO - Started process (PID=23153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:28,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:28,692] {logging_mixin.py:95} INFO - [2019-08-27 19:56:28,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:28,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:28,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:56:28,820] {scheduler_job.py:146} INFO - Started process (PID=23155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:33,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:33,830] {logging_mixin.py:95} INFO - [2019-08-27 19:56:33,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:33,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:33,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:56:33,960] {scheduler_job.py:146} INFO - Started process (PID=23156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:38,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:38,967] {logging_mixin.py:95} INFO - [2019-08-27 19:56:38,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:38,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:39,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:56:39,106] {scheduler_job.py:146} INFO - Started process (PID=23158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:44,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:44,114] {logging_mixin.py:95} INFO - [2019-08-27 19:56:44,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:44,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:44,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:56:44,241] {scheduler_job.py:146} INFO - Started process (PID=23161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:49,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:49,251] {logging_mixin.py:95} INFO - [2019-08-27 19:56:49,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:49,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:49,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:56:49,378] {scheduler_job.py:146} INFO - Started process (PID=23163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:54,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:54,386] {logging_mixin.py:95} INFO - [2019-08-27 19:56:54,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:54,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:54,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 19:56:54,506] {scheduler_job.py:146} INFO - Started process (PID=23168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:59,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:56:59,516] {logging_mixin.py:95} INFO - [2019-08-27 19:56:59,516] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:59,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:56:59,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:56:59,647] {scheduler_job.py:146} INFO - Started process (PID=23176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:04,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:04,654] {logging_mixin.py:95} INFO - [2019-08-27 19:57:04,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:04,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:04,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:57:04,802] {scheduler_job.py:146} INFO - Started process (PID=23177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:09,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:09,809] {logging_mixin.py:95} INFO - [2019-08-27 19:57:09,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:09,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:09,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:57:09,950] {scheduler_job.py:146} INFO - Started process (PID=23179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:14,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:14,956] {logging_mixin.py:95} INFO - [2019-08-27 19:57:14,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:14,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:14,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:57:15,093] {scheduler_job.py:146} INFO - Started process (PID=23180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:20,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:20,100] {logging_mixin.py:95} INFO - [2019-08-27 19:57:20,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:20,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:20,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:57:20,243] {scheduler_job.py:146} INFO - Started process (PID=23181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:25,248] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:25,249] {logging_mixin.py:95} INFO - [2019-08-27 19:57:25,249] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:25,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:25,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:57:25,387] {scheduler_job.py:146} INFO - Started process (PID=23184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:30,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:30,394] {logging_mixin.py:95} INFO - [2019-08-27 19:57:30,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:30,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:30,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:57:30,529] {scheduler_job.py:146} INFO - Started process (PID=23185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:35,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:35,536] {logging_mixin.py:95} INFO - [2019-08-27 19:57:35,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:35,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:35,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:57:35,682] {scheduler_job.py:146} INFO - Started process (PID=23186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:40,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:40,693] {logging_mixin.py:95} INFO - [2019-08-27 19:57:40,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:40,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:40,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:57:40,828] {scheduler_job.py:146} INFO - Started process (PID=23189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:45,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:45,839] {logging_mixin.py:95} INFO - [2019-08-27 19:57:45,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:45,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:45,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:57:45,986] {scheduler_job.py:146} INFO - Started process (PID=23190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:50,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:50,993] {logging_mixin.py:95} INFO - [2019-08-27 19:57:50,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:51,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:51,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:57:51,149] {scheduler_job.py:146} INFO - Started process (PID=23191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:56,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:57:56,159] {logging_mixin.py:95} INFO - [2019-08-27 19:57:56,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:56,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:57:56,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 19:57:56,298] {scheduler_job.py:146} INFO - Started process (PID=23194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:01,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:01,316] {logging_mixin.py:95} INFO - [2019-08-27 19:58:01,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:01,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:01,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:58:01,460] {scheduler_job.py:146} INFO - Started process (PID=23195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:06,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:06,467] {logging_mixin.py:95} INFO - [2019-08-27 19:58:06,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:06,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:06,510] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:58:06,619] {scheduler_job.py:146} INFO - Started process (PID=23196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:11,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:11,626] {logging_mixin.py:95} INFO - [2019-08-27 19:58:11,626] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:11,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:11,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:58:11,773] {scheduler_job.py:146} INFO - Started process (PID=23198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:16,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:16,781] {logging_mixin.py:95} INFO - [2019-08-27 19:58:16,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:16,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:16,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:58:16,928] {scheduler_job.py:146} INFO - Started process (PID=23199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:21,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:21,937] {logging_mixin.py:95} INFO - [2019-08-27 19:58:21,937] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:21,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:21,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:58:22,083] {scheduler_job.py:146} INFO - Started process (PID=23200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:27,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:27,093] {logging_mixin.py:95} INFO - [2019-08-27 19:58:27,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:27,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:27,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:58:27,228] {scheduler_job.py:146} INFO - Started process (PID=23202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:32,233] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:32,235] {logging_mixin.py:95} INFO - [2019-08-27 19:58:32,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:32,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:32,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:58:32,376] {scheduler_job.py:146} INFO - Started process (PID=23204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:37,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:37,383] {logging_mixin.py:95} INFO - [2019-08-27 19:58:37,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:37,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:37,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 19:58:37,520] {scheduler_job.py:146} INFO - Started process (PID=23205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:42,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:42,529] {logging_mixin.py:95} INFO - [2019-08-27 19:58:42,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:42,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:42,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:58:42,670] {scheduler_job.py:146} INFO - Started process (PID=23209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:47,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:47,678] {logging_mixin.py:95} INFO - [2019-08-27 19:58:47,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:47,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:47,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:58:47,827] {scheduler_job.py:146} INFO - Started process (PID=23210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:52,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:52,836] {logging_mixin.py:95} INFO - [2019-08-27 19:58:52,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:52,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:52,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:58:52,979] {scheduler_job.py:146} INFO - Started process (PID=23211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:57,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:58:57,987] {logging_mixin.py:95} INFO - [2019-08-27 19:58:57,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:57,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:58:58,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 19:58:58,130] {scheduler_job.py:146} INFO - Started process (PID=23213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:03,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:03,137] {logging_mixin.py:95} INFO - [2019-08-27 19:59:03,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:03,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:03,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 19:59:03,277] {scheduler_job.py:146} INFO - Started process (PID=23215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:08,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:08,284] {logging_mixin.py:95} INFO - [2019-08-27 19:59:08,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:08,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:08,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 19:59:08,430] {scheduler_job.py:146} INFO - Started process (PID=23216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:13,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:13,439] {logging_mixin.py:95} INFO - [2019-08-27 19:59:13,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:13,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:13,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 19:59:13,588] {scheduler_job.py:146} INFO - Started process (PID=23218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:18,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:18,594] {logging_mixin.py:95} INFO - [2019-08-27 19:59:18,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:18,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:18,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 19:59:18,747] {scheduler_job.py:146} INFO - Started process (PID=23219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:23,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:23,754] {logging_mixin.py:95} INFO - [2019-08-27 19:59:23,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:23,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:23,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 19:59:23,904] {scheduler_job.py:146} INFO - Started process (PID=23220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:28,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:28,912] {logging_mixin.py:95} INFO - [2019-08-27 19:59:28,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:28,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:28,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 19:59:29,048] {scheduler_job.py:146} INFO - Started process (PID=23225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:34,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:34,056] {logging_mixin.py:95} INFO - [2019-08-27 19:59:34,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:34,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:34,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 19:59:34,193] {scheduler_job.py:146} INFO - Started process (PID=23228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:39,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:39,204] {logging_mixin.py:95} INFO - [2019-08-27 19:59:39,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:39,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:39,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 19:59:39,345] {scheduler_job.py:146} INFO - Started process (PID=23230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:44,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:44,357] {logging_mixin.py:95} INFO - [2019-08-27 19:59:44,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:44,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:44,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 19:59:44,499] {scheduler_job.py:146} INFO - Started process (PID=23231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:49,506] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:49,507] {logging_mixin.py:95} INFO - [2019-08-27 19:59:49,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:49,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:49,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:59:49,651] {scheduler_job.py:146} INFO - Started process (PID=23232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:54,659] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:54,660] {logging_mixin.py:95} INFO - [2019-08-27 19:59:54,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:54,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:54,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 19:59:54,805] {scheduler_job.py:146} INFO - Started process (PID=23234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:59,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 19:59:59,816] {logging_mixin.py:95} INFO - [2019-08-27 19:59:59,816] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:59,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 19:59:59,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 19:59:59,967] {scheduler_job.py:146} INFO - Started process (PID=23235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:04,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:04,974] {logging_mixin.py:95} INFO - [2019-08-27 20:00:04,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:04,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:05,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:00:05,126] {scheduler_job.py:146} INFO - Started process (PID=23237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:10,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:10,133] {logging_mixin.py:95} INFO - [2019-08-27 20:00:10,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:10,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:10,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:00:10,289] {scheduler_job.py:146} INFO - Started process (PID=23239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:15,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:15,299] {logging_mixin.py:95} INFO - [2019-08-27 20:00:15,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:15,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:15,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.067 seconds
[2019-08-27 20:00:15,443] {scheduler_job.py:146} INFO - Started process (PID=23240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:20,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:20,452] {logging_mixin.py:95} INFO - [2019-08-27 20:00:20,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:20,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:20,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:00:20,585] {scheduler_job.py:146} INFO - Started process (PID=23242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:25,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:25,592] {logging_mixin.py:95} INFO - [2019-08-27 20:00:25,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:25,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:25,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 20:00:25,735] {scheduler_job.py:146} INFO - Started process (PID=23244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:30,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:30,744] {logging_mixin.py:95} INFO - [2019-08-27 20:00:30,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:30,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:30,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:00:30,888] {scheduler_job.py:146} INFO - Started process (PID=23245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:35,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:35,899] {logging_mixin.py:95} INFO - [2019-08-27 20:00:35,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:35,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:35,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:00:36,035] {scheduler_job.py:146} INFO - Started process (PID=23250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:41,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:41,044] {logging_mixin.py:95} INFO - [2019-08-27 20:00:41,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:41,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:41,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:00:41,186] {scheduler_job.py:146} INFO - Started process (PID=23255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:46,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:46,207] {logging_mixin.py:95} INFO - [2019-08-27 20:00:46,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:46,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:46,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:00:46,340] {scheduler_job.py:146} INFO - Started process (PID=23256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:51,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:51,349] {logging_mixin.py:95} INFO - [2019-08-27 20:00:51,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:51,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:51,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:00:51,492] {scheduler_job.py:146} INFO - Started process (PID=23258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:56,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:00:56,502] {logging_mixin.py:95} INFO - [2019-08-27 20:00:56,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:56,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:00:56,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:00:56,643] {scheduler_job.py:146} INFO - Started process (PID=23260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:01,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:01,652] {logging_mixin.py:95} INFO - [2019-08-27 20:01:01,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:01,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:01,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:01:01,802] {scheduler_job.py:146} INFO - Started process (PID=23261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:06,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:06,813] {logging_mixin.py:95} INFO - [2019-08-27 20:01:06,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:06,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:06,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:01:06,938] {scheduler_job.py:146} INFO - Started process (PID=23263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:11,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:11,948] {logging_mixin.py:95} INFO - [2019-08-27 20:01:11,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:11,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:11,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:01:12,070] {scheduler_job.py:146} INFO - Started process (PID=23265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:17,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:17,081] {logging_mixin.py:95} INFO - [2019-08-27 20:01:17,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:17,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:17,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:01:17,205] {scheduler_job.py:146} INFO - Started process (PID=23266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:22,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:22,213] {logging_mixin.py:95} INFO - [2019-08-27 20:01:22,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:22,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:22,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.062 seconds
[2019-08-27 20:01:22,338] {scheduler_job.py:146} INFO - Started process (PID=23267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:27,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:27,347] {logging_mixin.py:95} INFO - [2019-08-27 20:01:27,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:27,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:27,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:01:27,477] {scheduler_job.py:146} INFO - Started process (PID=23269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:32,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:32,488] {logging_mixin.py:95} INFO - [2019-08-27 20:01:32,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:32,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:32,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:01:32,619] {scheduler_job.py:146} INFO - Started process (PID=23270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:37,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:37,631] {logging_mixin.py:95} INFO - [2019-08-27 20:01:37,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:37,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:37,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:01:37,760] {scheduler_job.py:146} INFO - Started process (PID=23272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:42,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:42,770] {logging_mixin.py:95} INFO - [2019-08-27 20:01:42,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:42,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:42,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:01:42,886] {scheduler_job.py:146} INFO - Started process (PID=23275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:47,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:47,897] {logging_mixin.py:95} INFO - [2019-08-27 20:01:47,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:47,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:47,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:01:48,017] {scheduler_job.py:146} INFO - Started process (PID=23276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:53,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:53,025] {logging_mixin.py:95} INFO - [2019-08-27 20:01:53,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:53,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:53,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:01:53,151] {scheduler_job.py:146} INFO - Started process (PID=23277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:58,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:01:58,161] {logging_mixin.py:95} INFO - [2019-08-27 20:01:58,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:58,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:01:58,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:01:58,292] {scheduler_job.py:146} INFO - Started process (PID=23279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:03,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:03,302] {logging_mixin.py:95} INFO - [2019-08-27 20:02:03,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:03,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:03,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:02:03,432] {scheduler_job.py:146} INFO - Started process (PID=23280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:08,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:08,444] {logging_mixin.py:95} INFO - [2019-08-27 20:02:08,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:08,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:08,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 20:02:08,582] {scheduler_job.py:146} INFO - Started process (PID=23282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:13,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:13,592] {logging_mixin.py:95} INFO - [2019-08-27 20:02:13,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:13,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:13,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:02:13,719] {scheduler_job.py:146} INFO - Started process (PID=23284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:18,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:18,729] {logging_mixin.py:95} INFO - [2019-08-27 20:02:18,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:18,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:18,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:02:18,853] {scheduler_job.py:146} INFO - Started process (PID=23285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:23,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:23,862] {logging_mixin.py:95} INFO - [2019-08-27 20:02:23,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:23,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:23,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:02:23,990] {scheduler_job.py:146} INFO - Started process (PID=23286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:28,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:28,996] {logging_mixin.py:95} INFO - [2019-08-27 20:02:28,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:29,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:29,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:02:29,130] {scheduler_job.py:146} INFO - Started process (PID=23288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:34,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:34,139] {logging_mixin.py:95} INFO - [2019-08-27 20:02:34,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:34,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:34,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:02:34,267] {scheduler_job.py:146} INFO - Started process (PID=23289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:39,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:39,277] {logging_mixin.py:95} INFO - [2019-08-27 20:02:39,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:39,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:39,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.068 seconds
[2019-08-27 20:02:39,417] {scheduler_job.py:146} INFO - Started process (PID=23293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:44,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:44,426] {logging_mixin.py:95} INFO - [2019-08-27 20:02:44,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:44,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:44,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:02:44,551] {scheduler_job.py:146} INFO - Started process (PID=23295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:49,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:49,561] {logging_mixin.py:95} INFO - [2019-08-27 20:02:49,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:49,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:49,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 20:02:49,687] {scheduler_job.py:146} INFO - Started process (PID=23296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:54,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:54,696] {logging_mixin.py:95} INFO - [2019-08-27 20:02:54,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:54,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:54,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:02:54,825] {scheduler_job.py:146} INFO - Started process (PID=23298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:59,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:02:59,837] {logging_mixin.py:95} INFO - [2019-08-27 20:02:59,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:59,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:02:59,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 20:02:59,964] {scheduler_job.py:146} INFO - Started process (PID=23299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:04,970] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:04,971] {logging_mixin.py:95} INFO - [2019-08-27 20:03:04,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:04,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:05,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:03:05,103] {scheduler_job.py:146} INFO - Started process (PID=23300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:10,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:10,111] {logging_mixin.py:95} INFO - [2019-08-27 20:03:10,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:10,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:10,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:03:10,237] {scheduler_job.py:146} INFO - Started process (PID=23303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:15,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:15,245] {logging_mixin.py:95} INFO - [2019-08-27 20:03:15,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:15,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:15,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:03:15,376] {scheduler_job.py:146} INFO - Started process (PID=23304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:20,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:20,384] {logging_mixin.py:95} INFO - [2019-08-27 20:03:20,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:20,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:20,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:03:20,513] {scheduler_job.py:146} INFO - Started process (PID=23305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:25,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:25,521] {logging_mixin.py:95} INFO - [2019-08-27 20:03:25,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:25,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:25,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:03:25,654] {scheduler_job.py:146} INFO - Started process (PID=23307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:30,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:30,661] {logging_mixin.py:95} INFO - [2019-08-27 20:03:30,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:30,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:30,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:03:30,798] {scheduler_job.py:146} INFO - Started process (PID=23308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:35,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:35,806] {logging_mixin.py:95} INFO - [2019-08-27 20:03:35,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:35,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:35,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:03:35,949] {scheduler_job.py:146} INFO - Started process (PID=23309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:40,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:40,957] {logging_mixin.py:95} INFO - [2019-08-27 20:03:40,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:40,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:41,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:03:41,098] {scheduler_job.py:146} INFO - Started process (PID=23312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:46,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:46,109] {logging_mixin.py:95} INFO - [2019-08-27 20:03:46,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:46,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:46,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:03:46,242] {scheduler_job.py:146} INFO - Started process (PID=23318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:51,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:51,251] {logging_mixin.py:95} INFO - [2019-08-27 20:03:51,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:51,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:51,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 20:03:51,392] {scheduler_job.py:146} INFO - Started process (PID=23320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:56,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:03:56,404] {logging_mixin.py:95} INFO - [2019-08-27 20:03:56,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:56,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:03:56,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:03:56,540] {scheduler_job.py:146} INFO - Started process (PID=23322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:01,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:01,549] {logging_mixin.py:95} INFO - [2019-08-27 20:04:01,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:01,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:01,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:04:01,680] {scheduler_job.py:146} INFO - Started process (PID=23323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:06,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:06,689] {logging_mixin.py:95} INFO - [2019-08-27 20:04:06,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:06,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:06,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:04:06,813] {scheduler_job.py:146} INFO - Started process (PID=23324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:11,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:11,823] {logging_mixin.py:95} INFO - [2019-08-27 20:04:11,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:11,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:11,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:04:11,943] {scheduler_job.py:146} INFO - Started process (PID=23326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:16,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:16,954] {logging_mixin.py:95} INFO - [2019-08-27 20:04:16,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:16,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:17,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:04:17,081] {scheduler_job.py:146} INFO - Started process (PID=23328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:22,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:22,088] {logging_mixin.py:95} INFO - [2019-08-27 20:04:22,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:22,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:22,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.064 seconds
[2019-08-27 20:04:22,219] {scheduler_job.py:146} INFO - Started process (PID=23329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:27,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:27,228] {logging_mixin.py:95} INFO - [2019-08-27 20:04:27,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:27,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:27,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.071 seconds
[2019-08-27 20:04:27,355] {scheduler_job.py:146} INFO - Started process (PID=23331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:32,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:32,371] {logging_mixin.py:95} INFO - [2019-08-27 20:04:32,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:32,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:32,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.105 seconds
[2019-08-27 20:04:32,500] {scheduler_job.py:146} INFO - Started process (PID=23332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:37,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:37,511] {logging_mixin.py:95} INFO - [2019-08-27 20:04:37,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:37,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:37,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:04:37,634] {scheduler_job.py:146} INFO - Started process (PID=23333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:42,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:42,644] {logging_mixin.py:95} INFO - [2019-08-27 20:04:42,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:42,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:42,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:04:42,766] {scheduler_job.py:146} INFO - Started process (PID=23336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:47,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:47,773] {logging_mixin.py:95} INFO - [2019-08-27 20:04:47,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:47,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:47,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:04:47,901] {scheduler_job.py:146} INFO - Started process (PID=23338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:52,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:52,909] {logging_mixin.py:95} INFO - [2019-08-27 20:04:52,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:52,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:52,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:04:53,040] {scheduler_job.py:146} INFO - Started process (PID=23339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:58,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:04:58,046] {logging_mixin.py:95} INFO - [2019-08-27 20:04:58,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:58,057] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:04:58,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:04:58,180] {scheduler_job.py:146} INFO - Started process (PID=23341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:03,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:03,188] {logging_mixin.py:95} INFO - [2019-08-27 20:05:03,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:03,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:03,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:05:03,322] {scheduler_job.py:146} INFO - Started process (PID=23342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:08,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:08,333] {logging_mixin.py:95} INFO - [2019-08-27 20:05:08,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:08,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:08,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:05:08,457] {scheduler_job.py:146} INFO - Started process (PID=23343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:13,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:13,465] {logging_mixin.py:95} INFO - [2019-08-27 20:05:13,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:13,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:13,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:05:13,588] {scheduler_job.py:146} INFO - Started process (PID=23345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:18,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:18,601] {logging_mixin.py:95} INFO - [2019-08-27 20:05:18,600] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:18,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:18,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:05:18,722] {scheduler_job.py:146} INFO - Started process (PID=23347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:23,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:23,729] {logging_mixin.py:95} INFO - [2019-08-27 20:05:23,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:23,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:23,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:05:23,852] {scheduler_job.py:146} INFO - Started process (PID=23348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:28,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:28,861] {logging_mixin.py:95} INFO - [2019-08-27 20:05:28,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:28,872] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:28,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:05:28,983] {scheduler_job.py:146} INFO - Started process (PID=23350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:33,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:33,990] {logging_mixin.py:95} INFO - [2019-08-27 20:05:33,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:34,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:34,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:05:34,126] {scheduler_job.py:146} INFO - Started process (PID=23351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:39,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:39,137] {logging_mixin.py:95} INFO - [2019-08-27 20:05:39,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:39,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:39,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.066 seconds
[2019-08-27 20:05:39,260] {scheduler_job.py:146} INFO - Started process (PID=23352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:44,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:44,269] {logging_mixin.py:95} INFO - [2019-08-27 20:05:44,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:44,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:44,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:05:44,394] {scheduler_job.py:146} INFO - Started process (PID=23354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:49,401] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:49,403] {logging_mixin.py:95} INFO - [2019-08-27 20:05:49,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:49,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:49,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:05:49,532] {scheduler_job.py:146} INFO - Started process (PID=23356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:54,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:54,543] {logging_mixin.py:95} INFO - [2019-08-27 20:05:54,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:54,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:54,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.062 seconds
[2019-08-27 20:05:54,671] {scheduler_job.py:146} INFO - Started process (PID=23358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:59,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:05:59,679] {logging_mixin.py:95} INFO - [2019-08-27 20:05:59,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:59,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:05:59,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:05:59,809] {scheduler_job.py:146} INFO - Started process (PID=23359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:04,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:04,820] {logging_mixin.py:95} INFO - [2019-08-27 20:06:04,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:04,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:04,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:06:04,938] {scheduler_job.py:146} INFO - Started process (PID=23360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:09,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:09,944] {logging_mixin.py:95} INFO - [2019-08-27 20:06:09,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:09,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:09,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:06:10,068] {scheduler_job.py:146} INFO - Started process (PID=23362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:15,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:15,078] {logging_mixin.py:95} INFO - [2019-08-27 20:06:15,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:15,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:15,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:06:15,198] {scheduler_job.py:146} INFO - Started process (PID=23363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:20,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:20,206] {logging_mixin.py:95} INFO - [2019-08-27 20:06:20,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:20,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:20,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:06:20,330] {scheduler_job.py:146} INFO - Started process (PID=23365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:25,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:25,339] {logging_mixin.py:95} INFO - [2019-08-27 20:06:25,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:25,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:25,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:06:25,461] {scheduler_job.py:146} INFO - Started process (PID=23367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:30,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:30,470] {logging_mixin.py:95} INFO - [2019-08-27 20:06:30,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:30,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:30,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:06:30,600] {scheduler_job.py:146} INFO - Started process (PID=23368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:35,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:35,606] {logging_mixin.py:95} INFO - [2019-08-27 20:06:35,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:35,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:35,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:06:35,739] {scheduler_job.py:146} INFO - Started process (PID=23369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:40,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:40,758] {logging_mixin.py:95} INFO - [2019-08-27 20:06:40,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:40,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:40,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:06:40,872] {scheduler_job.py:146} INFO - Started process (PID=23372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:45,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:45,882] {logging_mixin.py:95} INFO - [2019-08-27 20:06:45,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:45,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:45,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:06:46,013] {scheduler_job.py:146} INFO - Started process (PID=23373) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:51,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:51,020] {logging_mixin.py:95} INFO - [2019-08-27 20:06:51,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:51,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:51,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:06:51,150] {scheduler_job.py:146} INFO - Started process (PID=23375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:56,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:06:56,157] {logging_mixin.py:95} INFO - [2019-08-27 20:06:56,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:56,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:06:56,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:06:56,290] {scheduler_job.py:146} INFO - Started process (PID=23377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:01,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:01,489] {logging_mixin.py:95} INFO - [2019-08-27 20:07:01,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:01,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:01,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.236 seconds
[2019-08-27 20:07:01,626] {scheduler_job.py:146} INFO - Started process (PID=23378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:06,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:06,637] {logging_mixin.py:95} INFO - [2019-08-27 20:07:06,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:06,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:06,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:07:06,766] {scheduler_job.py:146} INFO - Started process (PID=23379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:11,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:11,773] {logging_mixin.py:95} INFO - [2019-08-27 20:07:11,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:11,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:11,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:07:11,914] {scheduler_job.py:146} INFO - Started process (PID=23381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:16,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:16,921] {logging_mixin.py:95} INFO - [2019-08-27 20:07:16,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:16,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:16,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:07:17,051] {scheduler_job.py:146} INFO - Started process (PID=23382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:22,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:22,063] {logging_mixin.py:95} INFO - [2019-08-27 20:07:22,062] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:22,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:22,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:07:22,187] {scheduler_job.py:146} INFO - Started process (PID=23384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:27,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:27,200] {logging_mixin.py:95} INFO - [2019-08-27 20:07:27,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:27,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:27,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:07:27,317] {scheduler_job.py:146} INFO - Started process (PID=23386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:32,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:32,324] {logging_mixin.py:95} INFO - [2019-08-27 20:07:32,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:32,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:32,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:07:32,446] {scheduler_job.py:146} INFO - Started process (PID=23387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:37,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:37,454] {logging_mixin.py:95} INFO - [2019-08-27 20:07:37,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:37,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:37,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:07:37,594] {scheduler_job.py:146} INFO - Started process (PID=23388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:42,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:42,603] {logging_mixin.py:95} INFO - [2019-08-27 20:07:42,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:42,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:42,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 20:07:42,731] {scheduler_job.py:146} INFO - Started process (PID=23390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:47,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:47,736] {logging_mixin.py:95} INFO - [2019-08-27 20:07:47,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:47,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:47,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:07:47,866] {scheduler_job.py:146} INFO - Started process (PID=23391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:52,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:52,873] {logging_mixin.py:95} INFO - [2019-08-27 20:07:52,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:52,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:52,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:07:53,004] {scheduler_job.py:146} INFO - Started process (PID=23393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:58,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:07:58,010] {logging_mixin.py:95} INFO - [2019-08-27 20:07:58,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:58,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:07:58,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:07:58,139] {scheduler_job.py:146} INFO - Started process (PID=23395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:03,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:03,144] {logging_mixin.py:95} INFO - [2019-08-27 20:08:03,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:03,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:03,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:08:03,274] {scheduler_job.py:146} INFO - Started process (PID=23396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:08,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:08,284] {logging_mixin.py:95} INFO - [2019-08-27 20:08:08,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:08,296] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:08,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:08:08,407] {scheduler_job.py:146} INFO - Started process (PID=23397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:13,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:13,417] {logging_mixin.py:95} INFO - [2019-08-27 20:08:13,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:13,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:13,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:08:13,544] {scheduler_job.py:146} INFO - Started process (PID=23399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:18,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:18,553] {logging_mixin.py:95} INFO - [2019-08-27 20:08:18,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:18,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:18,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:08:18,680] {scheduler_job.py:146} INFO - Started process (PID=23400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:23,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:23,692] {logging_mixin.py:95} INFO - [2019-08-27 20:08:23,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:23,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:23,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:08:23,830] {scheduler_job.py:146} INFO - Started process (PID=23401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:28,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:28,844] {logging_mixin.py:95} INFO - [2019-08-27 20:08:28,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:28,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:28,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:08:28,980] {scheduler_job.py:146} INFO - Started process (PID=23404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:33,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:33,988] {logging_mixin.py:95} INFO - [2019-08-27 20:08:33,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:33,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:34,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:08:34,137] {scheduler_job.py:146} INFO - Started process (PID=23405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:39,144] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:39,145] {logging_mixin.py:95} INFO - [2019-08-27 20:08:39,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:39,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:39,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:08:39,288] {scheduler_job.py:146} INFO - Started process (PID=23407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:44,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:44,299] {logging_mixin.py:95} INFO - [2019-08-27 20:08:44,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:44,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:44,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:08:44,441] {scheduler_job.py:146} INFO - Started process (PID=23410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:49,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:49,449] {logging_mixin.py:95} INFO - [2019-08-27 20:08:49,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:49,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:49,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:08:49,593] {scheduler_job.py:146} INFO - Started process (PID=23411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:54,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:54,603] {logging_mixin.py:95} INFO - [2019-08-27 20:08:54,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:54,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:54,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:08:54,739] {scheduler_job.py:146} INFO - Started process (PID=23413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:59,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:08:59,757] {logging_mixin.py:95} INFO - [2019-08-27 20:08:59,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:59,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:08:59,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:08:59,885] {scheduler_job.py:146} INFO - Started process (PID=23415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:04,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:04,893] {logging_mixin.py:95} INFO - [2019-08-27 20:09:04,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:04,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:04,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:09:05,042] {scheduler_job.py:146} INFO - Started process (PID=23416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:10,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:10,049] {logging_mixin.py:95} INFO - [2019-08-27 20:09:10,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:10,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:10,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:09:10,197] {scheduler_job.py:146} INFO - Started process (PID=23418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:15,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:15,203] {logging_mixin.py:95} INFO - [2019-08-27 20:09:15,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:15,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:15,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:09:15,342] {scheduler_job.py:146} INFO - Started process (PID=23419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:20,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:20,351] {logging_mixin.py:95} INFO - [2019-08-27 20:09:20,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:20,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:20,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:09:20,496] {scheduler_job.py:146} INFO - Started process (PID=23420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:25,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:25,504] {logging_mixin.py:95} INFO - [2019-08-27 20:09:25,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:25,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:25,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:09:25,645] {scheduler_job.py:146} INFO - Started process (PID=23422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:30,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:30,653] {logging_mixin.py:95} INFO - [2019-08-27 20:09:30,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:30,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:30,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:09:30,795] {scheduler_job.py:146} INFO - Started process (PID=23424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:35,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:35,803] {logging_mixin.py:95} INFO - [2019-08-27 20:09:35,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:35,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:35,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:09:35,938] {scheduler_job.py:146} INFO - Started process (PID=23425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:40,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:40,948] {logging_mixin.py:95} INFO - [2019-08-27 20:09:40,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:40,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:40,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:09:41,084] {scheduler_job.py:146} INFO - Started process (PID=23428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:46,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:46,096] {logging_mixin.py:95} INFO - [2019-08-27 20:09:46,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:46,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:46,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:09:46,227] {scheduler_job.py:146} INFO - Started process (PID=23429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:51,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:51,237] {logging_mixin.py:95} INFO - [2019-08-27 20:09:51,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:51,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:51,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:09:51,378] {scheduler_job.py:146} INFO - Started process (PID=23430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:56,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:09:56,386] {logging_mixin.py:95} INFO - [2019-08-27 20:09:56,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:56,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:09:56,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:09:56,530] {scheduler_job.py:146} INFO - Started process (PID=23432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:01,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:01,550] {logging_mixin.py:95} INFO - [2019-08-27 20:10:01,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:01,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:01,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:10:01,685] {scheduler_job.py:146} INFO - Started process (PID=23434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:06,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:06,696] {logging_mixin.py:95} INFO - [2019-08-27 20:10:06,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:06,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:06,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:10:06,842] {scheduler_job.py:146} INFO - Started process (PID=23435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:11,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:11,850] {logging_mixin.py:95} INFO - [2019-08-27 20:10:11,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:11,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:11,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:10:12,002] {scheduler_job.py:146} INFO - Started process (PID=23437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:17,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:17,009] {logging_mixin.py:95} INFO - [2019-08-27 20:10:17,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:17,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:17,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:10:17,153] {scheduler_job.py:146} INFO - Started process (PID=23438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:22,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:22,162] {logging_mixin.py:95} INFO - [2019-08-27 20:10:22,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:22,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:22,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:10:22,308] {scheduler_job.py:146} INFO - Started process (PID=23439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:27,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:27,317] {logging_mixin.py:95} INFO - [2019-08-27 20:10:27,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:27,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:27,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:10:27,463] {scheduler_job.py:146} INFO - Started process (PID=23441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:32,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:32,474] {logging_mixin.py:95} INFO - [2019-08-27 20:10:32,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:32,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:32,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:10:32,621] {scheduler_job.py:146} INFO - Started process (PID=23443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:37,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:37,627] {logging_mixin.py:95} INFO - [2019-08-27 20:10:37,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:37,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:37,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:10:37,765] {scheduler_job.py:146} INFO - Started process (PID=23444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:42,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:42,771] {logging_mixin.py:95} INFO - [2019-08-27 20:10:42,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:42,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:42,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:10:42,916] {scheduler_job.py:146} INFO - Started process (PID=23446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:47,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:47,924] {logging_mixin.py:95} INFO - [2019-08-27 20:10:47,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:47,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:47,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:10:48,079] {scheduler_job.py:146} INFO - Started process (PID=23447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:53,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:53,087] {logging_mixin.py:95} INFO - [2019-08-27 20:10:53,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:53,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:53,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:10:53,232] {scheduler_job.py:146} INFO - Started process (PID=23448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:58,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:10:58,241] {logging_mixin.py:95} INFO - [2019-08-27 20:10:58,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:58,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:10:58,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:10:58,389] {scheduler_job.py:146} INFO - Started process (PID=23450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:03,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:03,403] {logging_mixin.py:95} INFO - [2019-08-27 20:11:03,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:03,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:03,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:11:03,544] {scheduler_job.py:146} INFO - Started process (PID=23452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:08,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:08,556] {logging_mixin.py:95} INFO - [2019-08-27 20:11:08,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:08,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:08,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:11:08,694] {scheduler_job.py:146} INFO - Started process (PID=23453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:13,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:13,703] {logging_mixin.py:95} INFO - [2019-08-27 20:11:13,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:13,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:13,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:11:13,864] {scheduler_job.py:146} INFO - Started process (PID=23455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:18,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:18,872] {logging_mixin.py:95} INFO - [2019-08-27 20:11:18,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:18,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:18,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:11:19,021] {scheduler_job.py:146} INFO - Started process (PID=23456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:24,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:24,028] {logging_mixin.py:95} INFO - [2019-08-27 20:11:24,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:24,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:24,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:11:24,175] {scheduler_job.py:146} INFO - Started process (PID=23457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:29,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:29,183] {logging_mixin.py:95} INFO - [2019-08-27 20:11:29,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:29,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:29,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:11:29,329] {scheduler_job.py:146} INFO - Started process (PID=23459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:34,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:34,341] {logging_mixin.py:95} INFO - [2019-08-27 20:11:34,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:34,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:34,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:11:34,468] {scheduler_job.py:146} INFO - Started process (PID=23464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:39,474] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:39,475] {logging_mixin.py:95} INFO - [2019-08-27 20:11:39,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:39,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:39,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 20:11:39,604] {scheduler_job.py:146} INFO - Started process (PID=23466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:44,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:44,613] {logging_mixin.py:95} INFO - [2019-08-27 20:11:44,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:44,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:44,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:11:44,750] {scheduler_job.py:146} INFO - Started process (PID=23468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:49,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:49,757] {logging_mixin.py:95} INFO - [2019-08-27 20:11:49,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:49,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:49,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 20:11:49,889] {scheduler_job.py:146} INFO - Started process (PID=23470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:54,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:11:54,897] {logging_mixin.py:95} INFO - [2019-08-27 20:11:54,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:54,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:11:54,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:11:55,037] {scheduler_job.py:146} INFO - Started process (PID=23472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:00,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:00,047] {logging_mixin.py:95} INFO - [2019-08-27 20:12:00,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:00,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:00,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:12:00,189] {scheduler_job.py:146} INFO - Started process (PID=23473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:05,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:05,202] {logging_mixin.py:95} INFO - [2019-08-27 20:12:05,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:05,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:05,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:12:05,336] {scheduler_job.py:146} INFO - Started process (PID=23475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:10,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:10,348] {logging_mixin.py:95} INFO - [2019-08-27 20:12:10,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:10,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:10,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:12:10,482] {scheduler_job.py:146} INFO - Started process (PID=23477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:15,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:15,491] {logging_mixin.py:95} INFO - [2019-08-27 20:12:15,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:15,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:15,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 20:12:15,628] {scheduler_job.py:146} INFO - Started process (PID=23478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:20,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:20,641] {logging_mixin.py:95} INFO - [2019-08-27 20:12:20,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:20,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:20,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:12:20,770] {scheduler_job.py:146} INFO - Started process (PID=23479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:25,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:25,779] {logging_mixin.py:95} INFO - [2019-08-27 20:12:25,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:25,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:25,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:12:25,910] {scheduler_job.py:146} INFO - Started process (PID=23481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:30,918] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:30,923] {logging_mixin.py:95} INFO - [2019-08-27 20:12:30,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:30,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:30,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:12:31,055] {scheduler_job.py:146} INFO - Started process (PID=23482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:36,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:36,061] {logging_mixin.py:95} INFO - [2019-08-27 20:12:36,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:36,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:36,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.038 seconds
[2019-08-27 20:12:36,193] {scheduler_job.py:146} INFO - Started process (PID=23484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:41,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:41,207] {logging_mixin.py:95} INFO - [2019-08-27 20:12:41,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:41,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:41,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:12:41,347] {scheduler_job.py:146} INFO - Started process (PID=23486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:46,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:46,358] {logging_mixin.py:95} INFO - [2019-08-27 20:12:46,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:46,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:46,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:12:46,512] {scheduler_job.py:146} INFO - Started process (PID=23487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:51,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:51,524] {logging_mixin.py:95} INFO - [2019-08-27 20:12:51,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:51,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:51,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.063 seconds
[2019-08-27 20:12:51,662] {scheduler_job.py:146} INFO - Started process (PID=23488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:56,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:12:56,669] {logging_mixin.py:95} INFO - [2019-08-27 20:12:56,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:56,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:12:56,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.038 seconds
[2019-08-27 20:12:56,802] {scheduler_job.py:146} INFO - Started process (PID=23491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:01,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:01,810] {logging_mixin.py:95} INFO - [2019-08-27 20:13:01,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:01,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:01,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:13:01,949] {scheduler_job.py:146} INFO - Started process (PID=23498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:06,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:06,959] {logging_mixin.py:95} INFO - [2019-08-27 20:13:06,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:06,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:06,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 20:13:07,094] {scheduler_job.py:146} INFO - Started process (PID=23500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:12,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:12,103] {logging_mixin.py:95} INFO - [2019-08-27 20:13:12,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:12,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:12,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 20:13:12,253] {scheduler_job.py:146} INFO - Started process (PID=23502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:17,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:17,265] {logging_mixin.py:95} INFO - [2019-08-27 20:13:17,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:17,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:17,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:13:17,406] {scheduler_job.py:146} INFO - Started process (PID=23503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:22,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:22,414] {logging_mixin.py:95} INFO - [2019-08-27 20:13:22,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:22,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:22,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:13:22,557] {scheduler_job.py:146} INFO - Started process (PID=23504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:27,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:27,567] {logging_mixin.py:95} INFO - [2019-08-27 20:13:27,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:27,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:27,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:13:27,710] {scheduler_job.py:146} INFO - Started process (PID=23506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:32,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:32,734] {logging_mixin.py:95} INFO - [2019-08-27 20:13:32,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:32,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:32,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.061 seconds
[2019-08-27 20:13:32,865] {scheduler_job.py:146} INFO - Started process (PID=23507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:37,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:37,876] {logging_mixin.py:95} INFO - [2019-08-27 20:13:37,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:37,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:37,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:13:38,023] {scheduler_job.py:146} INFO - Started process (PID=23508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:43,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:43,033] {logging_mixin.py:95} INFO - [2019-08-27 20:13:43,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:43,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:43,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:13:43,175] {scheduler_job.py:146} INFO - Started process (PID=23511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:48,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:48,187] {logging_mixin.py:95} INFO - [2019-08-27 20:13:48,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:48,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:48,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:13:48,331] {scheduler_job.py:146} INFO - Started process (PID=23512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:53,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:53,342] {logging_mixin.py:95} INFO - [2019-08-27 20:13:53,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:53,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:53,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:13:53,480] {scheduler_job.py:146} INFO - Started process (PID=23513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:58,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:13:58,491] {logging_mixin.py:95} INFO - [2019-08-27 20:13:58,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:58,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:13:58,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:13:58,627] {scheduler_job.py:146} INFO - Started process (PID=23515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:03,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:03,637] {logging_mixin.py:95} INFO - [2019-08-27 20:14:03,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:03,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:03,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:14:03,778] {scheduler_job.py:146} INFO - Started process (PID=23516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:08,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:08,787] {logging_mixin.py:95} INFO - [2019-08-27 20:14:08,786] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:08,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:08,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:14:08,934] {scheduler_job.py:146} INFO - Started process (PID=23517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:13,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:13,944] {logging_mixin.py:95} INFO - [2019-08-27 20:14:13,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:13,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:13,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:14:14,081] {scheduler_job.py:146} INFO - Started process (PID=23520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:19,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:19,091] {logging_mixin.py:95} INFO - [2019-08-27 20:14:19,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:19,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:19,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:14:19,237] {scheduler_job.py:146} INFO - Started process (PID=23521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:24,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:24,248] {logging_mixin.py:95} INFO - [2019-08-27 20:14:24,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:24,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:24,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:14:24,391] {scheduler_job.py:146} INFO - Started process (PID=23522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:29,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:29,399] {logging_mixin.py:95} INFO - [2019-08-27 20:14:29,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:29,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:29,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:14:29,542] {scheduler_job.py:146} INFO - Started process (PID=23524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:34,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:34,553] {logging_mixin.py:95} INFO - [2019-08-27 20:14:34,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:34,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:34,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:14:34,699] {scheduler_job.py:146} INFO - Started process (PID=23525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:39,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:39,706] {logging_mixin.py:95} INFO - [2019-08-27 20:14:39,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:39,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:39,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:14:39,843] {scheduler_job.py:146} INFO - Started process (PID=23526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:44,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:44,860] {logging_mixin.py:95} INFO - [2019-08-27 20:14:44,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:44,870] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:44,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:14:44,992] {scheduler_job.py:146} INFO - Started process (PID=23531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:50,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:50,002] {logging_mixin.py:95} INFO - [2019-08-27 20:14:50,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:50,012] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:50,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:14:50,070] {scheduler_job.py:146} INFO - Started process (PID=23532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:55,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:14:55,079] {logging_mixin.py:95} INFO - [2019-08-27 20:14:55,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:55,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:14:55,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:14:55,221] {scheduler_job.py:146} INFO - Started process (PID=23534) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:00,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:00,232] {logging_mixin.py:95} INFO - [2019-08-27 20:15:00,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:00,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:00,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:15:00,380] {scheduler_job.py:146} INFO - Started process (PID=23535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:05,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:05,390] {logging_mixin.py:95} INFO - [2019-08-27 20:15:05,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:05,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:05,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:15:05,536] {scheduler_job.py:146} INFO - Started process (PID=23536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:10,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:10,545] {logging_mixin.py:95} INFO - [2019-08-27 20:15:10,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:10,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:10,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:15:10,688] {scheduler_job.py:146} INFO - Started process (PID=23538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:15,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:15,704] {logging_mixin.py:95} INFO - [2019-08-27 20:15:15,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:15,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:15,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:15:15,839] {scheduler_job.py:146} INFO - Started process (PID=23540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:20,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:20,848] {logging_mixin.py:95} INFO - [2019-08-27 20:15:20,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:20,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:20,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:15:21,002] {scheduler_job.py:146} INFO - Started process (PID=23541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:26,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:26,010] {logging_mixin.py:95} INFO - [2019-08-27 20:15:26,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:26,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:26,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:15:26,165] {scheduler_job.py:146} INFO - Started process (PID=23543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:31,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:31,176] {logging_mixin.py:95} INFO - [2019-08-27 20:15:31,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:31,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:31,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:15:31,324] {scheduler_job.py:146} INFO - Started process (PID=23544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:36,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:36,333] {logging_mixin.py:95} INFO - [2019-08-27 20:15:36,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:36,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:36,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:15:36,478] {scheduler_job.py:146} INFO - Started process (PID=23545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:41,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:41,496] {logging_mixin.py:95} INFO - [2019-08-27 20:15:41,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:41,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:41,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:15:41,639] {scheduler_job.py:146} INFO - Started process (PID=23549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:46,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:46,654] {logging_mixin.py:95} INFO - [2019-08-27 20:15:46,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:46,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:46,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:15:46,791] {scheduler_job.py:146} INFO - Started process (PID=23551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:51,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:51,800] {logging_mixin.py:95} INFO - [2019-08-27 20:15:51,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:51,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:51,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:15:51,959] {scheduler_job.py:146} INFO - Started process (PID=23552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:56,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:15:56,972] {logging_mixin.py:95} INFO - [2019-08-27 20:15:56,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:56,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:15:57,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:15:57,123] {scheduler_job.py:146} INFO - Started process (PID=23554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:02,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:02,132] {logging_mixin.py:95} INFO - [2019-08-27 20:16:02,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:02,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:02,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:16:02,286] {scheduler_job.py:146} INFO - Started process (PID=23555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:07,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:07,297] {logging_mixin.py:95} INFO - [2019-08-27 20:16:07,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:07,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:07,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:16:07,449] {scheduler_job.py:146} INFO - Started process (PID=23556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:12,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:12,462] {logging_mixin.py:95} INFO - [2019-08-27 20:16:12,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:12,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:12,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:16:12,607] {scheduler_job.py:146} INFO - Started process (PID=23558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:17,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:17,621] {logging_mixin.py:95} INFO - [2019-08-27 20:16:17,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:17,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:17,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:16:17,764] {scheduler_job.py:146} INFO - Started process (PID=23560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:22,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:22,774] {logging_mixin.py:95} INFO - [2019-08-27 20:16:22,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:22,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:22,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:16:22,928] {scheduler_job.py:146} INFO - Started process (PID=23561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:27,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:27,940] {logging_mixin.py:95} INFO - [2019-08-27 20:16:27,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:27,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:27,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:16:28,089] {scheduler_job.py:146} INFO - Started process (PID=23563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:33,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:33,097] {logging_mixin.py:95} INFO - [2019-08-27 20:16:33,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:33,107] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:33,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:16:33,244] {scheduler_job.py:146} INFO - Started process (PID=23564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:38,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:38,252] {logging_mixin.py:95} INFO - [2019-08-27 20:16:38,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:38,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:38,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:16:38,403] {scheduler_job.py:146} INFO - Started process (PID=23565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:43,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:43,412] {logging_mixin.py:95} INFO - [2019-08-27 20:16:43,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:43,422] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:43,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:16:43,557] {scheduler_job.py:146} INFO - Started process (PID=23567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:48,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:48,566] {logging_mixin.py:95} INFO - [2019-08-27 20:16:48,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:48,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:48,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.042 seconds
[2019-08-27 20:16:48,716] {scheduler_job.py:146} INFO - Started process (PID=23569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:53,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:53,727] {logging_mixin.py:95} INFO - [2019-08-27 20:16:53,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:53,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:53,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:16:53,877] {scheduler_job.py:146} INFO - Started process (PID=23570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:58,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:16:58,889] {logging_mixin.py:95} INFO - [2019-08-27 20:16:58,888] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:58,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:16:58,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:16:59,037] {scheduler_job.py:146} INFO - Started process (PID=23572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:04,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:04,046] {logging_mixin.py:95} INFO - [2019-08-27 20:17:04,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:04,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:04,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:17:04,196] {scheduler_job.py:146} INFO - Started process (PID=23573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:09,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:09,210] {logging_mixin.py:95} INFO - [2019-08-27 20:17:09,209] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:09,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:09,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:17:09,357] {scheduler_job.py:146} INFO - Started process (PID=23574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:14,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:14,367] {logging_mixin.py:95} INFO - [2019-08-27 20:17:14,367] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:14,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:14,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:17:14,514] {scheduler_job.py:146} INFO - Started process (PID=23576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:19,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:19,527] {logging_mixin.py:95} INFO - [2019-08-27 20:17:19,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:19,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:19,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:17:19,690] {scheduler_job.py:146} INFO - Started process (PID=23578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:24,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:24,702] {logging_mixin.py:95} INFO - [2019-08-27 20:17:24,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:24,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:24,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:17:24,853] {scheduler_job.py:146} INFO - Started process (PID=23579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:29,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:29,862] {logging_mixin.py:95} INFO - [2019-08-27 20:17:29,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:29,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:29,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:17:30,018] {scheduler_job.py:146} INFO - Started process (PID=23581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:35,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:35,029] {logging_mixin.py:95} INFO - [2019-08-27 20:17:35,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:35,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:35,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:17:35,174] {scheduler_job.py:146} INFO - Started process (PID=23582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:40,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:40,179] {logging_mixin.py:95} INFO - [2019-08-27 20:17:40,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:40,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:40,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:17:40,333] {scheduler_job.py:146} INFO - Started process (PID=23589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:45,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:45,342] {logging_mixin.py:95} INFO - [2019-08-27 20:17:45,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:45,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:45,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:17:45,490] {scheduler_job.py:146} INFO - Started process (PID=23590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:50,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:50,497] {logging_mixin.py:95} INFO - [2019-08-27 20:17:50,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:50,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:50,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:17:50,648] {scheduler_job.py:146} INFO - Started process (PID=23592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:55,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:17:55,657] {logging_mixin.py:95} INFO - [2019-08-27 20:17:55,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:55,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:17:55,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:17:55,813] {scheduler_job.py:146} INFO - Started process (PID=23594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:00,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:00,828] {logging_mixin.py:95} INFO - [2019-08-27 20:18:00,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:00,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:00,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:18:00,970] {scheduler_job.py:146} INFO - Started process (PID=23595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:05,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:05,978] {logging_mixin.py:95} INFO - [2019-08-27 20:18:05,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:05,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:06,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:18:06,130] {scheduler_job.py:146} INFO - Started process (PID=23596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:11,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:11,142] {logging_mixin.py:95} INFO - [2019-08-27 20:18:11,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:11,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:11,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:18:11,293] {scheduler_job.py:146} INFO - Started process (PID=23598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:16,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:16,304] {logging_mixin.py:95} INFO - [2019-08-27 20:18:16,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:16,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:16,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:18:16,454] {scheduler_job.py:146} INFO - Started process (PID=23599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:21,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:21,462] {logging_mixin.py:95} INFO - [2019-08-27 20:18:21,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:21,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:21,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 20:18:21,615] {scheduler_job.py:146} INFO - Started process (PID=23601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:26,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:26,626] {logging_mixin.py:95} INFO - [2019-08-27 20:18:26,626] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:26,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:26,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:18:26,776] {scheduler_job.py:146} INFO - Started process (PID=23603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:31,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:31,785] {logging_mixin.py:95} INFO - [2019-08-27 20:18:31,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:31,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:31,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:18:31,937] {scheduler_job.py:146} INFO - Started process (PID=23604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:36,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:36,945] {logging_mixin.py:95} INFO - [2019-08-27 20:18:36,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:36,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:36,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:18:37,092] {scheduler_job.py:146} INFO - Started process (PID=23605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:42,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:42,099] {logging_mixin.py:95} INFO - [2019-08-27 20:18:42,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:42,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:42,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:18:42,245] {scheduler_job.py:146} INFO - Started process (PID=23609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:47,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:47,253] {logging_mixin.py:95} INFO - [2019-08-27 20:18:47,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:47,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:47,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:18:47,406] {scheduler_job.py:146} INFO - Started process (PID=23610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:52,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:52,412] {logging_mixin.py:95} INFO - [2019-08-27 20:18:52,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:52,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:52,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.044 seconds
[2019-08-27 20:18:52,565] {scheduler_job.py:146} INFO - Started process (PID=23612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:57,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:18:57,583] {logging_mixin.py:95} INFO - [2019-08-27 20:18:57,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:57,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:18:57,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:18:57,726] {scheduler_job.py:146} INFO - Started process (PID=23614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:02,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:02,737] {logging_mixin.py:95} INFO - [2019-08-27 20:19:02,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:02,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:02,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:19:02,883] {scheduler_job.py:146} INFO - Started process (PID=23615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:07,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:07,894] {logging_mixin.py:95} INFO - [2019-08-27 20:19:07,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:07,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:07,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:19:08,036] {scheduler_job.py:146} INFO - Started process (PID=23616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:13,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:13,044] {logging_mixin.py:95} INFO - [2019-08-27 20:19:13,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:13,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:13,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:19:13,195] {scheduler_job.py:146} INFO - Started process (PID=23618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:18,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:18,204] {logging_mixin.py:95} INFO - [2019-08-27 20:19:18,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:18,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:18,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:19:18,354] {scheduler_job.py:146} INFO - Started process (PID=23619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:23,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:23,367] {logging_mixin.py:95} INFO - [2019-08-27 20:19:23,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:23,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:23,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:19:23,428] {scheduler_job.py:146} INFO - Started process (PID=23620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:28,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:28,435] {logging_mixin.py:95} INFO - [2019-08-27 20:19:28,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:28,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:28,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:19:28,512] {scheduler_job.py:146} INFO - Started process (PID=23623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:33,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:33,529] {logging_mixin.py:95} INFO - [2019-08-27 20:19:33,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:33,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:33,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.060 seconds
[2019-08-27 20:19:33,605] {scheduler_job.py:146} INFO - Started process (PID=23624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:38,613] {logging_mixin.py:95} INFO - [2019-08-27 20:19:38,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:19:38,690] {scheduler_job.py:146} INFO - Started process (PID=23625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:38,695] {logging_mixin.py:95} INFO - [2019-08-27 20:19:38,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.038 seconds
[2019-08-27 20:19:38,799] {scheduler_job.py:146} INFO - Started process (PID=23626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:38,804] {logging_mixin.py:95} INFO - [2019-08-27 20:19:38,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,841] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:38,906] {scheduler_job.py:146} INFO - Started process (PID=23627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:38,911] {logging_mixin.py:95} INFO - [2019-08-27 20:19:38,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:38,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:39,013] {scheduler_job.py:146} INFO - Started process (PID=23628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,018] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:39,119] {scheduler_job.py:146} INFO - Started process (PID=23629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,124] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.050 seconds
[2019-08-27 20:19:39,223] {scheduler_job.py:146} INFO - Started process (PID=23630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,228] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:39,331] {scheduler_job.py:146} INFO - Started process (PID=23631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,337] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,337] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.050 seconds
[2019-08-27 20:19:39,441] {scheduler_job.py:146} INFO - Started process (PID=23633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,448] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.047 seconds
[2019-08-27 20:19:39,542] {scheduler_job.py:146} INFO - Started process (PID=23634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,547] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.039 seconds
[2019-08-27 20:19:39,647] {scheduler_job.py:146} INFO - Started process (PID=23635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,651] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.039 seconds
[2019-08-27 20:19:39,751] {scheduler_job.py:146} INFO - Started process (PID=23636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,756] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.040 seconds
[2019-08-27 20:19:39,857] {scheduler_job.py:146} INFO - Started process (PID=23637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,862] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,872] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:39,962] {scheduler_job.py:146} INFO - Started process (PID=23638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:39,968] {logging_mixin.py:95} INFO - [2019-08-27 20:19:39,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:39,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:40,067] {scheduler_job.py:146} INFO - Started process (PID=23639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,072] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.037 seconds
[2019-08-27 20:19:40,171] {scheduler_job.py:146} INFO - Started process (PID=23640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,176] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.039 seconds
[2019-08-27 20:19:40,282] {scheduler_job.py:146} INFO - Started process (PID=23641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,290] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.053 seconds
[2019-08-27 20:19:40,384] {scheduler_job.py:146} INFO - Started process (PID=23643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,389] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:40,489] {scheduler_job.py:146} INFO - Started process (PID=23644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,494] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:40,598] {scheduler_job.py:146} INFO - Started process (PID=23645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,604] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:40,701] {scheduler_job.py:146} INFO - Started process (PID=23646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,706] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,706] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:40,808] {scheduler_job.py:146} INFO - Started process (PID=23647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,814] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,851] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:40,913] {scheduler_job.py:146} INFO - Started process (PID=23648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:40,918] {logging_mixin.py:95} INFO - [2019-08-27 20:19:40,918] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:40,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:41,020] {scheduler_job.py:146} INFO - Started process (PID=23649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,025] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:41,124] {scheduler_job.py:146} INFO - Started process (PID=23650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,137] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.047 seconds
[2019-08-27 20:19:41,231] {scheduler_job.py:146} INFO - Started process (PID=23651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,236] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.065 seconds
[2019-08-27 20:19:41,338] {scheduler_job.py:146} INFO - Started process (PID=23652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,343] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.046 seconds
[2019-08-27 20:19:41,444] {scheduler_job.py:146} INFO - Started process (PID=23653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,449] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:41,551] {scheduler_job.py:146} INFO - Started process (PID=23654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,556] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.044 seconds
[2019-08-27 20:19:41,656] {scheduler_job.py:146} INFO - Started process (PID=23655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,662] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.040 seconds
[2019-08-27 20:19:41,762] {scheduler_job.py:146} INFO - Started process (PID=23656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,766] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,767] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:41,869] {scheduler_job.py:146} INFO - Started process (PID=23657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,874] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:41,975] {scheduler_job.py:146} INFO - Started process (PID=23658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,979] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:41,980] {logging_mixin.py:95} INFO - [2019-08-27 20:19:41,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:41,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:42,081] {scheduler_job.py:146} INFO - Started process (PID=23659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,087] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:42,189] {scheduler_job.py:146} INFO - Started process (PID=23660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,194] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:42,295] {scheduler_job.py:146} INFO - Started process (PID=23661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,301] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:42,401] {scheduler_job.py:146} INFO - Started process (PID=23662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,406] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.044 seconds
[2019-08-27 20:19:42,506] {scheduler_job.py:146} INFO - Started process (PID=23663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,511] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:42,612] {scheduler_job.py:146} INFO - Started process (PID=23664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,617] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:42,723] {scheduler_job.py:146} INFO - Started process (PID=23665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,729] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:42,857] {scheduler_job.py:146} INFO - Started process (PID=23666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:42,872] {logging_mixin.py:95} INFO - [2019-08-27 20:19:42,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:42,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.151 seconds
[2019-08-27 20:19:43,039] {scheduler_job.py:146} INFO - Started process (PID=23667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,044] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:43,143] {scheduler_job.py:146} INFO - Started process (PID=23668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,148] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.036 seconds
[2019-08-27 20:19:43,247] {scheduler_job.py:146} INFO - Started process (PID=23669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,252] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.037 seconds
[2019-08-27 20:19:43,352] {scheduler_job.py:146} INFO - Started process (PID=23670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,358] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.038 seconds
[2019-08-27 20:19:43,458] {scheduler_job.py:146} INFO - Started process (PID=23671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,463] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.036 seconds
[2019-08-27 20:19:43,563] {scheduler_job.py:146} INFO - Started process (PID=23672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,567] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:43,667] {scheduler_job.py:146} INFO - Started process (PID=23673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,672] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:43,772] {scheduler_job.py:146} INFO - Started process (PID=23674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,777] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:43,877] {scheduler_job.py:146} INFO - Started process (PID=23675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,882] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:43,982] {scheduler_job.py:146} INFO - Started process (PID=23676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:43,987] {logging_mixin.py:95} INFO - [2019-08-27 20:19:43,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:43,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.034 seconds
[2019-08-27 20:19:44,087] {scheduler_job.py:146} INFO - Started process (PID=23677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,092] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:44,194] {scheduler_job.py:146} INFO - Started process (PID=23678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,199] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.047 seconds
[2019-08-27 20:19:44,299] {scheduler_job.py:146} INFO - Started process (PID=23679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,304] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.039 seconds
[2019-08-27 20:19:44,404] {scheduler_job.py:146} INFO - Started process (PID=23680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,410] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:44,511] {scheduler_job.py:146} INFO - Started process (PID=23681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,516] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,516] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.040 seconds
[2019-08-27 20:19:44,619] {scheduler_job.py:146} INFO - Started process (PID=23682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,624] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:44,725] {scheduler_job.py:146} INFO - Started process (PID=23683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,730] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,768] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.043 seconds
[2019-08-27 20:19:44,831] {scheduler_job.py:146} INFO - Started process (PID=23684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,836] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.045 seconds
[2019-08-27 20:19:44,938] {scheduler_job.py:146} INFO - Started process (PID=23685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:44,943] {logging_mixin.py:95} INFO - [2019-08-27 20:19:44,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:44,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.044 seconds
[2019-08-27 20:19:45,045] {scheduler_job.py:146} INFO - Started process (PID=23686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:45,050] {logging_mixin.py:95} INFO - [2019-08-27 20:19:45,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.042 seconds
[2019-08-27 20:19:45,149] {scheduler_job.py:146} INFO - Started process (PID=23687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:45,155] {logging_mixin.py:95} INFO - [2019-08-27 20:19:45,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:45,256] {scheduler_job.py:146} INFO - Started process (PID=23688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:45,262] {logging_mixin.py:95} INFO - [2019-08-27 20:19:45,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:45,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:54,019] {scheduler_job.py:146} INFO - Started process (PID=23689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,024] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.127 seconds
[2019-08-27 20:19:54,226] {scheduler_job.py:146} INFO - Started process (PID=23690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,231] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.039 seconds
[2019-08-27 20:19:54,329] {scheduler_job.py:146} INFO - Started process (PID=23691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,334] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.034 seconds
[2019-08-27 20:19:54,431] {scheduler_job.py:146} INFO - Started process (PID=23692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,436] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.036 seconds
[2019-08-27 20:19:54,535] {scheduler_job.py:146} INFO - Started process (PID=23693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,540] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.035 seconds
[2019-08-27 20:19:54,643] {scheduler_job.py:146} INFO - Started process (PID=23694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:19:54,648] {logging_mixin.py:95} INFO - [2019-08-27 20:19:54,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:19:54,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.041 seconds
[2019-08-27 20:19:54,749] {scheduler_job.py:146} INFO - Started process (PID=23695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:00,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:00,301] {logging_mixin.py:95} INFO - [2019-08-27 20:20:00,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:00,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:00,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.591 seconds
[2019-08-27 20:20:00,461] {scheduler_job.py:146} INFO - Started process (PID=23698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:05,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:05,471] {logging_mixin.py:95} INFO - [2019-08-27 20:20:05,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:05,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:05,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:20:05,620] {scheduler_job.py:146} INFO - Started process (PID=23705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:10,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:10,632] {logging_mixin.py:95} INFO - [2019-08-27 20:20:10,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:10,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:10,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:20:10,780] {scheduler_job.py:146} INFO - Started process (PID=23708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:15,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:15,788] {logging_mixin.py:95} INFO - [2019-08-27 20:20:15,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:15,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:15,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:20:15,941] {scheduler_job.py:146} INFO - Started process (PID=23709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:20,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:20,952] {logging_mixin.py:95} INFO - [2019-08-27 20:20:20,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:20,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:20,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:20:21,093] {scheduler_job.py:146} INFO - Started process (PID=23711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:26,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:26,100] {logging_mixin.py:95} INFO - [2019-08-27 20:20:26,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:26,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:26,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:20:26,239] {scheduler_job.py:146} INFO - Started process (PID=23712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:31,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:31,246] {logging_mixin.py:95} INFO - [2019-08-27 20:20:31,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:31,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:31,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:20:31,394] {scheduler_job.py:146} INFO - Started process (PID=23713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:36,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:36,401] {logging_mixin.py:95} INFO - [2019-08-27 20:20:36,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:36,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:36,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:20:36,541] {scheduler_job.py:146} INFO - Started process (PID=23716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:41,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:41,549] {logging_mixin.py:95} INFO - [2019-08-27 20:20:41,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:41,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:41,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:20:41,694] {scheduler_job.py:146} INFO - Started process (PID=23717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:46,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:46,701] {logging_mixin.py:95} INFO - [2019-08-27 20:20:46,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:46,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:46,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:20:46,845] {scheduler_job.py:146} INFO - Started process (PID=23718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:51,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:51,856] {logging_mixin.py:95} INFO - [2019-08-27 20:20:51,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:51,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:51,895] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:20:51,995] {scheduler_job.py:146} INFO - Started process (PID=23721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:57,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:20:57,004] {logging_mixin.py:95} INFO - [2019-08-27 20:20:57,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:57,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:20:57,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:20:57,153] {scheduler_job.py:146} INFO - Started process (PID=23722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:02,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:02,162] {logging_mixin.py:95} INFO - [2019-08-27 20:21:02,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:02,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:02,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:21:02,307] {scheduler_job.py:146} INFO - Started process (PID=23723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:07,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:07,315] {logging_mixin.py:95} INFO - [2019-08-27 20:21:07,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:07,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:07,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.045 seconds
[2019-08-27 20:21:07,458] {scheduler_job.py:146} INFO - Started process (PID=23726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:12,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:12,469] {logging_mixin.py:95} INFO - [2019-08-27 20:21:12,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:12,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:12,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:21:12,609] {scheduler_job.py:146} INFO - Started process (PID=23727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:17,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:17,617] {logging_mixin.py:95} INFO - [2019-08-27 20:21:17,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:17,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:17,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:21:17,763] {scheduler_job.py:146} INFO - Started process (PID=23728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:22,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:22,770] {logging_mixin.py:95} INFO - [2019-08-27 20:21:22,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:22,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:22,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:21:22,911] {scheduler_job.py:146} INFO - Started process (PID=23730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:27,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:27,918] {logging_mixin.py:95} INFO - [2019-08-27 20:21:27,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:27,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:27,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:21:28,063] {scheduler_job.py:146} INFO - Started process (PID=23731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:33,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:33,070] {logging_mixin.py:95} INFO - [2019-08-27 20:21:33,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:33,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:33,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:21:33,218] {scheduler_job.py:146} INFO - Started process (PID=23732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:38,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:38,228] {logging_mixin.py:95} INFO - [2019-08-27 20:21:38,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:38,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:38,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:21:38,366] {scheduler_job.py:146} INFO - Started process (PID=23735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:43,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:43,376] {logging_mixin.py:95} INFO - [2019-08-27 20:21:43,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:43,388] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:43,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:21:43,520] {scheduler_job.py:146} INFO - Started process (PID=23736) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:48,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:48,530] {logging_mixin.py:95} INFO - [2019-08-27 20:21:48,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:48,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:48,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:21:48,683] {scheduler_job.py:146} INFO - Started process (PID=23742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:53,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:53,695] {logging_mixin.py:95} INFO - [2019-08-27 20:21:53,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:53,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:53,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:21:53,820] {scheduler_job.py:146} INFO - Started process (PID=23744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:58,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:21:58,827] {logging_mixin.py:95} INFO - [2019-08-27 20:21:58,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:58,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:21:58,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:21:58,965] {scheduler_job.py:146} INFO - Started process (PID=23745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:03,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:03,974] {logging_mixin.py:95} INFO - [2019-08-27 20:22:03,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:03,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:04,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:22:04,124] {scheduler_job.py:146} INFO - Started process (PID=23746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:09,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:09,132] {logging_mixin.py:95} INFO - [2019-08-27 20:22:09,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:09,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:09,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:22:09,277] {scheduler_job.py:146} INFO - Started process (PID=23748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:14,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:14,287] {logging_mixin.py:95} INFO - [2019-08-27 20:22:14,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:14,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:14,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:22:14,431] {scheduler_job.py:146} INFO - Started process (PID=23750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:19,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:19,438] {logging_mixin.py:95} INFO - [2019-08-27 20:22:19,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:19,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:19,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:22:19,583] {scheduler_job.py:146} INFO - Started process (PID=23752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:24,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:24,589] {logging_mixin.py:95} INFO - [2019-08-27 20:22:24,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:24,599] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:24,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:22:24,748] {scheduler_job.py:146} INFO - Started process (PID=23753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:29,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:29,755] {logging_mixin.py:95} INFO - [2019-08-27 20:22:29,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:29,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:29,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:22:29,905] {scheduler_job.py:146} INFO - Started process (PID=23754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:34,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:34,916] {logging_mixin.py:95} INFO - [2019-08-27 20:22:34,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:34,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:34,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:22:35,058] {scheduler_job.py:146} INFO - Started process (PID=23756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:40,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:40,079] {logging_mixin.py:95} INFO - [2019-08-27 20:22:40,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:40,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:40,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:22:40,209] {scheduler_job.py:146} INFO - Started process (PID=23757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:45,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:45,222] {logging_mixin.py:95} INFO - [2019-08-27 20:22:45,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:45,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:45,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:22:45,364] {scheduler_job.py:146} INFO - Started process (PID=23759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:50,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:50,380] {logging_mixin.py:95} INFO - [2019-08-27 20:22:50,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:50,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:50,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:22:50,508] {scheduler_job.py:146} INFO - Started process (PID=23761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:55,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:22:55,517] {logging_mixin.py:95} INFO - [2019-08-27 20:22:55,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:55,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:22:55,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:22:55,660] {scheduler_job.py:146} INFO - Started process (PID=23762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:00,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:00,669] {logging_mixin.py:95} INFO - [2019-08-27 20:23:00,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:00,681] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:00,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:23:00,817] {scheduler_job.py:146} INFO - Started process (PID=23763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:05,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:05,824] {logging_mixin.py:95} INFO - [2019-08-27 20:23:05,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:05,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:05,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:23:05,974] {scheduler_job.py:146} INFO - Started process (PID=23765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:10,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:10,986] {logging_mixin.py:95} INFO - [2019-08-27 20:23:10,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:10,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:11,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:23:11,121] {scheduler_job.py:146} INFO - Started process (PID=23766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:16,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:16,127] {logging_mixin.py:95} INFO - [2019-08-27 20:23:16,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:16,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:16,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:23:16,271] {scheduler_job.py:146} INFO - Started process (PID=23769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:21,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:21,281] {logging_mixin.py:95} INFO - [2019-08-27 20:23:21,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:21,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:21,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:23:21,411] {scheduler_job.py:146} INFO - Started process (PID=23775) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:26,419] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:26,421] {logging_mixin.py:95} INFO - [2019-08-27 20:23:26,420] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:26,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:26,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:23:26,564] {scheduler_job.py:146} INFO - Started process (PID=23776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:31,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:31,571] {logging_mixin.py:95} INFO - [2019-08-27 20:23:31,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:31,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:31,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:23:31,714] {scheduler_job.py:146} INFO - Started process (PID=23777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:36,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:36,727] {logging_mixin.py:95} INFO - [2019-08-27 20:23:36,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:36,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:36,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:23:36,875] {scheduler_job.py:146} INFO - Started process (PID=23779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:41,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:41,882] {logging_mixin.py:95} INFO - [2019-08-27 20:23:41,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:41,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:41,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:23:42,027] {scheduler_job.py:146} INFO - Started process (PID=23780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:47,035] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:47,036] {logging_mixin.py:95} INFO - [2019-08-27 20:23:47,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:47,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:47,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:23:47,172] {scheduler_job.py:146} INFO - Started process (PID=23782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:52,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:52,185] {logging_mixin.py:95} INFO - [2019-08-27 20:23:52,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:52,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:52,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:23:52,334] {scheduler_job.py:146} INFO - Started process (PID=23785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:57,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:23:57,341] {logging_mixin.py:95} INFO - [2019-08-27 20:23:57,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:57,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:23:57,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:23:57,481] {scheduler_job.py:146} INFO - Started process (PID=23786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:02,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:02,488] {logging_mixin.py:95} INFO - [2019-08-27 20:24:02,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:02,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:02,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.047 seconds
[2019-08-27 20:24:02,626] {scheduler_job.py:146} INFO - Started process (PID=23787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:07,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:07,636] {logging_mixin.py:95} INFO - [2019-08-27 20:24:07,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:07,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:07,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:24:07,779] {scheduler_job.py:146} INFO - Started process (PID=23789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:12,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:12,787] {logging_mixin.py:95} INFO - [2019-08-27 20:24:12,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:12,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:12,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:24:12,926] {scheduler_job.py:146} INFO - Started process (PID=23790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:17,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:17,942] {logging_mixin.py:95} INFO - [2019-08-27 20:24:17,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:17,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:17,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:24:18,065] {scheduler_job.py:146} INFO - Started process (PID=23792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:23,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:23,073] {logging_mixin.py:95} INFO - [2019-08-27 20:24:23,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:23,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:23,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:24:23,207] {scheduler_job.py:146} INFO - Started process (PID=23794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:28,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:28,215] {logging_mixin.py:95} INFO - [2019-08-27 20:24:28,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:28,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:28,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:24:28,352] {scheduler_job.py:146} INFO - Started process (PID=23795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:33,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:33,361] {logging_mixin.py:95} INFO - [2019-08-27 20:24:33,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:33,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:33,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:24:33,498] {scheduler_job.py:146} INFO - Started process (PID=23796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:38,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:38,504] {logging_mixin.py:95} INFO - [2019-08-27 20:24:38,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:38,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:38,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:24:38,641] {scheduler_job.py:146} INFO - Started process (PID=23798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:43,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:43,649] {logging_mixin.py:95} INFO - [2019-08-27 20:24:43,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:43,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:43,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:24:43,796] {scheduler_job.py:146} INFO - Started process (PID=23799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:48,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:48,807] {logging_mixin.py:95} INFO - [2019-08-27 20:24:48,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:48,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:48,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:24:48,949] {scheduler_job.py:146} INFO - Started process (PID=23802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:53,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:53,957] {logging_mixin.py:95} INFO - [2019-08-27 20:24:53,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:53,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:54,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:24:54,105] {scheduler_job.py:146} INFO - Started process (PID=23804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:59,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:24:59,111] {logging_mixin.py:95} INFO - [2019-08-27 20:24:59,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:59,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:24:59,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:24:59,260] {scheduler_job.py:146} INFO - Started process (PID=23805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:04,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:04,268] {logging_mixin.py:95} INFO - [2019-08-27 20:25:04,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:04,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:04,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:25:04,418] {scheduler_job.py:146} INFO - Started process (PID=23806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:09,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:09,424] {logging_mixin.py:95} INFO - [2019-08-27 20:25:09,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:09,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:09,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.050 seconds
[2019-08-27 20:25:09,570] {scheduler_job.py:146} INFO - Started process (PID=23808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:14,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:14,577] {logging_mixin.py:95} INFO - [2019-08-27 20:25:14,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:14,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:14,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:25:14,716] {scheduler_job.py:146} INFO - Started process (PID=23810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:19,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:19,733] {logging_mixin.py:95} INFO - [2019-08-27 20:25:19,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:19,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:19,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:25:19,860] {scheduler_job.py:146} INFO - Started process (PID=23813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:24,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:24,868] {logging_mixin.py:95} INFO - [2019-08-27 20:25:24,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:24,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:24,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:25:25,008] {scheduler_job.py:146} INFO - Started process (PID=23814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:30,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:30,016] {logging_mixin.py:95} INFO - [2019-08-27 20:25:30,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:30,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:30,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:25:30,166] {scheduler_job.py:146} INFO - Started process (PID=23815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:35,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:35,178] {logging_mixin.py:95} INFO - [2019-08-27 20:25:35,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:35,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:35,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:25:35,313] {scheduler_job.py:146} INFO - Started process (PID=23817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:40,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:40,334] {logging_mixin.py:95} INFO - [2019-08-27 20:25:40,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:40,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:40,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:25:40,471] {scheduler_job.py:146} INFO - Started process (PID=23818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:45,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:45,479] {logging_mixin.py:95} INFO - [2019-08-27 20:25:45,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:45,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:45,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:25:45,626] {scheduler_job.py:146} INFO - Started process (PID=23819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:50,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:50,639] {logging_mixin.py:95} INFO - [2019-08-27 20:25:50,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:50,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:50,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.058 seconds
[2019-08-27 20:25:50,778] {scheduler_job.py:146} INFO - Started process (PID=23823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:55,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:25:55,790] {logging_mixin.py:95} INFO - [2019-08-27 20:25:55,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:55,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:25:55,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:25:55,929] {scheduler_job.py:146} INFO - Started process (PID=23824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:00,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:00,939] {logging_mixin.py:95} INFO - [2019-08-27 20:26:00,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:00,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:00,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:26:01,075] {scheduler_job.py:146} INFO - Started process (PID=23825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:06,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:06,082] {logging_mixin.py:95} INFO - [2019-08-27 20:26:06,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:06,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:06,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:26:06,231] {scheduler_job.py:146} INFO - Started process (PID=23827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:11,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:11,240] {logging_mixin.py:95} INFO - [2019-08-27 20:26:11,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:11,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:11,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.051 seconds
[2019-08-27 20:26:11,393] {scheduler_job.py:146} INFO - Started process (PID=23828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:16,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:16,401] {logging_mixin.py:95} INFO - [2019-08-27 20:26:16,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:16,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:16,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:26:16,552] {scheduler_job.py:146} INFO - Started process (PID=23829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:21,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:21,562] {logging_mixin.py:95} INFO - [2019-08-27 20:26:21,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:21,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:21,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:26:21,704] {scheduler_job.py:146} INFO - Started process (PID=23832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:26,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:26,715] {logging_mixin.py:95} INFO - [2019-08-27 20:26:26,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:26,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:26,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.056 seconds
[2019-08-27 20:26:26,862] {scheduler_job.py:146} INFO - Started process (PID=23833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:31,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:31,873] {logging_mixin.py:95} INFO - [2019-08-27 20:26:31,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:31,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:31,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:26:32,023] {scheduler_job.py:146} INFO - Started process (PID=23834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:37,033] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:37,034] {logging_mixin.py:95} INFO - [2019-08-27 20:26:37,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:37,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:37,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.055 seconds
[2019-08-27 20:26:37,181] {scheduler_job.py:146} INFO - Started process (PID=23836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:42,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:42,189] {logging_mixin.py:95} INFO - [2019-08-27 20:26:42,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:42,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:42,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:26:42,347] {scheduler_job.py:146} INFO - Started process (PID=23837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:47,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:47,356] {logging_mixin.py:95} INFO - [2019-08-27 20:26:47,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:47,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:47,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:26:47,504] {scheduler_job.py:146} INFO - Started process (PID=23838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:52,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:52,512] {logging_mixin.py:95} INFO - [2019-08-27 20:26:52,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:52,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:52,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.046 seconds
[2019-08-27 20:26:52,660] {scheduler_job.py:146} INFO - Started process (PID=23841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:57,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:26:57,676] {logging_mixin.py:95} INFO - [2019-08-27 20:26:57,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:57,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:26:57,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.054 seconds
[2019-08-27 20:26:57,821] {scheduler_job.py:146} INFO - Started process (PID=23842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:02,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:02,832] {logging_mixin.py:95} INFO - [2019-08-27 20:27:02,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:02,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:02,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:27:02,981] {scheduler_job.py:146} INFO - Started process (PID=23843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:07,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:07,992] {logging_mixin.py:95} INFO - [2019-08-27 20:27:07,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:08,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:08,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:27:08,141] {scheduler_job.py:146} INFO - Started process (PID=23845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:13,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:13,152] {logging_mixin.py:95} INFO - [2019-08-27 20:27:13,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:13,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:13,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.048 seconds
[2019-08-27 20:27:13,301] {scheduler_job.py:146} INFO - Started process (PID=23846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:18,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:18,307] {logging_mixin.py:95} INFO - [2019-08-27 20:27:18,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:18,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:18,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.059 seconds
[2019-08-27 20:27:18,450] {scheduler_job.py:146} INFO - Started process (PID=23847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:23,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:23,458] {logging_mixin.py:95} INFO - [2019-08-27 20:27:23,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:23,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:23,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.053 seconds
[2019-08-27 20:27:23,598] {scheduler_job.py:146} INFO - Started process (PID=23849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:28,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:28,607] {logging_mixin.py:95} INFO - [2019-08-27 20:27:28,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:28,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:28,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.057 seconds
[2019-08-27 20:27:28,764] {scheduler_job.py:146} INFO - Started process (PID=23851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:33,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:33,771] {logging_mixin.py:95} INFO - [2019-08-27 20:27:33,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:33,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:33,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.049 seconds
[2019-08-27 20:27:33,918] {scheduler_job.py:146} INFO - Started process (PID=23852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:38,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:38,925] {logging_mixin.py:95} INFO - [2019-08-27 20:27:38,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:38,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:38,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:27:39,077] {scheduler_job.py:146} INFO - Started process (PID=23854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:44,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:44,084] {logging_mixin.py:95} INFO - [2019-08-27 20:27:44,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:44,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:44,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.052 seconds
[2019-08-27 20:27:44,236] {scheduler_job.py:146} INFO - Started process (PID=23855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:49,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:49,242] {logging_mixin.py:95} INFO - [2019-08-27 20:27:49,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:49,248] {logging_mixin.py:95} INFO - [2019-08-27 20:27:49,245] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:27:49,248] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:49,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:27:49,300] {scheduler_job.py:146} INFO - Started process (PID=23857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:54,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:54,311] {logging_mixin.py:95} INFO - [2019-08-27 20:27:54,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:54,316] {logging_mixin.py:95} INFO - [2019-08-27 20:27:54,315] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:27:54,316] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:54,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:27:54,444] {scheduler_job.py:146} INFO - Started process (PID=23859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:59,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:27:59,461] {logging_mixin.py:95} INFO - [2019-08-27 20:27:59,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:59,467] {logging_mixin.py:95} INFO - [2019-08-27 20:27:59,465] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:27:59,467] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:27:59,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:27:59,502] {scheduler_job.py:146} INFO - Started process (PID=23861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:04,509] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:04,510] {logging_mixin.py:95} INFO - [2019-08-27 20:28:04,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:04,515] {logging_mixin.py:95} INFO - [2019-08-27 20:28:04,514] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:04,515] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:04,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:28:04,561] {scheduler_job.py:146} INFO - Started process (PID=23862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:09,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:09,570] {logging_mixin.py:95} INFO - [2019-08-27 20:28:09,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:09,575] {logging_mixin.py:95} INFO - [2019-08-27 20:28:09,573] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:09,575] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:09,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:28:09,614] {scheduler_job.py:146} INFO - Started process (PID=23864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:14,625] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:14,626] {logging_mixin.py:95} INFO - [2019-08-27 20:28:14,625] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:14,630] {logging_mixin.py:95} INFO - [2019-08-27 20:28:14,629] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:14,631] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:14,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:28:14,671] {scheduler_job.py:146} INFO - Started process (PID=23865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:19,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:19,683] {logging_mixin.py:95} INFO - [2019-08-27 20:28:19,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:19,687] {logging_mixin.py:95} INFO - [2019-08-27 20:28:19,686] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:19,688] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:19,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:28:19,723] {scheduler_job.py:146} INFO - Started process (PID=23867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:24,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:24,733] {logging_mixin.py:95} INFO - [2019-08-27 20:28:24,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:24,738] {logging_mixin.py:95} INFO - [2019-08-27 20:28:24,737] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:24,738] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:24,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:28:24,863] {scheduler_job.py:146} INFO - Started process (PID=23871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:29,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:29,871] {logging_mixin.py:95} INFO - [2019-08-27 20:28:29,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:29,876] {logging_mixin.py:95} INFO - [2019-08-27 20:28:29,874] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:29,876] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:29,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:28:30,007] {scheduler_job.py:146} INFO - Started process (PID=23873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:35,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:35,016] {logging_mixin.py:95} INFO - [2019-08-27 20:28:35,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:35,020] {logging_mixin.py:95} INFO - [2019-08-27 20:28:35,019] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:35,021] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:35,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:28:35,052] {scheduler_job.py:146} INFO - Started process (PID=23876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:40,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:40,059] {logging_mixin.py:95} INFO - [2019-08-27 20:28:40,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:40,063] {logging_mixin.py:95} INFO - [2019-08-27 20:28:40,062] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:40,064] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:40,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:28:40,109] {scheduler_job.py:146} INFO - Started process (PID=23877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:45,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:45,118] {logging_mixin.py:95} INFO - [2019-08-27 20:28:45,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:45,123] {logging_mixin.py:95} INFO - [2019-08-27 20:28:45,122] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:45,123] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:45,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:28:45,161] {scheduler_job.py:146} INFO - Started process (PID=23878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:50,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:50,172] {logging_mixin.py:95} INFO - [2019-08-27 20:28:50,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:50,177] {logging_mixin.py:95} INFO - [2019-08-27 20:28:50,176] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:50,178] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:50,196] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:28:50,311] {scheduler_job.py:146} INFO - Started process (PID=23880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:55,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:28:55,319] {logging_mixin.py:95} INFO - [2019-08-27 20:28:55,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:55,323] {logging_mixin.py:95} INFO - [2019-08-27 20:28:55,322] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:28:55,324] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:28:55,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:28:55,362] {scheduler_job.py:146} INFO - Started process (PID=23881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:00,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:00,368] {logging_mixin.py:95} INFO - [2019-08-27 20:29:00,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:00,373] {logging_mixin.py:95} INFO - [2019-08-27 20:29:00,371] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:00,373] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:00,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:29:00,416] {scheduler_job.py:146} INFO - Started process (PID=23883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:05,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:05,428] {logging_mixin.py:95} INFO - [2019-08-27 20:29:05,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:05,432] {logging_mixin.py:95} INFO - [2019-08-27 20:29:05,431] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:05,433] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:05,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:29:05,473] {scheduler_job.py:146} INFO - Started process (PID=23885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:10,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:10,480] {logging_mixin.py:95} INFO - [2019-08-27 20:29:10,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:10,484] {logging_mixin.py:95} INFO - [2019-08-27 20:29:10,483] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:10,485] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:10,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:29:10,531] {scheduler_job.py:146} INFO - Started process (PID=23886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:15,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:15,539] {logging_mixin.py:95} INFO - [2019-08-27 20:29:15,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:15,544] {logging_mixin.py:95} INFO - [2019-08-27 20:29:15,543] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:15,544] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:15,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:29:15,587] {scheduler_job.py:146} INFO - Started process (PID=23887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:20,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:20,597] {logging_mixin.py:95} INFO - [2019-08-27 20:29:20,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:20,601] {logging_mixin.py:95} INFO - [2019-08-27 20:29:20,600] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:20,602] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:20,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:29:20,643] {scheduler_job.py:146} INFO - Started process (PID=23889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:25,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:25,654] {logging_mixin.py:95} INFO - [2019-08-27 20:29:25,654] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:25,659] {logging_mixin.py:95} INFO - [2019-08-27 20:29:25,658] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:25,660] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:25,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:29:25,703] {scheduler_job.py:146} INFO - Started process (PID=23890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:30,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:30,711] {logging_mixin.py:95} INFO - [2019-08-27 20:29:30,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:30,716] {logging_mixin.py:95} INFO - [2019-08-27 20:29:30,714] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:30,716] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:30,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:29:30,759] {scheduler_job.py:146} INFO - Started process (PID=23892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:35,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:35,766] {logging_mixin.py:95} INFO - [2019-08-27 20:29:35,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:35,771] {logging_mixin.py:95} INFO - [2019-08-27 20:29:35,769] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:35,771] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:35,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:29:35,816] {scheduler_job.py:146} INFO - Started process (PID=23894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:40,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:40,824] {logging_mixin.py:95} INFO - [2019-08-27 20:29:40,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:40,828] {logging_mixin.py:95} INFO - [2019-08-27 20:29:40,827] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:40,829] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:40,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:29:40,871] {scheduler_job.py:146} INFO - Started process (PID=23895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:45,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:45,881] {logging_mixin.py:95} INFO - [2019-08-27 20:29:45,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:45,886] {logging_mixin.py:95} INFO - [2019-08-27 20:29:45,885] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:45,887] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:45,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:29:45,937] {scheduler_job.py:146} INFO - Started process (PID=23896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:50,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:50,954] {logging_mixin.py:95} INFO - [2019-08-27 20:29:50,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:50,959] {logging_mixin.py:95} INFO - [2019-08-27 20:29:50,958] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:50,960] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:50,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:29:50,993] {scheduler_job.py:146} INFO - Started process (PID=23898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:56,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:29:56,004] {logging_mixin.py:95} INFO - [2019-08-27 20:29:56,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:56,008] {logging_mixin.py:95} INFO - [2019-08-27 20:29:56,007] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:29:56,009] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:29:56,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:29:56,055] {scheduler_job.py:146} INFO - Started process (PID=23899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:01,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:01,062] {logging_mixin.py:95} INFO - [2019-08-27 20:30:01,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:01,065] {logging_mixin.py:95} INFO - [2019-08-27 20:30:01,064] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:01,065] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:01,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.022 seconds
[2019-08-27 20:30:01,109] {scheduler_job.py:146} INFO - Started process (PID=23902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:06,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:06,120] {logging_mixin.py:95} INFO - [2019-08-27 20:30:06,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:06,125] {logging_mixin.py:95} INFO - [2019-08-27 20:30:06,123] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:06,125] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:06,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:30:06,168] {scheduler_job.py:146} INFO - Started process (PID=23904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:11,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:11,175] {logging_mixin.py:95} INFO - [2019-08-27 20:30:11,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:11,180] {logging_mixin.py:95} INFO - [2019-08-27 20:30:11,178] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:11,180] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:11,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:30:11,219] {scheduler_job.py:146} INFO - Started process (PID=23905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:16,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:16,225] {logging_mixin.py:95} INFO - [2019-08-27 20:30:16,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:16,230] {logging_mixin.py:95} INFO - [2019-08-27 20:30:16,229] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:16,231] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:16,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:30:16,278] {scheduler_job.py:146} INFO - Started process (PID=23906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:21,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:21,289] {logging_mixin.py:95} INFO - [2019-08-27 20:30:21,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:21,294] {logging_mixin.py:95} INFO - [2019-08-27 20:30:21,293] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:21,294] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:21,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:30:21,330] {scheduler_job.py:146} INFO - Started process (PID=23908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:26,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:26,339] {logging_mixin.py:95} INFO - [2019-08-27 20:30:26,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:26,344] {logging_mixin.py:95} INFO - [2019-08-27 20:30:26,342] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:26,344] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:26,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:30:26,379] {scheduler_job.py:146} INFO - Started process (PID=23909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:31,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:31,385] {logging_mixin.py:95} INFO - [2019-08-27 20:30:31,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:31,390] {logging_mixin.py:95} INFO - [2019-08-27 20:30:31,389] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:31,390] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:31,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:30:31,428] {scheduler_job.py:146} INFO - Started process (PID=23910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:36,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:36,436] {logging_mixin.py:95} INFO - [2019-08-27 20:30:36,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:36,441] {logging_mixin.py:95} INFO - [2019-08-27 20:30:36,440] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:36,441] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:36,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:30:36,478] {scheduler_job.py:146} INFO - Started process (PID=23913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:41,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:41,487] {logging_mixin.py:95} INFO - [2019-08-27 20:30:41,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:41,492] {logging_mixin.py:95} INFO - [2019-08-27 20:30:41,490] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:41,492] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:41,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:30:41,528] {scheduler_job.py:146} INFO - Started process (PID=23914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:46,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:46,539] {logging_mixin.py:95} INFO - [2019-08-27 20:30:46,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:46,544] {logging_mixin.py:95} INFO - [2019-08-27 20:30:46,543] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:46,545] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:46,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:30:46,584] {scheduler_job.py:146} INFO - Started process (PID=23915) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:51,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:51,607] {logging_mixin.py:95} INFO - [2019-08-27 20:30:51,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:51,612] {logging_mixin.py:95} INFO - [2019-08-27 20:30:51,611] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:51,613] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:51,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.041 seconds
[2019-08-27 20:30:51,733] {scheduler_job.py:146} INFO - Started process (PID=23917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:56,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:30:56,739] {logging_mixin.py:95} INFO - [2019-08-27 20:30:56,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:56,750] {logging_mixin.py:95} INFO - [2019-08-27 20:30:56,742] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:30:56,751] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:30:56,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:30:56,788] {scheduler_job.py:146} INFO - Started process (PID=23918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:01,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:01,794] {logging_mixin.py:95} INFO - [2019-08-27 20:31:01,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:01,799] {logging_mixin.py:95} INFO - [2019-08-27 20:31:01,797] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:01,799] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:01,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:31:01,842] {scheduler_job.py:146} INFO - Started process (PID=23919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:06,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:06,856] {logging_mixin.py:95} INFO - [2019-08-27 20:31:06,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:06,861] {logging_mixin.py:95} INFO - [2019-08-27 20:31:06,860] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:06,862] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:06,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:31:06,892] {scheduler_job.py:146} INFO - Started process (PID=23922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:11,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:11,904] {logging_mixin.py:95} INFO - [2019-08-27 20:31:11,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:11,909] {logging_mixin.py:95} INFO - [2019-08-27 20:31:11,907] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:11,909] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:11,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:31:11,950] {scheduler_job.py:146} INFO - Started process (PID=23923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:16,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:16,962] {logging_mixin.py:95} INFO - [2019-08-27 20:31:16,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:16,967] {logging_mixin.py:95} INFO - [2019-08-27 20:31:16,965] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:16,967] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:16,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:31:17,008] {scheduler_job.py:146} INFO - Started process (PID=23924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:22,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:22,020] {logging_mixin.py:95} INFO - [2019-08-27 20:31:22,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:22,025] {logging_mixin.py:95} INFO - [2019-08-27 20:31:22,024] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:22,025] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:22,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:31:22,066] {scheduler_job.py:146} INFO - Started process (PID=23926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:27,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:27,078] {logging_mixin.py:95} INFO - [2019-08-27 20:31:27,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:27,083] {logging_mixin.py:95} INFO - [2019-08-27 20:31:27,081] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:27,083] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:27,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:31:27,124] {scheduler_job.py:146} INFO - Started process (PID=23927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:32,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:32,136] {logging_mixin.py:95} INFO - [2019-08-27 20:31:32,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:32,140] {logging_mixin.py:95} INFO - [2019-08-27 20:31:32,139] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:32,141] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:32,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:31:32,180] {scheduler_job.py:146} INFO - Started process (PID=23928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:37,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:37,189] {logging_mixin.py:95} INFO - [2019-08-27 20:31:37,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:37,194] {logging_mixin.py:95} INFO - [2019-08-27 20:31:37,193] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:37,194] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:37,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:31:37,236] {scheduler_job.py:146} INFO - Started process (PID=23931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:42,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:42,244] {logging_mixin.py:95} INFO - [2019-08-27 20:31:42,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:42,249] {logging_mixin.py:95} INFO - [2019-08-27 20:31:42,247] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:42,249] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:42,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:31:42,284] {scheduler_job.py:146} INFO - Started process (PID=23932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:47,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:47,291] {logging_mixin.py:95} INFO - [2019-08-27 20:31:47,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:47,295] {logging_mixin.py:95} INFO - [2019-08-27 20:31:47,294] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context)):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:31:47,296] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:47,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 20:31:47,332] {scheduler_job.py:146} INFO - Started process (PID=23933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:52,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:52,339] {logging_mixin.py:95} INFO - [2019-08-27 20:31:52,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:52,344] {logging_mixin.py:95} INFO - [2019-08-27 20:31:52,342] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **context)):
                                   ^
SyntaxError: invalid syntax
[2019-08-27 20:31:52,344] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:52,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:31:52,376] {scheduler_job.py:146} INFO - Started process (PID=23936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:57,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:31:57,387] {logging_mixin.py:95} INFO - [2019-08-27 20:31:57,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:57,392] {logging_mixin.py:95} INFO - [2019-08-27 20:31:57,391] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **context)):
                                   ^
SyntaxError: invalid syntax
[2019-08-27 20:31:57,393] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:31:57,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:31:57,430] {scheduler_job.py:146} INFO - Started process (PID=23937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:02,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:02,437] {logging_mixin.py:95} INFO - [2019-08-27 20:32:02,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:02,442] {logging_mixin.py:95} INFO - [2019-08-27 20:32:02,441] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **context)):
                                   ^
SyntaxError: invalid syntax
[2019-08-27 20:32:02,442] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:02,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:32:02,491] {scheduler_job.py:146} INFO - Started process (PID=23938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:07,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:07,506] {logging_mixin.py:95} INFO - [2019-08-27 20:32:07,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:07,510] {logging_mixin.py:95} INFO - [2019-08-27 20:32:07,509] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **context)):
                                   ^
SyntaxError: invalid syntax
[2019-08-27 20:32:07,512] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:07,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:32:07,546] {scheduler_job.py:146} INFO - Started process (PID=23941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:12,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:12,554] {logging_mixin.py:95} INFO - [2019-08-27 20:32:12,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:12,558] {logging_mixin.py:95} INFO - [2019-08-27 20:32:12,557] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **context)):
                                   ^
SyntaxError: invalid syntax
[2019-08-27 20:32:12,558] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:12,572] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:32:12,603] {scheduler_job.py:146} INFO - Started process (PID=23942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:17,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:17,609] {logging_mixin.py:95} INFO - [2019-08-27 20:32:17,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:17,614] {logging_mixin.py:95} INFO - [2019-08-27 20:32:17,613] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:17,614] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:17,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:32:17,660] {scheduler_job.py:146} INFO - Started process (PID=23943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:22,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:22,671] {logging_mixin.py:95} INFO - [2019-08-27 20:32:22,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:22,675] {logging_mixin.py:95} INFO - [2019-08-27 20:32:22,674] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:22,676] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:22,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:32:22,717] {scheduler_job.py:146} INFO - Started process (PID=23945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:27,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:27,725] {logging_mixin.py:95} INFO - [2019-08-27 20:32:27,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:27,730] {logging_mixin.py:95} INFO - [2019-08-27 20:32:27,729] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:27,730] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:27,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:32:27,775] {scheduler_job.py:146} INFO - Started process (PID=23946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:32,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:32,785] {logging_mixin.py:95} INFO - [2019-08-27 20:32:32,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:32,790] {logging_mixin.py:95} INFO - [2019-08-27 20:32:32,789] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:32,790] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:32,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:32:32,842] {scheduler_job.py:146} INFO - Started process (PID=23947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:37,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:37,849] {logging_mixin.py:95} INFO - [2019-08-27 20:32:37,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:37,853] {logging_mixin.py:95} INFO - [2019-08-27 20:32:37,852] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:37,853] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:37,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:32:37,897] {scheduler_job.py:146} INFO - Started process (PID=23950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:42,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:42,909] {logging_mixin.py:95} INFO - [2019-08-27 20:32:42,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:42,913] {logging_mixin.py:95} INFO - [2019-08-27 20:32:42,912] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:42,914] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:42,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:32:42,952] {scheduler_job.py:146} INFO - Started process (PID=23951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:47,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:47,958] {logging_mixin.py:95} INFO - [2019-08-27 20:32:47,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:47,962] {logging_mixin.py:95} INFO - [2019-08-27 20:32:47,961] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:47,963] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:47,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 20:32:48,006] {scheduler_job.py:146} INFO - Started process (PID=23952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:53,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:53,013] {logging_mixin.py:95} INFO - [2019-08-27 20:32:53,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:53,018] {logging_mixin.py:95} INFO - [2019-08-27 20:32:53,016] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:53,018] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:53,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:32:53,050] {scheduler_job.py:146} INFO - Started process (PID=23957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:58,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:32:58,058] {logging_mixin.py:95} INFO - [2019-08-27 20:32:58,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:58,062] {logging_mixin.py:95} INFO - [2019-08-27 20:32:58,061] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:32:58,063] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:32:58,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:32:58,102] {scheduler_job.py:146} INFO - Started process (PID=23959) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:03,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:03,108] {logging_mixin.py:95} INFO - [2019-08-27 20:33:03,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:03,112] {logging_mixin.py:95} INFO - [2019-08-27 20:33:03,111] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:03,113] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:03,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:33:03,150] {scheduler_job.py:146} INFO - Started process (PID=23960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:08,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:08,156] {logging_mixin.py:95} INFO - [2019-08-27 20:33:08,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:08,160] {logging_mixin.py:95} INFO - [2019-08-27 20:33:08,159] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:08,160] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:08,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:33:08,198] {scheduler_job.py:146} INFO - Started process (PID=23962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:13,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:13,212] {logging_mixin.py:95} INFO - [2019-08-27 20:33:13,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:13,218] {logging_mixin.py:95} INFO - [2019-08-27 20:33:13,216] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:13,218] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:13,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:33:13,344] {scheduler_job.py:146} INFO - Started process (PID=23964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:18,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:18,354] {logging_mixin.py:95} INFO - [2019-08-27 20:33:18,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:18,359] {logging_mixin.py:95} INFO - [2019-08-27 20:33:18,357] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:18,359] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:18,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:33:18,392] {scheduler_job.py:146} INFO - Started process (PID=23965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:23,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:23,399] {logging_mixin.py:95} INFO - [2019-08-27 20:33:23,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:23,404] {logging_mixin.py:95} INFO - [2019-08-27 20:33:23,403] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:23,405] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:23,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:33:23,441] {scheduler_job.py:146} INFO - Started process (PID=23967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:28,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:28,452] {logging_mixin.py:95} INFO - [2019-08-27 20:33:28,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:28,457] {logging_mixin.py:95} INFO - [2019-08-27 20:33:28,456] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:28,457] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:28,477] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:33:28,594] {scheduler_job.py:146} INFO - Started process (PID=23968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:33,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:33,602] {logging_mixin.py:95} INFO - [2019-08-27 20:33:33,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:33,607] {logging_mixin.py:95} INFO - [2019-08-27 20:33:33,605] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:33,607] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:33,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:33:33,741] {scheduler_job.py:146} INFO - Started process (PID=23969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:38,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:38,754] {logging_mixin.py:95} INFO - [2019-08-27 20:33:38,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:38,760] {logging_mixin.py:95} INFO - [2019-08-27 20:33:38,759] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:38,760] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:38,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:33:38,885] {scheduler_job.py:146} INFO - Started process (PID=23971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:43,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:43,900] {logging_mixin.py:95} INFO - [2019-08-27 20:33:43,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:43,906] {logging_mixin.py:95} INFO - [2019-08-27 20:33:43,904] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:43,907] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:43,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:33:44,033] {scheduler_job.py:146} INFO - Started process (PID=23973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:49,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:49,044] {logging_mixin.py:95} INFO - [2019-08-27 20:33:49,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:49,049] {logging_mixin.py:95} INFO - [2019-08-27 20:33:49,047] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:49,049] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:49,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:33:49,086] {scheduler_job.py:146} INFO - Started process (PID=23974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:54,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:54,095] {logging_mixin.py:95} INFO - [2019-08-27 20:33:54,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:54,099] {logging_mixin.py:95} INFO - [2019-08-27 20:33:54,098] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:54,100] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:54,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:33:54,132] {scheduler_job.py:146} INFO - Started process (PID=23976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:59,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:33:59,140] {logging_mixin.py:95} INFO - [2019-08-27 20:33:59,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:59,144] {logging_mixin.py:95} INFO - [2019-08-27 20:33:59,143] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:33:59,145] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:33:59,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:33:59,278] {scheduler_job.py:146} INFO - Started process (PID=23977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:04,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:04,287] {logging_mixin.py:95} INFO - [2019-08-27 20:34:04,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:04,292] {logging_mixin.py:95} INFO - [2019-08-27 20:34:04,291] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:04,293] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:04,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:34:04,427] {scheduler_job.py:146} INFO - Started process (PID=23978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:09,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:09,435] {logging_mixin.py:95} INFO - [2019-08-27 20:34:09,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:09,440] {logging_mixin.py:95} INFO - [2019-08-27 20:34:09,438] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:09,440] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:09,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:34:09,572] {scheduler_job.py:146} INFO - Started process (PID=23980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:14,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:14,580] {logging_mixin.py:95} INFO - [2019-08-27 20:34:14,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:14,585] {logging_mixin.py:95} INFO - [2019-08-27 20:34:14,583] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:14,585] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:14,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:34:14,716] {scheduler_job.py:146} INFO - Started process (PID=23982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:19,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:19,723] {logging_mixin.py:95} INFO - [2019-08-27 20:34:19,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:19,728] {logging_mixin.py:95} INFO - [2019-08-27 20:34:19,727] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:19,728] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:19,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:34:19,766] {scheduler_job.py:146} INFO - Started process (PID=23984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:24,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:24,772] {logging_mixin.py:95} INFO - [2019-08-27 20:34:24,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:24,777] {logging_mixin.py:95} INFO - [2019-08-27 20:34:24,776] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:24,778] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:24,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:34:24,814] {scheduler_job.py:146} INFO - Started process (PID=23986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:29,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:29,821] {logging_mixin.py:95} INFO - [2019-08-27 20:34:29,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:29,826] {logging_mixin.py:95} INFO - [2019-08-27 20:34:29,824] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:29,826] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:29,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:34:29,863] {scheduler_job.py:146} INFO - Started process (PID=23987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:34,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:34,873] {logging_mixin.py:95} INFO - [2019-08-27 20:34:34,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:34,878] {logging_mixin.py:95} INFO - [2019-08-27 20:34:34,876] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:34,878] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:34,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:34:35,014] {scheduler_job.py:146} INFO - Started process (PID=23988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:40,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:40,035] {logging_mixin.py:95} INFO - [2019-08-27 20:34:40,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:40,040] {logging_mixin.py:95} INFO - [2019-08-27 20:34:40,039] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:40,041] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:40,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 20:34:40,153] {scheduler_job.py:146} INFO - Started process (PID=23990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:45,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:45,163] {logging_mixin.py:95} INFO - [2019-08-27 20:34:45,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:45,168] {logging_mixin.py:95} INFO - [2019-08-27 20:34:45,167] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:45,169] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:45,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:34:45,298] {scheduler_job.py:146} INFO - Started process (PID=23992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:50,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:50,305] {logging_mixin.py:95} INFO - [2019-08-27 20:34:50,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:50,309] {logging_mixin.py:95} INFO - [2019-08-27 20:34:50,308] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:50,310] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:50,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:34:50,439] {scheduler_job.py:146} INFO - Started process (PID=23994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:55,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:34:55,446] {logging_mixin.py:95} INFO - [2019-08-27 20:34:55,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:55,451] {logging_mixin.py:95} INFO - [2019-08-27 20:34:55,449] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:34:55,451] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:34:55,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:34:55,493] {scheduler_job.py:146} INFO - Started process (PID=23995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:00,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:00,502] {logging_mixin.py:95} INFO - [2019-08-27 20:35:00,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:00,507] {logging_mixin.py:95} INFO - [2019-08-27 20:35:00,506] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:00,507] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:00,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:35:00,639] {scheduler_job.py:146} INFO - Started process (PID=23996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:05,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:05,646] {logging_mixin.py:95} INFO - [2019-08-27 20:35:05,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:05,650] {logging_mixin.py:95} INFO - [2019-08-27 20:35:05,649] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:05,651] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:05,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:35:05,687] {scheduler_job.py:146} INFO - Started process (PID=23998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:10,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:10,693] {logging_mixin.py:95} INFO - [2019-08-27 20:35:10,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:10,698] {logging_mixin.py:95} INFO - [2019-08-27 20:35:10,696] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:10,698] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:10,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 20:35:10,729] {scheduler_job.py:146} INFO - Started process (PID=23999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:15,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:15,737] {logging_mixin.py:95} INFO - [2019-08-27 20:35:15,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:15,742] {logging_mixin.py:95} INFO - [2019-08-27 20:35:15,740] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:15,742] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:15,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:35:15,780] {scheduler_job.py:146} INFO - Started process (PID=24001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:20,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:20,786] {logging_mixin.py:95} INFO - [2019-08-27 20:35:20,786] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:20,791] {logging_mixin.py:95} INFO - [2019-08-27 20:35:20,790] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:20,791] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:20,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:35:20,830] {scheduler_job.py:146} INFO - Started process (PID=24003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:25,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:25,837] {logging_mixin.py:95} INFO - [2019-08-27 20:35:25,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:25,842] {logging_mixin.py:95} INFO - [2019-08-27 20:35:25,841] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:25,843] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:25,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:35:25,979] {scheduler_job.py:146} INFO - Started process (PID=24004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:30,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:30,990] {logging_mixin.py:95} INFO - [2019-08-27 20:35:30,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:30,994] {logging_mixin.py:95} INFO - [2019-08-27 20:35:30,993] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:30,995] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:31,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:35:31,130] {scheduler_job.py:146} INFO - Started process (PID=24005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:36,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:36,142] {logging_mixin.py:95} INFO - [2019-08-27 20:35:36,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:36,146] {logging_mixin.py:95} INFO - [2019-08-27 20:35:36,145] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:36,147] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:36,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:35:36,184] {scheduler_job.py:146} INFO - Started process (PID=24007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:41,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:41,190] {logging_mixin.py:95} INFO - [2019-08-27 20:35:41,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:41,195] {logging_mixin.py:95} INFO - [2019-08-27 20:35:41,193] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:41,195] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:41,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:35:41,237] {scheduler_job.py:146} INFO - Started process (PID=24008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:46,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:46,244] {logging_mixin.py:95} INFO - [2019-08-27 20:35:46,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:46,248] {logging_mixin.py:95} INFO - [2019-08-27 20:35:46,247] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:46,248] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:46,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:35:46,285] {scheduler_job.py:146} INFO - Started process (PID=24010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:51,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:51,296] {logging_mixin.py:95} INFO - [2019-08-27 20:35:51,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:51,302] {logging_mixin.py:95} INFO - [2019-08-27 20:35:51,301] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:51,302] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:51,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:35:51,335] {scheduler_job.py:146} INFO - Started process (PID=24013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:56,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:35:56,341] {logging_mixin.py:95} INFO - [2019-08-27 20:35:56,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:56,346] {logging_mixin.py:95} INFO - [2019-08-27 20:35:56,345] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:35:56,346] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:35:56,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.026 seconds
[2019-08-27 20:35:56,382] {scheduler_job.py:146} INFO - Started process (PID=24014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:01,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:01,390] {logging_mixin.py:95} INFO - [2019-08-27 20:36:01,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:01,395] {logging_mixin.py:95} INFO - [2019-08-27 20:36:01,393] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:01,395] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:01,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:36:01,435] {scheduler_job.py:146} INFO - Started process (PID=24015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:06,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:06,443] {logging_mixin.py:95} INFO - [2019-08-27 20:36:06,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:06,448] {logging_mixin.py:95} INFO - [2019-08-27 20:36:06,446] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:06,448] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:06,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:36:06,486] {scheduler_job.py:146} INFO - Started process (PID=24017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:11,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:11,493] {logging_mixin.py:95} INFO - [2019-08-27 20:36:11,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:11,498] {logging_mixin.py:95} INFO - [2019-08-27 20:36:11,497] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:11,499] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:11,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:36:11,631] {scheduler_job.py:146} INFO - Started process (PID=24018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:16,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:16,638] {logging_mixin.py:95} INFO - [2019-08-27 20:36:16,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:16,643] {logging_mixin.py:95} INFO - [2019-08-27 20:36:16,642] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:16,643] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:16,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.024 seconds
[2019-08-27 20:36:16,683] {scheduler_job.py:146} INFO - Started process (PID=24019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:21,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:21,692] {logging_mixin.py:95} INFO - [2019-08-27 20:36:21,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:21,697] {logging_mixin.py:95} INFO - [2019-08-27 20:36:21,696] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:21,698] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:21,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:36:21,737] {scheduler_job.py:146} INFO - Started process (PID=24022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:26,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:26,745] {logging_mixin.py:95} INFO - [2019-08-27 20:36:26,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:26,749] {logging_mixin.py:95} INFO - [2019-08-27 20:36:26,748] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:26,750] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:26,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:36:26,785] {scheduler_job.py:146} INFO - Started process (PID=24023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:31,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:31,799] {logging_mixin.py:95} INFO - [2019-08-27 20:36:31,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:31,804] {logging_mixin.py:95} INFO - [2019-08-27 20:36:31,803] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:31,805] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:31,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.039 seconds
[2019-08-27 20:36:31,931] {scheduler_job.py:146} INFO - Started process (PID=24024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:36,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:36,942] {logging_mixin.py:95} INFO - [2019-08-27 20:36:36,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:36,947] {logging_mixin.py:95} INFO - [2019-08-27 20:36:36,945] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:36,947] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:36,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:36:37,066] {scheduler_job.py:146} INFO - Started process (PID=24026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:42,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:42,073] {logging_mixin.py:95} INFO - [2019-08-27 20:36:42,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:42,077] {logging_mixin.py:95} INFO - [2019-08-27 20:36:42,076] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:42,078] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:42,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 20:36:42,111] {scheduler_job.py:146} INFO - Started process (PID=24027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:47,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:47,117] {logging_mixin.py:95} INFO - [2019-08-27 20:36:47,117] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:47,123] {logging_mixin.py:95} INFO - [2019-08-27 20:36:47,121] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:47,123] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:47,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:36:47,160] {scheduler_job.py:146} INFO - Started process (PID=24028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:52,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:52,169] {logging_mixin.py:95} INFO - [2019-08-27 20:36:52,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:52,180] {logging_mixin.py:95} INFO - [2019-08-27 20:36:52,172] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:52,181] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:52,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:36:52,309] {scheduler_job.py:146} INFO - Started process (PID=24031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:57,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:36:57,317] {logging_mixin.py:95} INFO - [2019-08-27 20:36:57,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:57,322] {logging_mixin.py:95} INFO - [2019-08-27 20:36:57,320] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:36:57,322] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:36:57,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.025 seconds
[2019-08-27 20:36:57,353] {scheduler_job.py:146} INFO - Started process (PID=24032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:02,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:02,360] {logging_mixin.py:95} INFO - [2019-08-27 20:37:02,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:02,365] {logging_mixin.py:95} INFO - [2019-08-27 20:37:02,364] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:02,366] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:02,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:37:02,403] {scheduler_job.py:146} INFO - Started process (PID=24033) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:07,414] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:07,415] {logging_mixin.py:95} INFO - [2019-08-27 20:37:07,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:07,420] {logging_mixin.py:95} INFO - [2019-08-27 20:37:07,419] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:07,420] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:07,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:37:07,547] {scheduler_job.py:146} INFO - Started process (PID=24035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:12,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:12,559] {logging_mixin.py:95} INFO - [2019-08-27 20:37:12,559] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:12,564] {logging_mixin.py:95} INFO - [2019-08-27 20:37:12,562] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:12,564] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:12,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.037 seconds
[2019-08-27 20:37:12,697] {scheduler_job.py:146} INFO - Started process (PID=24036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:17,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:17,705] {logging_mixin.py:95} INFO - [2019-08-27 20:37:17,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:17,711] {logging_mixin.py:95} INFO - [2019-08-27 20:37:17,709] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:17,711] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:17,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:37:17,834] {scheduler_job.py:146} INFO - Started process (PID=24037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:22,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:22,842] {logging_mixin.py:95} INFO - [2019-08-27 20:37:22,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:22,846] {logging_mixin.py:95} INFO - [2019-08-27 20:37:22,845] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:22,847] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:22,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:37:22,969] {scheduler_job.py:146} INFO - Started process (PID=24040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:27,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:27,977] {logging_mixin.py:95} INFO - [2019-08-27 20:37:27,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:27,981] {logging_mixin.py:95} INFO - [2019-08-27 20:37:27,980] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:27,981] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:27,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:37:28,110] {scheduler_job.py:146} INFO - Started process (PID=24041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:33,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:33,119] {logging_mixin.py:95} INFO - [2019-08-27 20:37:33,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:33,123] {logging_mixin.py:95} INFO - [2019-08-27 20:37:33,122] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:33,124] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:33,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.028 seconds
[2019-08-27 20:37:33,253] {scheduler_job.py:146} INFO - Started process (PID=24042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:38,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:38,262] {logging_mixin.py:95} INFO - [2019-08-27 20:37:38,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:38,266] {logging_mixin.py:95} INFO - [2019-08-27 20:37:38,264] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:38,266] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:38,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:37:38,385] {scheduler_job.py:146} INFO - Started process (PID=24044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:43,392] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:43,393] {logging_mixin.py:95} INFO - [2019-08-27 20:37:43,393] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:43,399] {logging_mixin.py:95} INFO - [2019-08-27 20:37:43,397] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, **context):
                                    ^
SyntaxError: invalid syntax
[2019-08-27 20:37:43,399] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:43,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:37:43,526] {scheduler_job.py:146} INFO - Started process (PID=24045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:48,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:48,534] {logging_mixin.py:95} INFO - [2019-08-27 20:37:48,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:48,539] {logging_mixin.py:95} INFO - [2019-08-27 20:37:48,538] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:37:48,539] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:48,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:37:48,663] {scheduler_job.py:146} INFO - Started process (PID=24047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:53,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:53,673] {logging_mixin.py:95} INFO - [2019-08-27 20:37:53,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:53,677] {logging_mixin.py:95} INFO - [2019-08-27 20:37:53,676] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:37:53,678] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:53,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:37:53,801] {scheduler_job.py:146} INFO - Started process (PID=24050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:58,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:37:58,808] {logging_mixin.py:95} INFO - [2019-08-27 20:37:58,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:58,812] {logging_mixin.py:95} INFO - [2019-08-27 20:37:58,811] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:37:58,813] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:37:58,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.031 seconds
[2019-08-27 20:37:58,942] {scheduler_job.py:146} INFO - Started process (PID=24054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:03,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:03,949] {logging_mixin.py:95} INFO - [2019-08-27 20:38:03,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:03,954] {logging_mixin.py:95} INFO - [2019-08-27 20:38:03,952] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:03,954] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:03,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.027 seconds
[2019-08-27 20:38:03,987] {scheduler_job.py:146} INFO - Started process (PID=24055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:08,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:08,995] {logging_mixin.py:95} INFO - [2019-08-27 20:38:08,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:08,999] {logging_mixin.py:95} INFO - [2019-08-27 20:38:08,997] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:08,999] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:09,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.029 seconds
[2019-08-27 20:38:09,129] {scheduler_job.py:146} INFO - Started process (PID=24057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:14,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:14,138] {logging_mixin.py:95} INFO - [2019-08-27 20:38:14,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:14,142] {logging_mixin.py:95} INFO - [2019-08-27 20:38:14,141] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:14,143] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:14,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:38:14,179] {scheduler_job.py:146} INFO - Started process (PID=24058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:19,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:19,187] {logging_mixin.py:95} INFO - [2019-08-27 20:38:19,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:19,192] {logging_mixin.py:95} INFO - [2019-08-27 20:38:19,191] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:19,193] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:19,211] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:38:19,327] {scheduler_job.py:146} INFO - Started process (PID=24059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:24,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:24,334] {logging_mixin.py:95} INFO - [2019-08-27 20:38:24,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:24,340] {logging_mixin.py:95} INFO - [2019-08-27 20:38:24,338] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:24,340] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:24,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.034 seconds
[2019-08-27 20:38:24,473] {scheduler_job.py:146} INFO - Started process (PID=24062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:29,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:29,484] {logging_mixin.py:95} INFO - [2019-08-27 20:38:29,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:29,489] {logging_mixin.py:95} INFO - [2019-08-27 20:38:29,488] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:29,490] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:29,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:38:29,528] {scheduler_job.py:146} INFO - Started process (PID=24063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:34,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:34,539] {logging_mixin.py:95} INFO - [2019-08-27 20:38:34,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:34,544] {logging_mixin.py:95} INFO - [2019-08-27 20:38:34,542] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:34,544] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:34,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.035 seconds
[2019-08-27 20:38:34,586] {scheduler_job.py:146} INFO - Started process (PID=24064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:39,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:39,598] {logging_mixin.py:95} INFO - [2019-08-27 20:38:39,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:39,602] {logging_mixin.py:95} INFO - [2019-08-27 20:38:39,601] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:39,603] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:39,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.036 seconds
[2019-08-27 20:38:39,644] {scheduler_job.py:146} INFO - Started process (PID=24066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:44,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:44,657] {logging_mixin.py:95} INFO - [2019-08-27 20:38:44,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:44,662] {logging_mixin.py:95} INFO - [2019-08-27 20:38:44,661] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:44,662] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:44,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.033 seconds
[2019-08-27 20:38:44,701] {scheduler_job.py:146} INFO - Started process (PID=24067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:49,708] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:49,709] {logging_mixin.py:95} INFO - [2019-08-27 20:38:49,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:49,714] {logging_mixin.py:95} INFO - [2019-08-27 20:38:49,713] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:49,715] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:49,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:38:49,754] {scheduler_job.py:146} INFO - Started process (PID=24068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:54,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:54,763] {logging_mixin.py:95} INFO - [2019-08-27 20:38:54,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:54,767] {logging_mixin.py:95} INFO - [2019-08-27 20:38:54,766] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:54,767] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:54,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:38:54,803] {scheduler_job.py:146} INFO - Started process (PID=24071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:59,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:38:59,809] {logging_mixin.py:95} INFO - [2019-08-27 20:38:59,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:59,814] {logging_mixin.py:95} INFO - [2019-08-27 20:38:59,813] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:38:59,814] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:38:59,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.030 seconds
[2019-08-27 20:38:59,855] {scheduler_job.py:146} INFO - Started process (PID=24072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:04,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:04,864] {logging_mixin.py:95} INFO - [2019-08-27 20:39:04,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:04,868] {logging_mixin.py:95} INFO - [2019-08-27 20:39:04,867] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:39:04,869] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:04,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.032 seconds
[2019-08-27 20:39:04,913] {scheduler_job.py:146} INFO - Started process (PID=24073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:09,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:09,938] {logging_mixin.py:95} INFO - [2019-08-27 20:39:09,937] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:09,943] {logging_mixin.py:95} INFO - [2019-08-27 20:39:09,942] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 34
    def upload_to_s3(ds, **kwargs, context):
                                         ^
SyntaxError: invalid syntax
[2019-08-27 20:39:09,943] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:09,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.043 seconds
[2019-08-27 20:39:10,066] {scheduler_job.py:146} INFO - Started process (PID=24075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:15,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:15,074] {logging_mixin.py:95} INFO - [2019-08-27 20:39:15,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:15,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:15,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.779 seconds
[2019-08-27 20:39:15,922] {scheduler_job.py:146} INFO - Started process (PID=24076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:20,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:20,929] {logging_mixin.py:95} INFO - [2019-08-27 20:39:20,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:21,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:21,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:39:21,386] {scheduler_job.py:146} INFO - Started process (PID=24078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:26,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:26,396] {logging_mixin.py:95} INFO - [2019-08-27 20:39:26,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:26,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:26,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 20:39:26,850] {scheduler_job.py:146} INFO - Started process (PID=24080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:31,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:31,864] {logging_mixin.py:95} INFO - [2019-08-27 20:39:31,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:32,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:32,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 20:39:32,311] {scheduler_job.py:146} INFO - Started process (PID=24081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:37,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:37,321] {logging_mixin.py:95} INFO - [2019-08-27 20:39:37,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:37,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:37,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:39:37,776] {scheduler_job.py:146} INFO - Started process (PID=24083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:42,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:42,788] {logging_mixin.py:95} INFO - [2019-08-27 20:39:42,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:43,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:43,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 20:39:43,236] {scheduler_job.py:146} INFO - Started process (PID=24084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:48,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:48,247] {logging_mixin.py:95} INFO - [2019-08-27 20:39:48,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:48,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:48,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-08-27 20:39:48,796] {scheduler_job.py:146} INFO - Started process (PID=24085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:53,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:53,807] {logging_mixin.py:95} INFO - [2019-08-27 20:39:53,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:54,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:54,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:39:54,249] {scheduler_job.py:146} INFO - Started process (PID=24087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:59,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:39:59,260] {logging_mixin.py:95} INFO - [2019-08-27 20:39:59,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:59,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:39:59,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-27 20:39:59,703] {scheduler_job.py:146} INFO - Started process (PID=24089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:04,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:04,711] {logging_mixin.py:95} INFO - [2019-08-27 20:40:04,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:05,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:05,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-27 20:40:05,162] {scheduler_job.py:146} INFO - Started process (PID=24092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:10,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:10,173] {logging_mixin.py:95} INFO - [2019-08-27 20:40:10,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:10,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:10,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-27 20:40:10,721] {scheduler_job.py:146} INFO - Started process (PID=24097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:15,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:15,732] {logging_mixin.py:95} INFO - [2019-08-27 20:40:15,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:16,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:16,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 20:40:16,168] {scheduler_job.py:146} INFO - Started process (PID=24098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:21,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:21,180] {logging_mixin.py:95} INFO - [2019-08-27 20:40:21,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:21,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:21,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 20:40:21,615] {scheduler_job.py:146} INFO - Started process (PID=24100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:26,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:26,624] {logging_mixin.py:95} INFO - [2019-08-27 20:40:26,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:27,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:27,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-27 20:40:27,067] {scheduler_job.py:146} INFO - Started process (PID=24102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:32,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:32,074] {logging_mixin.py:95} INFO - [2019-08-27 20:40:32,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:32,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:32,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:40:32,523] {scheduler_job.py:146} INFO - Started process (PID=24104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:37,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:37,533] {logging_mixin.py:95} INFO - [2019-08-27 20:40:37,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:37,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:37,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-27 20:40:37,982] {scheduler_job.py:146} INFO - Started process (PID=24106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:42,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:42,991] {logging_mixin.py:95} INFO - [2019-08-27 20:40:42,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:43,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:43,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:40:43,436] {scheduler_job.py:146} INFO - Started process (PID=24107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:48,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:48,446] {logging_mixin.py:95} INFO - [2019-08-27 20:40:48,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:48,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:48,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 20:40:48,889] {scheduler_job.py:146} INFO - Started process (PID=24109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:53,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:53,898] {logging_mixin.py:95} INFO - [2019-08-27 20:40:53,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:54,271] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:54,286] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 20:40:54,343] {scheduler_job.py:146} INFO - Started process (PID=24111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:59,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:40:59,349] {logging_mixin.py:95} INFO - [2019-08-27 20:40:59,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:59,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:40:59,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-27 20:40:59,796] {scheduler_job.py:146} INFO - Started process (PID=24112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:04,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:04,804] {logging_mixin.py:95} INFO - [2019-08-27 20:41:04,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:05,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:05,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:41:05,243] {scheduler_job.py:146} INFO - Started process (PID=24114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:10,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:10,264] {logging_mixin.py:95} INFO - [2019-08-27 20:41:10,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:10,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:10,641] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 20:41:10,686] {scheduler_job.py:146} INFO - Started process (PID=24116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:15,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:15,696] {logging_mixin.py:95} INFO - [2019-08-27 20:41:15,696] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:16,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:16,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:41:16,146] {scheduler_job.py:146} INFO - Started process (PID=24117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:21,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:21,156] {logging_mixin.py:95} INFO - [2019-08-27 20:41:21,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:21,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:21,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 20:41:21,596] {scheduler_job.py:146} INFO - Started process (PID=24119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:26,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:26,606] {logging_mixin.py:95} INFO - [2019-08-27 20:41:26,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:27,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:27,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-27 20:41:27,141] {scheduler_job.py:146} INFO - Started process (PID=24123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:32,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:32,148] {logging_mixin.py:95} INFO - [2019-08-27 20:41:32,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:32,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:32,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-27 20:41:32,688] {scheduler_job.py:146} INFO - Started process (PID=24125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:37,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:37,698] {logging_mixin.py:95} INFO - [2019-08-27 20:41:37,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:38,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:38,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-27 20:41:38,244] {scheduler_job.py:146} INFO - Started process (PID=24127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:43,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:43,252] {logging_mixin.py:95} INFO - [2019-08-27 20:41:43,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:43,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:43,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:41:43,699] {scheduler_job.py:146} INFO - Started process (PID=24128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:48,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:48,706] {logging_mixin.py:95} INFO - [2019-08-27 20:41:48,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:49,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:49,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-27 20:41:49,249] {scheduler_job.py:146} INFO - Started process (PID=24129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:54,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:54,261] {logging_mixin.py:95} INFO - [2019-08-27 20:41:54,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:54,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:54,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 20:41:54,698] {scheduler_job.py:146} INFO - Started process (PID=24131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:41:59,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:41:59,712] {logging_mixin.py:95} INFO - [2019-08-27 20:41:59,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:00,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:00,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-27 20:42:00,148] {scheduler_job.py:146} INFO - Started process (PID=24138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:05,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:05,155] {logging_mixin.py:95} INFO - [2019-08-27 20:42:05,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:05,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:05,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-27 20:42:05,698] {scheduler_job.py:146} INFO - Started process (PID=24141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:10,708] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:10,709] {logging_mixin.py:95} INFO - [2019-08-27 20:42:10,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:11,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:11,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-08-27 20:42:11,262] {scheduler_job.py:146} INFO - Started process (PID=24142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:16,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:16,272] {logging_mixin.py:95} INFO - [2019-08-27 20:42:16,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:16,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:16,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-27 20:42:16,714] {scheduler_job.py:146} INFO - Started process (PID=24143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:21,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:21,722] {logging_mixin.py:95} INFO - [2019-08-27 20:42:21,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:22,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:22,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-08-27 20:42:22,147] {scheduler_job.py:146} INFO - Started process (PID=24673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:27,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:27,157] {logging_mixin.py:95} INFO - [2019-08-27 20:42:27,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:27,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:27,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:42:27,600] {scheduler_job.py:146} INFO - Started process (PID=24675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:32,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:32,607] {logging_mixin.py:95} INFO - [2019-08-27 20:42:32,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:32,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:32,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:42:33,057] {scheduler_job.py:146} INFO - Started process (PID=24676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:38,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:38,075] {logging_mixin.py:95} INFO - [2019-08-27 20:42:38,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:38,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:38,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-27 20:42:38,615] {scheduler_job.py:146} INFO - Started process (PID=24679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:43,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:43,621] {logging_mixin.py:95} INFO - [2019-08-27 20:42:43,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:43,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:43,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:42:44,060] {scheduler_job.py:146} INFO - Started process (PID=24683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:49,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:49,067] {logging_mixin.py:95} INFO - [2019-08-27 20:42:49,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:49,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:49,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-27 20:42:49,605] {scheduler_job.py:146} INFO - Started process (PID=24687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:54,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:42:54,618] {logging_mixin.py:95} INFO - [2019-08-27 20:42:54,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:54,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:42:54,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:42:55,060] {scheduler_job.py:146} INFO - Started process (PID=24692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:00,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:00,069] {logging_mixin.py:95} INFO - [2019-08-27 20:43:00,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:00,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:00,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 20:43:00,511] {scheduler_job.py:146} INFO - Started process (PID=24693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:05,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:05,519] {logging_mixin.py:95} INFO - [2019-08-27 20:43:05,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:05,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:05,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 20:43:05,951] {scheduler_job.py:146} INFO - Started process (PID=24695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:10,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:10,959] {logging_mixin.py:95} INFO - [2019-08-27 20:43:10,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:11,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:11,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-27 20:43:11,392] {scheduler_job.py:146} INFO - Started process (PID=24705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:16,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:16,401] {logging_mixin.py:95} INFO - [2019-08-27 20:43:16,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:16,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:16,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 20:43:16,841] {scheduler_job.py:146} INFO - Started process (PID=24706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:21,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:21,852] {logging_mixin.py:95} INFO - [2019-08-27 20:43:21,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:22,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:22,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 20:43:22,296] {scheduler_job.py:146} INFO - Started process (PID=24709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:27,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:27,305] {logging_mixin.py:95} INFO - [2019-08-27 20:43:27,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:27,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:27,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 20:43:27,749] {scheduler_job.py:146} INFO - Started process (PID=24710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:32,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:32,756] {logging_mixin.py:95} INFO - [2019-08-27 20:43:32,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:33,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:33,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-27 20:43:33,200] {scheduler_job.py:146} INFO - Started process (PID=24714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:38,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:38,206] {logging_mixin.py:95} INFO - [2019-08-27 20:43:38,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:38,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:38,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-27 20:43:38,647] {scheduler_job.py:146} INFO - Started process (PID=24717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:43,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:43,655] {logging_mixin.py:95} INFO - [2019-08-27 20:43:43,654] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:44,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:44,036] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:43:44,108] {scheduler_job.py:146} INFO - Started process (PID=24718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:49,115] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:49,116] {logging_mixin.py:95} INFO - [2019-08-27 20:43:49,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:49,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:49,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-27 20:43:49,558] {scheduler_job.py:146} INFO - Started process (PID=24719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:54,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:43:54,566] {logging_mixin.py:95} INFO - [2019-08-27 20:43:54,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:54,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:43:54,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 20:43:55,017] {scheduler_job.py:146} INFO - Started process (PID=24722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:00,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:00,026] {logging_mixin.py:95} INFO - [2019-08-27 20:44:00,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:00,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:00,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-27 20:44:00,463] {scheduler_job.py:146} INFO - Started process (PID=24726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:05,474] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:05,475] {logging_mixin.py:95} INFO - [2019-08-27 20:44:05,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:05,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:05,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-27 20:44:05,908] {scheduler_job.py:146} INFO - Started process (PID=24729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:10,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:10,915] {logging_mixin.py:95} INFO - [2019-08-27 20:44:10,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:11,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:11,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-27 20:44:11,362] {scheduler_job.py:146} INFO - Started process (PID=24731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:16,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:16,371] {logging_mixin.py:95} INFO - [2019-08-27 20:44:16,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:16,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:16,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 20:44:16,810] {scheduler_job.py:146} INFO - Started process (PID=24732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:21,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:21,820] {logging_mixin.py:95} INFO - [2019-08-27 20:44:21,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:22,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:22,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-27 20:44:22,269] {scheduler_job.py:146} INFO - Started process (PID=24734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:27,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:27,279] {logging_mixin.py:95} INFO - [2019-08-27 20:44:27,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:27,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:27,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:44:27,730] {scheduler_job.py:146} INFO - Started process (PID=24735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:32,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:32,737] {logging_mixin.py:95} INFO - [2019-08-27 20:44:32,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:33,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:33,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:44:33,184] {scheduler_job.py:146} INFO - Started process (PID=24736) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:38,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:38,195] {logging_mixin.py:95} INFO - [2019-08-27 20:44:38,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:38,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:38,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:44:38,638] {scheduler_job.py:146} INFO - Started process (PID=24738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:43,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:43,644] {logging_mixin.py:95} INFO - [2019-08-27 20:44:43,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:44,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:44,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-27 20:44:44,093] {scheduler_job.py:146} INFO - Started process (PID=24740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:49,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:49,102] {logging_mixin.py:95} INFO - [2019-08-27 20:44:49,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:49,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:49,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 20:44:49,534] {scheduler_job.py:146} INFO - Started process (PID=24742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:54,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:54,543] {logging_mixin.py:95} INFO - [2019-08-27 20:44:54,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:54,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:54,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-27 20:44:54,982] {scheduler_job.py:146} INFO - Started process (PID=24744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:44:59,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:44:59,990] {logging_mixin.py:95} INFO - [2019-08-27 20:44:59,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:00,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:00,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-27 20:45:00,525] {scheduler_job.py:146} INFO - Started process (PID=24745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:05,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:05,533] {logging_mixin.py:95} INFO - [2019-08-27 20:45:05,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:05,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:05,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:45:05,973] {scheduler_job.py:146} INFO - Started process (PID=24747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:10,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:10,979] {logging_mixin.py:95} INFO - [2019-08-27 20:45:10,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:11,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:11,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-27 20:45:11,430] {scheduler_job.py:146} INFO - Started process (PID=24748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:16,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:16,437] {logging_mixin.py:95} INFO - [2019-08-27 20:45:16,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:16,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:16,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:45:16,887] {scheduler_job.py:146} INFO - Started process (PID=24750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:21,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:21,896] {logging_mixin.py:95} INFO - [2019-08-27 20:45:21,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:22,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:22,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-27 20:45:22,345] {scheduler_job.py:146} INFO - Started process (PID=24752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:27,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:27,352] {logging_mixin.py:95} INFO - [2019-08-27 20:45:27,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:27,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:27,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-27 20:45:27,904] {scheduler_job.py:146} INFO - Started process (PID=24753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:32,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:32,913] {logging_mixin.py:95} INFO - [2019-08-27 20:45:32,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:33,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:33,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-27 20:45:33,446] {scheduler_job.py:146} INFO - Started process (PID=24754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:38,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:38,453] {logging_mixin.py:95} INFO - [2019-08-27 20:45:38,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:38,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:38,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-27 20:45:38,994] {scheduler_job.py:146} INFO - Started process (PID=24756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:43,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:44,000] {logging_mixin.py:95} INFO - [2019-08-27 20:45:44,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:44,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:44,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-27 20:45:44,536] {scheduler_job.py:146} INFO - Started process (PID=24758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:49,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:49,542] {logging_mixin.py:95} INFO - [2019-08-27 20:45:49,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:49,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:49,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 20:45:49,989] {scheduler_job.py:146} INFO - Started process (PID=24759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:54,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:45:55,006] {logging_mixin.py:95} INFO - [2019-08-27 20:45:55,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:55,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:45:55,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:45:55,444] {scheduler_job.py:146} INFO - Started process (PID=24761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:00,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:00,455] {logging_mixin.py:95} INFO - [2019-08-27 20:46:00,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:00,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:00,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:46:00,887] {scheduler_job.py:146} INFO - Started process (PID=24762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:05,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:05,897] {logging_mixin.py:95} INFO - [2019-08-27 20:46:05,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:06,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:06,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:46:06,335] {scheduler_job.py:146} INFO - Started process (PID=24764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:11,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:11,346] {logging_mixin.py:95} INFO - [2019-08-27 20:46:11,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:11,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:11,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:46:11,782] {scheduler_job.py:146} INFO - Started process (PID=24765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:16,788] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:16,789] {logging_mixin.py:95} INFO - [2019-08-27 20:46:16,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:17,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:17,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-27 20:46:17,239] {scheduler_job.py:146} INFO - Started process (PID=24767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:22,245] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:22,246] {logging_mixin.py:95} INFO - [2019-08-27 20:46:22,246] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:22,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:22,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:46:22,701] {scheduler_job.py:146} INFO - Started process (PID=24769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:27,710] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:27,711] {logging_mixin.py:95} INFO - [2019-08-27 20:46:27,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:28,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:28,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-27 20:46:28,166] {scheduler_job.py:146} INFO - Started process (PID=24770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:33,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:33,175] {logging_mixin.py:95} INFO - [2019-08-27 20:46:33,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:33,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:33,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:46:33,632] {scheduler_job.py:146} INFO - Started process (PID=24771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:38,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:38,638] {logging_mixin.py:95} INFO - [2019-08-27 20:46:38,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:38,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:39,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-27 20:46:39,093] {scheduler_job.py:146} INFO - Started process (PID=24773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:44,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:44,102] {logging_mixin.py:95} INFO - [2019-08-27 20:46:44,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:44,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:44,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:46:44,556] {scheduler_job.py:146} INFO - Started process (PID=24774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:49,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:49,566] {logging_mixin.py:95} INFO - [2019-08-27 20:46:49,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:50,140] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:50,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.600 seconds
[2019-08-27 20:46:50,212] {scheduler_job.py:146} INFO - Started process (PID=24778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:55,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:46:55,222] {logging_mixin.py:95} INFO - [2019-08-27 20:46:55,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:55,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:46:55,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-27 20:46:55,758] {scheduler_job.py:146} INFO - Started process (PID=24780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:00,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:00,764] {logging_mixin.py:95} INFO - [2019-08-27 20:47:00,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:01,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:01,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:47:01,198] {scheduler_job.py:146} INFO - Started process (PID=24784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:06,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:06,208] {logging_mixin.py:95} INFO - [2019-08-27 20:47:06,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:06,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:06,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:47:06,649] {scheduler_job.py:146} INFO - Started process (PID=24787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:11,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:11,656] {logging_mixin.py:95} INFO - [2019-08-27 20:47:11,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:12,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:12,023] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-08-27 20:47:12,100] {scheduler_job.py:146} INFO - Started process (PID=24788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:17,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:17,110] {logging_mixin.py:95} INFO - [2019-08-27 20:47:17,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:17,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:17,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 20:47:17,551] {scheduler_job.py:146} INFO - Started process (PID=24789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:22,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:22,558] {logging_mixin.py:95} INFO - [2019-08-27 20:47:22,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:22,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:22,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:47:22,999] {scheduler_job.py:146} INFO - Started process (PID=24792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:28,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:28,007] {logging_mixin.py:95} INFO - [2019-08-27 20:47:28,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:28,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:28,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 20:47:28,448] {scheduler_job.py:146} INFO - Started process (PID=24793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:33,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:33,459] {logging_mixin.py:95} INFO - [2019-08-27 20:47:33,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:33,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:33,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 20:47:33,892] {scheduler_job.py:146} INFO - Started process (PID=24794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:38,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:38,902] {logging_mixin.py:95} INFO - [2019-08-27 20:47:38,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:39,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:39,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-08-27 20:47:39,354] {scheduler_job.py:146} INFO - Started process (PID=24796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:44,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:44,363] {logging_mixin.py:95} INFO - [2019-08-27 20:47:44,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:44,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:44,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 20:47:44,797] {scheduler_job.py:146} INFO - Started process (PID=24797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:49,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:49,806] {logging_mixin.py:95} INFO - [2019-08-27 20:47:49,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:50,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:50,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-27 20:47:50,343] {scheduler_job.py:146} INFO - Started process (PID=24800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:55,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:47:55,351] {logging_mixin.py:95} INFO - [2019-08-27 20:47:55,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:55,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:47:55,759] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 20:47:55,784] {scheduler_job.py:146} INFO - Started process (PID=24802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:00,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:00,795] {logging_mixin.py:95} INFO - [2019-08-27 20:48:00,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:01,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:01,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-27 20:48:01,228] {scheduler_job.py:146} INFO - Started process (PID=24803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:06,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:06,235] {logging_mixin.py:95} INFO - [2019-08-27 20:48:06,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:06,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:06,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 20:48:06,676] {scheduler_job.py:146} INFO - Started process (PID=24805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:11,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:11,687] {logging_mixin.py:95} INFO - [2019-08-27 20:48:11,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:12,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:12,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:48:12,127] {scheduler_job.py:146} INFO - Started process (PID=24806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:17,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:17,137] {logging_mixin.py:95} INFO - [2019-08-27 20:48:17,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:17,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:17,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 20:48:17,580] {scheduler_job.py:146} INFO - Started process (PID=24807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:22,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:22,590] {logging_mixin.py:95} INFO - [2019-08-27 20:48:22,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:22,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:23,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-27 20:48:23,049] {scheduler_job.py:146} INFO - Started process (PID=24810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:28,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:28,058] {logging_mixin.py:95} INFO - [2019-08-27 20:48:28,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:28,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:28,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:48:28,497] {scheduler_job.py:146} INFO - Started process (PID=24811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:33,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:33,503] {logging_mixin.py:95} INFO - [2019-08-27 20:48:33,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:33,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:33,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-27 20:48:33,955] {scheduler_job.py:146} INFO - Started process (PID=24812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:38,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:38,966] {logging_mixin.py:95} INFO - [2019-08-27 20:48:38,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:39,325] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:39,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 20:48:39,403] {scheduler_job.py:146} INFO - Started process (PID=24814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:44,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:44,411] {logging_mixin.py:95} INFO - [2019-08-27 20:48:44,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:44,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:44,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-27 20:48:44,860] {scheduler_job.py:146} INFO - Started process (PID=24815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:49,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:49,866] {logging_mixin.py:95} INFO - [2019-08-27 20:48:49,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:50,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:50,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:48:50,310] {scheduler_job.py:146} INFO - Started process (PID=24816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:55,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:48:55,317] {logging_mixin.py:95} INFO - [2019-08-27 20:48:55,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:55,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:48:55,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:48:55,757] {scheduler_job.py:146} INFO - Started process (PID=24819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:00,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:00,766] {logging_mixin.py:95} INFO - [2019-08-27 20:49:00,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:01,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:01,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 20:49:01,208] {scheduler_job.py:146} INFO - Started process (PID=24820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:06,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:06,215] {logging_mixin.py:95} INFO - [2019-08-27 20:49:06,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:06,602] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:06,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 20:49:06,654] {scheduler_job.py:146} INFO - Started process (PID=24822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:11,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:11,662] {logging_mixin.py:95} INFO - [2019-08-27 20:49:11,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:12,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:12,058] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 20:49:12,103] {scheduler_job.py:146} INFO - Started process (PID=24826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:17,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:17,109] {logging_mixin.py:95} INFO - [2019-08-27 20:49:17,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:17,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:17,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-27 20:49:17,558] {scheduler_job.py:146} INFO - Started process (PID=24827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:22,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:22,567] {logging_mixin.py:95} INFO - [2019-08-27 20:49:22,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:22,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:22,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:49:23,013] {scheduler_job.py:146} INFO - Started process (PID=24829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:28,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:28,020] {logging_mixin.py:95} INFO - [2019-08-27 20:49:28,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:28,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:28,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-27 20:49:28,463] {scheduler_job.py:146} INFO - Started process (PID=24831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:33,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:33,474] {logging_mixin.py:95} INFO - [2019-08-27 20:49:33,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:33,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:33,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:49:33,911] {scheduler_job.py:146} INFO - Started process (PID=24832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:38,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:38,923] {logging_mixin.py:95} INFO - [2019-08-27 20:49:38,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:39,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:39,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 20:49:39,367] {scheduler_job.py:146} INFO - Started process (PID=24834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:44,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:44,373] {logging_mixin.py:95} INFO - [2019-08-27 20:49:44,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:44,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:44,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:49:44,822] {scheduler_job.py:146} INFO - Started process (PID=24838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:49,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:49,833] {logging_mixin.py:95} INFO - [2019-08-27 20:49:49,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:50,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:50,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 20:49:50,290] {scheduler_job.py:146} INFO - Started process (PID=24840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:55,299] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:49:55,300] {logging_mixin.py:95} INFO - [2019-08-27 20:49:55,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:55,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:49:55,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 20:49:55,747] {scheduler_job.py:146} INFO - Started process (PID=24842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:00,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:00,755] {logging_mixin.py:95} INFO - [2019-08-27 20:50:00,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:01,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:01,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-27 20:50:01,208] {scheduler_job.py:146} INFO - Started process (PID=24844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:06,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:06,217] {logging_mixin.py:95} INFO - [2019-08-27 20:50:06,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:06,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:06,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:50:06,667] {scheduler_job.py:146} INFO - Started process (PID=24846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:11,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:11,678] {logging_mixin.py:95} INFO - [2019-08-27 20:50:11,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:12,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:12,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 20:50:12,121] {scheduler_job.py:146} INFO - Started process (PID=24847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:17,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:17,128] {logging_mixin.py:95} INFO - [2019-08-27 20:50:17,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:17,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:17,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:50:17,580] {scheduler_job.py:146} INFO - Started process (PID=24848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:22,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:22,589] {logging_mixin.py:95} INFO - [2019-08-27 20:50:22,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:22,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:22,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:50:23,042] {scheduler_job.py:146} INFO - Started process (PID=24850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:28,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:28,048] {logging_mixin.py:95} INFO - [2019-08-27 20:50:28,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:28,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:28,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:50:28,481] {scheduler_job.py:146} INFO - Started process (PID=24852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:33,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:33,488] {logging_mixin.py:95} INFO - [2019-08-27 20:50:33,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:33,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:33,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 20:50:33,927] {scheduler_job.py:146} INFO - Started process (PID=24853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:38,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:38,938] {logging_mixin.py:95} INFO - [2019-08-27 20:50:38,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:39,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:39,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 20:50:39,398] {scheduler_job.py:146} INFO - Started process (PID=24855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:44,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:44,408] {logging_mixin.py:95} INFO - [2019-08-27 20:50:44,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:44,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:44,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 20:50:44,827] {scheduler_job.py:146} INFO - Started process (PID=24856) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:49,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:49,838] {logging_mixin.py:95} INFO - [2019-08-27 20:50:49,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:50,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:50,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:50:50,274] {scheduler_job.py:146} INFO - Started process (PID=24858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:55,279] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:50:55,280] {logging_mixin.py:95} INFO - [2019-08-27 20:50:55,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:55,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:50:55,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 20:50:55,728] {scheduler_job.py:146} INFO - Started process (PID=24860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:00,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:00,738] {logging_mixin.py:95} INFO - [2019-08-27 20:51:00,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:01,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:01,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:51:01,187] {scheduler_job.py:146} INFO - Started process (PID=24862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:06,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:06,196] {logging_mixin.py:95} INFO - [2019-08-27 20:51:06,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:06,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:06,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:51:06,641] {scheduler_job.py:146} INFO - Started process (PID=24864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:11,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:11,646] {logging_mixin.py:95} INFO - [2019-08-27 20:51:11,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:12,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:12,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 20:51:12,086] {scheduler_job.py:146} INFO - Started process (PID=24868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:17,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:17,094] {logging_mixin.py:95} INFO - [2019-08-27 20:51:17,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:17,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:17,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 20:51:17,547] {scheduler_job.py:146} INFO - Started process (PID=24869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:22,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:22,554] {logging_mixin.py:95} INFO - [2019-08-27 20:51:22,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:22,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:22,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-27 20:51:23,016] {scheduler_job.py:146} INFO - Started process (PID=24871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:28,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:28,026] {logging_mixin.py:95} INFO - [2019-08-27 20:51:28,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:28,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:28,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:51:28,473] {scheduler_job.py:146} INFO - Started process (PID=24872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:33,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:33,486] {logging_mixin.py:95} INFO - [2019-08-27 20:51:33,486] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:33,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:33,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:51:33,930] {scheduler_job.py:146} INFO - Started process (PID=24874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:38,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:38,941] {logging_mixin.py:95} INFO - [2019-08-27 20:51:38,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:39,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:39,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:51:39,379] {scheduler_job.py:146} INFO - Started process (PID=24876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:44,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:44,387] {logging_mixin.py:95} INFO - [2019-08-27 20:51:44,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:44,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:44,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 20:51:44,824] {scheduler_job.py:146} INFO - Started process (PID=24877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:49,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:49,835] {logging_mixin.py:95} INFO - [2019-08-27 20:51:49,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:50,222] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:50,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-27 20:51:50,362] {scheduler_job.py:146} INFO - Started process (PID=24879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:55,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:51:55,371] {logging_mixin.py:95} INFO - [2019-08-27 20:51:55,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:55,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:51:55,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 20:51:55,809] {scheduler_job.py:146} INFO - Started process (PID=24881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:00,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:00,820] {logging_mixin.py:95} INFO - [2019-08-27 20:52:00,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:01,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:01,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 20:52:01,257] {scheduler_job.py:146} INFO - Started process (PID=24882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:06,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:06,270] {logging_mixin.py:95} INFO - [2019-08-27 20:52:06,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:06,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:06,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-27 20:52:06,806] {scheduler_job.py:146} INFO - Started process (PID=24885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:11,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:11,813] {logging_mixin.py:95} INFO - [2019-08-27 20:52:11,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:12,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:12,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:52:12,258] {scheduler_job.py:146} INFO - Started process (PID=24887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:17,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:17,266] {logging_mixin.py:95} INFO - [2019-08-27 20:52:17,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:17,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:17,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 20:52:17,712] {scheduler_job.py:146} INFO - Started process (PID=24892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:22,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:22,721] {logging_mixin.py:95} INFO - [2019-08-27 20:52:22,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:23,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:23,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-27 20:52:23,251] {scheduler_job.py:146} INFO - Started process (PID=24919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:28,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:28,261] {logging_mixin.py:95} INFO - [2019-08-27 20:52:28,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:28,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:28,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:52:28,697] {scheduler_job.py:146} INFO - Started process (PID=25436) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:33,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:33,702] {logging_mixin.py:95} INFO - [2019-08-27 20:52:33,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:34,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:34,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 20:52:34,140] {scheduler_job.py:146} INFO - Started process (PID=26479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:39,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:39,147] {logging_mixin.py:95} INFO - [2019-08-27 20:52:39,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:39,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:39,636] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.496 seconds
[2019-08-27 20:52:39,701] {scheduler_job.py:146} INFO - Started process (PID=26481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:44,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:44,711] {logging_mixin.py:95} INFO - [2019-08-27 20:52:44,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:45,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:45,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-08-27 20:52:45,251] {scheduler_job.py:146} INFO - Started process (PID=26482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:50,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:50,259] {logging_mixin.py:95} INFO - [2019-08-27 20:52:50,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:50,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:50,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-08-27 20:52:50,810] {scheduler_job.py:146} INFO - Started process (PID=26484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:55,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:52:55,819] {logging_mixin.py:95} INFO - [2019-08-27 20:52:55,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:56,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:52:56,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.501 seconds
[2019-08-27 20:52:56,364] {scheduler_job.py:146} INFO - Started process (PID=26486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:01,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:01,369] {logging_mixin.py:95} INFO - [2019-08-27 20:53:01,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:01,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:01,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-08-27 20:53:01,916] {scheduler_job.py:146} INFO - Started process (PID=26490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:06,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:06,923] {logging_mixin.py:95} INFO - [2019-08-27 20:53:06,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:07,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:07,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-27 20:53:07,464] {scheduler_job.py:146} INFO - Started process (PID=26493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:12,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:12,470] {logging_mixin.py:95} INFO - [2019-08-27 20:53:12,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:12,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:12,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-08-27 20:53:13,020] {scheduler_job.py:146} INFO - Started process (PID=26494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:18,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:18,027] {logging_mixin.py:95} INFO - [2019-08-27 20:53:18,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:18,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:18,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.527 seconds
[2019-08-27 20:53:18,576] {scheduler_job.py:146} INFO - Started process (PID=26495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:23,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:23,586] {logging_mixin.py:95} INFO - [2019-08-27 20:53:23,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:24,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:24,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-08-27 20:53:24,129] {scheduler_job.py:146} INFO - Started process (PID=26497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:29,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:29,139] {logging_mixin.py:95} INFO - [2019-08-27 20:53:29,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:29,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:29,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-27 20:53:29,673] {scheduler_job.py:146} INFO - Started process (PID=26514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:34,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:34,682] {logging_mixin.py:95} INFO - [2019-08-27 20:53:34,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:35,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:35,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:53:35,123] {scheduler_job.py:146} INFO - Started process (PID=26518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:40,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:40,157] {logging_mixin.py:95} INFO - [2019-08-27 20:53:40,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:40,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:40,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 20:53:40,579] {scheduler_job.py:146} INFO - Started process (PID=26521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:45,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:45,590] {logging_mixin.py:95} INFO - [2019-08-27 20:53:45,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:45,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:45,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 20:53:46,034] {scheduler_job.py:146} INFO - Started process (PID=26522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:51,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:51,043] {logging_mixin.py:95} INFO - [2019-08-27 20:53:51,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:51,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:51,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 20:53:51,489] {scheduler_job.py:146} INFO - Started process (PID=26529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:56,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:53:56,495] {logging_mixin.py:95} INFO - [2019-08-27 20:53:56,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:56,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:53:56,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-27 20:53:56,947] {scheduler_job.py:146} INFO - Started process (PID=26530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:01,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:01,955] {logging_mixin.py:95} INFO - [2019-08-27 20:54:01,955] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:02,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:02,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:54:02,402] {scheduler_job.py:146} INFO - Started process (PID=26531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:07,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:07,411] {logging_mixin.py:95} INFO - [2019-08-27 20:54:07,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:07,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:07,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-27 20:54:07,858] {scheduler_job.py:146} INFO - Started process (PID=26533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:12,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:12,865] {logging_mixin.py:95} INFO - [2019-08-27 20:54:12,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:13,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:13,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-27 20:54:13,317] {scheduler_job.py:146} INFO - Started process (PID=26535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:18,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:18,328] {logging_mixin.py:95} INFO - [2019-08-27 20:54:18,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:18,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:18,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 20:54:18,776] {scheduler_job.py:146} INFO - Started process (PID=26536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:23,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:23,786] {logging_mixin.py:95} INFO - [2019-08-27 20:54:23,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:24,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:24,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:54:24,234] {scheduler_job.py:146} INFO - Started process (PID=26538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:29,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:29,241] {logging_mixin.py:95} INFO - [2019-08-27 20:54:29,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:29,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:29,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-27 20:54:29,688] {scheduler_job.py:146} INFO - Started process (PID=26539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:34,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:34,698] {logging_mixin.py:95} INFO - [2019-08-27 20:54:34,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:35,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:35,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:54:35,150] {scheduler_job.py:146} INFO - Started process (PID=26540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:40,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:40,160] {logging_mixin.py:95} INFO - [2019-08-27 20:54:40,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:40,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:40,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-08-27 20:54:40,608] {scheduler_job.py:146} INFO - Started process (PID=26543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:45,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:45,620] {logging_mixin.py:95} INFO - [2019-08-27 20:54:45,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:46,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:46,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-27 20:54:46,164] {scheduler_job.py:146} INFO - Started process (PID=26544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:51,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:51,181] {logging_mixin.py:95} INFO - [2019-08-27 20:54:51,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:51,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:51,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-27 20:54:51,711] {scheduler_job.py:146} INFO - Started process (PID=26546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:56,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:54:56,718] {logging_mixin.py:95} INFO - [2019-08-27 20:54:56,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:57,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:54:57,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-27 20:54:57,163] {scheduler_job.py:146} INFO - Started process (PID=26547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:02,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:02,173] {logging_mixin.py:95} INFO - [2019-08-27 20:55:02,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:02,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:02,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-08-27 20:55:02,718] {scheduler_job.py:146} INFO - Started process (PID=26548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:07,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:07,728] {logging_mixin.py:95} INFO - [2019-08-27 20:55:07,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:08,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:08,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-27 20:55:08,260] {scheduler_job.py:146} INFO - Started process (PID=26552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:13,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:13,273] {logging_mixin.py:95} INFO - [2019-08-27 20:55:13,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:13,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:13,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-27 20:55:13,811] {scheduler_job.py:146} INFO - Started process (PID=26555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:18,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:18,822] {logging_mixin.py:95} INFO - [2019-08-27 20:55:18,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:19,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:19,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-08-27 20:55:19,366] {scheduler_job.py:146} INFO - Started process (PID=26557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:24,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:24,373] {logging_mixin.py:95} INFO - [2019-08-27 20:55:24,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:24,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:24,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 20:55:24,813] {scheduler_job.py:146} INFO - Started process (PID=26559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:29,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:29,820] {logging_mixin.py:95} INFO - [2019-08-27 20:55:29,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:30,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:30,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 20:55:30,268] {scheduler_job.py:146} INFO - Started process (PID=26561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:35,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:35,283] {logging_mixin.py:95} INFO - [2019-08-27 20:55:35,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:35,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:35,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-08-27 20:55:35,813] {scheduler_job.py:146} INFO - Started process (PID=26563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:40,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:40,822] {logging_mixin.py:95} INFO - [2019-08-27 20:55:40,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:41,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:41,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:55:41,262] {scheduler_job.py:146} INFO - Started process (PID=26565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:46,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:46,270] {logging_mixin.py:95} INFO - [2019-08-27 20:55:46,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:46,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:46,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 20:55:46,712] {scheduler_job.py:146} INFO - Started process (PID=26567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:51,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:51,723] {logging_mixin.py:95} INFO - [2019-08-27 20:55:51,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:52,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:52,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:55:52,162] {scheduler_job.py:146} INFO - Started process (PID=26574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:57,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:55:57,171] {logging_mixin.py:95} INFO - [2019-08-27 20:55:57,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:57,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:55:57,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 20:55:57,617] {scheduler_job.py:146} INFO - Started process (PID=26575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:02,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:02,627] {logging_mixin.py:95} INFO - [2019-08-27 20:56:02,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:02,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:03,011] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:56:03,071] {scheduler_job.py:146} INFO - Started process (PID=26576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:08,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:08,078] {logging_mixin.py:95} INFO - [2019-08-27 20:56:08,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:08,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:08,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 20:56:08,517] {scheduler_job.py:146} INFO - Started process (PID=26578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:13,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:13,526] {logging_mixin.py:95} INFO - [2019-08-27 20:56:13,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:13,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:13,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 20:56:13,972] {scheduler_job.py:146} INFO - Started process (PID=26579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:18,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:18,982] {logging_mixin.py:95} INFO - [2019-08-27 20:56:18,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:19,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:19,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 20:56:19,422] {scheduler_job.py:146} INFO - Started process (PID=26581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:24,429] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:24,431] {logging_mixin.py:95} INFO - [2019-08-27 20:56:24,430] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:24,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:24,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 20:56:24,884] {scheduler_job.py:146} INFO - Started process (PID=26583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:29,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:29,891] {logging_mixin.py:95} INFO - [2019-08-27 20:56:29,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:30,298] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:30,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-27 20:56:30,433] {scheduler_job.py:146} INFO - Started process (PID=26584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:35,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:35,440] {logging_mixin.py:95} INFO - [2019-08-27 20:56:35,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:35,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:35,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 20:56:35,884] {scheduler_job.py:146} INFO - Started process (PID=26585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:40,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:40,890] {logging_mixin.py:95} INFO - [2019-08-27 20:56:40,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:41,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:41,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 20:56:41,342] {scheduler_job.py:146} INFO - Started process (PID=26587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:46,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:46,352] {logging_mixin.py:95} INFO - [2019-08-27 20:56:46,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:46,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:46,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-27 20:56:46,891] {scheduler_job.py:146} INFO - Started process (PID=26589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:51,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:51,899] {logging_mixin.py:95} INFO - [2019-08-27 20:56:51,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:52,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:52,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:56:52,340] {scheduler_job.py:146} INFO - Started process (PID=26591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:57,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:56:57,350] {logging_mixin.py:95} INFO - [2019-08-27 20:56:57,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:57,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:56:57,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-08-27 20:56:57,894] {scheduler_job.py:146} INFO - Started process (PID=26592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:02,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:02,905] {logging_mixin.py:95} INFO - [2019-08-27 20:57:02,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:03,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:03,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-27 20:57:03,348] {scheduler_job.py:146} INFO - Started process (PID=26593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:08,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:08,356] {logging_mixin.py:95} INFO - [2019-08-27 20:57:08,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:08,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:08,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 20:57:08,801] {scheduler_job.py:146} INFO - Started process (PID=26595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:13,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:13,808] {logging_mixin.py:95} INFO - [2019-08-27 20:57:13,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:14,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:14,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-27 20:57:14,351] {scheduler_job.py:146} INFO - Started process (PID=26596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:19,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:19,359] {logging_mixin.py:95} INFO - [2019-08-27 20:57:19,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:19,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:19,754] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 20:57:19,802] {scheduler_job.py:146} INFO - Started process (PID=26598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:24,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:24,811] {logging_mixin.py:95} INFO - [2019-08-27 20:57:24,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:25,182] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:25,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 20:57:25,248] {scheduler_job.py:146} INFO - Started process (PID=26600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:30,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:30,255] {logging_mixin.py:95} INFO - [2019-08-27 20:57:30,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:30,626] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:30,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 20:57:30,692] {scheduler_job.py:146} INFO - Started process (PID=26602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:35,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:35,704] {logging_mixin.py:95} INFO - [2019-08-27 20:57:35,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:36,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:36,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-27 20:57:36,244] {scheduler_job.py:146} INFO - Started process (PID=26604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:41,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:41,252] {logging_mixin.py:95} INFO - [2019-08-27 20:57:41,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:41,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:41,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 20:57:41,705] {scheduler_job.py:146} INFO - Started process (PID=26606) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:46,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:46,711] {logging_mixin.py:95} INFO - [2019-08-27 20:57:46,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:47,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:47,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-27 20:57:47,248] {scheduler_job.py:146} INFO - Started process (PID=26608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:52,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:52,254] {logging_mixin.py:95} INFO - [2019-08-27 20:57:52,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:52,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:52,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-27 20:57:52,698] {scheduler_job.py:146} INFO - Started process (PID=26612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:57,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:57:57,710] {logging_mixin.py:95} INFO - [2019-08-27 20:57:57,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:58,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:57:58,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 20:57:58,146] {scheduler_job.py:146} INFO - Started process (PID=26613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:03,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:03,157] {logging_mixin.py:95} INFO - [2019-08-27 20:58:03,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:03,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:03,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-27 20:58:03,606] {scheduler_job.py:146} INFO - Started process (PID=26614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:08,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:08,618] {logging_mixin.py:95} INFO - [2019-08-27 20:58:08,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:09,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:09,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 20:58:09,055] {scheduler_job.py:146} INFO - Started process (PID=26616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:14,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:14,068] {logging_mixin.py:95} INFO - [2019-08-27 20:58:14,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:14,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:14,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:58:14,513] {scheduler_job.py:146} INFO - Started process (PID=26617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:19,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:19,522] {logging_mixin.py:95} INFO - [2019-08-27 20:58:19,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:19,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:19,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-27 20:58:19,973] {scheduler_job.py:146} INFO - Started process (PID=26618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:24,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:24,986] {logging_mixin.py:95} INFO - [2019-08-27 20:58:24,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:25,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:25,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:58:25,421] {scheduler_job.py:146} INFO - Started process (PID=26621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:30,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:30,434] {logging_mixin.py:95} INFO - [2019-08-27 20:58:30,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:30,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:30,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-27 20:58:30,881] {scheduler_job.py:146} INFO - Started process (PID=26622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:35,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:35,890] {logging_mixin.py:95} INFO - [2019-08-27 20:58:35,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:36,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:36,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 20:58:36,338] {scheduler_job.py:146} INFO - Started process (PID=26624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:41,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:41,360] {logging_mixin.py:95} INFO - [2019-08-27 20:58:41,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:41,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:41,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 20:58:41,800] {scheduler_job.py:146} INFO - Started process (PID=26625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:46,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:46,812] {logging_mixin.py:95} INFO - [2019-08-27 20:58:46,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:47,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:47,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-27 20:58:47,251] {scheduler_job.py:146} INFO - Started process (PID=26626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:52,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:52,258] {logging_mixin.py:95} INFO - [2019-08-27 20:58:52,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:52,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:52,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-08-27 20:58:52,697] {scheduler_job.py:146} INFO - Started process (PID=26630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:57,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:58:57,705] {logging_mixin.py:95} INFO - [2019-08-27 20:58:57,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:58,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:58:58,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-27 20:58:58,152] {scheduler_job.py:146} INFO - Started process (PID=26631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:03,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:03,160] {logging_mixin.py:95} INFO - [2019-08-27 20:59:03,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:03,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:03,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 20:59:03,591] {scheduler_job.py:146} INFO - Started process (PID=26632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:08,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:08,599] {logging_mixin.py:95} INFO - [2019-08-27 20:59:08,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:08,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:08,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 20:59:09,034] {scheduler_job.py:146} INFO - Started process (PID=26635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:14,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:14,044] {logging_mixin.py:95} INFO - [2019-08-27 20:59:14,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:14,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:14,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 20:59:14,492] {scheduler_job.py:146} INFO - Started process (PID=26636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:19,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:19,502] {logging_mixin.py:95} INFO - [2019-08-27 20:59:19,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:19,857] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:19,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-27 20:59:19,953] {scheduler_job.py:146} INFO - Started process (PID=26637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:24,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:24,960] {logging_mixin.py:95} INFO - [2019-08-27 20:59:24,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:25,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:25,342] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-27 20:59:25,406] {scheduler_job.py:146} INFO - Started process (PID=26640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:30,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:30,418] {logging_mixin.py:95} INFO - [2019-08-27 20:59:30,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:30,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:30,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 20:59:30,856] {scheduler_job.py:146} INFO - Started process (PID=26641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:35,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:35,868] {logging_mixin.py:95} INFO - [2019-08-27 20:59:35,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:36,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:36,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 20:59:36,314] {scheduler_job.py:146} INFO - Started process (PID=26642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:41,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:41,333] {logging_mixin.py:95} INFO - [2019-08-27 20:59:41,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:41,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:41,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-27 20:59:41,774] {scheduler_job.py:146} INFO - Started process (PID=26644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:46,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:46,787] {logging_mixin.py:95} INFO - [2019-08-27 20:59:46,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:47,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:47,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:59:47,236] {scheduler_job.py:146} INFO - Started process (PID=26645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:52,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:52,245] {logging_mixin.py:95} INFO - [2019-08-27 20:59:52,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:52,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:52,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-08-27 20:59:52,693] {scheduler_job.py:146} INFO - Started process (PID=26647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:57,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 20:59:57,702] {logging_mixin.py:95} INFO - [2019-08-27 20:59:57,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:58,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 20:59:58,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 20:59:58,147] {scheduler_job.py:146} INFO - Started process (PID=26649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:03,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:03,157] {logging_mixin.py:95} INFO - [2019-08-27 21:00:03,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:03,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:03,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 21:00:03,591] {scheduler_job.py:146} INFO - Started process (PID=26651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:08,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:08,602] {logging_mixin.py:95} INFO - [2019-08-27 21:00:08,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:08,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:09,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:00:09,040] {scheduler_job.py:146} INFO - Started process (PID=26653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:14,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:14,053] {logging_mixin.py:95} INFO - [2019-08-27 21:00:14,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:14,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:14,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 21:00:14,495] {scheduler_job.py:146} INFO - Started process (PID=26654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:19,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:19,505] {logging_mixin.py:95} INFO - [2019-08-27 21:00:19,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:19,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:19,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:00:19,954] {scheduler_job.py:146} INFO - Started process (PID=26655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:24,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:24,966] {logging_mixin.py:95} INFO - [2019-08-27 21:00:24,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:25,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:25,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:00:25,405] {scheduler_job.py:146} INFO - Started process (PID=26657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:30,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:30,412] {logging_mixin.py:95} INFO - [2019-08-27 21:00:30,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:30,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:30,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 21:00:30,861] {scheduler_job.py:146} INFO - Started process (PID=26659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:35,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:35,869] {logging_mixin.py:95} INFO - [2019-08-27 21:00:35,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:36,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:36,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:00:36,313] {scheduler_job.py:146} INFO - Started process (PID=26660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:41,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:41,321] {logging_mixin.py:95} INFO - [2019-08-27 21:00:41,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:41,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:41,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:00:41,768] {scheduler_job.py:146} INFO - Started process (PID=26662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:46,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:46,776] {logging_mixin.py:95} INFO - [2019-08-27 21:00:46,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:47,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:47,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:00:47,226] {scheduler_job.py:146} INFO - Started process (PID=26663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:52,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:52,236] {logging_mixin.py:95} INFO - [2019-08-27 21:00:52,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:52,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:52,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:00:52,672] {scheduler_job.py:146} INFO - Started process (PID=26667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:57,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:00:57,680] {logging_mixin.py:95} INFO - [2019-08-27 21:00:57,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:58,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:00:58,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-27 21:00:58,218] {scheduler_job.py:146} INFO - Started process (PID=26669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:03,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:03,227] {logging_mixin.py:95} INFO - [2019-08-27 21:01:03,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:03,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:03,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:01:03,680] {scheduler_job.py:146} INFO - Started process (PID=26670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:08,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:08,689] {logging_mixin.py:95} INFO - [2019-08-27 21:01:08,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:09,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:09,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-27 21:01:09,131] {scheduler_job.py:146} INFO - Started process (PID=26672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:14,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:14,143] {logging_mixin.py:95} INFO - [2019-08-27 21:01:14,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:14,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:14,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-27 21:01:14,577] {scheduler_job.py:146} INFO - Started process (PID=26673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:19,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:19,586] {logging_mixin.py:95} INFO - [2019-08-27 21:01:19,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:19,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:20,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-27 21:01:20,044] {scheduler_job.py:146} INFO - Started process (PID=26674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:25,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:25,053] {logging_mixin.py:95} INFO - [2019-08-27 21:01:25,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:25,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:25,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:01:25,494] {scheduler_job.py:146} INFO - Started process (PID=26676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:30,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:30,503] {logging_mixin.py:95} INFO - [2019-08-27 21:01:30,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:30,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:30,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-27 21:01:30,949] {scheduler_job.py:146} INFO - Started process (PID=26678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:35,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:35,959] {logging_mixin.py:95} INFO - [2019-08-27 21:01:35,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:36,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:36,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-27 21:01:36,404] {scheduler_job.py:146} INFO - Started process (PID=26679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:50,181] {scheduler_job.py:146} INFO - Started process (PID=26683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:55,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:01:55,190] {logging_mixin.py:95} INFO - [2019-08-27 21:01:55,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:55,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:01:55,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:01:55,641] {scheduler_job.py:146} INFO - Started process (PID=26685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:00,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:00,649] {logging_mixin.py:95} INFO - [2019-08-27 21:02:00,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:00,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:01,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-08-27 21:02:01,096] {scheduler_job.py:146} INFO - Started process (PID=26687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:06,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:06,104] {logging_mixin.py:95} INFO - [2019-08-27 21:02:06,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:06,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:06,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:02:06,549] {scheduler_job.py:146} INFO - Started process (PID=26710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:11,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:11,561] {logging_mixin.py:95} INFO - [2019-08-27 21:02:11,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:11,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:11,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-27 21:02:12,007] {scheduler_job.py:146} INFO - Started process (PID=26722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:17,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:17,017] {logging_mixin.py:95} INFO - [2019-08-27 21:02:17,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:17,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:17,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:02:17,457] {scheduler_job.py:146} INFO - Started process (PID=26723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:22,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:22,468] {logging_mixin.py:95} INFO - [2019-08-27 21:02:22,468] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:22,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:22,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-27 21:02:22,905] {scheduler_job.py:146} INFO - Started process (PID=26725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:27,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:27,917] {logging_mixin.py:95} INFO - [2019-08-27 21:02:27,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:28,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:28,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:02:28,354] {scheduler_job.py:146} INFO - Started process (PID=26726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:33,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:33,363] {logging_mixin.py:95} INFO - [2019-08-27 21:02:33,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:33,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:33,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:02:33,797] {scheduler_job.py:146} INFO - Started process (PID=26733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:38,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:38,806] {logging_mixin.py:95} INFO - [2019-08-27 21:02:38,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:39,155] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:39,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-27 21:02:39,255] {scheduler_job.py:146} INFO - Started process (PID=26735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:44,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:44,265] {logging_mixin.py:95} INFO - [2019-08-27 21:02:44,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:44,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:44,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-27 21:02:44,804] {scheduler_job.py:146} INFO - Started process (PID=26736) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:49,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:49,818] {logging_mixin.py:95} INFO - [2019-08-27 21:02:49,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:50,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:50,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:02:50,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:02:50,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-27 21:02:50,250] {scheduler_job.py:146} INFO - Started process (PID=26738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:55,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:02:55,262] {logging_mixin.py:95} INFO - [2019-08-27 21:02:55,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:55,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:02:55,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:02:55,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:02:55,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-27 21:02:55,709] {scheduler_job.py:146} INFO - Started process (PID=26740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:00,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:00,722] {logging_mixin.py:95} INFO - [2019-08-27 21:03:00,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:01,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:01,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:01,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:01,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 21:03:01,163] {scheduler_job.py:146} INFO - Started process (PID=26741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:06,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:06,172] {logging_mixin.py:95} INFO - [2019-08-27 21:03:06,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:06,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:06,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:06,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:06,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 21:03:06,613] {scheduler_job.py:146} INFO - Started process (PID=26744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:11,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:11,625] {logging_mixin.py:95} INFO - [2019-08-27 21:03:11,625] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:11,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:12,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:12,014] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:12,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-27 21:03:12,065] {scheduler_job.py:146} INFO - Started process (PID=26745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:17,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:17,075] {logging_mixin.py:95} INFO - [2019-08-27 21:03:17,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:17,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:17,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:17,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:17,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-27 21:03:17,522] {scheduler_job.py:146} INFO - Started process (PID=26746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:22,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:22,531] {logging_mixin.py:95} INFO - [2019-08-27 21:03:22,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:22,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:22,906] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:22,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:22,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:03:22,977] {scheduler_job.py:146} INFO - Started process (PID=26748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:27,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:27,988] {logging_mixin.py:95} INFO - [2019-08-27 21:03:27,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:28,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:28,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:28,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:28,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:03:28,436] {scheduler_job.py:146} INFO - Started process (PID=26749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:33,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:33,446] {logging_mixin.py:95} INFO - [2019-08-27 21:03:33,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:33,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:33,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:33,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:33,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-27 21:03:33,889] {scheduler_job.py:146} INFO - Started process (PID=26750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:38,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:38,901] {logging_mixin.py:95} INFO - [2019-08-27 21:03:38,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:39,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:39,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:39,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:39,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-27 21:03:39,341] {scheduler_job.py:146} INFO - Started process (PID=26752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:44,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:44,351] {logging_mixin.py:95} INFO - [2019-08-27 21:03:44,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:44,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:44,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:44,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:44,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-27 21:03:44,794] {scheduler_job.py:146} INFO - Started process (PID=26754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:49,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:49,807] {logging_mixin.py:95} INFO - [2019-08-27 21:03:49,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:50,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:50,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:50,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:50,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:03:50,240] {scheduler_job.py:146} INFO - Started process (PID=26755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:55,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:03:55,253] {logging_mixin.py:95} INFO - [2019-08-27 21:03:55,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:55,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:03:55,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:03:55,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:03:55,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:03:55,716] {scheduler_job.py:146} INFO - Started process (PID=26757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:00,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:00,727] {logging_mixin.py:95} INFO - [2019-08-27 21:04:00,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:01,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:01,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:01,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:01,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:04:01,172] {scheduler_job.py:146} INFO - Started process (PID=26758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:06,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:06,180] {logging_mixin.py:95} INFO - [2019-08-27 21:04:06,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:06,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:06,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:06,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:06,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-27 21:04:06,729] {scheduler_job.py:146} INFO - Started process (PID=26760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:11,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:11,739] {logging_mixin.py:95} INFO - [2019-08-27 21:04:11,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:12,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:12,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:12,124] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:12,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:04:12,180] {scheduler_job.py:146} INFO - Started process (PID=26762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:17,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:17,191] {logging_mixin.py:95} INFO - [2019-08-27 21:04:17,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:17,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:17,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:17,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:17,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:04:17,625] {scheduler_job.py:146} INFO - Started process (PID=26763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:22,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:22,636] {logging_mixin.py:95} INFO - [2019-08-27 21:04:22,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:22,985] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:23,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:23,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:23,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:04:23,082] {scheduler_job.py:146} INFO - Started process (PID=26765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:28,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:28,094] {logging_mixin.py:95} INFO - [2019-08-27 21:04:28,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:28,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:28,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:28,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:28,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 21:04:28,540] {scheduler_job.py:146} INFO - Started process (PID=26766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:33,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:33,550] {logging_mixin.py:95} INFO - [2019-08-27 21:04:33,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:33,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:33,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:33,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:33,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:04:33,996] {scheduler_job.py:146} INFO - Started process (PID=26767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:39,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:39,007] {logging_mixin.py:95} INFO - [2019-08-27 21:04:39,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:39,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:39,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:39,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:39,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:04:39,455] {scheduler_job.py:146} INFO - Started process (PID=26769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:44,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:44,466] {logging_mixin.py:95} INFO - [2019-08-27 21:04:44,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:44,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:44,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:44,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:44,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 21:04:44,905] {scheduler_job.py:146} INFO - Started process (PID=26771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:49,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:49,914] {logging_mixin.py:95} INFO - [2019-08-27 21:04:49,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:50,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:50,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:50,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:50,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 21:04:50,363] {scheduler_job.py:146} INFO - Started process (PID=26772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:55,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:04:55,373] {logging_mixin.py:95} INFO - [2019-08-27 21:04:55,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:55,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:04:55,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:04:55,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:04:55,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 21:04:55,822] {scheduler_job.py:146} INFO - Started process (PID=26775) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:00,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:00,834] {logging_mixin.py:95} INFO - [2019-08-27 21:05:00,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:01,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:01,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:01,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:01,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:05:01,284] {scheduler_job.py:146} INFO - Started process (PID=26776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:06,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:06,295] {logging_mixin.py:95} INFO - [2019-08-27 21:05:06,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:06,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:06,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:06,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:06,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 21:05:06,745] {scheduler_job.py:146} INFO - Started process (PID=26778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:11,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:11,754] {logging_mixin.py:95} INFO - [2019-08-27 21:05:11,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:12,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:12,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:12,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:12,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-27 21:05:12,211] {scheduler_job.py:146} INFO - Started process (PID=26779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:17,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:17,223] {logging_mixin.py:95} INFO - [2019-08-27 21:05:17,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:17,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:17,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:17,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:17,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:05:17,676] {scheduler_job.py:146} INFO - Started process (PID=26781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:22,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:22,683] {logging_mixin.py:95} INFO - [2019-08-27 21:05:22,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:23,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:23,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:23,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:23,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 21:05:23,140] {scheduler_job.py:146} INFO - Started process (PID=26783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:28,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:28,149] {logging_mixin.py:95} INFO - [2019-08-27 21:05:28,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:28,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:28,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:28,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:28,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:05:28,605] {scheduler_job.py:146} INFO - Started process (PID=26784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:33,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:33,617] {logging_mixin.py:95} INFO - [2019-08-27 21:05:33,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:33,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:33,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:33,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:34,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:05:34,068] {scheduler_job.py:146} INFO - Started process (PID=26785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:39,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:39,081] {logging_mixin.py:95} INFO - [2019-08-27 21:05:39,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:39,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:39,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:39,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:39,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:05:39,533] {scheduler_job.py:146} INFO - Started process (PID=26787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:44,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:44,543] {logging_mixin.py:95} INFO - [2019-08-27 21:05:44,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:44,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:44,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:44,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:44,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:05:44,999] {scheduler_job.py:146} INFO - Started process (PID=26788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:50,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:50,008] {logging_mixin.py:95} INFO - [2019-08-27 21:05:50,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:50,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:50,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:50,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:50,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:05:50,460] {scheduler_job.py:146} INFO - Started process (PID=26790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:55,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:05:55,473] {logging_mixin.py:95} INFO - [2019-08-27 21:05:55,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:55,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:05:55,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:05:55,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:05:55,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:05:55,925] {scheduler_job.py:146} INFO - Started process (PID=26792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:00,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:00,938] {logging_mixin.py:95} INFO - [2019-08-27 21:06:00,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:01,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:01,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:01,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:01,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:06:01,387] {scheduler_job.py:146} INFO - Started process (PID=26793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:06,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:06,401] {logging_mixin.py:95} INFO - [2019-08-27 21:06:06,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:06,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:06,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:06,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:06,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:06:06,851] {scheduler_job.py:146} INFO - Started process (PID=26795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:11,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:11,859] {logging_mixin.py:95} INFO - [2019-08-27 21:06:11,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:12,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:12,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:12,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:12,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-08-27 21:06:12,310] {scheduler_job.py:146} INFO - Started process (PID=26796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:17,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:17,317] {logging_mixin.py:95} INFO - [2019-08-27 21:06:17,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:17,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:17,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:17,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:17,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:06:17,767] {scheduler_job.py:146} INFO - Started process (PID=26798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:22,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:22,780] {logging_mixin.py:95} INFO - [2019-08-27 21:06:22,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:23,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:23,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:23,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:23,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 21:06:23,234] {scheduler_job.py:146} INFO - Started process (PID=26800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:28,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:28,243] {logging_mixin.py:95} INFO - [2019-08-27 21:06:28,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:28,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:28,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:28,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:28,632] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:06:28,698] {scheduler_job.py:146} INFO - Started process (PID=26801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:33,706] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:33,707] {logging_mixin.py:95} INFO - [2019-08-27 21:06:33,707] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:34,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:34,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:34,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:34,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 21:06:34,161] {scheduler_job.py:146} INFO - Started process (PID=26802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:39,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:39,171] {logging_mixin.py:95} INFO - [2019-08-27 21:06:39,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:39,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:39,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:39,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:39,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-27 21:06:39,624] {scheduler_job.py:146} INFO - Started process (PID=26804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:44,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:44,633] {logging_mixin.py:95} INFO - [2019-08-27 21:06:44,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:44,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:45,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:45,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:45,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:06:45,086] {scheduler_job.py:146} INFO - Started process (PID=26805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:50,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:50,097] {logging_mixin.py:95} INFO - [2019-08-27 21:06:50,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:50,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:50,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:50,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:50,486] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:06:50,562] {scheduler_job.py:146} INFO - Started process (PID=26807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:55,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:06:55,570] {logging_mixin.py:95} INFO - [2019-08-27 21:06:55,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:55,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:06:55,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:06:55,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:06:55,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-27 21:06:56,007] {scheduler_job.py:146} INFO - Started process (PID=26809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:01,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:01,014] {logging_mixin.py:95} INFO - [2019-08-27 21:07:01,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:01,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:01,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:01,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:01,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-27 21:07:01,459] {scheduler_job.py:146} INFO - Started process (PID=26810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:06,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:06,466] {logging_mixin.py:95} INFO - [2019-08-27 21:07:06,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:06,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:06,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:06,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:06,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:07:06,904] {scheduler_job.py:146} INFO - Started process (PID=26812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:11,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:11,915] {logging_mixin.py:95} INFO - [2019-08-27 21:07:11,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:12,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:12,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:12,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:12,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:07:12,357] {scheduler_job.py:146} INFO - Started process (PID=26813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:17,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:17,363] {logging_mixin.py:95} INFO - [2019-08-27 21:07:17,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:17,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:17,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:17,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:17,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 21:07:17,814] {scheduler_job.py:146} INFO - Started process (PID=26814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:22,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:22,825] {logging_mixin.py:95} INFO - [2019-08-27 21:07:22,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:23,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:23,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:23,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:23,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-08-27 21:07:23,363] {scheduler_job.py:146} INFO - Started process (PID=26817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:28,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:28,372] {logging_mixin.py:95} INFO - [2019-08-27 21:07:28,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:28,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:28,809] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:28,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:28,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-27 21:07:28,909] {scheduler_job.py:146} INFO - Started process (PID=26819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:33,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:33,916] {logging_mixin.py:95} INFO - [2019-08-27 21:07:33,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:34,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:34,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:34,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:34,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-27 21:07:34,448] {scheduler_job.py:146} INFO - Started process (PID=26823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:39,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:39,454] {logging_mixin.py:95} INFO - [2019-08-27 21:07:39,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:39,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:39,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:39,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:39,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-27 21:07:40,001] {scheduler_job.py:146} INFO - Started process (PID=26826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:45,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:45,008] {logging_mixin.py:95} INFO - [2019-08-27 21:07:45,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:45,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:45,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:45,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:45,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-27 21:07:45,455] {scheduler_job.py:146} INFO - Started process (PID=26828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:50,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:50,465] {logging_mixin.py:95} INFO - [2019-08-27 21:07:50,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:50,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:50,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:50,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:50,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-27 21:07:51,007] {scheduler_job.py:146} INFO - Started process (PID=26832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:56,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:07:56,015] {logging_mixin.py:95} INFO - [2019-08-27 21:07:56,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:56,409] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:07:56,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:07:56,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:07:56,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-27 21:07:56,466] {scheduler_job.py:146} INFO - Started process (PID=26835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:01,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:01,474] {logging_mixin.py:95} INFO - [2019-08-27 21:08:01,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:01,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:01,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:01,896] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:01,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:01,910] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 02:08:01.487966+00:00 [scheduled]> in ORM
[2019-08-27 21:08:01,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-27 21:08:02,018] {scheduler_job.py:146} INFO - Started process (PID=26836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:07,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:07,027] {logging_mixin.py:95} INFO - [2019-08-27 21:08:07,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:07,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:07,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:07,472] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:07,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:07,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-08-27 21:08:07,560] {scheduler_job.py:146} INFO - Started process (PID=26840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:12,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:12,568] {logging_mixin.py:95} INFO - [2019-08-27 21:08:12,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:12,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:12,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:12,975] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:12,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:12,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-27 21:08:13,013] {scheduler_job.py:146} INFO - Started process (PID=26841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:18,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:18,021] {logging_mixin.py:95} INFO - [2019-08-27 21:08:18,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:18,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:18,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:18,419] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:18,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:18,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-27 21:08:18,462] {scheduler_job.py:146} INFO - Started process (PID=26844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:23,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:23,473] {logging_mixin.py:95} INFO - [2019-08-27 21:08:23,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:23,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:23,881] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:23,889] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:23,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:23,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-27 21:08:24,005] {scheduler_job.py:146} INFO - Started process (PID=26848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:29,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:29,014] {logging_mixin.py:95} INFO - [2019-08-27 21:08:29,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:29,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:29,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:29,400] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:29,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:29,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 21:08:29,457] {scheduler_job.py:146} INFO - Started process (PID=26849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:34,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:34,464] {logging_mixin.py:95} INFO - [2019-08-27 21:08:34,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:34,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:34,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:34,907] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:34,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:34,923] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 02:08:01.487966+00:00 [scheduled]> in ORM
[2019-08-27 21:08:34,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-08-27 21:08:35,012] {scheduler_job.py:146} INFO - Started process (PID=26850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:40,018] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:40,032] {logging_mixin.py:95} INFO - [2019-08-27 21:08:40,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:40,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:40,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:40,420] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:40,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:40,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-27 21:08:40,468] {scheduler_job.py:146} INFO - Started process (PID=26853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:45,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:45,479] {logging_mixin.py:95} INFO - [2019-08-27 21:08:45,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:45,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:45,872] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:45,879] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:45,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:45,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-27 21:08:45,925] {scheduler_job.py:146} INFO - Started process (PID=26854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:50,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:50,932] {logging_mixin.py:95} INFO - [2019-08-27 21:08:50,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:51,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:51,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:51,337] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:51,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:51,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-27 21:08:51,378] {scheduler_job.py:146} INFO - Started process (PID=26856) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:56,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:08:56,386] {logging_mixin.py:95} INFO - [2019-08-27 21:08:56,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:56,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:08:56,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:08:56,778] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:08:56,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:08:56,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:08:56,832] {scheduler_job.py:146} INFO - Started process (PID=26860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:01,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:01,842] {logging_mixin.py:95} INFO - [2019-08-27 21:09:01,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:02,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:02,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:02,228] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:09:02,238] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:02,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:09:02,295] {scheduler_job.py:146} INFO - Started process (PID=26861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:07,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:07,302] {logging_mixin.py:95} INFO - [2019-08-27 21:09:07,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:07,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:07,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:07,756] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True>
[2019-08-27 21:09:07,761] {logging_mixin.py:95} INFO - [2019-08-27 21:09:07,761] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 02:08:01.487966+00:00: manual__2019-08-28T02:08:01.487966+00:00, externally triggered: True> successful
[2019-08-27 21:09:07,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:07,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-08-27 21:09:07,854] {scheduler_job.py:146} INFO - Started process (PID=26865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:12,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:12,862] {logging_mixin.py:95} INFO - [2019-08-27 21:09:12,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:13,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:13,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:13,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:13,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:09:13,312] {scheduler_job.py:146} INFO - Started process (PID=26866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:18,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:18,322] {logging_mixin.py:95} INFO - [2019-08-27 21:09:18,321] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:18,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:18,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:18,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:18,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:09:18,773] {scheduler_job.py:146} INFO - Started process (PID=26867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:23,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:23,783] {logging_mixin.py:95} INFO - [2019-08-27 21:09:23,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:24,136] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:24,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:24,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:24,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:09:24,233] {scheduler_job.py:146} INFO - Started process (PID=26869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:29,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:29,240] {logging_mixin.py:95} INFO - [2019-08-27 21:09:29,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:29,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:29,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:29,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:29,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:09:29,689] {scheduler_job.py:146} INFO - Started process (PID=26871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:34,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:34,698] {logging_mixin.py:95} INFO - [2019-08-27 21:09:34,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:35,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:35,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:35,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:35,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:09:35,148] {scheduler_job.py:146} INFO - Started process (PID=26872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:40,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:40,174] {logging_mixin.py:95} INFO - [2019-08-27 21:09:40,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:40,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:40,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:40,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:40,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:09:40,607] {scheduler_job.py:146} INFO - Started process (PID=26874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:45,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:45,613] {logging_mixin.py:95} INFO - [2019-08-27 21:09:45,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:45,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:45,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:45,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:46,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:09:46,068] {scheduler_job.py:146} INFO - Started process (PID=26875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:51,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:51,077] {logging_mixin.py:95} INFO - [2019-08-27 21:09:51,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:51,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:51,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:51,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:51,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:09:51,531] {scheduler_job.py:146} INFO - Started process (PID=26877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:56,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:09:56,542] {logging_mixin.py:95} INFO - [2019-08-27 21:09:56,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:56,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:09:56,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:09:56,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:09:56,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-27 21:09:56,990] {scheduler_job.py:146} INFO - Started process (PID=26879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:01,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:01,997] {logging_mixin.py:95} INFO - [2019-08-27 21:10:01,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:02,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:02,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:02,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:02,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:10:02,451] {scheduler_job.py:146} INFO - Started process (PID=26881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:07,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:07,461] {logging_mixin.py:95} INFO - [2019-08-27 21:10:07,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:07,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:07,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:07,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:07,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:10:07,914] {scheduler_job.py:146} INFO - Started process (PID=26883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:12,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:12,923] {logging_mixin.py:95} INFO - [2019-08-27 21:10:12,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:13,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:13,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:13,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:13,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 21:10:13,374] {scheduler_job.py:146} INFO - Started process (PID=26884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:18,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:18,382] {logging_mixin.py:95} INFO - [2019-08-27 21:10:18,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:18,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:18,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:18,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:18,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:10:18,836] {scheduler_job.py:146} INFO - Started process (PID=26885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:23,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:23,844] {logging_mixin.py:95} INFO - [2019-08-27 21:10:23,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:24,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:24,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:24,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:24,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:10:24,297] {scheduler_job.py:146} INFO - Started process (PID=26887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:29,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:29,307] {logging_mixin.py:95} INFO - [2019-08-27 21:10:29,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:29,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:29,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:29,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:29,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 21:10:29,757] {scheduler_job.py:146} INFO - Started process (PID=26889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:34,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:34,766] {logging_mixin.py:95} INFO - [2019-08-27 21:10:34,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:35,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:35,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:35,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:35,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 21:10:35,220] {scheduler_job.py:146} INFO - Started process (PID=26890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:40,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:40,229] {logging_mixin.py:95} INFO - [2019-08-27 21:10:40,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:40,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:40,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:40,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:40,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:10:40,680] {scheduler_job.py:146} INFO - Started process (PID=26892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:45,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:45,691] {logging_mixin.py:95} INFO - [2019-08-27 21:10:45,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:46,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:46,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:46,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:46,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:10:46,140] {scheduler_job.py:146} INFO - Started process (PID=26893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:51,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:51,147] {logging_mixin.py:95} INFO - [2019-08-27 21:10:51,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:51,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:51,526] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:51,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:51,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:10:51,600] {scheduler_job.py:146} INFO - Started process (PID=26894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:56,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:10:56,606] {logging_mixin.py:95} INFO - [2019-08-27 21:10:56,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:56,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:10:56,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:10:56,998] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:10:57,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:10:57,054] {scheduler_job.py:146} INFO - Started process (PID=26896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:02,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:02,064] {logging_mixin.py:95} INFO - [2019-08-27 21:11:02,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:02,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:02,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:02,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:02,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:11:02,516] {scheduler_job.py:146} INFO - Started process (PID=26898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:07,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:07,525] {logging_mixin.py:95} INFO - [2019-08-27 21:11:07,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:07,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:07,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:07,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:07,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-27 21:11:07,974] {scheduler_job.py:146} INFO - Started process (PID=26900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:12,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:12,982] {logging_mixin.py:95} INFO - [2019-08-27 21:11:12,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:13,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:13,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:13,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:13,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 21:11:13,431] {scheduler_job.py:146} INFO - Started process (PID=26901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:18,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:18,438] {logging_mixin.py:95} INFO - [2019-08-27 21:11:18,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:18,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:18,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:18,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:18,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:11:18,887] {scheduler_job.py:146} INFO - Started process (PID=26902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:23,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:23,896] {logging_mixin.py:95} INFO - [2019-08-27 21:11:23,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:24,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:24,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:24,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:24,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:11:24,348] {scheduler_job.py:146} INFO - Started process (PID=26904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:29,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:29,359] {logging_mixin.py:95} INFO - [2019-08-27 21:11:29,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:29,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:29,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:29,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:29,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-27 21:11:29,812] {scheduler_job.py:146} INFO - Started process (PID=26905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:34,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:34,823] {logging_mixin.py:95} INFO - [2019-08-27 21:11:34,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:35,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:35,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:35,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:35,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:11:35,271] {scheduler_job.py:146} INFO - Started process (PID=26907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:40,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:40,295] {logging_mixin.py:95} INFO - [2019-08-27 21:11:40,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:40,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:40,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:40,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:40,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-27 21:11:40,735] {scheduler_job.py:146} INFO - Started process (PID=26909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:45,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:45,742] {logging_mixin.py:95} INFO - [2019-08-27 21:11:45,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:46,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:46,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:46,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:46,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:11:46,200] {scheduler_job.py:146} INFO - Started process (PID=26910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:51,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:51,211] {logging_mixin.py:95} INFO - [2019-08-27 21:11:51,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:51,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:51,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:51,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:51,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:11:51,666] {scheduler_job.py:146} INFO - Started process (PID=26911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:56,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:11:56,677] {logging_mixin.py:95} INFO - [2019-08-27 21:11:56,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:57,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:11:57,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:11:57,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:11:57,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:11:57,130] {scheduler_job.py:146} INFO - Started process (PID=26913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:02,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:02,141] {logging_mixin.py:95} INFO - [2019-08-27 21:12:02,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:02,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:02,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:02,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:02,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:12:02,589] {scheduler_job.py:146} INFO - Started process (PID=26914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:07,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:07,599] {logging_mixin.py:95} INFO - [2019-08-27 21:12:07,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:07,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:07,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:07,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:07,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:12:08,050] {scheduler_job.py:146} INFO - Started process (PID=26917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:13,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:13,061] {logging_mixin.py:95} INFO - [2019-08-27 21:12:13,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:13,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:13,436] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:13,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:13,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 21:12:13,511] {scheduler_job.py:146} INFO - Started process (PID=26918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:18,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:18,519] {logging_mixin.py:95} INFO - [2019-08-27 21:12:18,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:18,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:18,895] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:18,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:18,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:12:18,973] {scheduler_job.py:146} INFO - Started process (PID=26919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:23,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:23,983] {logging_mixin.py:95} INFO - [2019-08-27 21:12:23,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:24,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:24,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:24,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:24,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:12:24,432] {scheduler_job.py:146} INFO - Started process (PID=26921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:29,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:29,439] {logging_mixin.py:95} INFO - [2019-08-27 21:12:29,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:29,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:29,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:29,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:29,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:12:29,893] {scheduler_job.py:146} INFO - Started process (PID=26922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:34,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:34,901] {logging_mixin.py:95} INFO - [2019-08-27 21:12:34,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:35,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:35,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:35,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:35,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:12:35,352] {scheduler_job.py:146} INFO - Started process (PID=26924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:40,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:40,360] {logging_mixin.py:95} INFO - [2019-08-27 21:12:40,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:40,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:40,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:40,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:40,754] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:12:40,815] {scheduler_job.py:146} INFO - Started process (PID=26926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:45,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:45,822] {logging_mixin.py:95} INFO - [2019-08-27 21:12:45,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:46,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:46,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:46,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:46,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-27 21:12:46,272] {scheduler_job.py:146} INFO - Started process (PID=26927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:51,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:51,280] {logging_mixin.py:95} INFO - [2019-08-27 21:12:51,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:51,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:51,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:51,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:51,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:12:51,732] {scheduler_job.py:146} INFO - Started process (PID=26929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:56,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:12:56,742] {logging_mixin.py:95} INFO - [2019-08-27 21:12:56,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:57,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:12:57,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:12:57,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:12:57,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-27 21:12:57,193] {scheduler_job.py:146} INFO - Started process (PID=26931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:02,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:02,199] {logging_mixin.py:95} INFO - [2019-08-27 21:13:02,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:02,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:02,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:02,589] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:02,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-27 21:13:02,653] {scheduler_job.py:146} INFO - Started process (PID=26932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:07,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:07,661] {logging_mixin.py:95} INFO - [2019-08-27 21:13:07,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:08,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:08,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:08,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:08,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-27 21:13:08,209] {scheduler_job.py:146} INFO - Started process (PID=26935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:13,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:13,216] {logging_mixin.py:95} INFO - [2019-08-27 21:13:13,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:13,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:13,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:13,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:13,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:13:13,671] {scheduler_job.py:146} INFO - Started process (PID=26936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:18,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:18,677] {logging_mixin.py:95} INFO - [2019-08-27 21:13:18,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:19,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:19,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:19,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:19,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-27 21:13:19,131] {scheduler_job.py:146} INFO - Started process (PID=26937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:24,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:24,137] {logging_mixin.py:95} INFO - [2019-08-27 21:13:24,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:24,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:24,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:24,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:24,909] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.779 seconds
[2019-08-27 21:13:24,965] {scheduler_job.py:146} INFO - Started process (PID=26939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:29,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:29,977] {logging_mixin.py:95} INFO - [2019-08-27 21:13:29,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:30,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:30,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:30,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:30,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-27 21:13:30,440] {scheduler_job.py:146} INFO - Started process (PID=26946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:35,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:35,448] {logging_mixin.py:95} INFO - [2019-08-27 21:13:35,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:35,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:35,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:35,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:35,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 21:13:35,900] {scheduler_job.py:146} INFO - Started process (PID=26954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:40,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:40,913] {logging_mixin.py:95} INFO - [2019-08-27 21:13:40,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:41,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:41,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:41,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:41,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-08-27 21:13:41,451] {scheduler_job.py:146} INFO - Started process (PID=26957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:46,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:46,459] {logging_mixin.py:95} INFO - [2019-08-27 21:13:46,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:46,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:46,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:46,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:46,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 21:13:46,898] {scheduler_job.py:146} INFO - Started process (PID=26958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:51,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:51,909] {logging_mixin.py:95} INFO - [2019-08-27 21:13:51,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:52,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:52,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:52,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:52,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:13:52,353] {scheduler_job.py:146} INFO - Started process (PID=26961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:57,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:13:57,360] {logging_mixin.py:95} INFO - [2019-08-27 21:13:57,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:57,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:13:57,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:13:57,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:13:57,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-27 21:13:57,808] {scheduler_job.py:146} INFO - Started process (PID=26962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:02,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:02,822] {logging_mixin.py:95} INFO - [2019-08-27 21:14:02,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:03,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:03,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:03,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:03,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-27 21:14:03,357] {scheduler_job.py:146} INFO - Started process (PID=26963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:08,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:08,367] {logging_mixin.py:95} INFO - [2019-08-27 21:14:08,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:08,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:08,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:08,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:08,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-08-27 21:14:08,905] {scheduler_job.py:146} INFO - Started process (PID=26965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:13,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:13,914] {logging_mixin.py:95} INFO - [2019-08-27 21:14:13,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:14,296] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:14,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:14,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:14,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-27 21:14:14,354] {scheduler_job.py:146} INFO - Started process (PID=26967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:19,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:19,360] {logging_mixin.py:95} INFO - [2019-08-27 21:14:19,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:19,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:19,792] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:19,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:19,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-27 21:14:19,904] {scheduler_job.py:146} INFO - Started process (PID=26968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:24,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:24,911] {logging_mixin.py:95} INFO - [2019-08-27 21:14:24,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:25,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:25,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:25,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:25,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:14:25,358] {scheduler_job.py:146} INFO - Started process (PID=26970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:30,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:30,366] {logging_mixin.py:95} INFO - [2019-08-27 21:14:30,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:30,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:30,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:30,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:30,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-27 21:14:30,818] {scheduler_job.py:146} INFO - Started process (PID=26971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:35,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:35,830] {logging_mixin.py:95} INFO - [2019-08-27 21:14:35,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:36,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:36,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:36,217] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:36,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:14:36,269] {scheduler_job.py:146} INFO - Started process (PID=26972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:41,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:41,274] {logging_mixin.py:95} INFO - [2019-08-27 21:14:41,274] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:41,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:41,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:41,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:41,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-27 21:14:41,820] {scheduler_job.py:146} INFO - Started process (PID=26975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:46,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:46,829] {logging_mixin.py:95} INFO - [2019-08-27 21:14:46,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:47,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:47,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:47,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:47,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-27 21:14:47,270] {scheduler_job.py:146} INFO - Started process (PID=26976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:52,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:52,278] {logging_mixin.py:95} INFO - [2019-08-27 21:14:52,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:52,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:52,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:52,676] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:52,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 21:14:52,721] {scheduler_job.py:146} INFO - Started process (PID=26978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:57,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:14:57,730] {logging_mixin.py:95} INFO - [2019-08-27 21:14:57,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:58,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:14:58,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:14:58,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:14:58,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:14:58,173] {scheduler_job.py:146} INFO - Started process (PID=26979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:03,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:03,184] {logging_mixin.py:95} INFO - [2019-08-27 21:15:03,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:03,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:03,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:03,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:03,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 21:15:03,624] {scheduler_job.py:146} INFO - Started process (PID=26981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:08,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:08,634] {logging_mixin.py:95} INFO - [2019-08-27 21:15:08,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:09,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:09,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:09,070] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:09,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-27 21:15:09,181] {scheduler_job.py:146} INFO - Started process (PID=26983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:14,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:14,190] {logging_mixin.py:95} INFO - [2019-08-27 21:15:14,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:14,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:14,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:14,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:14,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:15:14,622] {scheduler_job.py:146} INFO - Started process (PID=26985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:19,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:19,629] {logging_mixin.py:95} INFO - [2019-08-27 21:15:19,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:19,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:20,005] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:20,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:20,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-27 21:15:20,075] {scheduler_job.py:146} INFO - Started process (PID=26986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:25,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:25,085] {logging_mixin.py:95} INFO - [2019-08-27 21:15:25,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:25,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:25,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:25,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:25,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-27 21:15:25,528] {scheduler_job.py:146} INFO - Started process (PID=26988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:30,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:30,536] {logging_mixin.py:95} INFO - [2019-08-27 21:15:30,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:30,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:30,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:30,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:30,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-27 21:15:30,979] {scheduler_job.py:146} INFO - Started process (PID=26989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:35,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:35,990] {logging_mixin.py:95} INFO - [2019-08-27 21:15:35,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:36,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:36,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:36,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:36,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-27 21:15:36,436] {scheduler_job.py:146} INFO - Started process (PID=26990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:41,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:41,446] {logging_mixin.py:95} INFO - [2019-08-27 21:15:41,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:41,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:41,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:41,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:41,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:15:41,888] {scheduler_job.py:146} INFO - Started process (PID=26992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:46,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:46,905] {logging_mixin.py:95} INFO - [2019-08-27 21:15:46,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:47,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:47,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:47,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:47,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-27 21:15:47,435] {scheduler_job.py:146} INFO - Started process (PID=26994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:52,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:52,444] {logging_mixin.py:95} INFO - [2019-08-27 21:15:52,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:52,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:52,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:52,852] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:15:52,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:52,866] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 02:15:50.179314+00:00 [scheduled]> in ORM
[2019-08-27 21:15:52,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-27 21:15:52,983] {scheduler_job.py:146} INFO - Started process (PID=26998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:57,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:15:57,989] {logging_mixin.py:95} INFO - [2019-08-27 21:15:57,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:58,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:15:58,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:15:58,403] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:15:58,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:15:58,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-27 21:15:58,524] {scheduler_job.py:146} INFO - Started process (PID=27000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:03,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:03,534] {logging_mixin.py:95} INFO - [2019-08-27 21:16:03,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:03,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:03,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:03,987] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:03,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:04,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-08-27 21:16:04,068] {scheduler_job.py:146} INFO - Started process (PID=27001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:09,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:09,074] {logging_mixin.py:95} INFO - [2019-08-27 21:16:09,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:09,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:09,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:09,483] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:09,495] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:09,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-27 21:16:09,530] {scheduler_job.py:146} INFO - Started process (PID=27003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:14,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:14,541] {logging_mixin.py:95} INFO - [2019-08-27 21:16:14,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:14,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:14,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:14,936] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:14,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:14,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-27 21:16:14,976] {scheduler_job.py:146} INFO - Started process (PID=27005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:19,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:19,985] {logging_mixin.py:95} INFO - [2019-08-27 21:16:19,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:20,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:20,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:20,412] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:20,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:20,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-27 21:16:20,526] {scheduler_job.py:146} INFO - Started process (PID=27007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:25,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:25,533] {logging_mixin.py:95} INFO - [2019-08-27 21:16:25,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:25,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:25,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:25,922] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:25,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:25,937] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 02:15:50.179314+00:00 [scheduled]> in ORM
[2019-08-27 21:16:25,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-27 21:16:25,977] {scheduler_job.py:146} INFO - Started process (PID=27009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:30,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:30,984] {logging_mixin.py:95} INFO - [2019-08-27 21:16:30,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:31,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:31,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:31,379] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:31,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:31,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:16:31,434] {scheduler_job.py:146} INFO - Started process (PID=27011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:36,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:36,442] {logging_mixin.py:95} INFO - [2019-08-27 21:16:36,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:36,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:36,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:36,833] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:36,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:36,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-27 21:16:36,897] {scheduler_job.py:146} INFO - Started process (PID=27012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:41,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:41,904] {logging_mixin.py:95} INFO - [2019-08-27 21:16:41,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:42,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:42,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:42,309] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:42,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:42,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-27 21:16:42,349] {scheduler_job.py:146} INFO - Started process (PID=27014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:47,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:47,357] {logging_mixin.py:95} INFO - [2019-08-27 21:16:47,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:47,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:47,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:47,760] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:47,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:47,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-27 21:16:47,803] {scheduler_job.py:146} INFO - Started process (PID=27016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:52,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:52,811] {logging_mixin.py:95} INFO - [2019-08-27 21:16:52,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:53,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:53,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:53,205] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:53,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:53,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:16:53,266] {scheduler_job.py:146} INFO - Started process (PID=27018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:58,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:16:58,281] {logging_mixin.py:95} INFO - [2019-08-27 21:16:58,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:58,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:16:58,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:16:58,685] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True>
[2019-08-27 21:16:58,691] {logging_mixin.py:95} INFO - [2019-08-27 21:16:58,691] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 02:15:50.179314+00:00: manual__2019-08-28T02:15:50.179314+00:00, externally triggered: True> successful
[2019-08-27 21:16:58,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:16:58,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-27 21:16:58,724] {scheduler_job.py:146} INFO - Started process (PID=27022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:03,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:17:03,732] {logging_mixin.py:95} INFO - [2019-08-27 21:17:03,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:04,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:04,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:17:04,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:17:04,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 21:17:04,173] {scheduler_job.py:146} INFO - Started process (PID=27023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:09,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:17:09,183] {logging_mixin.py:95} INFO - [2019-08-27 21:17:09,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:09,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:09,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:17:09,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:17:09,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-27 21:17:09,620] {scheduler_job.py:146} INFO - Started process (PID=27026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:14,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:17:14,630] {logging_mixin.py:95} INFO - [2019-08-27 21:17:14,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:14,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:15,005] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:17:15,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:17:15,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-27 21:17:15,084] {scheduler_job.py:146} INFO - Started process (PID=27027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:20,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:17:20,096] {logging_mixin.py:95} INFO - [2019-08-27 21:17:20,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:20,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:20,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:17:20,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:17:20,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-27 21:17:20,547] {scheduler_job.py:146} INFO - Started process (PID=27028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:25,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:17:25,553] {logging_mixin.py:95} INFO - [2019-08-27 21:17:25,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:25,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:17:25,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:17:25,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:17:25,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-27 21:17:26,009] {scheduler_job.py:146} INFO - Started process (PID=27031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:24,611] {scheduler_job.py:146} INFO - Started process (PID=27083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:29,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:23:29,619] {logging_mixin.py:95} INFO - [2019-08-27 21:23:29,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:30,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:30,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:23:30,222] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:23:30,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:23:30,237] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 02:20:30.889081+00:00 [scheduled]> in ORM
[2019-08-27 21:23:30,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.634 seconds
[2019-08-27 21:23:30,272] {scheduler_job.py:146} INFO - Started process (PID=27084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:35,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:23:35,283] {logging_mixin.py:95} INFO - [2019-08-27 21:23:35,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:35,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:35,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:23:35,704] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:23:35,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:23:35,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-27 21:23:35,827] {scheduler_job.py:146} INFO - Started process (PID=27086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:40,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:23:40,846] {logging_mixin.py:95} INFO - [2019-08-27 21:23:40,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:41,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:41,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:23:41,250] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:23:41,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:23:41,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-27 21:23:41,290] {scheduler_job.py:146} INFO - Started process (PID=27088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:46,297] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:23:46,298] {logging_mixin.py:95} INFO - [2019-08-27 21:23:46,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:46,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:23:46,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:23:46,723] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:23:46,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:23:46,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-27 21:24:04,636] {scheduler_job.py:146} INFO - Started process (PID=27093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:09,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:09,649] {logging_mixin.py:95} INFO - [2019-08-27 21:24:09,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:10,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:10,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:10,058] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:24:10,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:10,075] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 02:20:30.889081+00:00 [scheduled]> in ORM
[2019-08-27 21:24:10,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-27 21:24:10,192] {scheduler_job.py:146} INFO - Started process (PID=27095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:15,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:15,202] {logging_mixin.py:95} INFO - [2019-08-27 21:24:15,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:15,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:15,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:15,619] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:24:15,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:15,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-27 21:24:15,742] {scheduler_job.py:146} INFO - Started process (PID=27098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:20,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:20,749] {logging_mixin.py:95} INFO - [2019-08-27 21:24:20,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:21,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:21,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:21,165] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:24:21,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:21,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-27 21:24:21,293] {scheduler_job.py:146} INFO - Started process (PID=27100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:26,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:26,301] {logging_mixin.py:95} INFO - [2019-08-27 21:24:26,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:26,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:26,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:26,726] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:24:26,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:26,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-27 21:24:43,912] {scheduler_job.py:146} INFO - Started process (PID=27106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:48,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:48,926] {logging_mixin.py:95} INFO - [2019-08-27 21:24:48,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:49,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:49,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:49,317] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True>
[2019-08-27 21:24:49,323] {logging_mixin.py:95} INFO - [2019-08-27 21:24:49,322] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 02:20:30.889081+00:00: manual__2019-08-28T02:20:30.889081+00:00, externally triggered: True> successful
[2019-08-27 21:24:49,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:49,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-27 21:24:49,369] {scheduler_job.py:146} INFO - Started process (PID=27107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:54,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:54,378] {logging_mixin.py:95} INFO - [2019-08-27 21:24:54,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:54,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:54,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:24:54,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:24:54,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-27 21:24:54,815] {scheduler_job.py:146} INFO - Started process (PID=27110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:24:59,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:24:59,829] {logging_mixin.py:95} INFO - [2019-08-27 21:24:59,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:00,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:00,245] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:00,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:00,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-27 21:25:00,364] {scheduler_job.py:146} INFO - Started process (PID=27111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:05,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:05,373] {logging_mixin.py:95} INFO - [2019-08-27 21:25:05,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:05,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:05,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:05,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:05,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-27 21:25:05,813] {scheduler_job.py:146} INFO - Started process (PID=27112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:10,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:10,836] {logging_mixin.py:95} INFO - [2019-08-27 21:25:10,835] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:11,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:11,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:11,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:11,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-27 21:25:11,368] {scheduler_job.py:146} INFO - Started process (PID=27114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:16,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:16,377] {logging_mixin.py:95} INFO - [2019-08-27 21:25:16,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:16,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:16,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:16,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:16,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-27 21:25:16,813] {scheduler_job.py:146} INFO - Started process (PID=27115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:21,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:21,821] {logging_mixin.py:95} INFO - [2019-08-27 21:25:21,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:22,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:22,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:22,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:22,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-08-27 21:25:22,362] {scheduler_job.py:146} INFO - Started process (PID=27117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:27,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:27,370] {logging_mixin.py:95} INFO - [2019-08-27 21:25:27,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:27,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:27,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:27,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:27,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-27 21:25:27,805] {scheduler_job.py:146} INFO - Started process (PID=27119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:32,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:32,814] {logging_mixin.py:95} INFO - [2019-08-27 21:25:32,814] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:33,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:33,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:33,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:33,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-27 21:25:33,254] {scheduler_job.py:146} INFO - Started process (PID=27120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:38,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:38,262] {logging_mixin.py:95} INFO - [2019-08-27 21:25:38,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:38,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:38,667] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:38,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:38,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-27 21:25:38,705] {scheduler_job.py:146} INFO - Started process (PID=27122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:43,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:43,713] {logging_mixin.py:95} INFO - [2019-08-27 21:25:43,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:44,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:44,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:44,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:44,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-27 21:25:44,152] {scheduler_job.py:146} INFO - Started process (PID=27123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:49,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:49,161] {logging_mixin.py:95} INFO - [2019-08-27 21:25:49,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:49,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:49,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:49,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:49,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-27 21:25:49,699] {scheduler_job.py:146} INFO - Started process (PID=27124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:54,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:25:54,708] {logging_mixin.py:95} INFO - [2019-08-27 21:25:54,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:55,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:25:55,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:25:55,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:25:55,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-27 21:25:55,252] {scheduler_job.py:146} INFO - Started process (PID=27129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:26:00,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-27 21:26:00,267] {logging_mixin.py:95} INFO - [2019-08-27 21:26:00,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:26:00,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-27 21:26:00,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-27 21:26:00,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-27 21:26:00,666] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-27 21:26:00,704] {scheduler_job.py:146} INFO - Started process (PID=27130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:30,114] {scheduler_job.py:146} INFO - Started process (PID=6414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:35,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:41:35,119] {logging_mixin.py:95} INFO - [2019-08-28 12:41:35,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:35,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:35,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:41:35,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:41:35,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.586 seconds
[2019-08-28 12:41:35,771] {scheduler_job.py:146} INFO - Started process (PID=6424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:40,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:41:40,781] {logging_mixin.py:95} INFO - [2019-08-28 12:41:40,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:41,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:41,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:41:41,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:41:41,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:41:41,222] {scheduler_job.py:146} INFO - Started process (PID=6425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:46,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:41:46,230] {logging_mixin.py:95} INFO - [2019-08-28 12:41:46,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:46,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:46,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:41:46,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:41:46,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:41:46,671] {scheduler_job.py:146} INFO - Started process (PID=6430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:51,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:41:51,680] {logging_mixin.py:95} INFO - [2019-08-28 12:41:51,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:52,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:52,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:41:52,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:41:52,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:41:52,122] {scheduler_job.py:146} INFO - Started process (PID=6431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:57,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:41:57,133] {logging_mixin.py:95} INFO - [2019-08-28 12:41:57,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:57,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:41:57,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:41:57,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:41:57,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-28 12:41:57,676] {scheduler_job.py:146} INFO - Started process (PID=6433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:02,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:02,688] {logging_mixin.py:95} INFO - [2019-08-28 12:42:02,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:03,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:03,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:03,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:03,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:42:03,121] {scheduler_job.py:146} INFO - Started process (PID=6442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:08,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:08,130] {logging_mixin.py:95} INFO - [2019-08-28 12:42:08,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:08,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:08,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:08,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:08,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-08-28 12:42:08,674] {scheduler_job.py:146} INFO - Started process (PID=6444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:13,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:13,692] {logging_mixin.py:95} INFO - [2019-08-28 12:42:13,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:14,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:14,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:14,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:14,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 12:42:14,217] {scheduler_job.py:146} INFO - Started process (PID=6446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:19,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:19,228] {logging_mixin.py:95} INFO - [2019-08-28 12:42:19,227] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:19,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:19,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:19,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:19,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-28 12:42:19,767] {scheduler_job.py:146} INFO - Started process (PID=6448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:24,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:24,776] {logging_mixin.py:95} INFO - [2019-08-28 12:42:24,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:25,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:25,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:25,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:25,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 12:42:25,304] {scheduler_job.py:146} INFO - Started process (PID=6452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:30,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:30,313] {logging_mixin.py:95} INFO - [2019-08-28 12:42:30,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:30,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:30,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:30,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:30,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:42:30,752] {scheduler_job.py:146} INFO - Started process (PID=6454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:35,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:35,761] {logging_mixin.py:95} INFO - [2019-08-28 12:42:35,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:36,136] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:36,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:36,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:36,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 12:42:36,202] {scheduler_job.py:146} INFO - Started process (PID=6456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:41,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:41,211] {logging_mixin.py:95} INFO - [2019-08-28 12:42:41,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:41,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:41,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:41,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:41,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:42:41,656] {scheduler_job.py:146} INFO - Started process (PID=6460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:46,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:46,664] {logging_mixin.py:95} INFO - [2019-08-28 12:42:46,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:47,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:47,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:47,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:47,050] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:42:47,115] {scheduler_job.py:146} INFO - Started process (PID=6462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:52,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:52,123] {logging_mixin.py:95} INFO - [2019-08-28 12:42:52,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:52,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:52,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:52,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:52,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:42:52,559] {scheduler_job.py:146} INFO - Started process (PID=6466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:57,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:42:57,567] {logging_mixin.py:95} INFO - [2019-08-28 12:42:57,567] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:57,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:42:57,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:42:58,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:42:58,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 12:42:58,111] {scheduler_job.py:146} INFO - Started process (PID=6467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:03,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:03,123] {logging_mixin.py:95} INFO - [2019-08-28 12:43:03,123] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:03,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:03,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:03,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:03,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 12:43:03,653] {scheduler_job.py:146} INFO - Started process (PID=6470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:08,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:08,662] {logging_mixin.py:95} INFO - [2019-08-28 12:43:08,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:09,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:09,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:09,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:09,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:43:09,107] {scheduler_job.py:146} INFO - Started process (PID=6474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:14,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:14,115] {logging_mixin.py:95} INFO - [2019-08-28 12:43:14,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:14,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:14,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:14,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:14,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:43:14,556] {scheduler_job.py:146} INFO - Started process (PID=6475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:19,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:19,566] {logging_mixin.py:95} INFO - [2019-08-28 12:43:19,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:19,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:19,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:19,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:19,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:43:20,011] {scheduler_job.py:146} INFO - Started process (PID=6477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:25,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:25,023] {logging_mixin.py:95} INFO - [2019-08-28 12:43:25,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:25,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:25,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:25,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:25,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 12:43:25,473] {scheduler_job.py:146} INFO - Started process (PID=6481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:30,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:30,480] {logging_mixin.py:95} INFO - [2019-08-28 12:43:30,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:30,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:30,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:30,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:30,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-08-28 12:43:31,017] {scheduler_job.py:146} INFO - Started process (PID=6483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:36,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:36,025] {logging_mixin.py:95} INFO - [2019-08-28 12:43:36,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:36,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:36,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:36,413] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:36,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:43:36,459] {scheduler_job.py:146} INFO - Started process (PID=6488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:41,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:41,467] {logging_mixin.py:95} INFO - [2019-08-28 12:43:41,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:41,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:41,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:41,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:41,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 12:43:41,908] {scheduler_job.py:146} INFO - Started process (PID=6489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:46,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:46,918] {logging_mixin.py:95} INFO - [2019-08-28 12:43:46,918] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:47,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:47,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:47,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:47,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:43:47,374] {scheduler_job.py:146} INFO - Started process (PID=6491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:52,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:52,384] {logging_mixin.py:95} INFO - [2019-08-28 12:43:52,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:52,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:52,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:52,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:52,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 12:43:52,834] {scheduler_job.py:146} INFO - Started process (PID=6495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:57,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:43:57,843] {logging_mixin.py:95} INFO - [2019-08-28 12:43:57,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:58,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:43:58,245] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:43:58,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:43:58,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 12:43:58,284] {scheduler_job.py:146} INFO - Started process (PID=6496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:03,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:03,292] {logging_mixin.py:95} INFO - [2019-08-28 12:44:03,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:03,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:03,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:03,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:03,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:44:03,723] {scheduler_job.py:146} INFO - Started process (PID=6499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:08,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:08,731] {logging_mixin.py:95} INFO - [2019-08-28 12:44:08,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:09,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:09,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:09,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:09,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 12:44:09,173] {scheduler_job.py:146} INFO - Started process (PID=6500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:14,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:14,187] {logging_mixin.py:95} INFO - [2019-08-28 12:44:14,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:14,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:14,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:14,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:14,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 12:44:14,623] {scheduler_job.py:146} INFO - Started process (PID=6504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:19,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:19,632] {logging_mixin.py:95} INFO - [2019-08-28 12:44:19,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:19,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:20,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:20,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:20,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:44:20,073] {scheduler_job.py:146} INFO - Started process (PID=6506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:25,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:25,085] {logging_mixin.py:95} INFO - [2019-08-28 12:44:25,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:25,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:25,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:25,459] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:25,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:25,472] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 17:44:22.745216+00:00 [scheduled]> in ORM
[2019-08-28 12:44:25,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 12:44:25,529] {scheduler_job.py:146} INFO - Started process (PID=6510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:30,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:30,542] {logging_mixin.py:95} INFO - [2019-08-28 12:44:30,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:30,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:30,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:30,965] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:30,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:30,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 12:44:31,080] {scheduler_job.py:146} INFO - Started process (PID=6512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:36,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:36,089] {logging_mixin.py:95} INFO - [2019-08-28 12:44:36,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:36,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:36,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:36,468] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:36,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:36,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 12:44:36,530] {scheduler_job.py:146} INFO - Started process (PID=6515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:41,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:41,538] {logging_mixin.py:95} INFO - [2019-08-28 12:44:41,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:41,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:41,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:41,911] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:41,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:41,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 12:44:41,991] {scheduler_job.py:146} INFO - Started process (PID=6516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:46,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:46,999] {logging_mixin.py:95} INFO - [2019-08-28 12:44:46,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:47,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:47,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:47,369] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:47,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:47,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:44:47,445] {scheduler_job.py:146} INFO - Started process (PID=6522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:52,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:52,457] {logging_mixin.py:95} INFO - [2019-08-28 12:44:52,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:52,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:52,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:52,839] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:52,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:52,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 12:44:52,898] {scheduler_job.py:146} INFO - Started process (PID=6523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:57,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:44:57,908] {logging_mixin.py:95} INFO - [2019-08-28 12:44:57,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:58,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:44:58,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:44:58,304] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:44:58,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:44:58,321] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 17:44:22.745216+00:00 [scheduled]> in ORM
[2019-08-28 12:44:58,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 12:44:58,440] {scheduler_job.py:146} INFO - Started process (PID=6527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:03,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:03,452] {logging_mixin.py:95} INFO - [2019-08-28 12:45:03,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:03,803] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:03,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:03,835] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:03,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:03,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 12:45:03,895] {scheduler_job.py:146} INFO - Started process (PID=6530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:08,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:08,908] {logging_mixin.py:95} INFO - [2019-08-28 12:45:08,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:09,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:09,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:09,280] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:09,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:09,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:45:09,342] {scheduler_job.py:146} INFO - Started process (PID=6532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:14,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:14,355] {logging_mixin.py:95} INFO - [2019-08-28 12:45:14,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:14,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:14,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:14,727] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:14,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:14,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:45:14,806] {scheduler_job.py:146} INFO - Started process (PID=6536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:19,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:19,815] {logging_mixin.py:95} INFO - [2019-08-28 12:45:19,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:20,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:20,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:20,210] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:20,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:20,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 12:45:20,268] {scheduler_job.py:146} INFO - Started process (PID=6539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:25,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:25,276] {logging_mixin.py:95} INFO - [2019-08-28 12:45:25,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:25,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:25,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:25,680] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:25,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:25,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 12:45:25,733] {scheduler_job.py:146} INFO - Started process (PID=6540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:30,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:30,742] {logging_mixin.py:95} INFO - [2019-08-28 12:45:30,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:31,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:31,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:31,125] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True>
[2019-08-28 12:45:31,131] {logging_mixin.py:95} INFO - [2019-08-28 12:45:31,131] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 17:44:22.745216+00:00: manual__2019-08-28T17:44:22.745216+00:00, externally triggered: True> successful
[2019-08-28 12:45:31,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:31,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:45:31,197] {scheduler_job.py:146} INFO - Started process (PID=6543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:36,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:36,206] {logging_mixin.py:95} INFO - [2019-08-28 12:45:36,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:36,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:36,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:36,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:36,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:45:36,657] {scheduler_job.py:146} INFO - Started process (PID=6549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:41,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:41,670] {logging_mixin.py:95} INFO - [2019-08-28 12:45:41,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:42,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:42,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:42,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:42,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 12:45:42,117] {scheduler_job.py:146} INFO - Started process (PID=6550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:47,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:47,125] {logging_mixin.py:95} INFO - [2019-08-28 12:45:47,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:47,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:47,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:47,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:47,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 12:45:47,580] {scheduler_job.py:146} INFO - Started process (PID=6552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:52,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:52,592] {logging_mixin.py:95} INFO - [2019-08-28 12:45:52,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:52,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:52,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:52,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:52,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:45:53,046] {scheduler_job.py:146} INFO - Started process (PID=6556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:58,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:45:58,056] {logging_mixin.py:95} INFO - [2019-08-28 12:45:58,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:58,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:45:58,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:45:58,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:45:58,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:45:58,508] {scheduler_job.py:146} INFO - Started process (PID=6557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:03,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:03,518] {logging_mixin.py:95} INFO - [2019-08-28 12:46:03,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:03,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:03,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:03,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:03,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 12:46:03,956] {scheduler_job.py:146} INFO - Started process (PID=6559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:08,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:08,963] {logging_mixin.py:95} INFO - [2019-08-28 12:46:08,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:09,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:09,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:09,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:09,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:46:09,405] {scheduler_job.py:146} INFO - Started process (PID=6565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:14,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:14,414] {logging_mixin.py:95} INFO - [2019-08-28 12:46:14,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:14,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:14,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:14,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:14,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 12:46:14,848] {scheduler_job.py:146} INFO - Started process (PID=6572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:19,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:19,855] {logging_mixin.py:95} INFO - [2019-08-28 12:46:19,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:20,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:20,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:20,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:20,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 12:46:20,296] {scheduler_job.py:146} INFO - Started process (PID=6574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:25,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:25,308] {logging_mixin.py:95} INFO - [2019-08-28 12:46:25,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:25,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:25,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:25,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:25,708] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 12:46:25,748] {scheduler_job.py:146} INFO - Started process (PID=6575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:30,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:30,757] {logging_mixin.py:95} INFO - [2019-08-28 12:46:30,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:31,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:31,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:31,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:31,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:46:31,259] {scheduler_job.py:146} INFO - Started process (PID=6576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:36,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:36,267] {logging_mixin.py:95} INFO - [2019-08-28 12:46:36,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:36,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:36,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:36,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:36,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:46:36,722] {scheduler_job.py:146} INFO - Started process (PID=6578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:41,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:41,738] {logging_mixin.py:95} INFO - [2019-08-28 12:46:41,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:42,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:42,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:42,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:42,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:46:42,180] {scheduler_job.py:146} INFO - Started process (PID=6583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:47,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:47,190] {logging_mixin.py:95} INFO - [2019-08-28 12:46:47,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:47,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:47,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:47,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:47,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-28 12:46:47,739] {scheduler_job.py:146} INFO - Started process (PID=6585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:52,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:52,750] {logging_mixin.py:95} INFO - [2019-08-28 12:46:52,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:53,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:53,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:53,129] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:53,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:46:53,199] {scheduler_job.py:146} INFO - Started process (PID=6589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:58,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:46:58,205] {logging_mixin.py:95} INFO - [2019-08-28 12:46:58,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:58,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:46:58,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:46:58,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:46:58,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:46:58,665] {scheduler_job.py:146} INFO - Started process (PID=6590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:03,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:03,672] {logging_mixin.py:95} INFO - [2019-08-28 12:47:03,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:04,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:04,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:04,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:04,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 12:47:04,132] {scheduler_job.py:146} INFO - Started process (PID=6592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:09,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:09,142] {logging_mixin.py:95} INFO - [2019-08-28 12:47:09,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:09,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:09,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:09,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:09,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 12:47:09,699] {scheduler_job.py:146} INFO - Started process (PID=6596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:14,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:14,706] {logging_mixin.py:95} INFO - [2019-08-28 12:47:14,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:15,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:15,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:15,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:15,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 12:47:15,147] {scheduler_job.py:146} INFO - Started process (PID=6598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:20,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:20,154] {logging_mixin.py:95} INFO - [2019-08-28 12:47:20,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:20,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:20,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:20,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:20,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-28 12:47:20,603] {scheduler_job.py:146} INFO - Started process (PID=6600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:25,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:25,609] {logging_mixin.py:95} INFO - [2019-08-28 12:47:25,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:25,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:26,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:26,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:26,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 12:47:26,060] {scheduler_job.py:146} INFO - Started process (PID=6604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:31,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:31,066] {logging_mixin.py:95} INFO - [2019-08-28 12:47:31,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:31,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:31,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:31,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:31,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-28 12:47:31,515] {scheduler_job.py:146} INFO - Started process (PID=6606) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:36,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:36,525] {logging_mixin.py:95} INFO - [2019-08-28 12:47:36,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:36,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:36,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:36,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:36,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:47:36,970] {scheduler_job.py:146} INFO - Started process (PID=6610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:41,979] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:41,980] {logging_mixin.py:95} INFO - [2019-08-28 12:47:41,979] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:42,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:42,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:42,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:42,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 12:47:42,425] {scheduler_job.py:146} INFO - Started process (PID=6612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:47,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:47,434] {logging_mixin.py:95} INFO - [2019-08-28 12:47:47,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:47,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:47,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:47,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:47,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 12:47:47,884] {scheduler_job.py:146} INFO - Started process (PID=6614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:52,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:52,890] {logging_mixin.py:95} INFO - [2019-08-28 12:47:52,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:53,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:53,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:53,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:53,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 12:47:53,338] {scheduler_job.py:146} INFO - Started process (PID=6618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:58,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:47:58,349] {logging_mixin.py:95} INFO - [2019-08-28 12:47:58,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:58,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:47:58,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:47:58,723] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:47:58,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:47:58,787] {scheduler_job.py:146} INFO - Started process (PID=6619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:03,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:03,798] {logging_mixin.py:95} INFO - [2019-08-28 12:48:03,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:04,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:04,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:04,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:04,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:48:04,248] {scheduler_job.py:146} INFO - Started process (PID=6621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:09,257] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:09,258] {logging_mixin.py:95} INFO - [2019-08-28 12:48:09,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:09,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:09,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:09,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:09,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:48:09,712] {scheduler_job.py:146} INFO - Started process (PID=6622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:14,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:14,721] {logging_mixin.py:95} INFO - [2019-08-28 12:48:14,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:15,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:15,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:15,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:15,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-08-28 12:48:15,267] {scheduler_job.py:146} INFO - Started process (PID=6627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:20,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:20,276] {logging_mixin.py:95} INFO - [2019-08-28 12:48:20,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:20,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:20,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:20,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:20,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:48:20,717] {scheduler_job.py:146} INFO - Started process (PID=6629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:25,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:25,724] {logging_mixin.py:95} INFO - [2019-08-28 12:48:25,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:26,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:26,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:26,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:26,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:48:26,176] {scheduler_job.py:146} INFO - Started process (PID=6630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:31,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:31,183] {logging_mixin.py:95} INFO - [2019-08-28 12:48:31,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:31,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:31,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:31,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:31,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-28 12:48:31,639] {scheduler_job.py:146} INFO - Started process (PID=6635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:36,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:36,650] {logging_mixin.py:95} INFO - [2019-08-28 12:48:36,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:36,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:37,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:37,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:37,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:48:37,103] {scheduler_job.py:146} INFO - Started process (PID=6636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:42,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:42,115] {logging_mixin.py:95} INFO - [2019-08-28 12:48:42,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:42,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:42,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:42,487] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:42,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:48:42,569] {scheduler_job.py:146} INFO - Started process (PID=6637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:47,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:47,575] {logging_mixin.py:95} INFO - [2019-08-28 12:48:47,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:47,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:47,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:47,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:47,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:48:48,016] {scheduler_job.py:146} INFO - Started process (PID=6647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:53,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:53,023] {logging_mixin.py:95} INFO - [2019-08-28 12:48:53,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:53,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:53,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:53,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:53,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 12:48:53,466] {scheduler_job.py:146} INFO - Started process (PID=6649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:58,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:48:58,474] {logging_mixin.py:95} INFO - [2019-08-28 12:48:58,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:58,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:48:58,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:48:58,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:48:58,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 12:48:58,916] {scheduler_job.py:146} INFO - Started process (PID=6651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:03,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:03,923] {logging_mixin.py:95} INFO - [2019-08-28 12:49:03,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:04,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:04,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:04,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:04,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 12:49:04,375] {scheduler_job.py:146} INFO - Started process (PID=6656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:09,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:09,381] {logging_mixin.py:95} INFO - [2019-08-28 12:49:09,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:09,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:09,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:09,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:09,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:49:09,828] {scheduler_job.py:146} INFO - Started process (PID=6657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:14,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:14,837] {logging_mixin.py:95} INFO - [2019-08-28 12:49:14,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:15,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:15,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:15,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:15,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:49:15,290] {scheduler_job.py:146} INFO - Started process (PID=6661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:20,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:20,295] {logging_mixin.py:95} INFO - [2019-08-28 12:49:20,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:20,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:20,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:20,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:20,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 12:49:20,741] {scheduler_job.py:146} INFO - Started process (PID=6664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:25,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:25,751] {logging_mixin.py:95} INFO - [2019-08-28 12:49:25,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:26,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:26,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:26,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:26,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:49:26,189] {scheduler_job.py:146} INFO - Started process (PID=6665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:31,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:31,195] {logging_mixin.py:95} INFO - [2019-08-28 12:49:31,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:31,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:31,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:31,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:31,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 12:49:31,640] {scheduler_job.py:146} INFO - Started process (PID=6670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:36,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:36,648] {logging_mixin.py:95} INFO - [2019-08-28 12:49:36,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:36,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:37,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:37,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:37,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 12:49:37,097] {scheduler_job.py:146} INFO - Started process (PID=6671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:42,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:42,104] {logging_mixin.py:95} INFO - [2019-08-28 12:49:42,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:42,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:42,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:42,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:42,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:49:42,551] {scheduler_job.py:146} INFO - Started process (PID=6672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:47,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:47,560] {logging_mixin.py:95} INFO - [2019-08-28 12:49:47,559] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:47,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:47,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:47,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:47,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 12:49:48,004] {scheduler_job.py:146} INFO - Started process (PID=6678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:53,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:53,011] {logging_mixin.py:95} INFO - [2019-08-28 12:49:53,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:53,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:53,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:53,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:53,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:49:53,453] {scheduler_job.py:146} INFO - Started process (PID=6679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:58,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:49:58,460] {logging_mixin.py:95} INFO - [2019-08-28 12:49:58,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:58,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:49:58,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:49:58,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:49:58,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:49:58,899] {scheduler_job.py:146} INFO - Started process (PID=6680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:03,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:03,910] {logging_mixin.py:95} INFO - [2019-08-28 12:50:03,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:04,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:04,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:04,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:04,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:50:04,347] {scheduler_job.py:146} INFO - Started process (PID=6685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:09,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:09,357] {logging_mixin.py:95} INFO - [2019-08-28 12:50:09,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:09,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:09,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:09,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:09,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:50:09,797] {scheduler_job.py:146} INFO - Started process (PID=6687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:14,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:14,807] {logging_mixin.py:95} INFO - [2019-08-28 12:50:14,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:15,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:15,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:15,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:15,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 12:50:15,347] {scheduler_job.py:146} INFO - Started process (PID=6691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:20,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:20,354] {logging_mixin.py:95} INFO - [2019-08-28 12:50:20,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:20,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:20,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:20,782] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:20,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 12:50:20,900] {scheduler_job.py:146} INFO - Started process (PID=6697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:25,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:25,907] {logging_mixin.py:95} INFO - [2019-08-28 12:50:25,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:26,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:26,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:26,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:26,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:50:26,356] {scheduler_job.py:146} INFO - Started process (PID=6698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:31,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:31,364] {logging_mixin.py:95} INFO - [2019-08-28 12:50:31,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:31,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:31,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:31,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:31,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 12:50:31,805] {scheduler_job.py:146} INFO - Started process (PID=6700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:36,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:36,814] {logging_mixin.py:95} INFO - [2019-08-28 12:50:36,814] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:37,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:37,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:37,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:37,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-08-28 12:50:37,355] {scheduler_job.py:146} INFO - Started process (PID=6704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:42,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:42,366] {logging_mixin.py:95} INFO - [2019-08-28 12:50:42,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:42,720] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:42,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:42,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:42,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 12:50:42,803] {scheduler_job.py:146} INFO - Started process (PID=6705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:47,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:47,810] {logging_mixin.py:95} INFO - [2019-08-28 12:50:47,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:48,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:48,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:48,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:48,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 12:50:48,261] {scheduler_job.py:146} INFO - Started process (PID=6710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:53,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:53,267] {logging_mixin.py:95} INFO - [2019-08-28 12:50:53,267] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:53,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:53,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:53,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:53,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 12:50:53,717] {scheduler_job.py:146} INFO - Started process (PID=6712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:58,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:50:58,724] {logging_mixin.py:95} INFO - [2019-08-28 12:50:58,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:59,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:50:59,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:50:59,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:50:59,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 12:50:59,162] {scheduler_job.py:146} INFO - Started process (PID=6714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:04,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:04,170] {logging_mixin.py:95} INFO - [2019-08-28 12:51:04,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:04,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:04,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:04,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:04,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 12:51:04,609] {scheduler_job.py:146} INFO - Started process (PID=6719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:09,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:09,619] {logging_mixin.py:95} INFO - [2019-08-28 12:51:09,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:09,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:09,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:10,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:10,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:51:10,064] {scheduler_job.py:146} INFO - Started process (PID=6723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:15,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:15,071] {logging_mixin.py:95} INFO - [2019-08-28 12:51:15,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:15,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:15,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:15,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:15,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:51:15,520] {scheduler_job.py:146} INFO - Started process (PID=6724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:20,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:20,530] {logging_mixin.py:95} INFO - [2019-08-28 12:51:20,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:20,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:20,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:20,910] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:20,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:51:20,977] {scheduler_job.py:146} INFO - Started process (PID=6729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:25,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:25,987] {logging_mixin.py:95} INFO - [2019-08-28 12:51:25,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:26,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:26,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:26,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:26,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 12:51:26,521] {scheduler_job.py:146} INFO - Started process (PID=6731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:31,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:31,531] {logging_mixin.py:95} INFO - [2019-08-28 12:51:31,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:31,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:31,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:31,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:31,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:51:31,973] {scheduler_job.py:146} INFO - Started process (PID=6733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:36,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:36,982] {logging_mixin.py:95} INFO - [2019-08-28 12:51:36,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:37,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:37,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:37,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:37,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-08-28 12:51:37,520] {scheduler_job.py:146} INFO - Started process (PID=6740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:42,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:42,532] {logging_mixin.py:95} INFO - [2019-08-28 12:51:42,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:42,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:42,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:42,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:42,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 12:51:42,967] {scheduler_job.py:146} INFO - Started process (PID=6741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:47,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:47,978] {logging_mixin.py:95} INFO - [2019-08-28 12:51:47,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:48,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:48,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:48,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:48,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 12:51:48,428] {scheduler_job.py:146} INFO - Started process (PID=6743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:53,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:53,437] {logging_mixin.py:95} INFO - [2019-08-28 12:51:53,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:53,786] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:53,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:53,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:53,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:51:53,889] {scheduler_job.py:146} INFO - Started process (PID=6744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:58,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:51:58,895] {logging_mixin.py:95} INFO - [2019-08-28 12:51:58,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:59,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:51:59,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:51:59,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:51:59,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:51:59,346] {scheduler_job.py:146} INFO - Started process (PID=6749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:04,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:04,353] {logging_mixin.py:95} INFO - [2019-08-28 12:52:04,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:04,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:04,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:04,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:04,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:52:04,804] {scheduler_job.py:146} INFO - Started process (PID=6751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:09,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:09,813] {logging_mixin.py:95} INFO - [2019-08-28 12:52:09,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:10,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:10,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:10,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:10,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:52:10,262] {scheduler_job.py:146} INFO - Started process (PID=6755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:15,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:15,269] {logging_mixin.py:95} INFO - [2019-08-28 12:52:15,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:15,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:15,660] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:15,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:15,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 12:52:15,720] {scheduler_job.py:146} INFO - Started process (PID=6756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:20,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:20,729] {logging_mixin.py:95} INFO - [2019-08-28 12:52:20,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:21,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:21,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:21,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:21,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 12:52:21,185] {scheduler_job.py:146} INFO - Started process (PID=6758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:26,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:26,190] {logging_mixin.py:95} INFO - [2019-08-28 12:52:26,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:26,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:26,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:26,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:26,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 12:52:26,638] {scheduler_job.py:146} INFO - Started process (PID=6760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:31,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:31,647] {logging_mixin.py:95} INFO - [2019-08-28 12:52:31,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:32,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:32,044] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:32,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:32,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 12:52:32,110] {scheduler_job.py:146} INFO - Started process (PID=6765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:37,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:37,127] {logging_mixin.py:95} INFO - [2019-08-28 12:52:37,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:37,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:37,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:37,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:37,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 12:52:37,564] {scheduler_job.py:146} INFO - Started process (PID=6766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:42,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:42,570] {logging_mixin.py:95} INFO - [2019-08-28 12:52:42,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:42,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:42,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:42,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:42,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:52:43,024] {scheduler_job.py:146} INFO - Started process (PID=6770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:48,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:48,031] {logging_mixin.py:95} INFO - [2019-08-28 12:52:48,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:48,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:48,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:48,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:48,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:52:48,485] {scheduler_job.py:146} INFO - Started process (PID=6772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:53,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:53,492] {logging_mixin.py:95} INFO - [2019-08-28 12:52:53,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:53,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:53,860] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:53,868] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:53,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:52:53,948] {scheduler_job.py:146} INFO - Started process (PID=6773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:58,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:52:58,954] {logging_mixin.py:95} INFO - [2019-08-28 12:52:58,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:59,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:52:59,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:52:59,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:52:59,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:52:59,402] {scheduler_job.py:146} INFO - Started process (PID=6778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:04,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:04,408] {logging_mixin.py:95} INFO - [2019-08-28 12:53:04,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:04,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:04,783] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:04,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:04,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:53:04,871] {scheduler_job.py:146} INFO - Started process (PID=6780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:09,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:09,883] {logging_mixin.py:95} INFO - [2019-08-28 12:53:09,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:10,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:10,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:10,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:10,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:53:10,332] {scheduler_job.py:146} INFO - Started process (PID=6781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:15,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:15,340] {logging_mixin.py:95} INFO - [2019-08-28 12:53:15,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:15,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:15,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:15,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:15,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 12:53:15,789] {scheduler_job.py:146} INFO - Started process (PID=6782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:20,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:20,806] {logging_mixin.py:95} INFO - [2019-08-28 12:53:20,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:21,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:21,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:21,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:21,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 12:53:21,244] {scheduler_job.py:146} INFO - Started process (PID=6787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:26,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:26,252] {logging_mixin.py:95} INFO - [2019-08-28 12:53:26,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:26,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:26,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:26,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:26,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:53:26,703] {scheduler_job.py:146} INFO - Started process (PID=6788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:31,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:31,712] {logging_mixin.py:95} INFO - [2019-08-28 12:53:31,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:32,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:32,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:32,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:32,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:53:32,158] {scheduler_job.py:146} INFO - Started process (PID=6794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:37,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:37,166] {logging_mixin.py:95} INFO - [2019-08-28 12:53:37,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:37,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:37,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:37,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:37,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 12:53:37,621] {scheduler_job.py:146} INFO - Started process (PID=6795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:42,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:42,632] {logging_mixin.py:95} INFO - [2019-08-28 12:53:42,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:43,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:43,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:43,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:43,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 12:53:43,079] {scheduler_job.py:146} INFO - Started process (PID=6797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:48,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:48,088] {logging_mixin.py:95} INFO - [2019-08-28 12:53:48,088] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:48,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:48,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:48,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:48,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 12:53:48,526] {scheduler_job.py:146} INFO - Started process (PID=6804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:53,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:53,536] {logging_mixin.py:95} INFO - [2019-08-28 12:53:53,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:53,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:53,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:53,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:53,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 12:53:53,979] {scheduler_job.py:146} INFO - Started process (PID=6805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:58,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:53:58,991] {logging_mixin.py:95} INFO - [2019-08-28 12:53:58,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:59,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:53:59,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:53:59,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:53:59,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 12:53:59,515] {scheduler_job.py:146} INFO - Started process (PID=6806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:04,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:04,523] {logging_mixin.py:95} INFO - [2019-08-28 12:54:04,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:04,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:04,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:04,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:04,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 12:54:04,956] {scheduler_job.py:146} INFO - Started process (PID=6812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:09,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:09,965] {logging_mixin.py:95} INFO - [2019-08-28 12:54:09,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:10,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:10,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:10,366] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:10,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 12:54:10,407] {scheduler_job.py:146} INFO - Started process (PID=6813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:15,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:15,417] {logging_mixin.py:95} INFO - [2019-08-28 12:54:15,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:15,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:15,783] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:15,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:15,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:54:15,860] {scheduler_job.py:146} INFO - Started process (PID=6814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:20,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:20,871] {logging_mixin.py:95} INFO - [2019-08-28 12:54:20,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:21,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:21,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:21,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:21,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 12:54:21,413] {scheduler_job.py:146} INFO - Started process (PID=6816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:26,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:26,424] {logging_mixin.py:95} INFO - [2019-08-28 12:54:26,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:26,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:26,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:26,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:26,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:54:26,861] {scheduler_job.py:146} INFO - Started process (PID=6820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:31,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:31,865] {logging_mixin.py:95} INFO - [2019-08-28 12:54:31,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:32,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:32,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:32,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:32,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 12:54:32,314] {scheduler_job.py:146} INFO - Started process (PID=6826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:37,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:37,321] {logging_mixin.py:95} INFO - [2019-08-28 12:54:37,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:37,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:37,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:37,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:37,763] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 12:54:37,862] {scheduler_job.py:146} INFO - Started process (PID=6827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:42,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:42,871] {logging_mixin.py:95} INFO - [2019-08-28 12:54:42,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:43,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:43,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:43,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:43,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 12:54:43,308] {scheduler_job.py:146} INFO - Started process (PID=6828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:48,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:48,327] {logging_mixin.py:95} INFO - [2019-08-28 12:54:48,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:48,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:48,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:48,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:48,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 12:54:48,765] {scheduler_job.py:146} INFO - Started process (PID=6833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:53,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:53,774] {logging_mixin.py:95} INFO - [2019-08-28 12:54:53,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:54,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:54,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:54,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:54,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 12:54:54,216] {scheduler_job.py:146} INFO - Started process (PID=6834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:59,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:54:59,226] {logging_mixin.py:95} INFO - [2019-08-28 12:54:59,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:59,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:54:59,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:54:59,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:54:59,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 12:54:59,665] {scheduler_job.py:146} INFO - Started process (PID=6835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:04,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:04,675] {logging_mixin.py:95} INFO - [2019-08-28 12:55:04,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:05,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:05,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:05,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:05,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 12:55:05,104] {scheduler_job.py:146} INFO - Started process (PID=6841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:10,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:10,111] {logging_mixin.py:95} INFO - [2019-08-28 12:55:10,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:10,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:10,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:10,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:10,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 12:55:10,559] {scheduler_job.py:146} INFO - Started process (PID=6842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:15,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:15,570] {logging_mixin.py:95} INFO - [2019-08-28 12:55:15,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:15,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:15,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:15,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:15,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 12:55:16,010] {scheduler_job.py:146} INFO - Started process (PID=6843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:21,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:21,016] {logging_mixin.py:95} INFO - [2019-08-28 12:55:21,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:21,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:21,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:21,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:21,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 12:55:21,461] {scheduler_job.py:146} INFO - Started process (PID=6848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:26,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:26,468] {logging_mixin.py:95} INFO - [2019-08-28 12:55:26,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:26,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:26,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:26,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:26,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 12:55:26,907] {scheduler_job.py:146} INFO - Started process (PID=6850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:31,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:31,918] {logging_mixin.py:95} INFO - [2019-08-28 12:55:31,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:32,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:32,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:32,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:32,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 12:55:32,360] {scheduler_job.py:146} INFO - Started process (PID=6853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:37,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:37,368] {logging_mixin.py:95} INFO - [2019-08-28 12:55:37,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:37,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:37,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:37,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:37,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:55:37,810] {scheduler_job.py:146} INFO - Started process (PID=6855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:42,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:42,821] {logging_mixin.py:95} INFO - [2019-08-28 12:55:42,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:43,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:43,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:43,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:43,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-28 12:55:43,274] {scheduler_job.py:146} INFO - Started process (PID=6859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:48,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:48,296] {logging_mixin.py:95} INFO - [2019-08-28 12:55:48,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:48,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:48,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:48,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:48,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 12:55:48,737] {scheduler_job.py:146} INFO - Started process (PID=6861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:53,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:53,744] {logging_mixin.py:95} INFO - [2019-08-28 12:55:53,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:54,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:54,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:54,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:54,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-28 12:55:54,200] {scheduler_job.py:146} INFO - Started process (PID=6862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:59,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:55:59,211] {logging_mixin.py:95} INFO - [2019-08-28 12:55:59,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:59,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:55:59,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:55:59,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:55:59,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:55:59,662] {scheduler_job.py:146} INFO - Started process (PID=6863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:04,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:04,669] {logging_mixin.py:95} INFO - [2019-08-28 12:56:04,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:05,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:05,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:05,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:05,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 12:56:05,110] {scheduler_job.py:146} INFO - Started process (PID=6868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:10,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:10,115] {logging_mixin.py:95} INFO - [2019-08-28 12:56:10,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:10,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:10,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:10,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:10,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 12:56:10,571] {scheduler_job.py:146} INFO - Started process (PID=6873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:15,581] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:15,582] {logging_mixin.py:95} INFO - [2019-08-28 12:56:15,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:15,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:15,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:15,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:15,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 12:56:16,031] {scheduler_job.py:146} INFO - Started process (PID=6874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:21,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:21,039] {logging_mixin.py:95} INFO - [2019-08-28 12:56:21,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:21,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:21,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:21,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:21,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 12:56:21,483] {scheduler_job.py:146} INFO - Started process (PID=6876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:26,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:26,492] {logging_mixin.py:95} INFO - [2019-08-28 12:56:26,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:26,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:26,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:26,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:26,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 12:56:26,939] {scheduler_job.py:146} INFO - Started process (PID=6880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:31,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:31,946] {logging_mixin.py:95} INFO - [2019-08-28 12:56:31,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:32,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:32,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:32,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:32,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:56:32,410] {scheduler_job.py:146} INFO - Started process (PID=6882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:37,419] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:37,419] {logging_mixin.py:95} INFO - [2019-08-28 12:56:37,419] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:37,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:37,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:37,806] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:37,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 12:56:37,860] {scheduler_job.py:146} INFO - Started process (PID=6884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:42,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:42,868] {logging_mixin.py:95} INFO - [2019-08-28 12:56:42,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:43,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:43,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:43,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:43,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:56:43,320] {scheduler_job.py:146} INFO - Started process (PID=6888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:48,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:48,328] {logging_mixin.py:95} INFO - [2019-08-28 12:56:48,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:48,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:48,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:48,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:48,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:56:48,786] {scheduler_job.py:146} INFO - Started process (PID=6890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:53,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:53,798] {logging_mixin.py:95} INFO - [2019-08-28 12:56:53,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:54,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:54,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:54,178] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:54,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 12:56:54,249] {scheduler_job.py:146} INFO - Started process (PID=6891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:59,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:56:59,260] {logging_mixin.py:95} INFO - [2019-08-28 12:56:59,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:59,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:56:59,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:56:59,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:56:59,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 12:56:59,711] {scheduler_job.py:146} INFO - Started process (PID=6892) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:04,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:04,718] {logging_mixin.py:95} INFO - [2019-08-28 12:57:04,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:05,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:05,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:05,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:05,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:57:05,166] {scheduler_job.py:146} INFO - Started process (PID=6897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:10,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:10,174] {logging_mixin.py:95} INFO - [2019-08-28 12:57:10,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:10,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:10,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:10,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:10,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-28 12:57:10,629] {scheduler_job.py:146} INFO - Started process (PID=6899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:15,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:15,640] {logging_mixin.py:95} INFO - [2019-08-28 12:57:15,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:15,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:16,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:16,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:16,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 12:57:16,092] {scheduler_job.py:146} INFO - Started process (PID=6903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:21,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:21,100] {logging_mixin.py:95} INFO - [2019-08-28 12:57:21,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:21,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:21,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:21,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:21,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:57:21,557] {scheduler_job.py:146} INFO - Started process (PID=6905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:26,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:26,568] {logging_mixin.py:95} INFO - [2019-08-28 12:57:26,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:26,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:26,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:26,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:26,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 12:57:27,022] {scheduler_job.py:146} INFO - Started process (PID=6906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:32,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:32,031] {logging_mixin.py:95} INFO - [2019-08-28 12:57:32,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:32,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:32,396] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:32,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:32,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 12:57:32,488] {scheduler_job.py:146} INFO - Started process (PID=6911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:37,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:37,494] {logging_mixin.py:95} INFO - [2019-08-28 12:57:37,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:37,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:37,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:37,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:37,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-28 12:57:37,952] {scheduler_job.py:146} INFO - Started process (PID=6912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:42,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:42,962] {logging_mixin.py:95} INFO - [2019-08-28 12:57:42,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:43,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:43,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:43,336] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:43,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:57:43,406] {scheduler_job.py:146} INFO - Started process (PID=6917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:48,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:48,414] {logging_mixin.py:95} INFO - [2019-08-28 12:57:48,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:48,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:48,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:48,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:48,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:57:48,871] {scheduler_job.py:146} INFO - Started process (PID=6919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:53,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:53,880] {logging_mixin.py:95} INFO - [2019-08-28 12:57:53,880] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:54,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:54,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:54,254] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:54,260] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:57:54,336] {scheduler_job.py:146} INFO - Started process (PID=6920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:59,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:57:59,347] {logging_mixin.py:95} INFO - [2019-08-28 12:57:59,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:59,689] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:57:59,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:57:59,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:57:59,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 12:57:59,800] {scheduler_job.py:146} INFO - Started process (PID=6921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:04,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:04,811] {logging_mixin.py:95} INFO - [2019-08-28 12:58:04,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:05,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:05,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:05,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:05,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:58:05,260] {scheduler_job.py:146} INFO - Started process (PID=6926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:10,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:10,271] {logging_mixin.py:95} INFO - [2019-08-28 12:58:10,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:10,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:10,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:10,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:10,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 12:58:10,723] {scheduler_job.py:146} INFO - Started process (PID=6927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:15,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:15,730] {logging_mixin.py:95} INFO - [2019-08-28 12:58:15,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:16,071] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:16,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:16,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:16,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 12:58:16,185] {scheduler_job.py:146} INFO - Started process (PID=6929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:21,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:21,193] {logging_mixin.py:95} INFO - [2019-08-28 12:58:21,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:21,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:21,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:21,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:21,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 12:58:21,648] {scheduler_job.py:146} INFO - Started process (PID=6931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:26,659] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:26,660] {logging_mixin.py:95} INFO - [2019-08-28 12:58:26,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:27,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:27,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:27,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:27,036] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 12:58:27,110] {scheduler_job.py:146} INFO - Started process (PID=6935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:32,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:32,120] {logging_mixin.py:95} INFO - [2019-08-28 12:58:32,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:32,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:32,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:32,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:32,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 12:58:32,580] {scheduler_job.py:146} INFO - Started process (PID=6937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:37,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:37,588] {logging_mixin.py:95} INFO - [2019-08-28 12:58:37,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:37,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:37,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:37,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:37,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 12:58:38,040] {scheduler_job.py:146} INFO - Started process (PID=6941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:43,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:43,048] {logging_mixin.py:95} INFO - [2019-08-28 12:58:43,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:43,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:43,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:43,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:43,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 12:58:43,498] {scheduler_job.py:146} INFO - Started process (PID=6943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:48,504] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:48,517] {logging_mixin.py:95} INFO - [2019-08-28 12:58:48,516] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:48,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:48,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:48,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:48,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:58:48,956] {scheduler_job.py:146} INFO - Started process (PID=6945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:53,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:53,963] {logging_mixin.py:95} INFO - [2019-08-28 12:58:53,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:54,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:54,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:54,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:54,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:58:54,418] {scheduler_job.py:146} INFO - Started process (PID=6949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:59,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:58:59,429] {logging_mixin.py:95} INFO - [2019-08-28 12:58:59,429] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:59,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:58:59,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:58:59,806] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:58:59,811] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 12:58:59,879] {scheduler_job.py:146} INFO - Started process (PID=6950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:04,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:04,886] {logging_mixin.py:95} INFO - [2019-08-28 12:59:04,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:05,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:05,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:05,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:05,260] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 12:59:05,346] {scheduler_job.py:146} INFO - Started process (PID=6952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:10,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:10,352] {logging_mixin.py:95} INFO - [2019-08-28 12:59:10,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:10,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:10,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:10,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:10,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-28 12:59:10,807] {scheduler_job.py:146} INFO - Started process (PID=6953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:15,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:15,814] {logging_mixin.py:95} INFO - [2019-08-28 12:59:15,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:16,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:16,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:16,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:16,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 12:59:16,270] {scheduler_job.py:146} INFO - Started process (PID=6958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:21,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:21,277] {logging_mixin.py:95} INFO - [2019-08-28 12:59:21,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:21,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:21,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:21,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:21,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:59:21,739] {scheduler_job.py:146} INFO - Started process (PID=6963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:26,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:26,746] {logging_mixin.py:95} INFO - [2019-08-28 12:59:26,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:27,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:27,178] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:27,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:27,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 12:59:27,211] {scheduler_job.py:146} INFO - Started process (PID=6964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:32,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:32,222] {logging_mixin.py:95} INFO - [2019-08-28 12:59:32,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:32,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:32,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:32,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:32,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 12:59:32,710] {scheduler_job.py:146} INFO - Started process (PID=6966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:37,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:37,716] {logging_mixin.py:95} INFO - [2019-08-28 12:59:37,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:38,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:38,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:38,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:38,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 12:59:38,201] {scheduler_job.py:146} INFO - Started process (PID=6970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:43,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:43,208] {logging_mixin.py:95} INFO - [2019-08-28 12:59:43,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:43,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:43,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:43,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:43,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 12:59:43,689] {scheduler_job.py:146} INFO - Started process (PID=6971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:43,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:43,695] {logging_mixin.py:95} INFO - [2019-08-28 12:59:43,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:44,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:44,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-08-28 12:59:44,102] {scheduler_job.py:146} INFO - Started process (PID=6972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:44,107] {logging_mixin.py:95} INFO - [2019-08-28 12:59:44,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:44,477] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:44,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-08-28 12:59:44,514] {scheduler_job.py:146} INFO - Started process (PID=6973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:44,519] {logging_mixin.py:95} INFO - [2019-08-28 12:59:44,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:44,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:44,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.377 seconds
[2019-08-28 12:59:44,923] {scheduler_job.py:146} INFO - Started process (PID=6974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:44,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:44,928] {logging_mixin.py:95} INFO - [2019-08-28 12:59:44,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,262] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:45,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:45,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-08-28 12:59:45,335] {scheduler_job.py:146} INFO - Started process (PID=6975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:45,339] {logging_mixin.py:95} INFO - [2019-08-28 12:59:45,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:45,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:45,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-08-28 12:59:45,746] {scheduler_job.py:146} INFO - Started process (PID=6976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:45,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:45,751] {logging_mixin.py:95} INFO - [2019-08-28 12:59:45,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:46,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:46,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-08-28 12:59:46,156] {scheduler_job.py:146} INFO - Started process (PID=6978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:46,161] {logging_mixin.py:95} INFO - [2019-08-28 12:59:46,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:46,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:46,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-08-28 12:59:46,565] {scheduler_job.py:146} INFO - Started process (PID=6979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:46,569] {logging_mixin.py:95} INFO - [2019-08-28 12:59:46,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:46,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:46,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:46,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.398 seconds
[2019-08-28 12:59:47,107] {scheduler_job.py:146} INFO - Started process (PID=6981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:47,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:47,128] {logging_mixin.py:95} INFO - [2019-08-28 12:59:47,123] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:47,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:47,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:47,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:47,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.871 seconds
[2019-08-28 12:59:48,002] {scheduler_job.py:146} INFO - Started process (PID=6982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:48,006] {logging_mixin.py:95} INFO - [2019-08-28 12:59:48,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:48,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:48,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.385 seconds
[2019-08-28 12:59:48,410] {scheduler_job.py:146} INFO - Started process (PID=6983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:48,414] {logging_mixin.py:95} INFO - [2019-08-28 12:59:48,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:48,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:48,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.359 seconds
[2019-08-28 12:59:48,821] {scheduler_job.py:146} INFO - Started process (PID=6984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:48,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:48,826] {logging_mixin.py:95} INFO - [2019-08-28 12:59:48,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:49,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:49,175] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 12:59:49,182] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 12:59:49,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.366 seconds
[2019-08-28 12:59:49,233] {scheduler_job.py:146} INFO - Started process (PID=6985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 12:59:49,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 12:59:49,238] {logging_mixin.py:95} INFO - [2019-08-28 12:59:49,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:12,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:12,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 22.927 seconds
[2019-08-28 13:00:12,217] {scheduler_job.py:146} INFO - Started process (PID=6986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:12,222] {logging_mixin.py:95} INFO - [2019-08-28 13:00:12,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:12,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:12,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.485 seconds
[2019-08-28 13:00:12,735] {scheduler_job.py:146} INFO - Started process (PID=6991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:12,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:12,742] {logging_mixin.py:95} INFO - [2019-08-28 13:00:12,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:13,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:13,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:13,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:13,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.514 seconds
[2019-08-28 13:00:13,336] {scheduler_job.py:146} INFO - Started process (PID=6992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:18,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:18,829] {logging_mixin.py:95} INFO - [2019-08-28 13:00:18,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:19,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:19,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:19,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:19,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.947 seconds
[2019-08-28 13:00:19,389] {scheduler_job.py:146} INFO - Started process (PID=6998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:24,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:24,396] {logging_mixin.py:95} INFO - [2019-08-28 13:00:24,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:24,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:24,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:24,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:24,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-08-28 13:00:24,835] {scheduler_job.py:146} INFO - Started process (PID=7007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:29,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:29,846] {logging_mixin.py:95} INFO - [2019-08-28 13:00:29,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:30,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:30,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:30,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:30,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:00:30,286] {scheduler_job.py:146} INFO - Started process (PID=7010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:35,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:35,292] {logging_mixin.py:95} INFO - [2019-08-28 13:00:35,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:35,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:35,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:35,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:35,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 13:00:35,842] {scheduler_job.py:146} INFO - Started process (PID=7011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:40,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:40,855] {logging_mixin.py:95} INFO - [2019-08-28 13:00:40,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:41,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:41,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:41,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:41,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 13:00:41,385] {scheduler_job.py:146} INFO - Started process (PID=7017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:46,392] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:46,393] {logging_mixin.py:95} INFO - [2019-08-28 13:00:46,393] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:46,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:46,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:46,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:46,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:00:46,842] {scheduler_job.py:146} INFO - Started process (PID=7018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:51,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:51,849] {logging_mixin.py:95} INFO - [2019-08-28 13:00:51,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:52,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:52,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:52,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:52,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:00:52,300] {scheduler_job.py:146} INFO - Started process (PID=7022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:57,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:00:57,310] {logging_mixin.py:95} INFO - [2019-08-28 13:00:57,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:57,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:00:57,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:00:57,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:00:57,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:00:57,751] {scheduler_job.py:146} INFO - Started process (PID=7024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:02,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:02,763] {logging_mixin.py:95} INFO - [2019-08-28 13:01:02,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:03,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:03,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:03,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:03,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:01:03,214] {scheduler_job.py:146} INFO - Started process (PID=7025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:08,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:08,225] {logging_mixin.py:95} INFO - [2019-08-28 13:01:08,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:08,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:08,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:08,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:08,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:01:08,672] {scheduler_job.py:146} INFO - Started process (PID=7029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:13,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:13,681] {logging_mixin.py:95} INFO - [2019-08-28 13:01:13,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:14,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:14,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:14,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:14,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:01:14,128] {scheduler_job.py:146} INFO - Started process (PID=7032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:19,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:19,134] {logging_mixin.py:95} INFO - [2019-08-28 13:01:19,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:19,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:19,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:19,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:19,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:01:19,583] {scheduler_job.py:146} INFO - Started process (PID=7036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:24,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:24,593] {logging_mixin.py:95} INFO - [2019-08-28 13:01:24,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:24,966] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:24,991] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:24,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:25,005] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:01:25,031] {scheduler_job.py:146} INFO - Started process (PID=7038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:30,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:30,038] {logging_mixin.py:95} INFO - [2019-08-28 13:01:30,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:30,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:30,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:30,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:30,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:01:30,491] {scheduler_job.py:146} INFO - Started process (PID=7039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:35,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:35,498] {logging_mixin.py:95} INFO - [2019-08-28 13:01:35,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:35,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:35,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:35,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:35,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:01:35,956] {scheduler_job.py:146} INFO - Started process (PID=7043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:40,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:40,965] {logging_mixin.py:95} INFO - [2019-08-28 13:01:40,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:41,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:41,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:41,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:41,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-08-28 13:01:41,506] {scheduler_job.py:146} INFO - Started process (PID=7045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:46,514] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:46,515] {logging_mixin.py:95} INFO - [2019-08-28 13:01:46,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:46,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:46,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:46,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:46,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:01:46,949] {scheduler_job.py:146} INFO - Started process (PID=7048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:51,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:51,957] {logging_mixin.py:95} INFO - [2019-08-28 13:01:51,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:52,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:52,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:52,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:52,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:01:52,394] {scheduler_job.py:146} INFO - Started process (PID=7052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:57,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:01:57,406] {logging_mixin.py:95} INFO - [2019-08-28 13:01:57,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:57,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:01:57,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:01:57,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:01:57,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:01:57,846] {scheduler_job.py:146} INFO - Started process (PID=7054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:02,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:02,856] {logging_mixin.py:95} INFO - [2019-08-28 13:02:02,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:03,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:03,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:03,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:03,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:02:03,307] {scheduler_job.py:146} INFO - Started process (PID=7055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:08,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:08,315] {logging_mixin.py:95} INFO - [2019-08-28 13:02:08,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:08,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:08,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:08,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:08,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:02:08,758] {scheduler_job.py:146} INFO - Started process (PID=7056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:13,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:13,766] {logging_mixin.py:95} INFO - [2019-08-28 13:02:13,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:14,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:14,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:14,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:14,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:02:14,213] {scheduler_job.py:146} INFO - Started process (PID=7061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:19,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:19,223] {logging_mixin.py:95} INFO - [2019-08-28 13:02:19,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:19,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:19,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:19,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:19,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 13:02:19,759] {scheduler_job.py:146} INFO - Started process (PID=7063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:24,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:24,766] {logging_mixin.py:95} INFO - [2019-08-28 13:02:24,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:25,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:25,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:25,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:25,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 13:02:25,207] {scheduler_job.py:146} INFO - Started process (PID=7065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:30,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:30,217] {logging_mixin.py:95} INFO - [2019-08-28 13:02:30,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:30,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:30,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:30,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:30,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:02:30,658] {scheduler_job.py:146} INFO - Started process (PID=7069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:35,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:35,667] {logging_mixin.py:95} INFO - [2019-08-28 13:02:35,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:36,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:36,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:36,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:36,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:02:36,109] {scheduler_job.py:146} INFO - Started process (PID=7070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:41,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:41,126] {logging_mixin.py:95} INFO - [2019-08-28 13:02:41,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:41,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:41,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:41,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:41,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 13:02:41,563] {scheduler_job.py:146} INFO - Started process (PID=7072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:46,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:46,569] {logging_mixin.py:95} INFO - [2019-08-28 13:02:46,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:46,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:46,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:46,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:46,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:02:47,009] {scheduler_job.py:146} INFO - Started process (PID=7077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:52,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:52,017] {logging_mixin.py:95} INFO - [2019-08-28 13:02:52,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:52,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:52,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:52,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:52,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:02:52,561] {scheduler_job.py:146} INFO - Started process (PID=7078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:57,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:02:57,570] {logging_mixin.py:95} INFO - [2019-08-28 13:02:57,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:57,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:02:57,931] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:02:57,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:02:57,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 13:02:58,020] {scheduler_job.py:146} INFO - Started process (PID=7083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:03,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:03,031] {logging_mixin.py:95} INFO - [2019-08-28 13:03:03,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:03,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:03,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:03,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:03,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:03:03,473] {scheduler_job.py:146} INFO - Started process (PID=7084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:08,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:08,484] {logging_mixin.py:95} INFO - [2019-08-28 13:03:08,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:08,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:08,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:08,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:08,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:03:08,929] {scheduler_job.py:146} INFO - Started process (PID=7085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:13,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:13,938] {logging_mixin.py:95} INFO - [2019-08-28 13:03:13,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:14,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:14,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:14,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:14,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:03:14,386] {scheduler_job.py:146} INFO - Started process (PID=7087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:19,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:19,396] {logging_mixin.py:95} INFO - [2019-08-28 13:03:19,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:19,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:19,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:19,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:19,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 13:03:19,840] {scheduler_job.py:146} INFO - Started process (PID=7092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:24,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:24,846] {logging_mixin.py:95} INFO - [2019-08-28 13:03:24,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:25,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:25,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:25,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:25,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:03:25,294] {scheduler_job.py:146} INFO - Started process (PID=7097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:30,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:30,304] {logging_mixin.py:95} INFO - [2019-08-28 13:03:30,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:30,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:30,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:30,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:30,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:03:30,757] {scheduler_job.py:146} INFO - Started process (PID=7098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:35,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:35,765] {logging_mixin.py:95} INFO - [2019-08-28 13:03:35,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:36,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:36,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:36,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:36,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 13:03:36,213] {scheduler_job.py:146} INFO - Started process (PID=7099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:41,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:41,232] {logging_mixin.py:95} INFO - [2019-08-28 13:03:41,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:41,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:41,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:41,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:41,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:03:41,672] {scheduler_job.py:146} INFO - Started process (PID=7101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:46,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:46,681] {logging_mixin.py:95} INFO - [2019-08-28 13:03:46,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:47,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:47,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:47,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:47,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:03:47,133] {scheduler_job.py:146} INFO - Started process (PID=7105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:52,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:52,141] {logging_mixin.py:95} INFO - [2019-08-28 13:03:52,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:52,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:52,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:52,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:52,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:03:52,590] {scheduler_job.py:146} INFO - Started process (PID=7107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:57,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:03:57,597] {logging_mixin.py:95} INFO - [2019-08-28 13:03:57,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:57,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:03:57,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:03:57,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:03:57,996] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:03:58,047] {scheduler_job.py:146} INFO - Started process (PID=7109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:03,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:03,055] {logging_mixin.py:95} INFO - [2019-08-28 13:04:03,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:03,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:03,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:03,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:03,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:04:03,508] {scheduler_job.py:146} INFO - Started process (PID=7113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:08,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:08,516] {logging_mixin.py:95} INFO - [2019-08-28 13:04:08,516] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:08,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:08,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:08,890] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:08,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:04:08,969] {scheduler_job.py:146} INFO - Started process (PID=7114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:13,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:13,978] {logging_mixin.py:95} INFO - [2019-08-28 13:04:13,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:14,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:14,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:14,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:14,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:04:14,430] {scheduler_job.py:146} INFO - Started process (PID=7119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:19,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:19,440] {logging_mixin.py:95} INFO - [2019-08-28 13:04:19,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:19,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:19,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:19,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:19,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:04:19,889] {scheduler_job.py:146} INFO - Started process (PID=7120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:24,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:24,901] {logging_mixin.py:95} INFO - [2019-08-28 13:04:24,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:25,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:25,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:25,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:25,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:04:25,339] {scheduler_job.py:146} INFO - Started process (PID=7123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:30,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:30,347] {logging_mixin.py:95} INFO - [2019-08-28 13:04:30,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:30,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:30,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:30,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:30,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:04:30,800] {scheduler_job.py:146} INFO - Started process (PID=7127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:35,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:35,807] {logging_mixin.py:95} INFO - [2019-08-28 13:04:35,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:36,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:36,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:36,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:36,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:04:36,260] {scheduler_job.py:146} INFO - Started process (PID=7128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:41,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:41,283] {logging_mixin.py:95} INFO - [2019-08-28 13:04:41,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:41,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:41,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:41,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:41,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:04:41,721] {scheduler_job.py:146} INFO - Started process (PID=7130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:46,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:46,730] {logging_mixin.py:95} INFO - [2019-08-28 13:04:46,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:47,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:47,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:47,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:47,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:04:47,184] {scheduler_job.py:146} INFO - Started process (PID=7134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:52,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:52,190] {logging_mixin.py:95} INFO - [2019-08-28 13:04:52,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:52,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:52,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:52,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:52,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 13:04:52,639] {scheduler_job.py:146} INFO - Started process (PID=7136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:57,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:04:57,650] {logging_mixin.py:95} INFO - [2019-08-28 13:04:57,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:58,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:04:58,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:04:58,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:04:58,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:04:58,092] {scheduler_job.py:146} INFO - Started process (PID=7138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:03,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:03,105] {logging_mixin.py:95} INFO - [2019-08-28 13:05:03,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:03,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:03,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:03,477] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:03,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:05:03,553] {scheduler_job.py:146} INFO - Started process (PID=7139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:08,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:08,562] {logging_mixin.py:95} INFO - [2019-08-28 13:05:08,562] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:08,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:08,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:08,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:08,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:05:09,012] {scheduler_job.py:146} INFO - Started process (PID=7143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:14,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:14,022] {logging_mixin.py:95} INFO - [2019-08-28 13:05:14,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:14,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:14,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:14,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:14,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:05:14,471] {scheduler_job.py:146} INFO - Started process (PID=7145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:19,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:19,480] {logging_mixin.py:95} INFO - [2019-08-28 13:05:19,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:19,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:19,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:19,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:19,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:05:19,926] {scheduler_job.py:146} INFO - Started process (PID=7149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:24,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:24,938] {logging_mixin.py:95} INFO - [2019-08-28 13:05:24,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:25,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:25,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:25,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:25,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:05:25,372] {scheduler_job.py:146} INFO - Started process (PID=7152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:30,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:30,379] {logging_mixin.py:95} INFO - [2019-08-28 13:05:30,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:30,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:30,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:30,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:30,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:05:30,824] {scheduler_job.py:146} INFO - Started process (PID=7153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:35,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:35,833] {logging_mixin.py:95} INFO - [2019-08-28 13:05:35,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:36,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:36,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:36,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:36,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:05:36,271] {scheduler_job.py:146} INFO - Started process (PID=7154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:41,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:41,290] {logging_mixin.py:95} INFO - [2019-08-28 13:05:41,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:41,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:41,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:41,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:41,666] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:05:41,721] {scheduler_job.py:146} INFO - Started process (PID=7159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:46,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:46,729] {logging_mixin.py:95} INFO - [2019-08-28 13:05:46,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:47,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:47,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:47,111] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:05:47,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:47,127] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 18:05:42.170877+00:00 [scheduled]> in ORM
[2019-08-28 13:05:47,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:05:47,175] {scheduler_job.py:146} INFO - Started process (PID=7160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:52,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:52,185] {logging_mixin.py:95} INFO - [2019-08-28 13:05:52,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:52,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:52,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:52,574] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:05:52,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:52,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:05:52,621] {scheduler_job.py:146} INFO - Started process (PID=7162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:57,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:05:57,633] {logging_mixin.py:95} INFO - [2019-08-28 13:05:57,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:58,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:05:58,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:05:58,030] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:05:58,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:05:58,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:05:58,074] {scheduler_job.py:146} INFO - Started process (PID=7168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:03,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:03,086] {logging_mixin.py:95} INFO - [2019-08-28 13:06:03,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:03,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:03,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:03,499] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:03,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:03,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 13:06:03,630] {scheduler_job.py:146} INFO - Started process (PID=7169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:08,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:08,642] {logging_mixin.py:95} INFO - [2019-08-28 13:06:08,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:08,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:09,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:09,018] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:09,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:09,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:06:09,085] {scheduler_job.py:146} INFO - Started process (PID=7171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:14,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:14,093] {logging_mixin.py:95} INFO - [2019-08-28 13:06:14,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:14,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:14,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:14,499] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:14,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:14,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:06:14,547] {scheduler_job.py:146} INFO - Started process (PID=7173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:19,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:19,554] {logging_mixin.py:95} INFO - [2019-08-28 13:06:19,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:19,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:19,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:19,981] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:19,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:19,998] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 18:05:42.170877+00:00 [scheduled]> in ORM
[2019-08-28 13:06:20,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-08-28 13:06:20,110] {scheduler_job.py:146} INFO - Started process (PID=7177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:25,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:25,122] {logging_mixin.py:95} INFO - [2019-08-28 13:06:25,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:25,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:25,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:25,492] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:25,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:25,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:06:25,570] {scheduler_job.py:146} INFO - Started process (PID=7183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:30,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:30,579] {logging_mixin.py:95} INFO - [2019-08-28 13:06:30,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:30,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:30,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:30,953] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:30,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:30,968] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:06:31,029] {scheduler_job.py:146} INFO - Started process (PID=7184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:36,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:36,041] {logging_mixin.py:95} INFO - [2019-08-28 13:06:36,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:36,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:36,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:36,418] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:36,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:36,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:06:36,494] {scheduler_job.py:146} INFO - Started process (PID=7186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:41,502] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:41,503] {logging_mixin.py:95} INFO - [2019-08-28 13:06:41,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:41,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:41,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:41,900] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:41,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:41,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:06:41,949] {scheduler_job.py:146} INFO - Started process (PID=7189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:46,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:46,955] {logging_mixin.py:95} INFO - [2019-08-28 13:06:46,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:47,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:47,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:47,363] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:47,373] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:47,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:06:47,411] {scheduler_job.py:146} INFO - Started process (PID=7193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:52,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:52,421] {logging_mixin.py:95} INFO - [2019-08-28 13:06:52,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:52,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:52,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:52,858] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:52,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:52,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-08-28 13:06:52,970] {scheduler_job.py:146} INFO - Started process (PID=7194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:57,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:06:57,979] {logging_mixin.py:95} INFO - [2019-08-28 13:06:57,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:58,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:06:58,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:06:58,354] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:06:58,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:06:58,372] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:06:58,426] {scheduler_job.py:146} INFO - Started process (PID=7199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:03,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:03,433] {logging_mixin.py:95} INFO - [2019-08-28 13:07:03,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:03,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:03,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:03,866] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:03,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:03,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-08-28 13:07:03,974] {scheduler_job.py:146} INFO - Started process (PID=7200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:08,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:08,985] {logging_mixin.py:95} INFO - [2019-08-28 13:07:08,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:09,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:09,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:09,375] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:09,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:09,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:07:09,426] {scheduler_job.py:146} INFO - Started process (PID=7202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:14,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:14,437] {logging_mixin.py:95} INFO - [2019-08-28 13:07:14,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:14,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:14,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:14,849] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:14,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:14,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 13:07:14,981] {scheduler_job.py:146} INFO - Started process (PID=7208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:19,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:19,989] {logging_mixin.py:95} INFO - [2019-08-28 13:07:19,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:20,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:20,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:20,375] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:20,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:20,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:07:20,437] {scheduler_job.py:146} INFO - Started process (PID=7209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:25,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:25,445] {logging_mixin.py:95} INFO - [2019-08-28 13:07:25,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:25,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:25,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:25,817] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:25,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:25,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:07:25,898] {scheduler_job.py:146} INFO - Started process (PID=7211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:30,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:30,910] {logging_mixin.py:95} INFO - [2019-08-28 13:07:30,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:31,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:31,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:31,289] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:31,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:31,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:07:31,350] {scheduler_job.py:146} INFO - Started process (PID=7213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:36,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:36,360] {logging_mixin.py:95} INFO - [2019-08-28 13:07:36,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:36,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:36,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:36,746] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:36,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:36,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:07:36,799] {scheduler_job.py:146} INFO - Started process (PID=7218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:41,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:41,808] {logging_mixin.py:95} INFO - [2019-08-28 13:07:41,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:42,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:42,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:42,200] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:42,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:42,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 13:07:42,253] {scheduler_job.py:146} INFO - Started process (PID=7220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:47,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:47,265] {logging_mixin.py:95} INFO - [2019-08-28 13:07:47,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:47,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:47,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:47,649] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:47,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:47,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:07:47,707] {scheduler_job.py:146} INFO - Started process (PID=7224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:52,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:52,717] {logging_mixin.py:95} INFO - [2019-08-28 13:07:52,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:53,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:53,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:53,128] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:53,141] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:53,145] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 18:05:42.170877+00:00 [scheduled]> in ORM
[2019-08-28 13:07:53,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 13:07:53,262] {scheduler_job.py:146} INFO - Started process (PID=7225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:58,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:07:58,273] {logging_mixin.py:95} INFO - [2019-08-28 13:07:58,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:58,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:07:58,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:07:58,654] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:07:58,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:07:58,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:07:58,715] {scheduler_job.py:146} INFO - Started process (PID=7228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:03,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:03,724] {logging_mixin.py:95} INFO - [2019-08-28 13:08:03,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:04,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:04,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:04,107] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:08:04,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:04,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:08:04,177] {scheduler_job.py:146} INFO - Started process (PID=7232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:09,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:09,188] {logging_mixin.py:95} INFO - [2019-08-28 13:08:09,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:09,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:09,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:09,557] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:08:09,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:09,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:08:09,636] {scheduler_job.py:146} INFO - Started process (PID=7234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:14,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:14,644] {logging_mixin.py:95} INFO - [2019-08-28 13:08:14,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:15,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:15,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:15,034] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:08:15,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:15,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:08:15,094] {scheduler_job.py:146} INFO - Started process (PID=7240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:20,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:20,102] {logging_mixin.py:95} INFO - [2019-08-28 13:08:20,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:20,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:20,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:20,503] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:08:20,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:20,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:08:20,554] {scheduler_job.py:146} INFO - Started process (PID=7241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:25,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:25,566] {logging_mixin.py:95} INFO - [2019-08-28 13:08:25,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:25,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:25,953] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:25,962] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True>
[2019-08-28 13:08:25,968] {logging_mixin.py:95} INFO - [2019-08-28 13:08:25,968] {dagrun.py:308} INFO - Marking run <DagRun stock_data @ 2019-08-28 18:05:42.170877+00:00: manual__2019-08-28T18:05:42.170877+00:00, externally triggered: True> failed
[2019-08-28 13:08:25,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:25,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 13:08:26,008] {scheduler_job.py:146} INFO - Started process (PID=7243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:31,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:31,016] {logging_mixin.py:95} INFO - [2019-08-28 13:08:31,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:31,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:31,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:31,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:31,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:08:31,468] {scheduler_job.py:146} INFO - Started process (PID=7244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:36,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:36,476] {logging_mixin.py:95} INFO - [2019-08-28 13:08:36,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:36,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:36,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:36,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:36,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:08:36,926] {scheduler_job.py:146} INFO - Started process (PID=7248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:41,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:41,946] {logging_mixin.py:95} INFO - [2019-08-28 13:08:41,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:42,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:42,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:42,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:42,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:08:42,383] {scheduler_job.py:146} INFO - Started process (PID=7251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:47,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:47,390] {logging_mixin.py:95} INFO - [2019-08-28 13:08:47,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:47,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:47,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:47,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:47,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:08:47,846] {scheduler_job.py:146} INFO - Started process (PID=7255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:52,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:52,856] {logging_mixin.py:95} INFO - [2019-08-28 13:08:52,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:53,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:53,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:53,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:53,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:08:53,302] {scheduler_job.py:146} INFO - Started process (PID=7256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:58,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:08:58,313] {logging_mixin.py:95} INFO - [2019-08-28 13:08:58,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:58,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:08:58,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:08:58,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:08:58,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:08:58,766] {scheduler_job.py:146} INFO - Started process (PID=7258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:03,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:03,776] {logging_mixin.py:95} INFO - [2019-08-28 13:09:03,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:04,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:04,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:04,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:04,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:09:04,227] {scheduler_job.py:146} INFO - Started process (PID=7259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:09,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:09,237] {logging_mixin.py:95} INFO - [2019-08-28 13:09:09,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:09,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:09,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:09,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:09,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:09:09,684] {scheduler_job.py:146} INFO - Started process (PID=7263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:14,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:14,692] {logging_mixin.py:95} INFO - [2019-08-28 13:09:14,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:15,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:15,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:15,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:15,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:09:15,138] {scheduler_job.py:146} INFO - Started process (PID=7266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:20,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:20,148] {logging_mixin.py:95} INFO - [2019-08-28 13:09:20,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:20,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:20,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:20,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:20,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:09:20,602] {scheduler_job.py:146} INFO - Started process (PID=7267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:25,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:25,611] {logging_mixin.py:95} INFO - [2019-08-28 13:09:25,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:25,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:25,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:25,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:25,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:09:26,066] {scheduler_job.py:146} INFO - Started process (PID=7272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:31,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:31,075] {logging_mixin.py:95} INFO - [2019-08-28 13:09:31,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:31,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:31,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:31,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:31,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:09:31,528] {scheduler_job.py:146} INFO - Started process (PID=7273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:36,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:36,536] {logging_mixin.py:95} INFO - [2019-08-28 13:09:36,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:36,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:36,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:36,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:36,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:09:36,981] {scheduler_job.py:146} INFO - Started process (PID=7274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:41,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:41,986] {logging_mixin.py:95} INFO - [2019-08-28 13:09:41,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:42,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:42,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:42,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:42,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:09:42,435] {scheduler_job.py:146} INFO - Started process (PID=7280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:47,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:47,444] {logging_mixin.py:95} INFO - [2019-08-28 13:09:47,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:47,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:47,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:47,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:47,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:09:47,895] {scheduler_job.py:146} INFO - Started process (PID=7281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:52,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:52,906] {logging_mixin.py:95} INFO - [2019-08-28 13:09:52,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:53,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:53,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:53,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:53,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:09:53,342] {scheduler_job.py:146} INFO - Started process (PID=7282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:58,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:09:58,349] {logging_mixin.py:95} INFO - [2019-08-28 13:09:58,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:58,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:09:58,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:09:58,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:09:58,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:09:58,785] {scheduler_job.py:146} INFO - Started process (PID=7287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:03,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:03,792] {logging_mixin.py:95} INFO - [2019-08-28 13:10:03,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:04,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:04,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:04,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:04,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:10:04,235] {scheduler_job.py:146} INFO - Started process (PID=7288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:09,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:09,242] {logging_mixin.py:95} INFO - [2019-08-28 13:10:09,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:09,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:09,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:09,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:09,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 13:10:09,684] {scheduler_job.py:146} INFO - Started process (PID=7292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:14,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:14,692] {logging_mixin.py:95} INFO - [2019-08-28 13:10:14,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:15,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:15,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:15,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:15,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:10:15,137] {scheduler_job.py:146} INFO - Started process (PID=7295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:20,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:20,147] {logging_mixin.py:95} INFO - [2019-08-28 13:10:20,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:20,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:20,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:20,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:20,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:10:20,599] {scheduler_job.py:146} INFO - Started process (PID=7296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:25,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:25,608] {logging_mixin.py:95} INFO - [2019-08-28 13:10:25,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:25,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:25,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:26,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:26,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:10:26,058] {scheduler_job.py:146} INFO - Started process (PID=7301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:31,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:31,067] {logging_mixin.py:95} INFO - [2019-08-28 13:10:31,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:31,417] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:31,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:31,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:31,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:10:31,506] {scheduler_job.py:146} INFO - Started process (PID=7302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:36,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:36,519] {logging_mixin.py:95} INFO - [2019-08-28 13:10:36,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:36,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:36,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:36,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:36,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:10:36,957] {scheduler_job.py:146} INFO - Started process (PID=7303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:41,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:41,967] {logging_mixin.py:95} INFO - [2019-08-28 13:10:41,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:42,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:42,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:42,351] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:42,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:10:42,409] {scheduler_job.py:146} INFO - Started process (PID=7305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:47,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:47,417] {logging_mixin.py:95} INFO - [2019-08-28 13:10:47,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:47,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:47,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:47,805] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:47,811] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:10:47,860] {scheduler_job.py:146} INFO - Started process (PID=7310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:52,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:52,869] {logging_mixin.py:95} INFO - [2019-08-28 13:10:52,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:53,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:53,263] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:53,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:53,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:10:53,317] {scheduler_job.py:146} INFO - Started process (PID=7314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:58,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:10:58,324] {logging_mixin.py:95} INFO - [2019-08-28 13:10:58,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:58,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:10:58,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:10:58,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:10:58,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:10:58,768] {scheduler_job.py:146} INFO - Started process (PID=7326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:03,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:03,777] {logging_mixin.py:95} INFO - [2019-08-28 13:11:03,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:04,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:04,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:04,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:04,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:11:04,223] {scheduler_job.py:146} INFO - Started process (PID=7327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:09,230] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:09,231] {logging_mixin.py:95} INFO - [2019-08-28 13:11:09,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:09,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:09,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:09,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:09,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 13:11:09,679] {scheduler_job.py:146} INFO - Started process (PID=7328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:14,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:14,690] {logging_mixin.py:95} INFO - [2019-08-28 13:11:14,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:15,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:15,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:15,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:15,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:11:15,123] {scheduler_job.py:146} INFO - Started process (PID=7333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:20,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:20,133] {logging_mixin.py:95} INFO - [2019-08-28 13:11:20,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:20,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:20,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:20,552] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:20,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:20,566] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 18:11:15.611156+00:00 [scheduled]> in ORM
[2019-08-28 13:11:20,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:11:20,670] {scheduler_job.py:146} INFO - Started process (PID=7335) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:25,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:25,683] {logging_mixin.py:95} INFO - [2019-08-28 13:11:25,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:26,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:26,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:26,103] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:26,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:26,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 13:11:26,231] {scheduler_job.py:146} INFO - Started process (PID=7338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:31,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:31,240] {logging_mixin.py:95} INFO - [2019-08-28 13:11:31,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:31,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:31,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:31,642] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:31,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:31,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 13:11:31,682] {scheduler_job.py:146} INFO - Started process (PID=7342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:36,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:36,689] {logging_mixin.py:95} INFO - [2019-08-28 13:11:36,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:37,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:37,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:37,064] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:37,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:37,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:11:37,151] {scheduler_job.py:146} INFO - Started process (PID=7343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:42,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:42,157] {logging_mixin.py:95} INFO - [2019-08-28 13:11:42,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:42,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:42,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:42,551] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:42,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:42,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:11:42,600] {scheduler_job.py:146} INFO - Started process (PID=7346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:47,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:47,609] {logging_mixin.py:95} INFO - [2019-08-28 13:11:47,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:47,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:48,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:48,018] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:48,030] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:48,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:11:48,056] {scheduler_job.py:146} INFO - Started process (PID=7351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:53,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:53,062] {logging_mixin.py:95} INFO - [2019-08-28 13:11:53,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:53,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:53,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:53,456] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:53,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:53,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:11:53,511] {scheduler_job.py:146} INFO - Started process (PID=7352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:58,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:11:58,518] {logging_mixin.py:95} INFO - [2019-08-28 13:11:58,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:58,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:11:58,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:11:58,905] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:11:58,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:11:58,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:11:58,963] {scheduler_job.py:146} INFO - Started process (PID=7357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:03,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:03,970] {logging_mixin.py:95} INFO - [2019-08-28 13:12:03,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:04,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:04,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:04,348] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:04,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:04,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:12:04,414] {scheduler_job.py:146} INFO - Started process (PID=7358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:09,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:09,423] {logging_mixin.py:95} INFO - [2019-08-28 13:12:09,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:09,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:09,794] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:09,802] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:09,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:09,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:12:09,873] {scheduler_job.py:146} INFO - Started process (PID=7359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:14,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:14,878] {logging_mixin.py:95} INFO - [2019-08-28 13:12:14,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:15,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:15,263] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:15,271] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:15,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:15,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:12:15,321] {scheduler_job.py:146} INFO - Started process (PID=7364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:20,329] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:20,330] {logging_mixin.py:95} INFO - [2019-08-28 13:12:20,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:20,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:20,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:20,778] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:20,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:20,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-08-28 13:12:20,882] {scheduler_job.py:146} INFO - Started process (PID=7366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:25,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:25,890] {logging_mixin.py:95} INFO - [2019-08-28 13:12:25,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:26,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:26,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:26,268] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:26,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:26,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:12:26,349] {scheduler_job.py:146} INFO - Started process (PID=7368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:31,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:31,357] {logging_mixin.py:95} INFO - [2019-08-28 13:12:31,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:31,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:31,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:31,731] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:31,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:31,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:12:31,815] {scheduler_job.py:146} INFO - Started process (PID=7369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:36,824] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:36,825] {logging_mixin.py:95} INFO - [2019-08-28 13:12:36,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:37,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:37,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:37,275] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:37,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:37,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-08-28 13:12:37,357] {scheduler_job.py:146} INFO - Started process (PID=7379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:42,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:42,367] {logging_mixin.py:95} INFO - [2019-08-28 13:12:42,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:42,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:42,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:42,819] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:42,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:42,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-08-28 13:12:42,895] {scheduler_job.py:146} INFO - Started process (PID=7383) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:47,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:47,906] {logging_mixin.py:95} INFO - [2019-08-28 13:12:47,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:48,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:48,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:48,280] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:48,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:48,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:12:48,353] {scheduler_job.py:146} INFO - Started process (PID=7384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:53,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:53,358] {logging_mixin.py:95} INFO - [2019-08-28 13:12:53,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:53,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:53,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:53,773] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:53,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:53,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 13:12:53,910] {scheduler_job.py:146} INFO - Started process (PID=7391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:58,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:12:58,917] {logging_mixin.py:95} INFO - [2019-08-28 13:12:58,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:59,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:12:59,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:12:59,296] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:12:59,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:12:59,311] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:12:59,352] {scheduler_job.py:146} INFO - Started process (PID=7393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:04,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:04,363] {logging_mixin.py:95} INFO - [2019-08-28 13:13:04,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:04,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:04,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:04,732] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:04,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:04,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:13:04,810] {scheduler_job.py:146} INFO - Started process (PID=7394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:09,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:09,820] {logging_mixin.py:95} INFO - [2019-08-28 13:13:09,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:10,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:10,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:10,206] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:10,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:10,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:13:10,263] {scheduler_job.py:146} INFO - Started process (PID=7399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:15,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:15,271] {logging_mixin.py:95} INFO - [2019-08-28 13:13:15,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:15,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:15,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:15,732] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:15,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:15,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-08-28 13:13:15,815] {scheduler_job.py:146} INFO - Started process (PID=7401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:20,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:20,823] {logging_mixin.py:95} INFO - [2019-08-28 13:13:20,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:21,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:21,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:21,238] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:21,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:21,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:13:21,278] {scheduler_job.py:146} INFO - Started process (PID=7403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:26,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:26,289] {logging_mixin.py:95} INFO - [2019-08-28 13:13:26,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:26,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:26,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:26,686] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:26,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:26,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 13:13:26,728] {scheduler_job.py:146} INFO - Started process (PID=7409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:31,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:31,738] {logging_mixin.py:95} INFO - [2019-08-28 13:13:31,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:32,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:32,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:32,116] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:32,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:32,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:13:32,178] {scheduler_job.py:146} INFO - Started process (PID=7413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:37,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:37,185] {logging_mixin.py:95} INFO - [2019-08-28 13:13:37,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:37,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:37,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:37,561] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:37,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:37,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:13:37,618] {scheduler_job.py:146} INFO - Started process (PID=7417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:42,626] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:42,627] {logging_mixin.py:95} INFO - [2019-08-28 13:13:42,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:43,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:43,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:43,054] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:43,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:43,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:13:43,166] {scheduler_job.py:146} INFO - Started process (PID=7432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:48,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:48,172] {logging_mixin.py:95} INFO - [2019-08-28 13:13:48,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:48,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:48,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:48,550] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:48,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:48,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:13:48,611] {scheduler_job.py:146} INFO - Started process (PID=7435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:53,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:53,621] {logging_mixin.py:95} INFO - [2019-08-28 13:13:53,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:53,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:54,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:54,012] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:54,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:54,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 13:13:54,068] {scheduler_job.py:146} INFO - Started process (PID=7442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:59,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:13:59,074] {logging_mixin.py:95} INFO - [2019-08-28 13:13:59,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:59,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:13:59,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:13:59,450] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:13:59,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:13:59,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:13:59,528] {scheduler_job.py:146} INFO - Started process (PID=7444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:04,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:04,534] {logging_mixin.py:95} INFO - [2019-08-28 13:14:04,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:04,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:04,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:04,904] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:04,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:04,918] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_stock_data 2019-08-28 18:11:15.611156+00:00 [scheduled]> in ORM
[2019-08-28 13:14:04,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:14:04,984] {scheduler_job.py:146} INFO - Started process (PID=7496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:09,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:09,993] {logging_mixin.py:95} INFO - [2019-08-28 13:14:09,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:10,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:10,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:10,360] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:10,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:10,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:14:10,440] {scheduler_job.py:146} INFO - Started process (PID=7514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:15,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:15,451] {logging_mixin.py:95} INFO - [2019-08-28 13:14:15,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:15,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:15,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:15,832] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:15,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:15,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:14:15,899] {scheduler_job.py:146} INFO - Started process (PID=7518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:20,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:20,903] {logging_mixin.py:95} INFO - [2019-08-28 13:14:20,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:21,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:21,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:21,289] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:21,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:21,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:14:21,359] {scheduler_job.py:146} INFO - Started process (PID=7522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:26,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:26,365] {logging_mixin.py:95} INFO - [2019-08-28 13:14:26,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:26,797] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:26,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:26,821] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:26,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:26,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-08-28 13:14:26,920] {scheduler_job.py:146} INFO - Started process (PID=7526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:31,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:31,927] {logging_mixin.py:95} INFO - [2019-08-28 13:14:31,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:32,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:32,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:32,338] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:32,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:32,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:14:32,371] {scheduler_job.py:146} INFO - Started process (PID=7532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:37,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:37,376] {logging_mixin.py:95} INFO - [2019-08-28 13:14:37,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:37,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:37,790] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:37,797] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:37,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:37,813] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 18:11:15.611156+00:00 [scheduled]> in ORM
[2019-08-28 13:14:37,823] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:14:37,902] {scheduler_job.py:146} INFO - Started process (PID=7533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:42,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:42,906] {logging_mixin.py:95} INFO - [2019-08-28 13:14:42,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:43,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:43,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:43,283] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:43,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:43,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:14:43,338] {scheduler_job.py:146} INFO - Started process (PID=7539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:48,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:48,349] {logging_mixin.py:95} INFO - [2019-08-28 13:14:48,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:48,689] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:48,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:48,721] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:48,731] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:48,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:14:48,797] {scheduler_job.py:146} INFO - Started process (PID=7540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:53,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:53,804] {logging_mixin.py:95} INFO - [2019-08-28 13:14:53,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:54,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:54,168] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:54,176] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:54,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:54,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:14:54,253] {scheduler_job.py:146} INFO - Started process (PID=7542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:59,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:14:59,265] {logging_mixin.py:95} INFO - [2019-08-28 13:14:59,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:59,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:14:59,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:14:59,663] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:14:59,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:14:59,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 13:14:59,707] {scheduler_job.py:146} INFO - Started process (PID=7549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:04,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:04,716] {logging_mixin.py:95} INFO - [2019-08-28 13:15:04,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:05,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:05,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:05,139] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:15:05,150] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:05,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 13:15:05,264] {scheduler_job.py:146} INFO - Started process (PID=7550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:10,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:10,272] {logging_mixin.py:95} INFO - [2019-08-28 13:15:10,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:10,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:10,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:10,662] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True>
[2019-08-28 13:15:10,669] {logging_mixin.py:95} INFO - [2019-08-28 13:15:10,669] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 18:11:15.611156+00:00: manual__2019-08-28T18:11:15.611156+00:00, externally triggered: True> successful
[2019-08-28 13:15:10,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:10,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:15:10,719] {scheduler_job.py:146} INFO - Started process (PID=7556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:15,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:15,732] {logging_mixin.py:95} INFO - [2019-08-28 13:15:15,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:16,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:16,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:16,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:16,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:15:16,172] {scheduler_job.py:146} INFO - Started process (PID=7559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:21,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:21,183] {logging_mixin.py:95} INFO - [2019-08-28 13:15:21,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:21,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:21,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:21,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:21,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.353 seconds
[2019-08-28 13:15:21,629] {scheduler_job.py:146} INFO - Started process (PID=7569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:26,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:26,637] {logging_mixin.py:95} INFO - [2019-08-28 13:15:26,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:26,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:27,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:27,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:27,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:15:27,098] {scheduler_job.py:146} INFO - Started process (PID=7571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:32,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:32,104] {logging_mixin.py:95} INFO - [2019-08-28 13:15:32,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:32,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:32,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:32,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:32,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:15:32,551] {scheduler_job.py:146} INFO - Started process (PID=7576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:37,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:37,557] {logging_mixin.py:95} INFO - [2019-08-28 13:15:37,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:37,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:37,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:37,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:37,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:15:37,997] {scheduler_job.py:146} INFO - Started process (PID=7602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:43,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:43,003] {logging_mixin.py:95} INFO - [2019-08-28 13:15:43,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:43,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:43,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:43,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:43,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:15:43,457] {scheduler_job.py:146} INFO - Started process (PID=7605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:48,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:48,464] {logging_mixin.py:95} INFO - [2019-08-28 13:15:48,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:48,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:48,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:48,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:48,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:15:48,919] {scheduler_job.py:146} INFO - Started process (PID=7609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:53,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:53,928] {logging_mixin.py:95} INFO - [2019-08-28 13:15:53,928] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:54,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:54,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:54,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:54,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-28 13:15:54,371] {scheduler_job.py:146} INFO - Started process (PID=7612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:59,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:15:59,380] {logging_mixin.py:95} INFO - [2019-08-28 13:15:59,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:59,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:15:59,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:15:59,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:15:59,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:15:59,826] {scheduler_job.py:146} INFO - Started process (PID=7618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:04,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:04,834] {logging_mixin.py:95} INFO - [2019-08-28 13:16:04,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:05,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:05,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:05,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:05,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:16:05,283] {scheduler_job.py:146} INFO - Started process (PID=7621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:10,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:10,289] {logging_mixin.py:95} INFO - [2019-08-28 13:16:10,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:10,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:10,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:10,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:10,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:16:10,729] {scheduler_job.py:146} INFO - Started process (PID=7625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:15,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:15,738] {logging_mixin.py:95} INFO - [2019-08-28 13:16:15,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:16,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:16,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:16,124] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:16,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:16:16,183] {scheduler_job.py:146} INFO - Started process (PID=7629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:21,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:21,191] {logging_mixin.py:95} INFO - [2019-08-28 13:16:21,190] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:21,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:21,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:21,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:21,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:16:21,631] {scheduler_job.py:146} INFO - Started process (PID=7630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:26,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:26,638] {logging_mixin.py:95} INFO - [2019-08-28 13:16:26,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:27,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:27,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:27,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:27,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 13:16:27,179] {scheduler_job.py:146} INFO - Started process (PID=7632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:32,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:32,187] {logging_mixin.py:95} INFO - [2019-08-28 13:16:32,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:32,599] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:32,615] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:32,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:32,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 13:16:32,722] {scheduler_job.py:146} INFO - Started process (PID=7634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:37,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:37,731] {logging_mixin.py:95} INFO - [2019-08-28 13:16:37,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:38,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:38,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:38,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:38,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:16:38,185] {scheduler_job.py:146} INFO - Started process (PID=7638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:43,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:43,194] {logging_mixin.py:95} INFO - [2019-08-28 13:16:43,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:43,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:43,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:43,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:43,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:16:43,634] {scheduler_job.py:146} INFO - Started process (PID=7641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:48,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:48,640] {logging_mixin.py:95} INFO - [2019-08-28 13:16:48,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:49,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:49,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:49,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:49,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:16:49,077] {scheduler_job.py:146} INFO - Started process (PID=7645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:54,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:54,087] {logging_mixin.py:95} INFO - [2019-08-28 13:16:54,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:54,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:54,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:54,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:54,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:16:54,534] {scheduler_job.py:146} INFO - Started process (PID=7646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:59,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:16:59,540] {logging_mixin.py:95} INFO - [2019-08-28 13:16:59,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:59,907] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:16:59,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:16:59,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:16:59,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:16:59,984] {scheduler_job.py:146} INFO - Started process (PID=7648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:04,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:04,990] {logging_mixin.py:95} INFO - [2019-08-28 13:17:04,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:05,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:05,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:05,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:05,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:17:05,438] {scheduler_job.py:146} INFO - Started process (PID=7650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:10,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:10,448] {logging_mixin.py:95} INFO - [2019-08-28 13:17:10,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:10,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:10,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:10,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:10,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:17:10,904] {scheduler_job.py:146} INFO - Started process (PID=7655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:15,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:15,914] {logging_mixin.py:95} INFO - [2019-08-28 13:17:15,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:16,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:16,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:16,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:16,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:17:16,367] {scheduler_job.py:146} INFO - Started process (PID=7656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:21,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:21,376] {logging_mixin.py:95} INFO - [2019-08-28 13:17:21,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:21,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:21,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:21,755] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:21,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:17:21,824] {scheduler_job.py:146} INFO - Started process (PID=7660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:26,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:26,831] {logging_mixin.py:95} INFO - [2019-08-28 13:17:26,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:27,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:27,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:27,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:27,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:17:27,281] {scheduler_job.py:146} INFO - Started process (PID=7662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:32,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:32,288] {logging_mixin.py:95} INFO - [2019-08-28 13:17:32,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:32,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:32,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:32,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:32,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:17:32,746] {scheduler_job.py:146} INFO - Started process (PID=7663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:37,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:37,754] {logging_mixin.py:95} INFO - [2019-08-28 13:17:37,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:38,104] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:38,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:38,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:38,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:17:38,205] {scheduler_job.py:146} INFO - Started process (PID=7665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:43,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:43,213] {logging_mixin.py:95} INFO - [2019-08-28 13:17:43,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:43,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:43,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:43,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:43,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:17:43,670] {scheduler_job.py:146} INFO - Started process (PID=7673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:48,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:48,678] {logging_mixin.py:95} INFO - [2019-08-28 13:17:48,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:49,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:49,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:49,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:49,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:17:49,133] {scheduler_job.py:146} INFO - Started process (PID=7674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:54,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:54,140] {logging_mixin.py:95} INFO - [2019-08-28 13:17:54,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:54,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:54,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:54,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:54,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-28 13:17:54,597] {scheduler_job.py:146} INFO - Started process (PID=7678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:59,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:17:59,608] {logging_mixin.py:95} INFO - [2019-08-28 13:17:59,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:59,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:17:59,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:17:59,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:17:59,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:18:00,049] {scheduler_job.py:146} INFO - Started process (PID=7680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:05,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:05,056] {logging_mixin.py:95} INFO - [2019-08-28 13:18:05,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:05,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:05,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:05,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:05,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:18:05,510] {scheduler_job.py:146} INFO - Started process (PID=7681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:10,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:10,521] {logging_mixin.py:95} INFO - [2019-08-28 13:18:10,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:10,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:10,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:10,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:10,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:18:10,963] {scheduler_job.py:146} INFO - Started process (PID=7687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:15,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:15,974] {logging_mixin.py:95} INFO - [2019-08-28 13:18:15,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:16,325] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:16,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:16,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:16,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:18:16,427] {scheduler_job.py:146} INFO - Started process (PID=7688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:21,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:21,439] {logging_mixin.py:95} INFO - [2019-08-28 13:18:21,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:21,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:21,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:21,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:21,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:18:21,890] {scheduler_job.py:146} INFO - Started process (PID=7689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:26,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:26,898] {logging_mixin.py:95} INFO - [2019-08-28 13:18:26,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:27,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:27,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:27,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:27,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:18:27,357] {scheduler_job.py:146} INFO - Started process (PID=7691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:32,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:32,368] {logging_mixin.py:95} INFO - [2019-08-28 13:18:32,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:32,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:32,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:32,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:32,754] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:18:32,809] {scheduler_job.py:146} INFO - Started process (PID=7695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:37,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:37,815] {logging_mixin.py:95} INFO - [2019-08-28 13:18:37,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:38,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:38,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:38,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:38,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:18:38,277] {scheduler_job.py:146} INFO - Started process (PID=7697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:43,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:43,285] {logging_mixin.py:95} INFO - [2019-08-28 13:18:43,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:43,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:43,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:43,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:43,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:18:43,735] {scheduler_job.py:146} INFO - Started process (PID=7702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:48,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:48,747] {logging_mixin.py:95} INFO - [2019-08-28 13:18:48,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:49,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:49,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:49,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:49,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:18:49,203] {scheduler_job.py:146} INFO - Started process (PID=7703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:54,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:54,214] {logging_mixin.py:95} INFO - [2019-08-28 13:18:54,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:54,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:54,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:18:54,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:18:54,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:18:54,658] {scheduler_job.py:146} INFO - Started process (PID=7704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:18:59,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:18:59,676] {logging_mixin.py:95} INFO - [2019-08-28 13:18:59,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:00,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:00,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:00,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:00,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:19:00,119] {scheduler_job.py:146} INFO - Started process (PID=7706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:05,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:05,125] {logging_mixin.py:95} INFO - [2019-08-28 13:19:05,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:05,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:05,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:05,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:05,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:19:05,572] {scheduler_job.py:146} INFO - Started process (PID=7710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:10,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:10,583] {logging_mixin.py:95} INFO - [2019-08-28 13:19:10,583] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:10,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:10,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:10,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:10,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:19:11,034] {scheduler_job.py:146} INFO - Started process (PID=7713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:16,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:16,043] {logging_mixin.py:95} INFO - [2019-08-28 13:19:16,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:16,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:16,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:16,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:16,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:19:16,500] {scheduler_job.py:146} INFO - Started process (PID=7717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:21,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:21,511] {logging_mixin.py:95} INFO - [2019-08-28 13:19:21,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:21,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:21,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:21,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:21,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:19:21,960] {scheduler_job.py:146} INFO - Started process (PID=7718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:26,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:26,967] {logging_mixin.py:95} INFO - [2019-08-28 13:19:26,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:27,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:27,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:27,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:27,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:19:27,427] {scheduler_job.py:146} INFO - Started process (PID=7723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:32,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:32,438] {logging_mixin.py:95} INFO - [2019-08-28 13:19:32,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:32,786] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:32,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:32,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:32,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:19:32,892] {scheduler_job.py:146} INFO - Started process (PID=7724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:37,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:37,900] {logging_mixin.py:95} INFO - [2019-08-28 13:19:37,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:38,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:38,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:38,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:38,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:19:38,356] {scheduler_job.py:146} INFO - Started process (PID=7725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:43,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:43,363] {logging_mixin.py:95} INFO - [2019-08-28 13:19:43,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:43,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:43,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:43,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:43,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:19:43,812] {scheduler_job.py:146} INFO - Started process (PID=7728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:48,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:48,819] {logging_mixin.py:95} INFO - [2019-08-28 13:19:48,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:49,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:49,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:49,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:49,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:19:49,277] {scheduler_job.py:146} INFO - Started process (PID=7729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:54,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:54,284] {logging_mixin.py:95} INFO - [2019-08-28 13:19:54,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:54,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:54,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:19:54,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:19:54,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:19:54,739] {scheduler_job.py:146} INFO - Started process (PID=7733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:19:59,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:19:59,762] {logging_mixin.py:95} INFO - [2019-08-28 13:19:59,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:00,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:00,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:00,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:00,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:20:00,207] {scheduler_job.py:146} INFO - Started process (PID=7735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:05,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:05,217] {logging_mixin.py:95} INFO - [2019-08-28 13:20:05,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:05,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:05,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:05,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:05,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:20:05,668] {scheduler_job.py:146} INFO - Started process (PID=7739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:10,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:10,678] {logging_mixin.py:95} INFO - [2019-08-28 13:20:10,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:11,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:11,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:11,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:11,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:20:11,127] {scheduler_job.py:146} INFO - Started process (PID=7741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:16,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:16,136] {logging_mixin.py:95} INFO - [2019-08-28 13:20:16,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:16,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:16,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:16,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:16,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:20:16,591] {scheduler_job.py:146} INFO - Started process (PID=7746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:21,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:21,597] {logging_mixin.py:95} INFO - [2019-08-28 13:20:21,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:21,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:21,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:21,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:21,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:20:22,055] {scheduler_job.py:146} INFO - Started process (PID=7747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:27,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:27,063] {logging_mixin.py:95} INFO - [2019-08-28 13:20:27,062] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:27,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:27,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:27,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:27,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:20:27,518] {scheduler_job.py:146} INFO - Started process (PID=7749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:32,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:32,529] {logging_mixin.py:95} INFO - [2019-08-28 13:20:32,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:32,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:32,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:32,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:32,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:20:32,977] {scheduler_job.py:146} INFO - Started process (PID=7750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:37,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:37,983] {logging_mixin.py:95} INFO - [2019-08-28 13:20:37,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:38,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:38,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:38,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:38,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:20:38,444] {scheduler_job.py:146} INFO - Started process (PID=7754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:43,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:43,452] {logging_mixin.py:95} INFO - [2019-08-28 13:20:43,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:43,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:43,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:43,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:43,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:20:43,907] {scheduler_job.py:146} INFO - Started process (PID=7757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:48,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:48,916] {logging_mixin.py:95} INFO - [2019-08-28 13:20:48,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:49,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:49,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:49,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:49,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:20:49,366] {scheduler_job.py:146} INFO - Started process (PID=7761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:54,373] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:54,374] {logging_mixin.py:95} INFO - [2019-08-28 13:20:54,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:54,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:54,746] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:20:54,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:20:54,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:20:54,824] {scheduler_job.py:146} INFO - Started process (PID=7762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:20:59,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:20:59,833] {logging_mixin.py:95} INFO - [2019-08-28 13:20:59,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:00,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:00,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:00,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:00,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:21:00,291] {scheduler_job.py:146} INFO - Started process (PID=7764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:05,299] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:05,300] {logging_mixin.py:95} INFO - [2019-08-28 13:21:05,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:05,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:05,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:05,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:05,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:21:05,753] {scheduler_job.py:146} INFO - Started process (PID=7765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:10,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:10,763] {logging_mixin.py:95} INFO - [2019-08-28 13:21:10,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:11,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:11,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:11,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:11,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:21:11,205] {scheduler_job.py:146} INFO - Started process (PID=7770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:16,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:16,212] {logging_mixin.py:95} INFO - [2019-08-28 13:21:16,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:16,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:16,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:16,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:16,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:21:16,665] {scheduler_job.py:146} INFO - Started process (PID=7772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:21,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:21,671] {logging_mixin.py:95} INFO - [2019-08-28 13:21:21,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:22,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:22,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:22,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:22,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:21:22,130] {scheduler_job.py:146} INFO - Started process (PID=7776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:27,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:27,136] {logging_mixin.py:95} INFO - [2019-08-28 13:21:27,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:27,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:27,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:27,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:27,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:21:27,596] {scheduler_job.py:146} INFO - Started process (PID=7778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:32,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:32,607] {logging_mixin.py:95} INFO - [2019-08-28 13:21:32,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:32,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:32,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:32,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:32,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:21:33,061] {scheduler_job.py:146} INFO - Started process (PID=7779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:38,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:38,071] {logging_mixin.py:95} INFO - [2019-08-28 13:21:38,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:38,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:38,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:38,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:38,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:21:38,524] {scheduler_job.py:146} INFO - Started process (PID=7780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:43,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:43,532] {logging_mixin.py:95} INFO - [2019-08-28 13:21:43,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:43,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:43,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:43,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:43,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:21:43,986] {scheduler_job.py:146} INFO - Started process (PID=7785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:48,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:48,998] {logging_mixin.py:95} INFO - [2019-08-28 13:21:48,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:49,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:49,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:49,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:49,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:21:49,441] {scheduler_job.py:146} INFO - Started process (PID=7790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:54,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:54,449] {logging_mixin.py:95} INFO - [2019-08-28 13:21:54,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:54,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:54,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:21:54,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:21:54,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:21:54,905] {scheduler_job.py:146} INFO - Started process (PID=7791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:21:59,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:21:59,915] {logging_mixin.py:95} INFO - [2019-08-28 13:21:59,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:00,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:00,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:00,294] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:00,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:22:00,370] {scheduler_job.py:146} INFO - Started process (PID=7793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:05,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:05,381] {logging_mixin.py:95} INFO - [2019-08-28 13:22:05,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:05,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:05,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:05,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:05,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:22:05,859] {scheduler_job.py:146} INFO - Started process (PID=7795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:10,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:10,867] {logging_mixin.py:95} INFO - [2019-08-28 13:22:10,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:11,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:11,240] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:11,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:11,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:22:11,341] {scheduler_job.py:146} INFO - Started process (PID=7800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:16,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:16,348] {logging_mixin.py:95} INFO - [2019-08-28 13:22:16,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:16,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:16,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:16,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:16,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:22:16,817] {scheduler_job.py:146} INFO - Started process (PID=7809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:21,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:21,831] {logging_mixin.py:95} INFO - [2019-08-28 13:22:21,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:22,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:22,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:22,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:22,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:22:22,305] {scheduler_job.py:146} INFO - Started process (PID=7812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:27,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:27,320] {logging_mixin.py:95} INFO - [2019-08-28 13:22:27,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:27,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:27,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:27,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:27,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:22:27,773] {scheduler_job.py:146} INFO - Started process (PID=7815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:32,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:32,781] {logging_mixin.py:95} INFO - [2019-08-28 13:22:32,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:33,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:33,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:33,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:33,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-28 13:22:33,245] {scheduler_job.py:146} INFO - Started process (PID=7819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:38,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:38,253] {logging_mixin.py:95} INFO - [2019-08-28 13:22:38,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:38,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:38,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:38,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:38,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:22:38,731] {scheduler_job.py:146} INFO - Started process (PID=7820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:43,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:43,739] {logging_mixin.py:95} INFO - [2019-08-28 13:22:43,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:44,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:44,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:44,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:44,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-08-28 13:22:44,121] {scheduler_job.py:146} INFO - Started process (PID=7823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:49,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:49,130] {logging_mixin.py:95} INFO - [2019-08-28 13:22:49,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:49,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:49,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:49,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:49,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:22:49,607] {scheduler_job.py:146} INFO - Started process (PID=7825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:54,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:22:54,614] {logging_mixin.py:95} INFO - [2019-08-28 13:22:54,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:54,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:22:54,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:22:54,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:22:54,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 13:22:55,095] {scheduler_job.py:146} INFO - Started process (PID=7829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:00,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:00,106] {logging_mixin.py:95} INFO - [2019-08-28 13:23:00,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:00,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:00,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:00,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:00,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-08-28 13:23:00,481] {scheduler_job.py:146} INFO - Started process (PID=7831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:05,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:05,491] {logging_mixin.py:95} INFO - [2019-08-28 13:23:05,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:05,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:05,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:05,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:05,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-08-28 13:23:05,970] {scheduler_job.py:146} INFO - Started process (PID=7835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:10,979] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:10,980] {logging_mixin.py:95} INFO - [2019-08-28 13:23:10,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:11,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:11,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:11,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:11,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-08-28 13:23:11,456] {scheduler_job.py:146} INFO - Started process (PID=7837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:16,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:16,469] {logging_mixin.py:95} INFO - [2019-08-28 13:23:16,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:16,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:16,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:16,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:16,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-28 13:23:16,929] {scheduler_job.py:146} INFO - Started process (PID=7838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:21,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:21,946] {logging_mixin.py:95} INFO - [2019-08-28 13:23:21,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:22,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:22,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:22,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:22,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:23:22,420] {scheduler_job.py:146} INFO - Started process (PID=7840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:27,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:27,427] {logging_mixin.py:95} INFO - [2019-08-28 13:23:27,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:27,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:27,796] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:27,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:27,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:23:27,902] {scheduler_job.py:146} INFO - Started process (PID=7846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:32,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:32,909] {logging_mixin.py:95} INFO - [2019-08-28 13:23:32,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:33,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:33,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:33,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:33,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-08-28 13:23:33,467] {scheduler_job.py:146} INFO - Started process (PID=7847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:38,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:38,475] {logging_mixin.py:95} INFO - [2019-08-28 13:23:38,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:38,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:38,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:38,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:38,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:23:38,938] {scheduler_job.py:146} INFO - Started process (PID=7848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:43,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:43,944] {logging_mixin.py:95} INFO - [2019-08-28 13:23:43,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:44,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:44,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:44,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:44,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-08-28 13:23:44,380] {scheduler_job.py:146} INFO - Started process (PID=7850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:49,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:49,387] {logging_mixin.py:95} INFO - [2019-08-28 13:23:49,386] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:49,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:49,745] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:49,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:49,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-08-28 13:23:49,818] {scheduler_job.py:146} INFO - Started process (PID=7854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:54,824] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:23:54,825] {logging_mixin.py:95} INFO - [2019-08-28 13:23:54,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:55,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:23:55,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:23:55,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:23:55,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-08-28 13:23:55,266] {scheduler_job.py:146} INFO - Started process (PID=7856) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:00,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:00,274] {logging_mixin.py:95} INFO - [2019-08-28 13:24:00,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:00,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:00,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:00,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:00,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:24:00,813] {scheduler_job.py:146} INFO - Started process (PID=7858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:05,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:05,820] {logging_mixin.py:95} INFO - [2019-08-28 13:24:05,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:06,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:06,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:06,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:06,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-08-28 13:24:06,252] {scheduler_job.py:146} INFO - Started process (PID=7862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:11,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:11,262] {logging_mixin.py:95} INFO - [2019-08-28 13:24:11,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:11,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:11,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:11,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:11,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:24:11,692] {scheduler_job.py:146} INFO - Started process (PID=7864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:16,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:16,698] {logging_mixin.py:95} INFO - [2019-08-28 13:24:16,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:17,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:17,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:17,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:17,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:24:17,125] {scheduler_job.py:146} INFO - Started process (PID=7865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:22,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:22,132] {logging_mixin.py:95} INFO - [2019-08-28 13:24:22,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:22,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:22,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:22,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:22,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:24:22,563] {scheduler_job.py:146} INFO - Started process (PID=7866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:27,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:27,570] {logging_mixin.py:95} INFO - [2019-08-28 13:24:27,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:27,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:27,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:27,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:27,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:24:28,039] {scheduler_job.py:146} INFO - Started process (PID=7872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:33,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:33,046] {logging_mixin.py:95} INFO - [2019-08-28 13:24:33,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:33,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:33,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:33,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:33,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 13:24:33,471] {scheduler_job.py:146} INFO - Started process (PID=7873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:38,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:38,482] {logging_mixin.py:95} INFO - [2019-08-28 13:24:38,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:38,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:38,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:38,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:38,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:24:38,902] {scheduler_job.py:146} INFO - Started process (PID=7874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:43,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:43,909] {logging_mixin.py:95} INFO - [2019-08-28 13:24:43,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:44,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:44,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:44,273] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:44,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-08-28 13:24:44,350] {scheduler_job.py:146} INFO - Started process (PID=7879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:49,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:49,357] {logging_mixin.py:95} INFO - [2019-08-28 13:24:49,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:49,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:49,746] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:49,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:49,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:24:49,810] {scheduler_job.py:146} INFO - Started process (PID=7880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:54,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:24:54,818] {logging_mixin.py:95} INFO - [2019-08-28 13:24:54,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:55,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:24:55,172] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:24:55,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:24:55,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-08-28 13:24:55,245] {scheduler_job.py:146} INFO - Started process (PID=7882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:00,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:00,252] {logging_mixin.py:95} INFO - [2019-08-28 13:25:00,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:00,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:00,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:00,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:00,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:25:00,706] {scheduler_job.py:146} INFO - Started process (PID=7884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:05,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:05,712] {logging_mixin.py:95} INFO - [2019-08-28 13:25:05,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:06,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:06,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:06,079] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:06,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-28 13:25:06,143] {scheduler_job.py:146} INFO - Started process (PID=7888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:11,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:11,149] {logging_mixin.py:95} INFO - [2019-08-28 13:25:11,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:11,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:11,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:11,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:11,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-08-28 13:25:11,574] {scheduler_job.py:146} INFO - Started process (PID=7890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:16,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:16,581] {logging_mixin.py:95} INFO - [2019-08-28 13:25:16,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:16,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:16,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:16,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:17,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:25:17,024] {scheduler_job.py:146} INFO - Started process (PID=7894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:22,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:22,029] {logging_mixin.py:95} INFO - [2019-08-28 13:25:22,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:22,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:22,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:22,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:22,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-08-28 13:25:22,474] {scheduler_job.py:146} INFO - Started process (PID=7895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:27,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:27,486] {logging_mixin.py:95} INFO - [2019-08-28 13:25:27,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:27,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:27,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:27,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:27,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:25:27,918] {scheduler_job.py:146} INFO - Started process (PID=7901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:32,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:32,925] {logging_mixin.py:95} INFO - [2019-08-28 13:25:32,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:33,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:33,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:33,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:33,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 13:25:33,396] {scheduler_job.py:146} INFO - Started process (PID=7902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:38,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:38,408] {logging_mixin.py:95} INFO - [2019-08-28 13:25:38,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:38,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:38,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:38,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:38,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:25:38,845] {scheduler_job.py:146} INFO - Started process (PID=7903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:43,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:43,862] {logging_mixin.py:95} INFO - [2019-08-28 13:25:43,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:44,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:44,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:44,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:44,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:25:44,319] {scheduler_job.py:146} INFO - Started process (PID=7906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:49,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:49,326] {logging_mixin.py:95} INFO - [2019-08-28 13:25:49,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:49,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:49,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:49,721] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:49,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:25:49,789] {scheduler_job.py:146} INFO - Started process (PID=7910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:54,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:25:54,794] {logging_mixin.py:95} INFO - [2019-08-28 13:25:54,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:55,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:25:55,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:25:55,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:25:55,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:25:55,241] {scheduler_job.py:146} INFO - Started process (PID=7911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:00,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:00,247] {logging_mixin.py:95} INFO - [2019-08-28 13:26:00,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:00,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:00,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:00,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:00,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-28 13:26:00,693] {scheduler_job.py:146} INFO - Started process (PID=7914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:05,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:05,699] {logging_mixin.py:95} INFO - [2019-08-28 13:26:05,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:06,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:06,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:06,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:06,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-08-28 13:26:06,140] {scheduler_job.py:146} INFO - Started process (PID=7918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:11,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:11,155] {logging_mixin.py:95} INFO - [2019-08-28 13:26:11,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:11,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:11,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:11,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:11,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-08-28 13:26:11,699] {scheduler_job.py:146} INFO - Started process (PID=7920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:16,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:16,705] {logging_mixin.py:95} INFO - [2019-08-28 13:26:16,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:17,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:17,082] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:17,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:17,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:26:17,141] {scheduler_job.py:146} INFO - Started process (PID=7921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:22,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:22,151] {logging_mixin.py:95} INFO - [2019-08-28 13:26:22,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:22,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:22,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:22,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:22,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:26:22,605] {scheduler_job.py:146} INFO - Started process (PID=7923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:27,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:27,612] {logging_mixin.py:95} INFO - [2019-08-28 13:26:27,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:28,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:28,035] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:28,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:28,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 13:26:28,080] {scheduler_job.py:146} INFO - Started process (PID=7925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:33,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:33,095] {logging_mixin.py:95} INFO - [2019-08-28 13:26:33,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:33,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:33,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:33,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:33,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:26:33,533] {scheduler_job.py:146} INFO - Started process (PID=7930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:38,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:38,539] {logging_mixin.py:95} INFO - [2019-08-28 13:26:38,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:38,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:38,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:38,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:38,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-28 13:26:38,978] {scheduler_job.py:146} INFO - Started process (PID=7931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:43,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:43,983] {logging_mixin.py:95} INFO - [2019-08-28 13:26:43,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:44,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:44,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:44,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:44,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-08-28 13:26:44,433] {scheduler_job.py:146} INFO - Started process (PID=7933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:49,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:49,439] {logging_mixin.py:95} INFO - [2019-08-28 13:26:49,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:49,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:49,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:49,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:49,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:26:49,889] {scheduler_job.py:146} INFO - Started process (PID=7934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:54,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:26:54,901] {logging_mixin.py:95} INFO - [2019-08-28 13:26:54,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:55,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:26:55,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:26:55,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:26:55,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:26:55,338] {scheduler_job.py:146} INFO - Started process (PID=7938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:00,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:00,344] {logging_mixin.py:95} INFO - [2019-08-28 13:27:00,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:00,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:00,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:00,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:00,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:27:00,786] {scheduler_job.py:146} INFO - Started process (PID=7941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:05,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:05,799] {logging_mixin.py:95} INFO - [2019-08-28 13:27:05,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:06,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:06,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:06,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:06,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:27:06,245] {scheduler_job.py:146} INFO - Started process (PID=7945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:11,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:11,252] {logging_mixin.py:95} INFO - [2019-08-28 13:27:11,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:11,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:11,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:11,641] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:11,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:27:11,704] {scheduler_job.py:146} INFO - Started process (PID=7947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:16,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:16,716] {logging_mixin.py:95} INFO - [2019-08-28 13:27:16,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:17,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:17,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:17,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:17,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:27:17,170] {scheduler_job.py:146} INFO - Started process (PID=7948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:22,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:22,177] {logging_mixin.py:95} INFO - [2019-08-28 13:27:22,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:22,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:22,547] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:22,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:22,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:27:22,632] {scheduler_job.py:146} INFO - Started process (PID=7949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:27,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:27,642] {logging_mixin.py:95} INFO - [2019-08-28 13:27:27,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:27,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:28,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:28,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:28,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:27:28,087] {scheduler_job.py:146} INFO - Started process (PID=7954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:33,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:33,094] {logging_mixin.py:95} INFO - [2019-08-28 13:27:33,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:33,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:33,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:33,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:33,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-08-28 13:27:33,554] {scheduler_job.py:146} INFO - Started process (PID=7956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:38,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:38,562] {logging_mixin.py:95} INFO - [2019-08-28 13:27:38,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:38,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:38,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:38,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:38,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:27:39,017] {scheduler_job.py:146} INFO - Started process (PID=7960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:44,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:44,027] {logging_mixin.py:95} INFO - [2019-08-28 13:27:44,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:44,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:44,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:44,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:44,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:27:44,475] {scheduler_job.py:146} INFO - Started process (PID=7963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:49,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:49,481] {logging_mixin.py:95} INFO - [2019-08-28 13:27:49,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:49,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:49,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:49,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:49,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:27:49,924] {scheduler_job.py:146} INFO - Started process (PID=7964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:54,935] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:27:54,936] {logging_mixin.py:95} INFO - [2019-08-28 13:27:54,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:55,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:27:55,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:27:55,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:27:55,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:27:55,374] {scheduler_job.py:146} INFO - Started process (PID=7965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:00,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:00,382] {logging_mixin.py:95} INFO - [2019-08-28 13:28:00,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:00,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:00,760] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:00,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:00,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:28:00,837] {scheduler_job.py:146} INFO - Started process (PID=7970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:05,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:05,843] {logging_mixin.py:95} INFO - [2019-08-28 13:28:05,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:06,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:06,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:06,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:06,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:28:06,297] {scheduler_job.py:146} INFO - Started process (PID=7972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:11,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:11,308] {logging_mixin.py:95} INFO - [2019-08-28 13:28:11,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:11,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:11,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:11,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:11,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:28:11,754] {scheduler_job.py:146} INFO - Started process (PID=7974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:16,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:16,760] {logging_mixin.py:95} INFO - [2019-08-28 13:28:16,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:17,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:17,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:17,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:17,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:28:17,212] {scheduler_job.py:146} INFO - Started process (PID=7979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:22,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:22,221] {logging_mixin.py:95} INFO - [2019-08-28 13:28:22,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:22,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:22,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:22,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:22,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:28:22,671] {scheduler_job.py:146} INFO - Started process (PID=7980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:27,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:27,679] {logging_mixin.py:95} INFO - [2019-08-28 13:28:27,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:28,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:28,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:28,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:28,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:28:28,130] {scheduler_job.py:146} INFO - Started process (PID=7985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:33,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:33,141] {logging_mixin.py:95} INFO - [2019-08-28 13:28:33,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:33,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:33,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:33,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:33,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:28:33,584] {scheduler_job.py:146} INFO - Started process (PID=7986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:38,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:38,593] {logging_mixin.py:95} INFO - [2019-08-28 13:28:38,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:38,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:38,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:38,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:38,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:28:39,050] {scheduler_job.py:146} INFO - Started process (PID=7988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:44,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:44,059] {logging_mixin.py:95} INFO - [2019-08-28 13:28:44,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:44,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:44,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:44,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:44,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:28:44,514] {scheduler_job.py:146} INFO - Started process (PID=7993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:49,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:49,525] {logging_mixin.py:95} INFO - [2019-08-28 13:28:49,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:49,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:49,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:49,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:49,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:28:49,977] {scheduler_job.py:146} INFO - Started process (PID=7994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:54,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:28:54,989] {logging_mixin.py:95} INFO - [2019-08-28 13:28:54,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:55,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:28:55,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:28:55,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:28:55,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:28:55,440] {scheduler_job.py:146} INFO - Started process (PID=7995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:00,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:00,451] {logging_mixin.py:95} INFO - [2019-08-28 13:29:00,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:00,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:00,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:00,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:00,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:29:00,904] {scheduler_job.py:146} INFO - Started process (PID=8000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:05,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:05,915] {logging_mixin.py:95} INFO - [2019-08-28 13:29:05,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:06,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:06,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:06,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:06,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:29:06,369] {scheduler_job.py:146} INFO - Started process (PID=8001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:11,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:11,376] {logging_mixin.py:95} INFO - [2019-08-28 13:29:11,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:11,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:11,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:11,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:11,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:29:11,834] {scheduler_job.py:146} INFO - Started process (PID=8004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:16,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:16,842] {logging_mixin.py:95} INFO - [2019-08-28 13:29:16,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:17,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:17,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:17,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:17,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:29:17,300] {scheduler_job.py:146} INFO - Started process (PID=8005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:22,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:22,306] {logging_mixin.py:95} INFO - [2019-08-28 13:29:22,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:22,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:22,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:22,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:22,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:29:22,760] {scheduler_job.py:146} INFO - Started process (PID=8009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:27,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:27,771] {logging_mixin.py:95} INFO - [2019-08-28 13:29:27,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:28,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:28,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:28,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:28,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:29:28,223] {scheduler_job.py:146} INFO - Started process (PID=8011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:33,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:33,229] {logging_mixin.py:95} INFO - [2019-08-28 13:29:33,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:33,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:33,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:33,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:33,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:29:33,672] {scheduler_job.py:146} INFO - Started process (PID=8015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:38,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:38,678] {logging_mixin.py:95} INFO - [2019-08-28 13:29:38,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:39,062] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:39,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:39,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:39,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:29:39,140] {scheduler_job.py:146} INFO - Started process (PID=8017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:44,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:44,147] {logging_mixin.py:95} INFO - [2019-08-28 13:29:44,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:44,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:44,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:44,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:44,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:29:44,597] {scheduler_job.py:146} INFO - Started process (PID=8019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:49,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:49,604] {logging_mixin.py:95} INFO - [2019-08-28 13:29:49,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:49,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:49,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:49,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:49,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:29:50,058] {scheduler_job.py:146} INFO - Started process (PID=8020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:55,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:29:55,065] {logging_mixin.py:95} INFO - [2019-08-28 13:29:55,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:55,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:29:55,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:29:55,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:29:55,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 13:29:55,524] {scheduler_job.py:146} INFO - Started process (PID=8024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:00,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:00,533] {logging_mixin.py:95} INFO - [2019-08-28 13:30:00,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:00,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:00,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:00,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:00,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:30:00,991] {scheduler_job.py:146} INFO - Started process (PID=8030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:06,000] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:06,001] {logging_mixin.py:95} INFO - [2019-08-28 13:30:06,001] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:06,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:06,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:06,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:06,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:30:06,449] {scheduler_job.py:146} INFO - Started process (PID=8031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:11,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:11,458] {logging_mixin.py:95} INFO - [2019-08-28 13:30:11,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:11,829] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:11,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:11,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:11,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:30:11,905] {scheduler_job.py:146} INFO - Started process (PID=8034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:16,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:16,915] {logging_mixin.py:95} INFO - [2019-08-28 13:30:16,915] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:17,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:17,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:17,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:17,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:30:17,355] {scheduler_job.py:146} INFO - Started process (PID=8035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:22,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:22,366] {logging_mixin.py:95} INFO - [2019-08-28 13:30:22,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:22,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:22,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:22,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:22,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:30:22,812] {scheduler_job.py:146} INFO - Started process (PID=8039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:27,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:27,823] {logging_mixin.py:95} INFO - [2019-08-28 13:30:27,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:28,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:28,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:28,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:28,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:30:28,270] {scheduler_job.py:146} INFO - Started process (PID=8041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:33,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:33,279] {logging_mixin.py:95} INFO - [2019-08-28 13:30:33,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:33,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:33,678] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:33,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:33,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:30:33,719] {scheduler_job.py:146} INFO - Started process (PID=8045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:38,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:38,726] {logging_mixin.py:95} INFO - [2019-08-28 13:30:38,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:39,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:39,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:39,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:39,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:30:39,180] {scheduler_job.py:146} INFO - Started process (PID=8046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:44,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:44,191] {logging_mixin.py:95} INFO - [2019-08-28 13:30:44,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:44,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:44,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:44,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:44,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:30:44,639] {scheduler_job.py:146} INFO - Started process (PID=8049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:49,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:49,646] {logging_mixin.py:95} INFO - [2019-08-28 13:30:49,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:50,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:50,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:50,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:50,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:30:50,096] {scheduler_job.py:146} INFO - Started process (PID=8053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:55,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:30:55,107] {logging_mixin.py:95} INFO - [2019-08-28 13:30:55,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:55,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:30:55,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:30:55,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:30:55,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:30:55,548] {scheduler_job.py:146} INFO - Started process (PID=8054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:00,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:00,557] {logging_mixin.py:95} INFO - [2019-08-28 13:31:00,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:00,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:00,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:00,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:00,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 13:31:01,098] {scheduler_job.py:146} INFO - Started process (PID=8056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:06,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:06,106] {logging_mixin.py:95} INFO - [2019-08-28 13:31:06,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:06,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:06,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:06,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:06,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 13:31:06,643] {scheduler_job.py:146} INFO - Started process (PID=8065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:11,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:11,648] {logging_mixin.py:95} INFO - [2019-08-28 13:31:11,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:12,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:12,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:12,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:12,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:31:12,089] {scheduler_job.py:146} INFO - Started process (PID=8067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:17,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:17,096] {logging_mixin.py:95} INFO - [2019-08-28 13:31:17,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:17,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:17,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:17,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:17,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:31:17,540] {scheduler_job.py:146} INFO - Started process (PID=8069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:22,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:22,548] {logging_mixin.py:95} INFO - [2019-08-28 13:31:22,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:22,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:22,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:22,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:22,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:31:23,087] {scheduler_job.py:146} INFO - Started process (PID=8073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:28,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:28,099] {logging_mixin.py:95} INFO - [2019-08-28 13:31:28,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:28,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:28,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:28,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:28,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 13:31:28,634] {scheduler_job.py:146} INFO - Started process (PID=8076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:33,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:33,641] {logging_mixin.py:95} INFO - [2019-08-28 13:31:33,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:34,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:34,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:34,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:34,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 13:31:34,086] {scheduler_job.py:146} INFO - Started process (PID=8077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:39,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:39,092] {logging_mixin.py:95} INFO - [2019-08-28 13:31:39,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:39,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:39,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:39,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:39,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:31:39,535] {scheduler_job.py:146} INFO - Started process (PID=8081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:44,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:44,541] {logging_mixin.py:95} INFO - [2019-08-28 13:31:44,541] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:44,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:44,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:44,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:44,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:31:44,988] {scheduler_job.py:146} INFO - Started process (PID=8084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:49,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:49,996] {logging_mixin.py:95} INFO - [2019-08-28 13:31:49,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:50,347] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:50,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:50,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:50,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:31:50,439] {scheduler_job.py:146} INFO - Started process (PID=8085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:55,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:31:55,447] {logging_mixin.py:95} INFO - [2019-08-28 13:31:55,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:55,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:31:55,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:31:55,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:31:55,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:31:55,985] {scheduler_job.py:146} INFO - Started process (PID=8089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:00,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:00,995] {logging_mixin.py:95} INFO - [2019-08-28 13:32:00,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:01,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:01,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:01,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:01,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:32:01,431] {scheduler_job.py:146} INFO - Started process (PID=8091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:06,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:06,440] {logging_mixin.py:95} INFO - [2019-08-28 13:32:06,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:06,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:06,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:06,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:06,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:32:06,888] {scheduler_job.py:146} INFO - Started process (PID=8092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:11,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:11,898] {logging_mixin.py:95} INFO - [2019-08-28 13:32:11,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:12,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:12,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:12,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:12,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:32:12,338] {scheduler_job.py:146} INFO - Started process (PID=8100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:17,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:17,344] {logging_mixin.py:95} INFO - [2019-08-28 13:32:17,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:17,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:17,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:17,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:17,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:32:17,797] {scheduler_job.py:146} INFO - Started process (PID=8102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:22,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:22,806] {logging_mixin.py:95} INFO - [2019-08-28 13:32:22,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:23,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:23,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:23,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:23,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:32:23,255] {scheduler_job.py:146} INFO - Started process (PID=8104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:28,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:28,266] {logging_mixin.py:95} INFO - [2019-08-28 13:32:28,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:28,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:28,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:28,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:28,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:32:28,718] {scheduler_job.py:146} INFO - Started process (PID=8108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:33,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:33,731] {logging_mixin.py:95} INFO - [2019-08-28 13:32:33,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:34,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:34,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:34,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:34,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:32:34,172] {scheduler_job.py:146} INFO - Started process (PID=8109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:39,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:39,179] {logging_mixin.py:95} INFO - [2019-08-28 13:32:39,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:39,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:39,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:39,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:39,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 13:32:39,631] {scheduler_job.py:146} INFO - Started process (PID=8113) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:44,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:44,639] {logging_mixin.py:95} INFO - [2019-08-28 13:32:44,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:45,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:45,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:45,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:45,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 13:32:45,177] {scheduler_job.py:146} INFO - Started process (PID=8115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:50,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:50,189] {logging_mixin.py:95} INFO - [2019-08-28 13:32:50,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:50,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:50,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:50,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:50,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 13:32:50,717] {scheduler_job.py:146} INFO - Started process (PID=8122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:55,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:32:55,723] {logging_mixin.py:95} INFO - [2019-08-28 13:32:55,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:56,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:32:56,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:32:56,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:32:56,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:32:56,168] {scheduler_job.py:146} INFO - Started process (PID=8126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:01,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:01,175] {logging_mixin.py:95} INFO - [2019-08-28 13:33:01,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:01,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:01,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:01,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:01,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:33:01,623] {scheduler_job.py:146} INFO - Started process (PID=8128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:06,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:06,630] {logging_mixin.py:95} INFO - [2019-08-28 13:33:06,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:06,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:07,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:07,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:07,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:33:07,079] {scheduler_job.py:146} INFO - Started process (PID=8129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:12,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:12,086] {logging_mixin.py:95} INFO - [2019-08-28 13:33:12,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:12,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:12,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:12,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:12,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:33:12,534] {scheduler_job.py:146} INFO - Started process (PID=8134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:17,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:17,545] {logging_mixin.py:95} INFO - [2019-08-28 13:33:17,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:17,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:17,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:17,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:17,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:33:17,992] {scheduler_job.py:146} INFO - Started process (PID=8135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:22,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:22,999] {logging_mixin.py:95} INFO - [2019-08-28 13:33:22,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:23,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:23,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:23,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:23,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:33:23,445] {scheduler_job.py:146} INFO - Started process (PID=8137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:28,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:28,455] {logging_mixin.py:95} INFO - [2019-08-28 13:33:28,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:28,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:28,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:28,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:28,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:33:28,904] {scheduler_job.py:146} INFO - Started process (PID=8139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:33,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:33,911] {logging_mixin.py:95} INFO - [2019-08-28 13:33:33,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:34,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:34,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:34,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:34,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:33:34,352] {scheduler_job.py:146} INFO - Started process (PID=8148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:39,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:39,358] {logging_mixin.py:95} INFO - [2019-08-28 13:33:39,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:39,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:39,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:39,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:39,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 13:33:39,910] {scheduler_job.py:146} INFO - Started process (PID=8150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:44,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:44,921] {logging_mixin.py:95} INFO - [2019-08-28 13:33:44,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:45,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:45,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:45,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:45,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:33:45,445] {scheduler_job.py:146} INFO - Started process (PID=8155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:50,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:50,453] {logging_mixin.py:95} INFO - [2019-08-28 13:33:50,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:50,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:50,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:50,846] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:50,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:33:50,896] {scheduler_job.py:146} INFO - Started process (PID=8157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:55,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:33:55,906] {logging_mixin.py:95} INFO - [2019-08-28 13:33:55,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:56,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:33:56,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:33:56,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:33:56,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 13:33:56,350] {scheduler_job.py:146} INFO - Started process (PID=8158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:01,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:01,359] {logging_mixin.py:95} INFO - [2019-08-28 13:34:01,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:01,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:01,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:01,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:01,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:34:01,807] {scheduler_job.py:146} INFO - Started process (PID=8160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:06,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:06,814] {logging_mixin.py:95} INFO - [2019-08-28 13:34:06,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:07,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:07,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:07,205] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:07,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:34:07,266] {scheduler_job.py:146} INFO - Started process (PID=8164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:12,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:12,272] {logging_mixin.py:95} INFO - [2019-08-28 13:34:12,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:12,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:12,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:12,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:12,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:34:12,719] {scheduler_job.py:146} INFO - Started process (PID=8166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:17,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:17,728] {logging_mixin.py:95} INFO - [2019-08-28 13:34:17,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:18,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:18,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:18,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:18,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:34:18,171] {scheduler_job.py:146} INFO - Started process (PID=8167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:23,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:23,178] {logging_mixin.py:95} INFO - [2019-08-28 13:34:23,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:23,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:23,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:23,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:23,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:34:23,629] {scheduler_job.py:146} INFO - Started process (PID=8172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:28,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:28,637] {logging_mixin.py:95} INFO - [2019-08-28 13:34:28,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:28,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:29,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:29,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:29,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:34:29,091] {scheduler_job.py:146} INFO - Started process (PID=8174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:34,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:34,101] {logging_mixin.py:95} INFO - [2019-08-28 13:34:34,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:34,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:34,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:34,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:34,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:34:34,548] {scheduler_job.py:146} INFO - Started process (PID=8178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:39,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:39,555] {logging_mixin.py:95} INFO - [2019-08-28 13:34:39,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:39,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:39,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:39,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:39,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:34:40,007] {scheduler_job.py:146} INFO - Started process (PID=8179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:45,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:45,014] {logging_mixin.py:95} INFO - [2019-08-28 13:34:45,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:45,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:45,396] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:45,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:45,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:34:45,463] {scheduler_job.py:146} INFO - Started process (PID=8181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:50,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:50,471] {logging_mixin.py:95} INFO - [2019-08-28 13:34:50,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:50,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:50,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:50,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:50,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:34:50,917] {scheduler_job.py:146} INFO - Started process (PID=8185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:55,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:34:55,928] {logging_mixin.py:95} INFO - [2019-08-28 13:34:55,928] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:56,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:34:56,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:34:56,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:34:56,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:34:56,365] {scheduler_job.py:146} INFO - Started process (PID=8187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:01,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:01,370] {logging_mixin.py:95} INFO - [2019-08-28 13:35:01,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:01,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:01,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:01,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:01,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:35:01,817] {scheduler_job.py:146} INFO - Started process (PID=8192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:06,824] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:06,825] {logging_mixin.py:95} INFO - [2019-08-28 13:35:06,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:07,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:07,227] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:07,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:07,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:35:07,265] {scheduler_job.py:146} INFO - Started process (PID=8193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:12,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:12,273] {logging_mixin.py:95} INFO - [2019-08-28 13:35:12,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:12,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:12,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:12,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:12,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:35:12,803] {scheduler_job.py:146} INFO - Started process (PID=8199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:17,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:17,810] {logging_mixin.py:95} INFO - [2019-08-28 13:35:17,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:18,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:18,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:18,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:18,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 13:35:18,350] {scheduler_job.py:146} INFO - Started process (PID=8200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:23,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:23,358] {logging_mixin.py:95} INFO - [2019-08-28 13:35:23,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:23,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:23,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:23,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:23,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:35:23,799] {scheduler_job.py:146} INFO - Started process (PID=8204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:28,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:28,806] {logging_mixin.py:95} INFO - [2019-08-28 13:35:28,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:29,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:29,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:29,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:29,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:35:29,257] {scheduler_job.py:146} INFO - Started process (PID=8207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:34,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:34,263] {logging_mixin.py:95} INFO - [2019-08-28 13:35:34,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:34,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:34,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:34,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:34,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:35:34,718] {scheduler_job.py:146} INFO - Started process (PID=8208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:39,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:39,730] {logging_mixin.py:95} INFO - [2019-08-28 13:35:39,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:40,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:40,111] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:40,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:40,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:35:40,170] {scheduler_job.py:146} INFO - Started process (PID=8212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:45,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:45,177] {logging_mixin.py:95} INFO - [2019-08-28 13:35:45,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:45,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:45,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:45,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:45,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 13:35:45,724] {scheduler_job.py:146} INFO - Started process (PID=8214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:50,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:50,731] {logging_mixin.py:95} INFO - [2019-08-28 13:35:50,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:51,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:51,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:51,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:51,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 13:35:51,269] {scheduler_job.py:146} INFO - Started process (PID=8215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:56,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:35:56,279] {logging_mixin.py:95} INFO - [2019-08-28 13:35:56,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:56,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:35:56,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:35:56,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:35:56,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:35:56,811] {scheduler_job.py:146} INFO - Started process (PID=8221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:01,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:01,820] {logging_mixin.py:95} INFO - [2019-08-28 13:36:01,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:02,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:02,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:02,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:02,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:36:02,267] {scheduler_job.py:146} INFO - Started process (PID=8222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:07,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:07,278] {logging_mixin.py:95} INFO - [2019-08-28 13:36:07,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:07,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:07,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:07,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:07,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:36:07,720] {scheduler_job.py:146} INFO - Started process (PID=8223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:12,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:12,726] {logging_mixin.py:95} INFO - [2019-08-28 13:36:12,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:13,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:13,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:13,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:13,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 13:36:13,272] {scheduler_job.py:146} INFO - Started process (PID=8228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:18,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:18,284] {logging_mixin.py:95} INFO - [2019-08-28 13:36:18,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:18,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:18,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:18,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:18,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:36:18,725] {scheduler_job.py:146} INFO - Started process (PID=8229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:23,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:23,735] {logging_mixin.py:95} INFO - [2019-08-28 13:36:23,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:24,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:24,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:24,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:24,141] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:36:24,175] {scheduler_job.py:146} INFO - Started process (PID=8233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:29,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:29,185] {logging_mixin.py:95} INFO - [2019-08-28 13:36:29,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:29,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:29,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:29,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:29,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:36:29,630] {scheduler_job.py:146} INFO - Started process (PID=8236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:34,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:34,638] {logging_mixin.py:95} INFO - [2019-08-28 13:36:34,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:34,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:35,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:35,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:35,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:36:35,086] {scheduler_job.py:146} INFO - Started process (PID=8237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:40,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:40,097] {logging_mixin.py:95} INFO - [2019-08-28 13:36:40,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:40,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:40,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:40,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:40,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:36:40,546] {scheduler_job.py:146} INFO - Started process (PID=8241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:45,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:45,553] {logging_mixin.py:95} INFO - [2019-08-28 13:36:45,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:45,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:45,975] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:45,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:45,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 13:36:46,095] {scheduler_job.py:146} INFO - Started process (PID=8243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:51,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:51,102] {logging_mixin.py:95} INFO - [2019-08-28 13:36:51,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:51,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:51,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:51,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:51,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:36:51,542] {scheduler_job.py:146} INFO - Started process (PID=8244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:56,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:36:56,553] {logging_mixin.py:95} INFO - [2019-08-28 13:36:56,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:56,925] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:36:56,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:36:56,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:36:56,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:36:56,997] {scheduler_job.py:146} INFO - Started process (PID=8249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:02,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:02,006] {logging_mixin.py:95} INFO - [2019-08-28 13:37:02,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:02,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:02,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:02,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:02,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:37:02,449] {scheduler_job.py:146} INFO - Started process (PID=8251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:07,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:07,456] {logging_mixin.py:95} INFO - [2019-08-28 13:37:07,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:07,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:07,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:07,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:07,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:37:07,904] {scheduler_job.py:146} INFO - Started process (PID=8252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:12,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:12,914] {logging_mixin.py:95} INFO - [2019-08-28 13:37:12,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:13,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:13,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:13,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:13,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:37:13,357] {scheduler_job.py:146} INFO - Started process (PID=8257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:18,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:18,366] {logging_mixin.py:95} INFO - [2019-08-28 13:37:18,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:18,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:18,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:18,754] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:18,759] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:37:18,816] {scheduler_job.py:146} INFO - Started process (PID=8258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:23,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:23,824] {logging_mixin.py:95} INFO - [2019-08-28 13:37:23,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:24,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:24,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:24,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:24,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:37:24,277] {scheduler_job.py:146} INFO - Started process (PID=8259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:29,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:29,287] {logging_mixin.py:95} INFO - [2019-08-28 13:37:29,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:29,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:29,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:29,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:29,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:37:29,734] {scheduler_job.py:146} INFO - Started process (PID=8261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:34,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:34,742] {logging_mixin.py:95} INFO - [2019-08-28 13:37:34,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:35,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:35,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:35,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:35,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:37:35,187] {scheduler_job.py:146} INFO - Started process (PID=8266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:40,191] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:40,192] {logging_mixin.py:95} INFO - [2019-08-28 13:37:40,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:40,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:40,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:40,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:40,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 13:37:40,738] {scheduler_job.py:146} INFO - Started process (PID=8267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:45,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:45,746] {logging_mixin.py:95} INFO - [2019-08-28 13:37:45,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:46,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:46,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:46,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:46,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:37:46,180] {scheduler_job.py:146} INFO - Started process (PID=8272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:51,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:51,187] {logging_mixin.py:95} INFO - [2019-08-28 13:37:51,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:51,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:51,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:51,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:51,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:37:51,637] {scheduler_job.py:146} INFO - Started process (PID=8274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:56,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:37:56,645] {logging_mixin.py:95} INFO - [2019-08-28 13:37:56,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:57,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:37:57,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:37:57,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:37:57,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:37:57,084] {scheduler_job.py:146} INFO - Started process (PID=8277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:02,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:02,089] {logging_mixin.py:95} INFO - [2019-08-28 13:38:02,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:02,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:02,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:02,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:02,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:38:02,544] {scheduler_job.py:146} INFO - Started process (PID=8281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:07,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:07,554] {logging_mixin.py:95} INFO - [2019-08-28 13:38:07,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:07,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:07,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:07,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:07,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:38:08,002] {scheduler_job.py:146} INFO - Started process (PID=8284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:13,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:13,011] {logging_mixin.py:95} INFO - [2019-08-28 13:38:13,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:13,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:13,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:13,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:13,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:38:13,465] {scheduler_job.py:146} INFO - Started process (PID=8286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:18,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:18,472] {logging_mixin.py:95} INFO - [2019-08-28 13:38:18,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:18,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:18,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:18,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:18,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:38:18,921] {scheduler_job.py:146} INFO - Started process (PID=8287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:23,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:23,930] {logging_mixin.py:95} INFO - [2019-08-28 13:38:23,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:24,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:24,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:24,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:24,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:38:24,374] {scheduler_job.py:146} INFO - Started process (PID=8291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:29,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:29,379] {logging_mixin.py:95} INFO - [2019-08-28 13:38:29,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:29,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:29,750] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:29,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:29,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:38:29,837] {scheduler_job.py:146} INFO - Started process (PID=8293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:34,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:34,848] {logging_mixin.py:95} INFO - [2019-08-28 13:38:34,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:35,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:35,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:35,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:35,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:38:35,300] {scheduler_job.py:146} INFO - Started process (PID=8295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:40,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:40,307] {logging_mixin.py:95} INFO - [2019-08-28 13:38:40,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:40,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:40,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:40,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:40,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:38:40,763] {scheduler_job.py:146} INFO - Started process (PID=8299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:45,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:45,770] {logging_mixin.py:95} INFO - [2019-08-28 13:38:45,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:46,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:46,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:46,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:46,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:38:46,227] {scheduler_job.py:146} INFO - Started process (PID=8301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:51,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:51,237] {logging_mixin.py:95} INFO - [2019-08-28 13:38:51,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:51,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:51,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:51,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:51,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:38:51,690] {scheduler_job.py:146} INFO - Started process (PID=8305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:56,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:38:56,696] {logging_mixin.py:95} INFO - [2019-08-28 13:38:56,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:57,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:38:57,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:38:57,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:38:57,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-08-28 13:38:57,150] {scheduler_job.py:146} INFO - Started process (PID=8307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:02,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:02,159] {logging_mixin.py:95} INFO - [2019-08-28 13:39:02,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:02,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:02,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:02,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:02,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:39:02,601] {scheduler_job.py:146} INFO - Started process (PID=8311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:07,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:07,610] {logging_mixin.py:95} INFO - [2019-08-28 13:39:07,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:07,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:08,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:08,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:08,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:39:08,051] {scheduler_job.py:146} INFO - Started process (PID=8313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:13,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:13,060] {logging_mixin.py:95} INFO - [2019-08-28 13:39:13,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:13,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:13,454] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:13,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:13,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:39:13,501] {scheduler_job.py:146} INFO - Started process (PID=8315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:18,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:18,510] {logging_mixin.py:95} INFO - [2019-08-28 13:39:18,509] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:18,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:18,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:18,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:18,923] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:39:18,951] {scheduler_job.py:146} INFO - Started process (PID=8316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:23,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:23,957] {logging_mixin.py:95} INFO - [2019-08-28 13:39:23,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:24,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:24,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:24,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:24,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:39:24,402] {scheduler_job.py:146} INFO - Started process (PID=8320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:29,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:29,410] {logging_mixin.py:95} INFO - [2019-08-28 13:39:29,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:29,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:29,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:29,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:29,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:39:29,852] {scheduler_job.py:146} INFO - Started process (PID=8322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:34,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:34,859] {logging_mixin.py:95} INFO - [2019-08-28 13:39:34,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:35,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:35,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:35,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:35,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:39:35,309] {scheduler_job.py:146} INFO - Started process (PID=8323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:40,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:40,318] {logging_mixin.py:95} INFO - [2019-08-28 13:39:40,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:40,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:40,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:40,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:40,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:39:40,757] {scheduler_job.py:146} INFO - Started process (PID=8328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:45,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:45,768] {logging_mixin.py:95} INFO - [2019-08-28 13:39:45,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:46,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:46,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:46,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:46,157] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:39:46,207] {scheduler_job.py:146} INFO - Started process (PID=8330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:51,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:51,213] {logging_mixin.py:95} INFO - [2019-08-28 13:39:51,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:51,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:51,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:51,612] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:51,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:39:51,661] {scheduler_job.py:146} INFO - Started process (PID=8334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:56,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:39:56,669] {logging_mixin.py:95} INFO - [2019-08-28 13:39:56,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:57,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:39:57,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:39:57,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:39:57,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 13:39:57,111] {scheduler_job.py:146} INFO - Started process (PID=8336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:02,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:02,118] {logging_mixin.py:95} INFO - [2019-08-28 13:40:02,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:02,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:02,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:02,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:02,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:40:02,560] {scheduler_job.py:146} INFO - Started process (PID=8337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:07,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:07,570] {logging_mixin.py:95} INFO - [2019-08-28 13:40:07,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:07,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:07,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:07,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:08,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 13:40:08,114] {scheduler_job.py:146} INFO - Started process (PID=8339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:13,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:13,120] {logging_mixin.py:95} INFO - [2019-08-28 13:40:13,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:13,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:13,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:13,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:13,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:40:13,563] {scheduler_job.py:146} INFO - Started process (PID=8344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:18,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:18,571] {logging_mixin.py:95} INFO - [2019-08-28 13:40:18,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:18,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:18,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:18,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:18,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:40:19,015] {scheduler_job.py:146} INFO - Started process (PID=8345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:24,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:24,024] {logging_mixin.py:95} INFO - [2019-08-28 13:40:24,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:24,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:24,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:24,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:24,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:40:24,472] {scheduler_job.py:146} INFO - Started process (PID=8346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:29,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:29,481] {logging_mixin.py:95} INFO - [2019-08-28 13:40:29,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:29,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:29,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:29,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:29,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:40:29,928] {scheduler_job.py:146} INFO - Started process (PID=8348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:34,935] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:34,936] {logging_mixin.py:95} INFO - [2019-08-28 13:40:34,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:35,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:35,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:35,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:35,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:40:35,385] {scheduler_job.py:146} INFO - Started process (PID=8352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:40,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:40,395] {logging_mixin.py:95} INFO - [2019-08-28 13:40:40,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:40,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:40,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:40,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:40,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-08-28 13:40:40,940] {scheduler_job.py:146} INFO - Started process (PID=8354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:45,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:45,946] {logging_mixin.py:95} INFO - [2019-08-28 13:40:45,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:46,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:46,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:46,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:46,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:40:46,393] {scheduler_job.py:146} INFO - Started process (PID=8359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:51,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:51,401] {logging_mixin.py:95} INFO - [2019-08-28 13:40:51,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:51,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:51,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:51,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:51,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:40:51,845] {scheduler_job.py:146} INFO - Started process (PID=8360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:56,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:40:56,852] {logging_mixin.py:95} INFO - [2019-08-28 13:40:56,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:57,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:40:57,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:40:57,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:40:57,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 13:40:57,300] {scheduler_job.py:146} INFO - Started process (PID=8365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:02,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:02,311] {logging_mixin.py:95} INFO - [2019-08-28 13:41:02,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:02,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:02,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:02,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:02,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 13:41:02,750] {scheduler_job.py:146} INFO - Started process (PID=8366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:07,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:07,762] {logging_mixin.py:95} INFO - [2019-08-28 13:41:07,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:08,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:08,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:08,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:08,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:41:08,206] {scheduler_job.py:146} INFO - Started process (PID=8367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:13,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:13,213] {logging_mixin.py:95} INFO - [2019-08-28 13:41:13,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:13,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:13,595] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:13,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:13,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:41:13,661] {scheduler_job.py:146} INFO - Started process (PID=8370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:18,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:18,668] {logging_mixin.py:95} INFO - [2019-08-28 13:41:18,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:19,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:19,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:19,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:19,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:41:19,113] {scheduler_job.py:146} INFO - Started process (PID=8374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:24,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:24,122] {logging_mixin.py:95} INFO - [2019-08-28 13:41:24,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:24,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:24,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:24,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:24,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:41:24,571] {scheduler_job.py:146} INFO - Started process (PID=8375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:29,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:29,579] {logging_mixin.py:95} INFO - [2019-08-28 13:41:29,579] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:29,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:29,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:29,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:29,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:41:30,030] {scheduler_job.py:146} INFO - Started process (PID=8380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:35,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:35,037] {logging_mixin.py:95} INFO - [2019-08-28 13:41:35,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:35,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:35,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:35,526] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:35,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-08-28 13:41:35,577] {scheduler_job.py:146} INFO - Started process (PID=8382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:40,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:40,584] {logging_mixin.py:95} INFO - [2019-08-28 13:41:40,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:40,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:40,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:41,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:41,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 13:41:41,128] {scheduler_job.py:146} INFO - Started process (PID=8383) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:46,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:46,134] {logging_mixin.py:95} INFO - [2019-08-28 13:41:46,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:46,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:46,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:46,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:46,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:41:46,577] {scheduler_job.py:146} INFO - Started process (PID=8387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:51,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:51,586] {logging_mixin.py:95} INFO - [2019-08-28 13:41:51,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:51,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:51,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:51,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:51,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:41:52,029] {scheduler_job.py:146} INFO - Started process (PID=8391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:57,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:41:57,038] {logging_mixin.py:95} INFO - [2019-08-28 13:41:57,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:57,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:41:57,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:41:57,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:41:57,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:41:57,576] {scheduler_job.py:146} INFO - Started process (PID=8393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:02,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:02,585] {logging_mixin.py:95} INFO - [2019-08-28 13:42:02,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:02,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:02,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:02,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:02,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 13:42:03,023] {scheduler_job.py:146} INFO - Started process (PID=8397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:08,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:08,030] {logging_mixin.py:95} INFO - [2019-08-28 13:42:08,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:08,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:08,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:08,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:08,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:42:08,469] {scheduler_job.py:146} INFO - Started process (PID=8398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:13,474] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:13,475] {logging_mixin.py:95} INFO - [2019-08-28 13:42:13,475] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:13,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:13,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:13,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:13,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:42:13,914] {scheduler_job.py:146} INFO - Started process (PID=8402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:18,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:18,922] {logging_mixin.py:95} INFO - [2019-08-28 13:42:18,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:19,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:19,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:19,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:19,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:42:19,367] {scheduler_job.py:146} INFO - Started process (PID=8406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:24,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:24,376] {logging_mixin.py:95} INFO - [2019-08-28 13:42:24,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:24,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:24,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:24,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:24,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:42:24,813] {scheduler_job.py:146} INFO - Started process (PID=8409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:29,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:29,824] {logging_mixin.py:95} INFO - [2019-08-28 13:42:29,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:30,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:30,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:30,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:30,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:42:30,268] {scheduler_job.py:146} INFO - Started process (PID=8411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:35,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:35,275] {logging_mixin.py:95} INFO - [2019-08-28 13:42:35,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:35,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:35,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:35,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:35,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:42:35,723] {scheduler_job.py:146} INFO - Started process (PID=8415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:40,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:40,743] {logging_mixin.py:95} INFO - [2019-08-28 13:42:40,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:41,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:41,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:41,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:41,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 13:42:41,272] {scheduler_job.py:146} INFO - Started process (PID=8416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:46,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:46,284] {logging_mixin.py:95} INFO - [2019-08-28 13:42:46,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:46,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:46,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:46,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:46,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:42:46,818] {scheduler_job.py:146} INFO - Started process (PID=8419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:51,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:51,826] {logging_mixin.py:95} INFO - [2019-08-28 13:42:51,825] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:52,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:52,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:52,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:52,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:42:52,279] {scheduler_job.py:146} INFO - Started process (PID=8420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:57,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:42:57,285] {logging_mixin.py:95} INFO - [2019-08-28 13:42:57,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:57,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:42:57,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:42:57,700] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:42:57,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 13:42:57,728] {scheduler_job.py:146} INFO - Started process (PID=8425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:02,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:02,737] {logging_mixin.py:95} INFO - [2019-08-28 13:43:02,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:03,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:03,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:03,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:03,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:43:03,180] {scheduler_job.py:146} INFO - Started process (PID=8426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:08,191] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:08,192] {logging_mixin.py:95} INFO - [2019-08-28 13:43:08,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:08,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:08,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:08,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:08,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:43:08,637] {scheduler_job.py:146} INFO - Started process (PID=8430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:13,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:13,645] {logging_mixin.py:95} INFO - [2019-08-28 13:43:13,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:14,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:14,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:14,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:14,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:43:14,083] {scheduler_job.py:146} INFO - Started process (PID=8432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:19,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:19,090] {logging_mixin.py:95} INFO - [2019-08-28 13:43:19,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:19,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:19,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:19,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:19,497] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:43:19,538] {scheduler_job.py:146} INFO - Started process (PID=8437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:24,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:24,548] {logging_mixin.py:95} INFO - [2019-08-28 13:43:24,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:24,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:24,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:24,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:24,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:43:24,991] {scheduler_job.py:146} INFO - Started process (PID=8438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:29,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:30,000] {logging_mixin.py:95} INFO - [2019-08-28 13:43:30,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:30,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:30,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:30,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:30,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:43:30,447] {scheduler_job.py:146} INFO - Started process (PID=8443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:35,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:35,454] {logging_mixin.py:95} INFO - [2019-08-28 13:43:35,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:35,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:35,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:35,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:35,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:43:35,900] {scheduler_job.py:146} INFO - Started process (PID=8444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:40,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:40,918] {logging_mixin.py:95} INFO - [2019-08-28 13:43:40,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:41,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:41,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:41,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:41,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:43:41,348] {scheduler_job.py:146} INFO - Started process (PID=8448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:46,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:46,358] {logging_mixin.py:95} INFO - [2019-08-28 13:43:46,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:46,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:46,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:46,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:46,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:43:46,798] {scheduler_job.py:146} INFO - Started process (PID=8450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:51,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:51,810] {logging_mixin.py:95} INFO - [2019-08-28 13:43:51,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:52,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:52,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:52,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:52,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:43:52,253] {scheduler_job.py:146} INFO - Started process (PID=8453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:57,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:43:57,261] {logging_mixin.py:95} INFO - [2019-08-28 13:43:57,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:57,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:43:57,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:43:57,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:43:57,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 13:43:57,705] {scheduler_job.py:146} INFO - Started process (PID=8458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:02,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:02,724] {logging_mixin.py:95} INFO - [2019-08-28 13:44:02,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:03,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:03,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:03,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:03,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-28 13:44:03,265] {scheduler_job.py:146} INFO - Started process (PID=8459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:08,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:08,272] {logging_mixin.py:95} INFO - [2019-08-28 13:44:08,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:08,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:08,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:08,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:08,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:44:08,712] {scheduler_job.py:146} INFO - Started process (PID=8460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:13,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:13,719] {logging_mixin.py:95} INFO - [2019-08-28 13:44:13,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:14,087] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:14,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:14,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:14,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:44:14,155] {scheduler_job.py:146} INFO - Started process (PID=8462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:19,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:19,166] {logging_mixin.py:95} INFO - [2019-08-28 13:44:19,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:19,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:19,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:19,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:19,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:44:19,696] {scheduler_job.py:146} INFO - Started process (PID=8467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:24,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:24,702] {logging_mixin.py:95} INFO - [2019-08-28 13:44:24,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:25,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:25,111] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:25,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:25,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:44:25,151] {scheduler_job.py:146} INFO - Started process (PID=8471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:30,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:30,160] {logging_mixin.py:95} INFO - [2019-08-28 13:44:30,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:30,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:30,566] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:30,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:30,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:44:30,605] {scheduler_job.py:146} INFO - Started process (PID=8473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:35,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:35,616] {logging_mixin.py:95} INFO - [2019-08-28 13:44:35,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:35,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:36,009] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:36,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:36,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:44:36,052] {scheduler_job.py:146} INFO - Started process (PID=8474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:41,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:41,068] {logging_mixin.py:95} INFO - [2019-08-28 13:44:41,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:41,453] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:41,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:41,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:41,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:44:41,603] {scheduler_job.py:146} INFO - Started process (PID=8475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:46,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:46,611] {logging_mixin.py:95} INFO - [2019-08-28 13:44:46,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:46,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:47,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:47,028] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:47,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:44:47,144] {scheduler_job.py:146} INFO - Started process (PID=8480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:52,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:52,156] {logging_mixin.py:95} INFO - [2019-08-28 13:44:52,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:52,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:52,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:52,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:52,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 13:44:52,598] {scheduler_job.py:146} INFO - Started process (PID=8482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:57,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:44:57,604] {logging_mixin.py:95} INFO - [2019-08-28 13:44:57,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:57,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:44:58,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:44:58,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:44:58,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:44:58,049] {scheduler_job.py:146} INFO - Started process (PID=8487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:03,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:03,056] {logging_mixin.py:95} INFO - [2019-08-28 13:45:03,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:03,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:03,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:03,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:03,486] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 13:45:03,601] {scheduler_job.py:146} INFO - Started process (PID=8488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:08,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:08,608] {logging_mixin.py:95} INFO - [2019-08-28 13:45:08,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:08,974] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:08,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:09,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:09,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:45:09,043] {scheduler_job.py:146} INFO - Started process (PID=8489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:14,050] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:14,051] {logging_mixin.py:95} INFO - [2019-08-28 13:45:14,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:14,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:14,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:14,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:14,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 13:45:14,492] {scheduler_job.py:146} INFO - Started process (PID=8494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:19,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:19,499] {logging_mixin.py:95} INFO - [2019-08-28 13:45:19,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:19,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:19,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:19,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:19,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:45:19,932] {scheduler_job.py:146} INFO - Started process (PID=8495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:24,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:24,940] {logging_mixin.py:95} INFO - [2019-08-28 13:45:24,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:25,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:25,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:25,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:25,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:45:25,379] {scheduler_job.py:146} INFO - Started process (PID=8497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:30,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:30,385] {logging_mixin.py:95} INFO - [2019-08-28 13:45:30,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:30,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:30,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:30,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:30,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-28 13:45:30,932] {scheduler_job.py:146} INFO - Started process (PID=8501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:35,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:35,940] {logging_mixin.py:95} INFO - [2019-08-28 13:45:35,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:36,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:36,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:36,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:36,339] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:45:36,386] {scheduler_job.py:146} INFO - Started process (PID=8505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:41,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:41,409] {logging_mixin.py:95} INFO - [2019-08-28 13:45:41,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:41,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:41,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:41,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:41,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 13:45:41,843] {scheduler_job.py:146} INFO - Started process (PID=8506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:46,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:46,855] {logging_mixin.py:95} INFO - [2019-08-28 13:45:46,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:47,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:47,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:47,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:47,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:45:47,305] {scheduler_job.py:146} INFO - Started process (PID=8511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:52,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:52,314] {logging_mixin.py:95} INFO - [2019-08-28 13:45:52,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:52,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:52,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:52,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:52,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 13:45:52,770] {scheduler_job.py:146} INFO - Started process (PID=8512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:57,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:45:57,777] {logging_mixin.py:95} INFO - [2019-08-28 13:45:57,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:58,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:45:58,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:45:58,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:45:58,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:45:58,219] {scheduler_job.py:146} INFO - Started process (PID=8515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:03,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:03,226] {logging_mixin.py:95} INFO - [2019-08-28 13:46:03,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:03,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:03,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:03,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:03,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:46:03,681] {scheduler_job.py:146} INFO - Started process (PID=8516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:08,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:08,688] {logging_mixin.py:95} INFO - [2019-08-28 13:46:08,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:09,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:09,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:09,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:09,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:46:09,143] {scheduler_job.py:146} INFO - Started process (PID=8520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:14,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:14,154] {logging_mixin.py:95} INFO - [2019-08-28 13:46:14,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:14,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:14,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:14,535] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:14,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:46:14,600] {scheduler_job.py:146} INFO - Started process (PID=8522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:19,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:19,610] {logging_mixin.py:95} INFO - [2019-08-28 13:46:19,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:19,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:20,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:20,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:20,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:46:20,050] {scheduler_job.py:146} INFO - Started process (PID=8526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:25,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:25,059] {logging_mixin.py:95} INFO - [2019-08-28 13:46:25,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:25,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:25,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:25,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:25,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:46:25,511] {scheduler_job.py:146} INFO - Started process (PID=8528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:30,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:30,519] {logging_mixin.py:95} INFO - [2019-08-28 13:46:30,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:30,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:30,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:30,932] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:30,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:46:30,960] {scheduler_job.py:146} INFO - Started process (PID=8530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:35,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:35,967] {logging_mixin.py:95} INFO - [2019-08-28 13:46:35,967] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:36,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:36,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:36,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:36,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:46:36,418] {scheduler_job.py:146} INFO - Started process (PID=8531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:41,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:41,427] {logging_mixin.py:95} INFO - [2019-08-28 13:46:41,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:41,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:41,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:41,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:41,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:46:41,888] {scheduler_job.py:146} INFO - Started process (PID=8535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:46,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:46,899] {logging_mixin.py:95} INFO - [2019-08-28 13:46:46,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:47,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:47,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:47,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:47,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:46:47,352] {scheduler_job.py:146} INFO - Started process (PID=8537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:52,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:52,360] {logging_mixin.py:95} INFO - [2019-08-28 13:46:52,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:52,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:52,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:52,755] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:52,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:46:52,796] {scheduler_job.py:146} INFO - Started process (PID=8541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:57,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:46:57,803] {logging_mixin.py:95} INFO - [2019-08-28 13:46:57,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:58,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:46:58,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:46:58,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:46:58,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 13:46:58,353] {scheduler_job.py:146} INFO - Started process (PID=8545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:03,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:03,361] {logging_mixin.py:95} INFO - [2019-08-28 13:47:03,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:03,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:03,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:03,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:03,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:47:03,811] {scheduler_job.py:146} INFO - Started process (PID=8547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:08,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:08,820] {logging_mixin.py:95} INFO - [2019-08-28 13:47:08,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:09,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:09,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:09,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:09,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 13:47:09,253] {scheduler_job.py:146} INFO - Started process (PID=8553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:14,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:14,264] {logging_mixin.py:95} INFO - [2019-08-28 13:47:14,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:14,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:14,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:14,677] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:14,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:47:14,708] {scheduler_job.py:146} INFO - Started process (PID=8555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:19,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:19,719] {logging_mixin.py:95} INFO - [2019-08-28 13:47:19,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:20,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:20,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:20,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:20,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:47:20,156] {scheduler_job.py:146} INFO - Started process (PID=8559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:25,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:25,167] {logging_mixin.py:95} INFO - [2019-08-28 13:47:25,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:25,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:25,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:25,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:25,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:47:25,608] {scheduler_job.py:146} INFO - Started process (PID=8560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:30,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:30,618] {logging_mixin.py:95} INFO - [2019-08-28 13:47:30,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:30,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:30,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:30,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:31,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:47:31,054] {scheduler_job.py:146} INFO - Started process (PID=8566) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:36,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:36,062] {logging_mixin.py:95} INFO - [2019-08-28 13:47:36,062] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:36,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:36,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:36,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:36,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:47:36,606] {scheduler_job.py:146} INFO - Started process (PID=8567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:41,617] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:41,629] {logging_mixin.py:95} INFO - [2019-08-28 13:47:41,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:41,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:42,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:42,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:42,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 13:47:42,057] {scheduler_job.py:146} INFO - Started process (PID=8568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:47,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:47,069] {logging_mixin.py:95} INFO - [2019-08-28 13:47:47,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:47,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:47,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:47,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:47,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:47:47,513] {scheduler_job.py:146} INFO - Started process (PID=8573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:52,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:52,520] {logging_mixin.py:95} INFO - [2019-08-28 13:47:52,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:52,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:52,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:52,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:52,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:47:52,965] {scheduler_job.py:146} INFO - Started process (PID=8577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:57,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:47:57,977] {logging_mixin.py:95} INFO - [2019-08-28 13:47:57,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:58,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:47:58,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:47:58,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:47:58,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:47:58,425] {scheduler_job.py:146} INFO - Started process (PID=8579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:03,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:03,433] {logging_mixin.py:95} INFO - [2019-08-28 13:48:03,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:03,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:03,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:03,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:03,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:48:03,883] {scheduler_job.py:146} INFO - Started process (PID=8581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:08,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:08,894] {logging_mixin.py:95} INFO - [2019-08-28 13:48:08,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:09,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:09,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:09,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:09,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:48:09,347] {scheduler_job.py:146} INFO - Started process (PID=8582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:14,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:14,360] {logging_mixin.py:95} INFO - [2019-08-28 13:48:14,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:14,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:14,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:14,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:14,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:48:14,809] {scheduler_job.py:146} INFO - Started process (PID=8587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:19,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:19,819] {logging_mixin.py:95} INFO - [2019-08-28 13:48:19,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:20,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:20,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:20,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:20,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:48:20,265] {scheduler_job.py:146} INFO - Started process (PID=8588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:25,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:25,275] {logging_mixin.py:95} INFO - [2019-08-28 13:48:25,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:25,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:25,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:25,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:25,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:48:25,721] {scheduler_job.py:146} INFO - Started process (PID=8592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:30,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:30,732] {logging_mixin.py:95} INFO - [2019-08-28 13:48:30,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:31,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:31,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:31,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:31,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 13:48:31,171] {scheduler_job.py:146} INFO - Started process (PID=8594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:36,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:36,179] {logging_mixin.py:95} INFO - [2019-08-28 13:48:36,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:36,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:36,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:36,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:36,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:48:36,626] {scheduler_job.py:146} INFO - Started process (PID=8596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:41,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:41,634] {logging_mixin.py:95} INFO - [2019-08-28 13:48:41,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:42,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:42,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:42,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:42,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 13:48:42,078] {scheduler_job.py:146} INFO - Started process (PID=8599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:47,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:47,087] {logging_mixin.py:95} INFO - [2019-08-28 13:48:47,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:47,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:47,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:47,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:47,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:48:47,528] {scheduler_job.py:146} INFO - Started process (PID=8604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:52,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:52,539] {logging_mixin.py:95} INFO - [2019-08-28 13:48:52,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:52,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:52,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:52,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:52,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:48:52,975] {scheduler_job.py:146} INFO - Started process (PID=8605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:57,982] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:48:57,983] {logging_mixin.py:95} INFO - [2019-08-28 13:48:57,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:58,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:48:58,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:48:58,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:48:58,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 13:48:58,426] {scheduler_job.py:146} INFO - Started process (PID=8607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:03,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:03,433] {logging_mixin.py:95} INFO - [2019-08-28 13:49:03,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:03,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:03,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:03,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:03,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 13:49:03,876] {scheduler_job.py:146} INFO - Started process (PID=8612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:08,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:08,885] {logging_mixin.py:95} INFO - [2019-08-28 13:49:08,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:09,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:09,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:09,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:09,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 13:49:09,328] {scheduler_job.py:146} INFO - Started process (PID=8613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:14,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:14,341] {logging_mixin.py:95} INFO - [2019-08-28 13:49:14,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:14,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:14,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:14,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:14,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:49:14,783] {scheduler_job.py:146} INFO - Started process (PID=8618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:19,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:19,791] {logging_mixin.py:95} INFO - [2019-08-28 13:49:19,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:20,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:20,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:20,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:20,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:49:20,231] {scheduler_job.py:146} INFO - Started process (PID=8619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:25,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:25,243] {logging_mixin.py:95} INFO - [2019-08-28 13:49:25,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:25,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:25,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:25,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:25,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:49:25,681] {scheduler_job.py:146} INFO - Started process (PID=8620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:30,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:30,690] {logging_mixin.py:95} INFO - [2019-08-28 13:49:30,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:31,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:31,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:31,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:31,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:49:31,138] {scheduler_job.py:146} INFO - Started process (PID=8625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:36,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:36,147] {logging_mixin.py:95} INFO - [2019-08-28 13:49:36,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:36,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:36,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:36,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:36,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 13:49:36,600] {scheduler_job.py:146} INFO - Started process (PID=8627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:41,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:41,618] {logging_mixin.py:95} INFO - [2019-08-28 13:49:41,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:42,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:42,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:42,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:42,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 13:49:42,058] {scheduler_job.py:146} INFO - Started process (PID=8628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:47,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:47,065] {logging_mixin.py:95} INFO - [2019-08-28 13:49:47,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:47,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:47,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:47,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:47,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 13:49:47,515] {scheduler_job.py:146} INFO - Started process (PID=8633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:52,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:52,526] {logging_mixin.py:95} INFO - [2019-08-28 13:49:52,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:52,875] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:52,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:52,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:52,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:49:52,969] {scheduler_job.py:146} INFO - Started process (PID=8634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:57,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:49:57,981] {logging_mixin.py:95} INFO - [2019-08-28 13:49:57,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:58,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:49:58,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:49:58,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:49:58,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:49:58,434] {scheduler_job.py:146} INFO - Started process (PID=8636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:03,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:03,442] {logging_mixin.py:95} INFO - [2019-08-28 13:50:03,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:03,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:03,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:03,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:03,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:50:03,891] {scheduler_job.py:146} INFO - Started process (PID=8640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:08,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:08,904] {logging_mixin.py:95} INFO - [2019-08-28 13:50:08,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:09,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:09,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:09,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:09,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:50:09,344] {scheduler_job.py:146} INFO - Started process (PID=8642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:14,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:14,353] {logging_mixin.py:95} INFO - [2019-08-28 13:50:14,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:14,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:14,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:14,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:14,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:50:14,810] {scheduler_job.py:146} INFO - Started process (PID=8644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:19,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:19,823] {logging_mixin.py:95} INFO - [2019-08-28 13:50:19,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:20,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:20,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:20,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:20,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:50:20,271] {scheduler_job.py:146} INFO - Started process (PID=8645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:25,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:25,279] {logging_mixin.py:95} INFO - [2019-08-28 13:50:25,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:25,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:25,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:25,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:25,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 13:50:25,730] {scheduler_job.py:146} INFO - Started process (PID=8649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:30,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:30,743] {logging_mixin.py:95} INFO - [2019-08-28 13:50:30,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:31,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:31,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:31,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:31,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:50:31,185] {scheduler_job.py:146} INFO - Started process (PID=8651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:36,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:36,193] {logging_mixin.py:95} INFO - [2019-08-28 13:50:36,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:36,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:36,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:36,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:36,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 13:50:36,649] {scheduler_job.py:146} INFO - Started process (PID=8655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:41,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:41,675] {logging_mixin.py:95} INFO - [2019-08-28 13:50:41,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:42,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:42,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:42,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:42,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 13:50:42,106] {scheduler_job.py:146} INFO - Started process (PID=8657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:47,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:47,114] {logging_mixin.py:95} INFO - [2019-08-28 13:50:47,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:47,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:47,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:47,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:47,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:50:47,569] {scheduler_job.py:146} INFO - Started process (PID=8659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:52,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:52,578] {logging_mixin.py:95} INFO - [2019-08-28 13:50:52,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:52,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:52,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:52,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:52,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 13:50:53,029] {scheduler_job.py:146} INFO - Started process (PID=8660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:58,041] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:50:58,042] {logging_mixin.py:95} INFO - [2019-08-28 13:50:58,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:58,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:50:58,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:50:58,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:50:58,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 13:50:58,481] {scheduler_job.py:146} INFO - Started process (PID=8665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:03,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:03,490] {logging_mixin.py:95} INFO - [2019-08-28 13:51:03,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:03,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:03,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:03,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:03,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 13:51:03,940] {scheduler_job.py:146} INFO - Started process (PID=8666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:08,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:08,950] {logging_mixin.py:95} INFO - [2019-08-28 13:51:08,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:09,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:09,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:09,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:09,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:51:09,389] {scheduler_job.py:146} INFO - Started process (PID=8671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:14,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:14,401] {logging_mixin.py:95} INFO - [2019-08-28 13:51:14,401] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:14,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:14,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:14,779] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:14,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:51:14,854] {scheduler_job.py:146} INFO - Started process (PID=8673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:19,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:19,867] {logging_mixin.py:95} INFO - [2019-08-28 13:51:19,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:20,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:20,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:20,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:20,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:51:20,314] {scheduler_job.py:146} INFO - Started process (PID=8674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:25,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:25,327] {logging_mixin.py:95} INFO - [2019-08-28 13:51:25,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:25,675] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:25,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:25,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:25,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:51:25,774] {scheduler_job.py:146} INFO - Started process (PID=8675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:30,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:30,784] {logging_mixin.py:95} INFO - [2019-08-28 13:51:30,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:31,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:31,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:31,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:31,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:51:31,225] {scheduler_job.py:146} INFO - Started process (PID=8680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:36,233] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:36,234] {logging_mixin.py:95} INFO - [2019-08-28 13:51:36,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:36,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:36,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:36,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:36,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 13:51:36,686] {scheduler_job.py:146} INFO - Started process (PID=8684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:41,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:41,701] {logging_mixin.py:95} INFO - [2019-08-28 13:51:41,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:42,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:42,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:42,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:42,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-08-28 13:51:42,244] {scheduler_job.py:146} INFO - Started process (PID=8689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:47,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:47,256] {logging_mixin.py:95} INFO - [2019-08-28 13:51:47,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:47,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:47,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:47,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:47,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 13:51:47,701] {scheduler_job.py:146} INFO - Started process (PID=8691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:52,708] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:52,709] {logging_mixin.py:95} INFO - [2019-08-28 13:51:52,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:53,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:53,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:53,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:53,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 13:51:53,161] {scheduler_job.py:146} INFO - Started process (PID=8692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:58,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:51:58,172] {logging_mixin.py:95} INFO - [2019-08-28 13:51:58,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:58,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:51:58,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:51:58,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:51:58,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:51:58,616] {scheduler_job.py:146} INFO - Started process (PID=8697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:03,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:03,625] {logging_mixin.py:95} INFO - [2019-08-28 13:52:03,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:04,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:04,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:04,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:04,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:52:04,067] {scheduler_job.py:146} INFO - Started process (PID=8703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:09,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:09,075] {logging_mixin.py:95} INFO - [2019-08-28 13:52:09,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:09,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:09,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:09,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:09,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:52:09,516] {scheduler_job.py:146} INFO - Started process (PID=8707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:14,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:14,527] {logging_mixin.py:95} INFO - [2019-08-28 13:52:14,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:14,897] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:14,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:14,927] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:14,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:52:14,961] {scheduler_job.py:146} INFO - Started process (PID=8712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:19,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:19,972] {logging_mixin.py:95} INFO - [2019-08-28 13:52:19,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:20,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:20,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:20,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:20,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:52:20,411] {scheduler_job.py:146} INFO - Started process (PID=8713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:25,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:25,423] {logging_mixin.py:95} INFO - [2019-08-28 13:52:25,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:25,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:25,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:25,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:25,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:52:25,964] {scheduler_job.py:146} INFO - Started process (PID=8714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:30,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:30,975] {logging_mixin.py:95} INFO - [2019-08-28 13:52:30,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:31,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:31,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:31,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:31,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 13:52:31,414] {scheduler_job.py:146} INFO - Started process (PID=8719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:36,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:36,427] {logging_mixin.py:95} INFO - [2019-08-28 13:52:36,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:36,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:36,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:36,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:36,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 13:52:36,869] {scheduler_job.py:146} INFO - Started process (PID=8720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:41,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:41,878] {logging_mixin.py:95} INFO - [2019-08-28 13:52:41,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:42,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:42,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:42,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:42,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:52:42,329] {scheduler_job.py:146} INFO - Started process (PID=8721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:47,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:47,338] {logging_mixin.py:95} INFO - [2019-08-28 13:52:47,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:47,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:47,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:47,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:47,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:52:47,779] {scheduler_job.py:146} INFO - Started process (PID=8727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:52,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:52,792] {logging_mixin.py:95} INFO - [2019-08-28 13:52:52,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:53,136] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:53,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:53,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:53,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:52:53,242] {scheduler_job.py:146} INFO - Started process (PID=8728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:58,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:52:58,251] {logging_mixin.py:95} INFO - [2019-08-28 13:52:58,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:58,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:52:58,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:52:58,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:52:58,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 13:52:58,797] {scheduler_job.py:146} INFO - Started process (PID=8733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:03,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:03,806] {logging_mixin.py:95} INFO - [2019-08-28 13:53:03,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:04,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:04,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:04,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:04,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:53:04,256] {scheduler_job.py:146} INFO - Started process (PID=8734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:09,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:09,265] {logging_mixin.py:95} INFO - [2019-08-28 13:53:09,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:09,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:09,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:09,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:09,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:53:09,713] {scheduler_job.py:146} INFO - Started process (PID=8735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:14,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:14,725] {logging_mixin.py:95} INFO - [2019-08-28 13:53:14,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:15,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:15,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:15,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:15,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 13:53:15,163] {scheduler_job.py:146} INFO - Started process (PID=8738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:20,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:20,172] {logging_mixin.py:95} INFO - [2019-08-28 13:53:20,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:20,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:20,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:20,548] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:20,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 13:53:20,627] {scheduler_job.py:146} INFO - Started process (PID=8742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:25,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:25,636] {logging_mixin.py:95} INFO - [2019-08-28 13:53:25,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:25,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:26,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:26,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:26,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 13:53:26,083] {scheduler_job.py:146} INFO - Started process (PID=8743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:31,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:31,091] {logging_mixin.py:95} INFO - [2019-08-28 13:53:31,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:31,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:31,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:31,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:31,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:53:31,534] {scheduler_job.py:146} INFO - Started process (PID=8748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:36,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:36,541] {logging_mixin.py:95} INFO - [2019-08-28 13:53:36,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:36,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:36,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:36,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:36,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 13:53:36,983] {scheduler_job.py:146} INFO - Started process (PID=8749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:41,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:41,992] {logging_mixin.py:95} INFO - [2019-08-28 13:53:41,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:42,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:42,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:42,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:42,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 13:53:42,426] {scheduler_job.py:146} INFO - Started process (PID=8751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:47,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:47,438] {logging_mixin.py:95} INFO - [2019-08-28 13:53:47,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:48,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:48,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:48,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:48,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.708 seconds
[2019-08-28 13:53:48,181] {scheduler_job.py:146} INFO - Started process (PID=8757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:53,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:53,190] {logging_mixin.py:95} INFO - [2019-08-28 13:53:53,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:53,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:53,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:53,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:53,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 13:53:53,622] {scheduler_job.py:146} INFO - Started process (PID=8761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:58,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:53:58,632] {logging_mixin.py:95} INFO - [2019-08-28 13:53:58,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:59,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:53:59,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:53:59,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:53:59,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 13:53:59,069] {scheduler_job.py:146} INFO - Started process (PID=8763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:04,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:04,075] {logging_mixin.py:95} INFO - [2019-08-28 13:54:04,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:04,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:04,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:04,507] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:04,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 13:54:04,618] {scheduler_job.py:146} INFO - Started process (PID=8767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:09,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:09,625] {logging_mixin.py:95} INFO - [2019-08-28 13:54:09,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:10,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:10,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:10,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:10,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 13:54:10,169] {scheduler_job.py:146} INFO - Started process (PID=8768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:15,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:15,177] {logging_mixin.py:95} INFO - [2019-08-28 13:54:15,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:15,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:15,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:15,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:15,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:54:15,621] {scheduler_job.py:146} INFO - Started process (PID=8772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:20,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:20,631] {logging_mixin.py:95} INFO - [2019-08-28 13:54:20,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:21,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:21,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:21,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:21,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 13:54:21,067] {scheduler_job.py:146} INFO - Started process (PID=8774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:26,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:26,075] {logging_mixin.py:95} INFO - [2019-08-28 13:54:26,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:26,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:26,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:26,487] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:26,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 13:54:26,518] {scheduler_job.py:146} INFO - Started process (PID=8778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:31,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:31,528] {logging_mixin.py:95} INFO - [2019-08-28 13:54:31,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:31,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:31,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:31,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:31,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 13:54:31,969] {scheduler_job.py:146} INFO - Started process (PID=8780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:36,975] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:36,976] {logging_mixin.py:95} INFO - [2019-08-28 13:54:36,975] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:37,338] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:37,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:37,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:37,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 13:54:37,424] {scheduler_job.py:146} INFO - Started process (PID=8784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:42,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:42,434] {logging_mixin.py:95} INFO - [2019-08-28 13:54:42,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:42,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:42,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:42,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:42,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 13:54:42,882] {scheduler_job.py:146} INFO - Started process (PID=8786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:47,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:47,890] {logging_mixin.py:95} INFO - [2019-08-28 13:54:47,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:48,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:48,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:48,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:48,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 13:54:48,348] {scheduler_job.py:146} INFO - Started process (PID=8787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:53,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:53,358] {logging_mixin.py:95} INFO - [2019-08-28 13:54:53,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:53,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:53,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:53,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:53,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 13:54:53,804] {scheduler_job.py:146} INFO - Started process (PID=8796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:58,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:54:58,810] {logging_mixin.py:95} INFO - [2019-08-28 13:54:58,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:59,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:54:59,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:54:59,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:54:59,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 13:54:59,262] {scheduler_job.py:146} INFO - Started process (PID=8798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:04,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:04,268] {logging_mixin.py:95} INFO - [2019-08-28 13:55:04,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:04,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:04,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:04,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:04,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 13:55:04,717] {scheduler_job.py:146} INFO - Started process (PID=8802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:09,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:09,729] {logging_mixin.py:95} INFO - [2019-08-28 13:55:09,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:10,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:10,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:10,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:10,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-08-28 13:55:10,267] {scheduler_job.py:146} INFO - Started process (PID=8804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:15,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:15,276] {logging_mixin.py:95} INFO - [2019-08-28 13:55:15,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:15,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:15,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:15,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:15,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 13:55:15,806] {scheduler_job.py:146} INFO - Started process (PID=8806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:20,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:20,812] {logging_mixin.py:95} INFO - [2019-08-28 13:55:20,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:21,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:21,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:21,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:21,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 13:55:21,254] {scheduler_job.py:146} INFO - Started process (PID=8811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:26,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:26,265] {logging_mixin.py:95} INFO - [2019-08-28 13:55:26,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:26,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:26,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:26,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:26,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:55:26,804] {scheduler_job.py:146} INFO - Started process (PID=8812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:31,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:31,814] {logging_mixin.py:95} INFO - [2019-08-28 13:55:31,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:32,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:32,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:32,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:32,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:55:32,339] {scheduler_job.py:146} INFO - Started process (PID=8814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:37,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:37,346] {logging_mixin.py:95} INFO - [2019-08-28 13:55:37,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:37,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:37,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:37,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:37,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:55:37,870] {scheduler_job.py:146} INFO - Started process (PID=8815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:42,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:42,877] {logging_mixin.py:95} INFO - [2019-08-28 13:55:42,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:43,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:43,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:43,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:43,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 13:55:43,413] {scheduler_job.py:146} INFO - Started process (PID=8817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:48,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:48,424] {logging_mixin.py:95} INFO - [2019-08-28 13:55:48,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:48,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:48,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:48,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:48,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:55:48,951] {scheduler_job.py:146} INFO - Started process (PID=8821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:53,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:53,961] {logging_mixin.py:95} INFO - [2019-08-28 13:55:53,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:54,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:54,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:54,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:54,409] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-08-28 13:55:54,494] {scheduler_job.py:146} INFO - Started process (PID=8826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:59,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:55:59,502] {logging_mixin.py:95} INFO - [2019-08-28 13:55:59,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:59,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:55:59,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:55:59,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:55:59,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 13:56:00,044] {scheduler_job.py:146} INFO - Started process (PID=8828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:05,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:05,053] {logging_mixin.py:95} INFO - [2019-08-28 13:56:05,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:05,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:05,461] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:05,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:05,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 13:56:05,584] {scheduler_job.py:146} INFO - Started process (PID=8829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:10,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:10,591] {logging_mixin.py:95} INFO - [2019-08-28 13:56:10,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:11,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:11,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:11,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:11,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-08-28 13:56:11,128] {scheduler_job.py:146} INFO - Started process (PID=8830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:16,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:16,136] {logging_mixin.py:95} INFO - [2019-08-28 13:56:16,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:16,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:16,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:16,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:16,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-08-28 13:56:16,661] {scheduler_job.py:146} INFO - Started process (PID=8835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:21,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:21,668] {logging_mixin.py:95} INFO - [2019-08-28 13:56:21,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:22,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:22,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:22,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:22,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 13:56:22,197] {scheduler_job.py:146} INFO - Started process (PID=8836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:27,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:27,212] {logging_mixin.py:95} INFO - [2019-08-28 13:56:27,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:27,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:27,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:27,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:27,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 13:56:27,735] {scheduler_job.py:146} INFO - Started process (PID=8842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:32,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:32,744] {logging_mixin.py:95} INFO - [2019-08-28 13:56:32,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:33,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:33,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:33,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:33,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 13:56:33,282] {scheduler_job.py:146} INFO - Started process (PID=8843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:38,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:38,291] {logging_mixin.py:95} INFO - [2019-08-28 13:56:38,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:38,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:38,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:38,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:38,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-08-28 13:56:38,822] {scheduler_job.py:146} INFO - Started process (PID=8847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:43,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:43,828] {logging_mixin.py:95} INFO - [2019-08-28 13:56:43,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:44,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:44,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:44,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:44,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-28 13:56:44,366] {scheduler_job.py:146} INFO - Started process (PID=8849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:49,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:49,376] {logging_mixin.py:95} INFO - [2019-08-28 13:56:49,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:49,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:49,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:49,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:49,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-08-28 13:56:49,904] {scheduler_job.py:146} INFO - Started process (PID=8850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:54,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:56:54,910] {logging_mixin.py:95} INFO - [2019-08-28 13:56:54,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:55,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:56:55,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:56:55,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:56:55,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 13:56:55,436] {scheduler_job.py:146} INFO - Started process (PID=8855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:00,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:00,446] {logging_mixin.py:95} INFO - [2019-08-28 13:57:00,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:00,907] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:00,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:00,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:00,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.511 seconds
[2019-08-28 13:57:00,977] {scheduler_job.py:146} INFO - Started process (PID=8857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:05,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:05,985] {logging_mixin.py:95} INFO - [2019-08-28 13:57:05,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:06,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:06,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:06,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:06,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:57:06,510] {scheduler_job.py:146} INFO - Started process (PID=8858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:11,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:11,521] {logging_mixin.py:95} INFO - [2019-08-28 13:57:11,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:11,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:11,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:11,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:11,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 13:57:12,048] {scheduler_job.py:146} INFO - Started process (PID=8859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:17,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:17,057] {logging_mixin.py:95} INFO - [2019-08-28 13:57:17,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:17,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:17,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:17,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:17,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 13:57:17,586] {scheduler_job.py:146} INFO - Started process (PID=8864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:22,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:22,597] {logging_mixin.py:95} INFO - [2019-08-28 13:57:22,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:22,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:23,005] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:23,016] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:23,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 13:57:23,135] {scheduler_job.py:146} INFO - Started process (PID=8865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:28,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:28,144] {logging_mixin.py:95} INFO - [2019-08-28 13:57:28,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:28,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:28,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:28,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:28,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 13:57:28,672] {scheduler_job.py:146} INFO - Started process (PID=8869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:33,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:33,681] {logging_mixin.py:95} INFO - [2019-08-28 13:57:33,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:34,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:34,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:34,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:34,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:57:34,215] {scheduler_job.py:146} INFO - Started process (PID=8872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:39,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:39,223] {logging_mixin.py:95} INFO - [2019-08-28 13:57:39,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:39,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:39,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:39,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:39,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:57:39,765] {scheduler_job.py:146} INFO - Started process (PID=8873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:44,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:44,773] {logging_mixin.py:95} INFO - [2019-08-28 13:57:44,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:45,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:45,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:45,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:45,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-08-28 13:57:45,306] {scheduler_job.py:146} INFO - Started process (PID=8878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:50,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:50,314] {logging_mixin.py:95} INFO - [2019-08-28 13:57:50,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:50,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:50,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:50,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:50,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-08-28 13:57:50,841] {scheduler_job.py:146} INFO - Started process (PID=8879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:55,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:57:55,850] {logging_mixin.py:95} INFO - [2019-08-28 13:57:55,850] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:56,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:57:56,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:57:56,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:57:56,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-08-28 13:57:56,375] {scheduler_job.py:146} INFO - Started process (PID=8880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:01,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:01,382] {logging_mixin.py:95} INFO - [2019-08-28 13:58:01,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:01,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:01,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:01,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:01,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 13:58:01,910] {scheduler_job.py:146} INFO - Started process (PID=8886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:06,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:06,916] {logging_mixin.py:95} INFO - [2019-08-28 13:58:06,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:07,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:07,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:07,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:07,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 13:58:07,453] {scheduler_job.py:146} INFO - Started process (PID=8887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:12,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:12,460] {logging_mixin.py:95} INFO - [2019-08-28 13:58:12,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:12,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:12,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:12,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:12,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 13:58:12,999] {scheduler_job.py:146} INFO - Started process (PID=8889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:18,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:18,009] {logging_mixin.py:95} INFO - [2019-08-28 13:58:18,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:18,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:18,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:18,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:18,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 13:58:18,537] {scheduler_job.py:146} INFO - Started process (PID=8890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:23,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:23,544] {logging_mixin.py:95} INFO - [2019-08-28 13:58:23,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:23,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:23,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:23,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:23,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 13:58:24,086] {scheduler_job.py:146} INFO - Started process (PID=8894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:29,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:29,093] {logging_mixin.py:95} INFO - [2019-08-28 13:58:29,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:29,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:29,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:29,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:29,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 13:58:29,634] {scheduler_job.py:146} INFO - Started process (PID=8896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:34,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:34,641] {logging_mixin.py:95} INFO - [2019-08-28 13:58:34,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:35,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:35,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:35,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:35,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-08-28 13:58:35,174] {scheduler_job.py:146} INFO - Started process (PID=8898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:40,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:40,181] {logging_mixin.py:95} INFO - [2019-08-28 13:58:40,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:40,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:40,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:40,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:40,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 13:58:40,717] {scheduler_job.py:146} INFO - Started process (PID=8902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:45,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:45,727] {logging_mixin.py:95} INFO - [2019-08-28 13:58:45,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:46,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:46,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:46,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:46,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 13:58:46,258] {scheduler_job.py:146} INFO - Started process (PID=8904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:51,268] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:51,270] {logging_mixin.py:95} INFO - [2019-08-28 13:58:51,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:51,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:51,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:51,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:51,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 13:58:51,703] {scheduler_job.py:146} INFO - Started process (PID=8908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:56,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:58:56,710] {logging_mixin.py:95} INFO - [2019-08-28 13:58:56,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:57,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:58:57,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:58:57,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:58:57,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 13:58:57,247] {scheduler_job.py:146} INFO - Started process (PID=8909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:02,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:02,256] {logging_mixin.py:95} INFO - [2019-08-28 13:59:02,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:02,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:02,745] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:02,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:02,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-08-28 13:59:02,792] {scheduler_job.py:146} INFO - Started process (PID=8912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:07,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:07,804] {logging_mixin.py:95} INFO - [2019-08-28 13:59:07,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:08,215] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:08,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:08,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:08,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-08-28 13:59:08,333] {scheduler_job.py:146} INFO - Started process (PID=8913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:13,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:13,341] {logging_mixin.py:95} INFO - [2019-08-28 13:59:13,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:13,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:13,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:13,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:13,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 13:59:13,882] {scheduler_job.py:146} INFO - Started process (PID=8918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:18,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:18,891] {logging_mixin.py:95} INFO - [2019-08-28 13:59:18,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:19,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:19,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:19,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:19,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-08-28 13:59:19,428] {scheduler_job.py:146} INFO - Started process (PID=8922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:24,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:24,439] {logging_mixin.py:95} INFO - [2019-08-28 13:59:24,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:24,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:24,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:24,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:24,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:59:24,972] {scheduler_job.py:146} INFO - Started process (PID=8923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:29,979] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:29,980] {logging_mixin.py:95} INFO - [2019-08-28 13:59:29,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:30,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:30,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:30,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:30,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-28 13:59:30,514] {scheduler_job.py:146} INFO - Started process (PID=8925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:35,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:35,523] {logging_mixin.py:95} INFO - [2019-08-28 13:59:35,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:35,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:35,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:35,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:35,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 13:59:36,052] {scheduler_job.py:146} INFO - Started process (PID=8930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:41,058] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:41,059] {logging_mixin.py:95} INFO - [2019-08-28 13:59:41,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:41,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:41,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:41,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:41,504] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:59:41,590] {scheduler_job.py:146} INFO - Started process (PID=8931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:46,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:46,600] {logging_mixin.py:95} INFO - [2019-08-28 13:59:46,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:46,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:47,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:47,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:47,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 13:59:47,125] {scheduler_job.py:146} INFO - Started process (PID=8933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:52,134] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:52,135] {logging_mixin.py:95} INFO - [2019-08-28 13:59:52,135] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:52,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:52,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:52,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:52,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 13:59:52,663] {scheduler_job.py:146} INFO - Started process (PID=8937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:57,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 13:59:57,672] {logging_mixin.py:95} INFO - [2019-08-28 13:59:57,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:58,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 13:59:58,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 13:59:58,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 13:59:58,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 13:59:58,204] {scheduler_job.py:146} INFO - Started process (PID=8939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:03,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:03,211] {logging_mixin.py:95} INFO - [2019-08-28 14:00:03,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:03,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:03,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:03,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:03,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 14:00:03,741] {scheduler_job.py:146} INFO - Started process (PID=8940) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:08,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:08,753] {logging_mixin.py:95} INFO - [2019-08-28 14:00:08,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:09,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:09,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:09,181] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:09,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 14:00:09,279] {scheduler_job.py:146} INFO - Started process (PID=8942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:14,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:14,287] {logging_mixin.py:95} INFO - [2019-08-28 14:00:14,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:14,681] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:14,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:14,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:14,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 14:00:14,821] {scheduler_job.py:146} INFO - Started process (PID=8947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:19,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:19,829] {logging_mixin.py:95} INFO - [2019-08-28 14:00:19,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:20,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:20,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:20,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:20,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-08-28 14:00:20,360] {scheduler_job.py:146} INFO - Started process (PID=8948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:25,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:25,370] {logging_mixin.py:95} INFO - [2019-08-28 14:00:25,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:25,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:25,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:25,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:25,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-08-28 14:00:25,904] {scheduler_job.py:146} INFO - Started process (PID=8949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:30,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:30,909] {logging_mixin.py:95} INFO - [2019-08-28 14:00:30,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:31,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:31,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:31,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:31,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 14:00:31,443] {scheduler_job.py:146} INFO - Started process (PID=8954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:36,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:36,448] {logging_mixin.py:95} INFO - [2019-08-28 14:00:36,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:36,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:36,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:36,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:36,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-08-28 14:00:36,984] {scheduler_job.py:146} INFO - Started process (PID=8956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:41,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:42,009] {logging_mixin.py:95} INFO - [2019-08-28 14:00:42,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:42,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:42,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:42,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:42,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 14:00:42,438] {scheduler_job.py:146} INFO - Started process (PID=8960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:47,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:47,446] {logging_mixin.py:95} INFO - [2019-08-28 14:00:47,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:47,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:47,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:47,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:47,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:00:47,890] {scheduler_job.py:146} INFO - Started process (PID=8962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:52,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:52,895] {logging_mixin.py:95} INFO - [2019-08-28 14:00:52,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:53,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:53,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:53,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:53,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-28 14:00:53,439] {scheduler_job.py:146} INFO - Started process (PID=8963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:58,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:00:58,451] {logging_mixin.py:95} INFO - [2019-08-28 14:00:58,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:58,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:00:58,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:00:58,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:00:58,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:00:58,888] {scheduler_job.py:146} INFO - Started process (PID=8968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:03,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:03,897] {logging_mixin.py:95} INFO - [2019-08-28 14:01:03,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:04,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:04,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:04,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:04,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:01:04,344] {scheduler_job.py:146} INFO - Started process (PID=8969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:09,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:09,352] {logging_mixin.py:95} INFO - [2019-08-28 14:01:09,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:09,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:09,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:09,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:09,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:01:09,797] {scheduler_job.py:146} INFO - Started process (PID=8971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:14,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:14,813] {logging_mixin.py:95} INFO - [2019-08-28 14:01:14,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:15,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:15,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:15,273] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:15,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-08-28 14:01:15,354] {scheduler_job.py:146} INFO - Started process (PID=8973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:20,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:20,362] {logging_mixin.py:95} INFO - [2019-08-28 14:01:20,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:20,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:20,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:20,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:20,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 14:01:20,812] {scheduler_job.py:146} INFO - Started process (PID=8977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:25,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:25,824] {logging_mixin.py:95} INFO - [2019-08-28 14:01:25,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:26,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:26,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:26,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:26,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:01:26,267] {scheduler_job.py:146} INFO - Started process (PID=8978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:31,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:31,275] {logging_mixin.py:95} INFO - [2019-08-28 14:01:31,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:31,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:31,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:31,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:31,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:01:31,719] {scheduler_job.py:146} INFO - Started process (PID=8983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:36,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:36,726] {logging_mixin.py:95} INFO - [2019-08-28 14:01:36,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:37,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:37,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:37,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:37,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:01:37,170] {scheduler_job.py:146} INFO - Started process (PID=8984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:42,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:42,178] {logging_mixin.py:95} INFO - [2019-08-28 14:01:42,178] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:42,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:42,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:42,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:42,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:01:42,617] {scheduler_job.py:146} INFO - Started process (PID=8992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:47,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:47,628] {logging_mixin.py:95} INFO - [2019-08-28 14:01:47,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:47,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:47,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:47,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:47,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-08-28 14:01:48,080] {scheduler_job.py:146} INFO - Started process (PID=8994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:53,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:53,087] {logging_mixin.py:95} INFO - [2019-08-28 14:01:53,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:53,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:53,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:53,484] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:53,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:01:53,531] {scheduler_job.py:146} INFO - Started process (PID=8995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:58,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:01:58,543] {logging_mixin.py:95} INFO - [2019-08-28 14:01:58,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:58,897] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:01:58,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:01:58,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:01:58,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:01:58,981] {scheduler_job.py:146} INFO - Started process (PID=8997) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:03,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:03,989] {logging_mixin.py:95} INFO - [2019-08-28 14:02:03,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:04,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:04,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:04,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:04,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:02:04,431] {scheduler_job.py:146} INFO - Started process (PID=9001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:09,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:09,438] {logging_mixin.py:95} INFO - [2019-08-28 14:02:09,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:09,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:09,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:09,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:09,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:02:09,890] {scheduler_job.py:146} INFO - Started process (PID=9002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:14,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:14,900] {logging_mixin.py:95} INFO - [2019-08-28 14:02:14,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:15,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:15,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:15,317] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:15,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:02:15,344] {scheduler_job.py:146} INFO - Started process (PID=9005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:20,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:20,352] {logging_mixin.py:95} INFO - [2019-08-28 14:02:20,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:20,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:20,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:20,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:20,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:02:20,799] {scheduler_job.py:146} INFO - Started process (PID=9006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:25,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:25,809] {logging_mixin.py:95} INFO - [2019-08-28 14:02:25,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:26,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:26,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:26,178] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:26,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 14:02:26,256] {scheduler_job.py:146} INFO - Started process (PID=9010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:31,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:31,264] {logging_mixin.py:95} INFO - [2019-08-28 14:02:31,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:31,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:31,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:31,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:31,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 14:02:31,712] {scheduler_job.py:146} INFO - Started process (PID=9012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:36,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:36,718] {logging_mixin.py:95} INFO - [2019-08-28 14:02:36,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:37,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:37,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:37,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:37,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:02:37,163] {scheduler_job.py:146} INFO - Started process (PID=9016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:42,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:42,173] {logging_mixin.py:95} INFO - [2019-08-28 14:02:42,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:42,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:42,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:42,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:42,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:02:42,618] {scheduler_job.py:146} INFO - Started process (PID=9018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:47,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:47,629] {logging_mixin.py:95} INFO - [2019-08-28 14:02:47,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:48,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:48,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:48,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:48,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-28 14:02:48,167] {scheduler_job.py:146} INFO - Started process (PID=9020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:53,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:53,174] {logging_mixin.py:95} INFO - [2019-08-28 14:02:53,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:53,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:53,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:53,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:53,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:02:53,624] {scheduler_job.py:146} INFO - Started process (PID=9024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:58,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:02:58,633] {logging_mixin.py:95} INFO - [2019-08-28 14:02:58,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:59,012] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:02:59,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:02:59,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:02:59,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:02:59,078] {scheduler_job.py:146} INFO - Started process (PID=9026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:04,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:04,085] {logging_mixin.py:95} INFO - [2019-08-28 14:03:04,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:04,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:04,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:04,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:04,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:03:04,536] {scheduler_job.py:146} INFO - Started process (PID=9027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:09,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:09,543] {logging_mixin.py:95} INFO - [2019-08-28 14:03:09,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:09,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:09,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:09,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:09,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:03:09,985] {scheduler_job.py:146} INFO - Started process (PID=9031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:14,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:14,996] {logging_mixin.py:95} INFO - [2019-08-28 14:03:14,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:15,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:15,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:15,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:15,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:03:15,445] {scheduler_job.py:146} INFO - Started process (PID=9034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:20,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:20,452] {logging_mixin.py:95} INFO - [2019-08-28 14:03:20,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:20,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:20,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:20,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:20,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:03:20,897] {scheduler_job.py:146} INFO - Started process (PID=9035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:25,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:25,909] {logging_mixin.py:95} INFO - [2019-08-28 14:03:25,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:26,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:26,290] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:26,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:26,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:03:26,355] {scheduler_job.py:146} INFO - Started process (PID=9039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:31,363] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:31,364] {logging_mixin.py:95} INFO - [2019-08-28 14:03:31,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:31,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:31,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:31,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:31,725] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-08-28 14:03:31,810] {scheduler_job.py:146} INFO - Started process (PID=9041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:36,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:36,818] {logging_mixin.py:95} INFO - [2019-08-28 14:03:36,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:37,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:37,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:37,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:37,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-08-28 14:03:37,260] {scheduler_job.py:146} INFO - Started process (PID=9043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:42,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:42,276] {logging_mixin.py:95} INFO - [2019-08-28 14:03:42,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:42,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:42,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:42,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:42,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:03:42,720] {scheduler_job.py:146} INFO - Started process (PID=9046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:47,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:47,733] {logging_mixin.py:95} INFO - [2019-08-28 14:03:47,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:48,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:48,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:48,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:48,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:03:48,175] {scheduler_job.py:146} INFO - Started process (PID=9049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:53,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:53,182] {logging_mixin.py:95} INFO - [2019-08-28 14:03:53,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:53,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:53,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:53,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:53,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:03:53,630] {scheduler_job.py:146} INFO - Started process (PID=9050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:58,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:03:58,636] {logging_mixin.py:95} INFO - [2019-08-28 14:03:58,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:59,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:03:59,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:03:59,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:03:59,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 14:03:59,175] {scheduler_job.py:146} INFO - Started process (PID=9058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:04,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:04,184] {logging_mixin.py:95} INFO - [2019-08-28 14:04:04,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:04,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:04,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:04,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:04,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 14:04:04,715] {scheduler_job.py:146} INFO - Started process (PID=9061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:09,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:09,723] {logging_mixin.py:95} INFO - [2019-08-28 14:04:09,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:10,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:10,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:10,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:10,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:04:10,166] {scheduler_job.py:146} INFO - Started process (PID=9065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:15,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:15,178] {logging_mixin.py:95} INFO - [2019-08-28 14:04:15,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:15,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:15,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:15,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:15,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:04:15,612] {scheduler_job.py:146} INFO - Started process (PID=9067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:20,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:20,620] {logging_mixin.py:95} INFO - [2019-08-28 14:04:20,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:21,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:21,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:21,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:21,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-28 14:04:21,160] {scheduler_job.py:146} INFO - Started process (PID=9072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:26,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:26,167] {logging_mixin.py:95} INFO - [2019-08-28 14:04:26,167] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:26,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:26,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:26,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:26,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:04:26,611] {scheduler_job.py:146} INFO - Started process (PID=9073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:31,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:31,622] {logging_mixin.py:95} INFO - [2019-08-28 14:04:31,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:32,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:32,054] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:32,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:32,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-08-28 14:04:32,158] {scheduler_job.py:146} INFO - Started process (PID=9078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:37,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:37,166] {logging_mixin.py:95} INFO - [2019-08-28 14:04:37,165] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:37,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:37,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:37,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:37,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:04:37,609] {scheduler_job.py:146} INFO - Started process (PID=9079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:42,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:42,620] {logging_mixin.py:95} INFO - [2019-08-28 14:04:42,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:43,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:43,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:43,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:43,033] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:04:43,057] {scheduler_job.py:146} INFO - Started process (PID=9084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:48,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:48,065] {logging_mixin.py:95} INFO - [2019-08-28 14:04:48,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:48,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:48,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:48,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:48,494] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 14:04:48,517] {scheduler_job.py:146} INFO - Started process (PID=9086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:53,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:53,522] {logging_mixin.py:95} INFO - [2019-08-28 14:04:53,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:53,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:53,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:53,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:53,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 14:04:54,066] {scheduler_job.py:146} INFO - Started process (PID=9087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:59,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:04:59,076] {logging_mixin.py:95} INFO - [2019-08-28 14:04:59,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:59,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:04:59,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:04:59,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:04:59,510] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 14:04:59,606] {scheduler_job.py:146} INFO - Started process (PID=9092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:04,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:04,615] {logging_mixin.py:95} INFO - [2019-08-28 14:05:04,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:05,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:05,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:05,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:05,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 14:05:05,139] {scheduler_job.py:146} INFO - Started process (PID=9093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:10,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:10,150] {logging_mixin.py:95} INFO - [2019-08-28 14:05:10,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:10,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:10,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:10,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:10,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-08-28 14:05:10,678] {scheduler_job.py:146} INFO - Started process (PID=9094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:15,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:15,689] {logging_mixin.py:95} INFO - [2019-08-28 14:05:15,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:16,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:16,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:16,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:16,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-08-28 14:05:16,218] {scheduler_job.py:146} INFO - Started process (PID=9099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:21,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:21,228] {logging_mixin.py:95} INFO - [2019-08-28 14:05:21,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:21,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:21,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:21,677] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:21,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-08-28 14:05:21,749] {scheduler_job.py:146} INFO - Started process (PID=9101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:26,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:26,756] {logging_mixin.py:95} INFO - [2019-08-28 14:05:26,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:27,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:27,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:27,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:27,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:05:27,193] {scheduler_job.py:146} INFO - Started process (PID=9105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:32,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:32,200] {logging_mixin.py:95} INFO - [2019-08-28 14:05:32,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:32,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:32,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:32,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:32,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:05:32,644] {scheduler_job.py:146} INFO - Started process (PID=9107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:37,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:37,655] {logging_mixin.py:95} INFO - [2019-08-28 14:05:37,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:38,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:38,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:38,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:38,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:05:38,101] {scheduler_job.py:146} INFO - Started process (PID=9108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:43,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:43,108] {logging_mixin.py:95} INFO - [2019-08-28 14:05:43,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:43,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:43,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:43,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:43,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:05:43,546] {scheduler_job.py:146} INFO - Started process (PID=9110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:48,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:48,556] {logging_mixin.py:95} INFO - [2019-08-28 14:05:48,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:48,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:48,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:48,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:48,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 14:05:49,001] {scheduler_job.py:146} INFO - Started process (PID=9111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:54,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:54,012] {logging_mixin.py:95} INFO - [2019-08-28 14:05:54,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:54,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:54,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:54,379] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:54,385] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-28 14:05:54,459] {scheduler_job.py:146} INFO - Started process (PID=9116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:59,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:05:59,467] {logging_mixin.py:95} INFO - [2019-08-28 14:05:59,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:59,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:05:59,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:05:59,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:05:59,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:05:59,914] {scheduler_job.py:146} INFO - Started process (PID=9118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:04,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:04,924] {logging_mixin.py:95} INFO - [2019-08-28 14:06:04,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:05,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:05,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:05,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:05,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:06:05,374] {scheduler_job.py:146} INFO - Started process (PID=9122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:10,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:10,381] {logging_mixin.py:95} INFO - [2019-08-28 14:06:10,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:10,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:10,753] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:10,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:10,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 14:06:10,831] {scheduler_job.py:146} INFO - Started process (PID=9123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:15,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:15,842] {logging_mixin.py:95} INFO - [2019-08-28 14:06:15,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:16,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:16,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:16,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:16,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:06:16,292] {scheduler_job.py:146} INFO - Started process (PID=9125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:21,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:21,305] {logging_mixin.py:95} INFO - [2019-08-28 14:06:21,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:21,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:21,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:21,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:21,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:06:21,746] {scheduler_job.py:146} INFO - Started process (PID=9126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:26,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:26,756] {logging_mixin.py:95} INFO - [2019-08-28 14:06:26,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:27,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:27,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:27,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:27,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:06:27,201] {scheduler_job.py:146} INFO - Started process (PID=9131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:32,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:32,209] {logging_mixin.py:95} INFO - [2019-08-28 14:06:32,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:32,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:32,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:32,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:32,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:06:32,652] {scheduler_job.py:146} INFO - Started process (PID=9136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:37,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:37,658] {logging_mixin.py:95} INFO - [2019-08-28 14:06:37,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:38,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:38,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:38,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:38,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-08-28 14:06:38,203] {scheduler_job.py:146} INFO - Started process (PID=9137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:43,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:43,212] {logging_mixin.py:95} INFO - [2019-08-28 14:06:43,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:43,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:43,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:43,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:43,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:06:43,654] {scheduler_job.py:146} INFO - Started process (PID=9139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:48,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:48,663] {logging_mixin.py:95} INFO - [2019-08-28 14:06:48,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:49,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:49,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:49,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:49,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:06:49,113] {scheduler_job.py:146} INFO - Started process (PID=9143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:54,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:54,118] {logging_mixin.py:95} INFO - [2019-08-28 14:06:54,117] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:54,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:54,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:54,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:54,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:06:54,564] {scheduler_job.py:146} INFO - Started process (PID=9145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:59,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:06:59,573] {logging_mixin.py:95} INFO - [2019-08-28 14:06:59,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:59,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:06:59,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:06:59,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:06:59,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:07:00,011] {scheduler_job.py:146} INFO - Started process (PID=9147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:05,018] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:05,019] {logging_mixin.py:95} INFO - [2019-08-28 14:07:05,019] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:05,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:05,432] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:05,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:05,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:07:05,557] {scheduler_job.py:146} INFO - Started process (PID=9148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:10,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:10,566] {logging_mixin.py:95} INFO - [2019-08-28 14:07:10,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:10,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:10,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:10,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:10,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:07:11,002] {scheduler_job.py:146} INFO - Started process (PID=9152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:16,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:16,013] {logging_mixin.py:95} INFO - [2019-08-28 14:07:16,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:16,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:16,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:16,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:16,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:07:16,455] {scheduler_job.py:146} INFO - Started process (PID=9154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:21,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:21,464] {logging_mixin.py:95} INFO - [2019-08-28 14:07:21,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:21,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:21,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:21,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:21,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:07:21,903] {scheduler_job.py:146} INFO - Started process (PID=9158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:26,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:26,914] {logging_mixin.py:95} INFO - [2019-08-28 14:07:26,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:27,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:27,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:27,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:27,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:07:27,349] {scheduler_job.py:146} INFO - Started process (PID=9160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:32,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:32,359] {logging_mixin.py:95} INFO - [2019-08-28 14:07:32,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:32,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:32,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:32,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:32,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 14:07:32,796] {scheduler_job.py:146} INFO - Started process (PID=9163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:37,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:37,803] {logging_mixin.py:95} INFO - [2019-08-28 14:07:37,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:38,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:38,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:38,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:38,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:07:38,247] {scheduler_job.py:146} INFO - Started process (PID=9164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:43,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:43,253] {logging_mixin.py:95} INFO - [2019-08-28 14:07:43,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:43,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:43,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:43,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:43,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:07:43,693] {scheduler_job.py:146} INFO - Started process (PID=9169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:48,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:48,699] {logging_mixin.py:95} INFO - [2019-08-28 14:07:48,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:49,061] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:49,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:49,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:49,097] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:07:49,141] {scheduler_job.py:146} INFO - Started process (PID=9170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:54,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:54,149] {logging_mixin.py:95} INFO - [2019-08-28 14:07:54,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:54,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:54,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:07:54,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:07:54,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 14:07:54,694] {scheduler_job.py:146} INFO - Started process (PID=9171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:07:59,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:07:59,701] {logging_mixin.py:95} INFO - [2019-08-28 14:07:59,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:00,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:00,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:00,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:00,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:08:00,143] {scheduler_job.py:146} INFO - Started process (PID=9177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:05,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:05,153] {logging_mixin.py:95} INFO - [2019-08-28 14:08:05,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:05,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:05,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:05,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:05,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:08:05,592] {scheduler_job.py:146} INFO - Started process (PID=9178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:10,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:10,602] {logging_mixin.py:95} INFO - [2019-08-28 14:08:10,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:11,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:11,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:11,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:11,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-08-28 14:08:11,141] {scheduler_job.py:146} INFO - Started process (PID=9182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:16,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:16,150] {logging_mixin.py:95} INFO - [2019-08-28 14:08:16,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:16,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:16,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:16,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:16,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:08:16,587] {scheduler_job.py:146} INFO - Started process (PID=9184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:21,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:21,597] {logging_mixin.py:95} INFO - [2019-08-28 14:08:21,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:21,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:21,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:21,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:21,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:08:22,046] {scheduler_job.py:146} INFO - Started process (PID=9185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:27,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:27,054] {logging_mixin.py:95} INFO - [2019-08-28 14:08:27,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:27,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:27,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:27,458] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:27,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 14:08:27,503] {scheduler_job.py:146} INFO - Started process (PID=9186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:32,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:32,513] {logging_mixin.py:95} INFO - [2019-08-28 14:08:32,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:32,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:32,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:32,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:32,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-28 14:08:32,954] {scheduler_job.py:146} INFO - Started process (PID=9192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:37,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:37,963] {logging_mixin.py:95} INFO - [2019-08-28 14:08:37,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:38,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:38,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:38,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:38,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:08:38,416] {scheduler_job.py:146} INFO - Started process (PID=9193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:43,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:43,426] {logging_mixin.py:95} INFO - [2019-08-28 14:08:43,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:43,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:43,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:43,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:43,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:08:43,856] {scheduler_job.py:146} INFO - Started process (PID=9198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:48,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:48,864] {logging_mixin.py:95} INFO - [2019-08-28 14:08:48,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:49,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:49,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:49,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:49,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 14:08:49,304] {scheduler_job.py:146} INFO - Started process (PID=9199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:54,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:54,312] {logging_mixin.py:95} INFO - [2019-08-28 14:08:54,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:54,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:54,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:08:54,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:08:54,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:08:54,754] {scheduler_job.py:146} INFO - Started process (PID=9203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:08:59,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:08:59,760] {logging_mixin.py:95} INFO - [2019-08-28 14:08:59,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:00,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:00,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:00,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:00,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:09:00,204] {scheduler_job.py:146} INFO - Started process (PID=9206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:05,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:05,213] {logging_mixin.py:95} INFO - [2019-08-28 14:09:05,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:05,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:05,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:05,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:05,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:09:05,669] {scheduler_job.py:146} INFO - Started process (PID=9207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:10,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:10,679] {logging_mixin.py:95} INFO - [2019-08-28 14:09:10,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:11,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:11,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:11,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:11,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 14:09:11,119] {scheduler_job.py:146} INFO - Started process (PID=9208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:16,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:16,128] {logging_mixin.py:95} INFO - [2019-08-28 14:09:16,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:16,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:16,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:16,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:16,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 14:09:16,571] {scheduler_job.py:146} INFO - Started process (PID=9210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:21,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:21,578] {logging_mixin.py:95} INFO - [2019-08-28 14:09:21,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:21,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:21,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:21,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:21,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:09:22,028] {scheduler_job.py:146} INFO - Started process (PID=9214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:27,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:27,033] {logging_mixin.py:95} INFO - [2019-08-28 14:09:27,033] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:27,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:27,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:27,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:27,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:09:27,484] {scheduler_job.py:146} INFO - Started process (PID=9215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:32,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:32,495] {logging_mixin.py:95} INFO - [2019-08-28 14:09:32,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:32,862] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:32,886] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:32,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:32,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:09:32,936] {scheduler_job.py:146} INFO - Started process (PID=9221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:37,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:37,946] {logging_mixin.py:95} INFO - [2019-08-28 14:09:37,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:38,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:38,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:38,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:38,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:09:38,396] {scheduler_job.py:146} INFO - Started process (PID=9222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:43,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:43,405] {logging_mixin.py:95} INFO - [2019-08-28 14:09:43,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:43,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:43,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:43,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:43,807] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:09:43,848] {scheduler_job.py:146} INFO - Started process (PID=9224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:48,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:48,857] {logging_mixin.py:95} INFO - [2019-08-28 14:09:48,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:49,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:49,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:49,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:49,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:09:49,301] {scheduler_job.py:146} INFO - Started process (PID=9228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:54,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:54,312] {logging_mixin.py:95} INFO - [2019-08-28 14:09:54,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:54,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:54,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:09:54,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:09:54,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:09:54,756] {scheduler_job.py:146} INFO - Started process (PID=9229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:09:59,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:09:59,766] {logging_mixin.py:95} INFO - [2019-08-28 14:09:59,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:00,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:00,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:00,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:00,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:10:00,205] {scheduler_job.py:146} INFO - Started process (PID=9231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:05,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:05,213] {logging_mixin.py:95} INFO - [2019-08-28 14:10:05,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:05,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:05,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:05,627] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:05,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:10:05,659] {scheduler_job.py:146} INFO - Started process (PID=9236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:10,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:10,668] {logging_mixin.py:95} INFO - [2019-08-28 14:10:10,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:11,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:11,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:11,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:11,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:10:11,114] {scheduler_job.py:146} INFO - Started process (PID=9237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:16,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:16,121] {logging_mixin.py:95} INFO - [2019-08-28 14:10:16,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:16,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:16,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:16,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:16,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 14:10:16,571] {scheduler_job.py:146} INFO - Started process (PID=9242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:21,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:21,577] {logging_mixin.py:95} INFO - [2019-08-28 14:10:21,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:21,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:21,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:21,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:21,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:10:22,034] {scheduler_job.py:146} INFO - Started process (PID=9243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:27,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:27,044] {logging_mixin.py:95} INFO - [2019-08-28 14:10:27,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:27,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:27,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:27,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:27,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:10:27,483] {scheduler_job.py:146} INFO - Started process (PID=9244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:32,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:32,501] {logging_mixin.py:95} INFO - [2019-08-28 14:10:32,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:32,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:32,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:32,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:32,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:10:32,932] {scheduler_job.py:146} INFO - Started process (PID=9249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:37,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:37,940] {logging_mixin.py:95} INFO - [2019-08-28 14:10:37,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:38,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:38,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:38,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:38,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 14:10:38,387] {scheduler_job.py:146} INFO - Started process (PID=9251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:43,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:43,398] {logging_mixin.py:95} INFO - [2019-08-28 14:10:43,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:43,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:43,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:43,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:43,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:10:43,845] {scheduler_job.py:146} INFO - Started process (PID=9253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:48,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:48,856] {logging_mixin.py:95} INFO - [2019-08-28 14:10:48,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:49,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:49,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:49,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:49,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:10:49,301] {scheduler_job.py:146} INFO - Started process (PID=9254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:54,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:54,308] {logging_mixin.py:95} INFO - [2019-08-28 14:10:54,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:54,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:54,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:10:54,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:10:54,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-08-28 14:10:54,840] {scheduler_job.py:146} INFO - Started process (PID=9258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:10:59,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:10:59,847] {logging_mixin.py:95} INFO - [2019-08-28 14:10:59,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:00,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:00,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:00,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:00,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:11:00,382] {scheduler_job.py:146} INFO - Started process (PID=9260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:05,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:05,391] {logging_mixin.py:95} INFO - [2019-08-28 14:11:05,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:05,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:05,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:05,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:05,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 14:11:05,835] {scheduler_job.py:146} INFO - Started process (PID=9265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:10,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:10,848] {logging_mixin.py:95} INFO - [2019-08-28 14:11:10,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:11,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:11,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:11,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:11,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 14:11:11,282] {scheduler_job.py:146} INFO - Started process (PID=9266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:16,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:16,289] {logging_mixin.py:95} INFO - [2019-08-28 14:11:16,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:16,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:16,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:16,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:16,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:11:16,726] {scheduler_job.py:146} INFO - Started process (PID=9268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:21,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:21,734] {logging_mixin.py:95} INFO - [2019-08-28 14:11:21,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:22,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:22,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:22,203] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:22,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-08-28 14:11:22,268] {scheduler_job.py:146} INFO - Started process (PID=9269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:27,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:27,275] {logging_mixin.py:95} INFO - [2019-08-28 14:11:27,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:27,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:27,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:27,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:27,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:11:27,722] {scheduler_job.py:146} INFO - Started process (PID=9273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:32,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:32,732] {logging_mixin.py:95} INFO - [2019-08-28 14:11:32,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:33,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:33,111] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:33,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:33,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:11:33,172] {scheduler_job.py:146} INFO - Started process (PID=9275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:38,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:38,183] {logging_mixin.py:95} INFO - [2019-08-28 14:11:38,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:38,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:38,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:38,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:38,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-28 14:11:38,727] {scheduler_job.py:146} INFO - Started process (PID=9280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:43,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:43,733] {logging_mixin.py:95} INFO - [2019-08-28 14:11:43,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:44,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:44,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:44,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:44,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:11:44,173] {scheduler_job.py:146} INFO - Started process (PID=9282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:49,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:49,181] {logging_mixin.py:95} INFO - [2019-08-28 14:11:49,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:49,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:49,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:49,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:49,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:11:49,633] {scheduler_job.py:146} INFO - Started process (PID=9283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:54,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:11:54,645] {logging_mixin.py:95} INFO - [2019-08-28 14:11:54,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:55,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:11:55,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:11:55,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:11:55,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 14:11:55,188] {scheduler_job.py:146} INFO - Started process (PID=9287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:00,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:00,195] {logging_mixin.py:95} INFO - [2019-08-28 14:12:00,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:00,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:00,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:00,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:00,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:12:00,644] {scheduler_job.py:146} INFO - Started process (PID=9289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:05,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:05,650] {logging_mixin.py:95} INFO - [2019-08-28 14:12:05,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:06,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:06,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:06,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:06,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:12:06,099] {scheduler_job.py:146} INFO - Started process (PID=9290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:11,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:11,105] {logging_mixin.py:95} INFO - [2019-08-28 14:12:11,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:11,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:11,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:11,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:11,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:12:11,549] {scheduler_job.py:146} INFO - Started process (PID=9292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:16,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:16,558] {logging_mixin.py:95} INFO - [2019-08-28 14:12:16,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:16,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:16,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:16,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:16,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:12:17,002] {scheduler_job.py:146} INFO - Started process (PID=9298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:22,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:22,012] {logging_mixin.py:95} INFO - [2019-08-28 14:12:22,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:22,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:22,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:22,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:22,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:12:22,450] {scheduler_job.py:146} INFO - Started process (PID=9300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:27,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:27,460] {logging_mixin.py:95} INFO - [2019-08-28 14:12:27,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:27,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:27,848] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:27,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:27,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:12:27,897] {scheduler_job.py:146} INFO - Started process (PID=9303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:32,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:32,905] {logging_mixin.py:95} INFO - [2019-08-28 14:12:32,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:33,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:33,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:33,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:33,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:12:33,343] {scheduler_job.py:146} INFO - Started process (PID=9305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:38,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:38,353] {logging_mixin.py:95} INFO - [2019-08-28 14:12:38,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:38,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:38,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:38,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:38,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:12:38,792] {scheduler_job.py:146} INFO - Started process (PID=9306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:43,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:43,803] {logging_mixin.py:95} INFO - [2019-08-28 14:12:43,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:44,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:44,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:44,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:44,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:12:44,235] {scheduler_job.py:146} INFO - Started process (PID=9312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:49,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:49,245] {logging_mixin.py:95} INFO - [2019-08-28 14:12:49,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:49,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:49,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:49,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:49,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-08-28 14:12:49,776] {scheduler_job.py:146} INFO - Started process (PID=9313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:54,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:12:54,785] {logging_mixin.py:95} INFO - [2019-08-28 14:12:54,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:55,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:12:55,166] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:12:55,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:12:55,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:12:55,218] {scheduler_job.py:146} INFO - Started process (PID=9314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:00,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:00,225] {logging_mixin.py:95} INFO - [2019-08-28 14:13:00,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:00,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:00,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:13:00,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:13:00,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:13:00,766] {scheduler_job.py:146} INFO - Started process (PID=9319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:05,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:05,776] {logging_mixin.py:95} INFO - [2019-08-28 14:13:05,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:06,147] {logging_mixin.py:95} INFO - [2019-08-28 14:13:06,142] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:06,148] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:06,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 14:13:06,220] {scheduler_job.py:146} INFO - Started process (PID=9320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:11,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:11,237] {logging_mixin.py:95} INFO - [2019-08-28 14:13:11,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:11,627] {logging_mixin.py:95} INFO - [2019-08-28 14:13:11,625] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:11,627] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:11,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:13:11,670] {scheduler_job.py:146} INFO - Started process (PID=9322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:16,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:16,681] {logging_mixin.py:95} INFO - [2019-08-28 14:13:16,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:17,053] {logging_mixin.py:95} INFO - [2019-08-28 14:13:17,051] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:17,055] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:17,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:13:17,120] {scheduler_job.py:146} INFO - Started process (PID=9328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:22,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:22,136] {logging_mixin.py:95} INFO - [2019-08-28 14:13:22,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:22,576] {logging_mixin.py:95} INFO - [2019-08-28 14:13:22,574] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:22,576] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:22,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 14:13:22,667] {scheduler_job.py:146} INFO - Started process (PID=9329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:27,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:27,673] {logging_mixin.py:95} INFO - [2019-08-28 14:13:27,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:28,036] {logging_mixin.py:95} INFO - [2019-08-28 14:13:28,035] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:28,036] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:28,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-08-28 14:13:28,112] {scheduler_job.py:146} INFO - Started process (PID=9333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:33,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:33,119] {logging_mixin.py:95} INFO - [2019-08-28 14:13:33,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:33,512] {logging_mixin.py:95} INFO - [2019-08-28 14:13:33,511] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:33,513] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:33,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:13:33,563] {scheduler_job.py:146} INFO - Started process (PID=9338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:38,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:38,570] {logging_mixin.py:95} INFO - [2019-08-28 14:13:38,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:38,939] {logging_mixin.py:95} INFO - [2019-08-28 14:13:38,938] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:38,940] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:38,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 14:13:39,010] {scheduler_job.py:146} INFO - Started process (PID=9339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:44,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:44,018] {logging_mixin.py:95} INFO - [2019-08-28 14:13:44,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:44,433] {logging_mixin.py:95} INFO - [2019-08-28 14:13:44,431] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:44,433] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:44,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:13:44,470] {scheduler_job.py:146} INFO - Started process (PID=9345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:49,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:49,477] {logging_mixin.py:95} INFO - [2019-08-28 14:13:49,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:49,848] {logging_mixin.py:95} INFO - [2019-08-28 14:13:49,846] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 61, in <module>
    start_task = DummyOperator(task_id='start')
NameError: name 'DummyOperator' is not defined
[2019-08-28 14:13:49,848] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:49,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 14:13:49,918] {scheduler_job.py:146} INFO - Started process (PID=9346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:54,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:13:54,926] {logging_mixin.py:95} INFO - [2019-08-28 14:13:54,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:55,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:13:55,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:13:55,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:13:55,342] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:13:55,370] {scheduler_job.py:146} INFO - Started process (PID=9347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:00,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:00,379] {logging_mixin.py:95} INFO - [2019-08-28 14:14:00,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:00,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:00,795] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:00,803] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:00,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 14:14:00,920] {scheduler_job.py:146} INFO - Started process (PID=9352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:05,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:05,928] {logging_mixin.py:95} INFO - [2019-08-28 14:14:05,928] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:06,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:06,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:06,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:06,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:14:06,369] {scheduler_job.py:146} INFO - Started process (PID=9353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:11,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:11,384] {logging_mixin.py:95} INFO - [2019-08-28 14:14:11,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:11,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:11,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:11,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:11,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 14:14:11,924] {scheduler_job.py:146} INFO - Started process (PID=9354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:16,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:16,931] {logging_mixin.py:95} INFO - [2019-08-28 14:14:16,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:17,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:17,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:17,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:17,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:14:17,366] {scheduler_job.py:146} INFO - Started process (PID=9357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:22,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:22,375] {logging_mixin.py:95} INFO - [2019-08-28 14:14:22,374] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:22,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:22,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:22,805] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:22,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 14:14:22,919] {scheduler_job.py:146} INFO - Started process (PID=9361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:27,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:27,927] {logging_mixin.py:95} INFO - [2019-08-28 14:14:27,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:28,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:28,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:28,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:28,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:14:28,363] {scheduler_job.py:146} INFO - Started process (PID=9362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:33,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:33,370] {logging_mixin.py:95} INFO - [2019-08-28 14:14:33,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:33,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:33,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:33,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:33,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.509 seconds
[2019-08-28 14:14:33,905] {scheduler_job.py:146} INFO - Started process (PID=9367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:38,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:38,916] {logging_mixin.py:95} INFO - [2019-08-28 14:14:38,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:39,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:39,290] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:39,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:39,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:14:39,360] {scheduler_job.py:146} INFO - Started process (PID=9368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:44,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:44,366] {logging_mixin.py:95} INFO - [2019-08-28 14:14:44,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:44,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:44,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:44,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:44,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:14:44,817] {scheduler_job.py:146} INFO - Started process (PID=9370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:49,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:49,827] {logging_mixin.py:95} INFO - [2019-08-28 14:14:49,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:50,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:50,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:50,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:50,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:14:50,254] {scheduler_job.py:146} INFO - Started process (PID=9372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:55,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:14:55,263] {logging_mixin.py:95} INFO - [2019-08-28 14:14:55,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:55,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:14:55,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:14:55,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:14:55,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:14:55,707] {scheduler_job.py:146} INFO - Started process (PID=9376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:00,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:00,718] {logging_mixin.py:95} INFO - [2019-08-28 14:15:00,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:01,107] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:01,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:01,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:01,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:15:01,258] {scheduler_job.py:146} INFO - Started process (PID=9378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:06,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:06,263] {logging_mixin.py:95} INFO - [2019-08-28 14:15:06,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:06,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:06,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:06,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:06,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 14:15:06,707] {scheduler_job.py:146} INFO - Started process (PID=9382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:11,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:11,726] {logging_mixin.py:95} INFO - [2019-08-28 14:15:11,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:12,158] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:12,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:12,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:12,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-08-28 14:15:12,256] {scheduler_job.py:146} INFO - Started process (PID=9383) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:17,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:17,263] {logging_mixin.py:95} INFO - [2019-08-28 14:15:17,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:17,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:17,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:17,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:17,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 14:15:17,717] {scheduler_job.py:146} INFO - Started process (PID=9386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:22,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:22,725] {logging_mixin.py:95} INFO - [2019-08-28 14:15:22,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:23,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:23,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:23,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:23,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:15:23,166] {scheduler_job.py:146} INFO - Started process (PID=9390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:28,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:28,174] {logging_mixin.py:95} INFO - [2019-08-28 14:15:28,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:28,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:28,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:28,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:28,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:15:28,612] {scheduler_job.py:146} INFO - Started process (PID=9392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:33,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:33,619] {logging_mixin.py:95} INFO - [2019-08-28 14:15:33,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:33,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:34,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:34,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:34,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:15:34,053] {scheduler_job.py:146} INFO - Started process (PID=9393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:39,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:39,063] {logging_mixin.py:95} INFO - [2019-08-28 14:15:39,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:39,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:39,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:39,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:39,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:15:39,502] {scheduler_job.py:146} INFO - Started process (PID=9397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:44,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:44,512] {logging_mixin.py:95} INFO - [2019-08-28 14:15:44,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:44,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:44,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:44,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:44,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:15:44,952] {scheduler_job.py:146} INFO - Started process (PID=9399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:49,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:49,963] {logging_mixin.py:95} INFO - [2019-08-28 14:15:49,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:50,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:50,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:50,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:50,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.507 seconds
[2019-08-28 14:15:50,503] {scheduler_job.py:146} INFO - Started process (PID=9401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:55,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:15:55,511] {logging_mixin.py:95} INFO - [2019-08-28 14:15:55,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:55,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:15:55,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:15:55,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:15:55,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:15:55,949] {scheduler_job.py:146} INFO - Started process (PID=9402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:00,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:00,957] {logging_mixin.py:95} INFO - [2019-08-28 14:16:00,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:01,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:01,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:01,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:01,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:16:01,401] {scheduler_job.py:146} INFO - Started process (PID=9407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:06,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:06,412] {logging_mixin.py:95} INFO - [2019-08-28 14:16:06,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:06,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:06,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:06,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:06,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:16:06,851] {scheduler_job.py:146} INFO - Started process (PID=9408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:11,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:11,860] {logging_mixin.py:95} INFO - [2019-08-28 14:16:11,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:12,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:12,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:12,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:12,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:16:12,305] {scheduler_job.py:146} INFO - Started process (PID=9412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:17,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:17,316] {logging_mixin.py:95} INFO - [2019-08-28 14:16:17,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:17,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:17,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:17,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:17,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:16:17,759] {scheduler_job.py:146} INFO - Started process (PID=9414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:22,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:22,770] {logging_mixin.py:95} INFO - [2019-08-28 14:16:22,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:23,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:23,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:23,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:23,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:16:23,218] {scheduler_job.py:146} INFO - Started process (PID=9416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:28,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:28,226] {logging_mixin.py:95} INFO - [2019-08-28 14:16:28,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:28,571] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:28,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:28,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:28,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 14:16:28,668] {scheduler_job.py:146} INFO - Started process (PID=9418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:33,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:33,675] {logging_mixin.py:95} INFO - [2019-08-28 14:16:33,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:34,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:34,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:34,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:34,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:16:34,117] {scheduler_job.py:146} INFO - Started process (PID=9422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:39,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:39,128] {logging_mixin.py:95} INFO - [2019-08-28 14:16:39,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:39,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:39,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:39,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:39,533] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:16:39,566] {scheduler_job.py:146} INFO - Started process (PID=9427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:44,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:44,574] {logging_mixin.py:95} INFO - [2019-08-28 14:16:44,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:44,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:44,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:44,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:44,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:16:45,024] {scheduler_job.py:146} INFO - Started process (PID=9429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:50,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:50,031] {logging_mixin.py:95} INFO - [2019-08-28 14:16:50,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:50,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:50,434] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:50,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:50,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:16:50,479] {scheduler_job.py:146} INFO - Started process (PID=9430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:55,485] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:16:55,485] {logging_mixin.py:95} INFO - [2019-08-28 14:16:55,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:55,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:16:55,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:16:55,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:16:55,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 14:16:55,927] {scheduler_job.py:146} INFO - Started process (PID=9432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:00,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:00,936] {logging_mixin.py:95} INFO - [2019-08-28 14:17:00,935] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:01,317] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:01,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:01,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:01,350] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:17:01,371] {scheduler_job.py:146} INFO - Started process (PID=9437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:06,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:06,378] {logging_mixin.py:95} INFO - [2019-08-28 14:17:06,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:06,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:06,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:06,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:06,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:17:06,820] {scheduler_job.py:146} INFO - Started process (PID=9438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:11,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:11,830] {logging_mixin.py:95} INFO - [2019-08-28 14:17:11,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:12,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:12,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:12,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:12,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:17:12,274] {scheduler_job.py:146} INFO - Started process (PID=9442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:17,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:17,284] {logging_mixin.py:95} INFO - [2019-08-28 14:17:17,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:17,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:17,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:17,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:17,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:17:17,735] {scheduler_job.py:146} INFO - Started process (PID=9444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:22,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:22,745] {logging_mixin.py:95} INFO - [2019-08-28 14:17:22,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:23,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:23,143] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:23,150] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:23,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:17:23,184] {scheduler_job.py:146} INFO - Started process (PID=9445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:28,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:28,195] {logging_mixin.py:95} INFO - [2019-08-28 14:17:28,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:28,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:28,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:28,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:28,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 14:17:28,637] {scheduler_job.py:146} INFO - Started process (PID=9446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:33,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:33,644] {logging_mixin.py:95} INFO - [2019-08-28 14:17:33,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:34,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:34,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:34,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:34,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-08-28 14:17:34,187] {scheduler_job.py:146} INFO - Started process (PID=9452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:39,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:39,196] {logging_mixin.py:95} INFO - [2019-08-28 14:17:39,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:39,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:39,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:39,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:39,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:17:39,639] {scheduler_job.py:146} INFO - Started process (PID=9453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:44,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:44,647] {logging_mixin.py:95} INFO - [2019-08-28 14:17:44,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:45,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:45,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:45,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:45,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:17:45,083] {scheduler_job.py:146} INFO - Started process (PID=9458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:50,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:50,093] {logging_mixin.py:95} INFO - [2019-08-28 14:17:50,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:50,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:50,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:50,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:50,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:17:50,542] {scheduler_job.py:146} INFO - Started process (PID=9459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:55,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:17:55,548] {logging_mixin.py:95} INFO - [2019-08-28 14:17:55,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:55,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:17:55,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:17:55,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:17:55,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:17:56,001] {scheduler_job.py:146} INFO - Started process (PID=9460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:01,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:01,008] {logging_mixin.py:95} INFO - [2019-08-28 14:18:01,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:01,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:01,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:01,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:01,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:18:01,453] {scheduler_job.py:146} INFO - Started process (PID=9465) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:06,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:06,461] {logging_mixin.py:95} INFO - [2019-08-28 14:18:06,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:06,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:06,872] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:06,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:06,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:18:06,907] {scheduler_job.py:146} INFO - Started process (PID=9485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:11,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:11,917] {logging_mixin.py:95} INFO - [2019-08-28 14:18:11,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:12,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:12,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:12,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:12,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:18:12,365] {scheduler_job.py:146} INFO - Started process (PID=9486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:17,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:17,372] {logging_mixin.py:95} INFO - [2019-08-28 14:18:17,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:17,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:17,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:17,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:17,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:18:17,817] {scheduler_job.py:146} INFO - Started process (PID=9491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:22,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:22,826] {logging_mixin.py:95} INFO - [2019-08-28 14:18:22,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:23,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:23,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:23,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:23,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:18:23,269] {scheduler_job.py:146} INFO - Started process (PID=9492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:28,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:28,279] {logging_mixin.py:95} INFO - [2019-08-28 14:18:28,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:28,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:28,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:28,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:28,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 14:18:28,726] {scheduler_job.py:146} INFO - Started process (PID=9494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:33,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:33,737] {logging_mixin.py:95} INFO - [2019-08-28 14:18:33,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:34,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:34,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:34,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:34,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:18:34,174] {scheduler_job.py:146} INFO - Started process (PID=9498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:39,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:39,181] {logging_mixin.py:95} INFO - [2019-08-28 14:18:39,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:39,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:39,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:39,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:39,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:18:39,625] {scheduler_job.py:146} INFO - Started process (PID=9500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:44,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:44,636] {logging_mixin.py:95} INFO - [2019-08-28 14:18:44,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:45,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:45,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:45,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:45,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:18:45,068] {scheduler_job.py:146} INFO - Started process (PID=9502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:50,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:50,078] {logging_mixin.py:95} INFO - [2019-08-28 14:18:50,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:50,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:50,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:50,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:50,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:18:50,519] {scheduler_job.py:146} INFO - Started process (PID=9506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:55,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:18:55,527] {logging_mixin.py:95} INFO - [2019-08-28 14:18:55,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:55,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:18:55,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:18:55,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:18:55,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 14:18:55,981] {scheduler_job.py:146} INFO - Started process (PID=9507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:00,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:00,988] {logging_mixin.py:95} INFO - [2019-08-28 14:19:00,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:01,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:01,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:01,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:01,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:19:01,437] {scheduler_job.py:146} INFO - Started process (PID=9509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:06,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:06,447] {logging_mixin.py:95} INFO - [2019-08-28 14:19:06,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:06,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:06,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:06,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:06,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:19:06,887] {scheduler_job.py:146} INFO - Started process (PID=9513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:11,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:11,893] {logging_mixin.py:95} INFO - [2019-08-28 14:19:11,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:12,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:12,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:12,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:12,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:19:12,341] {scheduler_job.py:146} INFO - Started process (PID=9515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:17,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:17,352] {logging_mixin.py:95} INFO - [2019-08-28 14:19:17,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:17,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:17,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:17,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:17,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:19:17,797] {scheduler_job.py:146} INFO - Started process (PID=9517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:22,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:22,804] {logging_mixin.py:95} INFO - [2019-08-28 14:19:22,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:23,158] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:23,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:23,190] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:23,197] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:19:23,252] {scheduler_job.py:146} INFO - Started process (PID=9521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:28,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:28,262] {logging_mixin.py:95} INFO - [2019-08-28 14:19:28,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:28,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:28,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:28,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:28,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:19:28,707] {scheduler_job.py:146} INFO - Started process (PID=9522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:33,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:33,714] {logging_mixin.py:95} INFO - [2019-08-28 14:19:33,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:34,071] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:34,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:34,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:34,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:19:34,163] {scheduler_job.py:146} INFO - Started process (PID=9524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:39,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:39,169] {logging_mixin.py:95} INFO - [2019-08-28 14:19:39,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:39,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:39,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:39,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:39,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:19:39,615] {scheduler_job.py:146} INFO - Started process (PID=9529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:44,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:44,622] {logging_mixin.py:95} INFO - [2019-08-28 14:19:44,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:44,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:45,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:45,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:45,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:19:45,065] {scheduler_job.py:146} INFO - Started process (PID=9531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:50,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:50,072] {logging_mixin.py:95} INFO - [2019-08-28 14:19:50,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:50,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:50,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:50,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:50,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 14:19:50,519] {scheduler_job.py:146} INFO - Started process (PID=9532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:55,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:19:55,530] {logging_mixin.py:95} INFO - [2019-08-28 14:19:55,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:55,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:19:55,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:19:55,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:19:55,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:19:55,967] {scheduler_job.py:146} INFO - Started process (PID=9536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:00,974] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:00,975] {logging_mixin.py:95} INFO - [2019-08-28 14:20:00,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:01,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:01,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:01,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:01,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:20:01,423] {scheduler_job.py:146} INFO - Started process (PID=9538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:06,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:06,434] {logging_mixin.py:95} INFO - [2019-08-28 14:20:06,434] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:06,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:06,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:06,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:06,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:20:06,881] {scheduler_job.py:146} INFO - Started process (PID=9539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:11,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:11,892] {logging_mixin.py:95} INFO - [2019-08-28 14:20:11,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:12,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:12,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:12,273] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:12,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:20:12,341] {scheduler_job.py:146} INFO - Started process (PID=9541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:17,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:17,352] {logging_mixin.py:95} INFO - [2019-08-28 14:20:17,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:17,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:17,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:17,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:17,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 14:20:17,800] {scheduler_job.py:146} INFO - Started process (PID=9546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:22,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:22,811] {logging_mixin.py:95} INFO - [2019-08-28 14:20:22,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:23,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:23,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:23,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:23,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:20:23,256] {scheduler_job.py:146} INFO - Started process (PID=9550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:28,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:28,264] {logging_mixin.py:95} INFO - [2019-08-28 14:20:28,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:28,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:28,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:28,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:28,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:20:28,704] {scheduler_job.py:146} INFO - Started process (PID=9551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:33,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:33,710] {logging_mixin.py:95} INFO - [2019-08-28 14:20:33,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:34,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:34,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:34,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:34,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 14:20:34,160] {scheduler_job.py:146} INFO - Started process (PID=9553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:39,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:39,170] {logging_mixin.py:95} INFO - [2019-08-28 14:20:39,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:39,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:39,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:39,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:39,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:20:39,607] {scheduler_job.py:146} INFO - Started process (PID=9554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:44,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:44,613] {logging_mixin.py:95} INFO - [2019-08-28 14:20:44,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:44,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:45,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:45,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:45,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:20:45,056] {scheduler_job.py:146} INFO - Started process (PID=9560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:50,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:50,066] {logging_mixin.py:95} INFO - [2019-08-28 14:20:50,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:50,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:50,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:50,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:50,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 14:20:50,507] {scheduler_job.py:146} INFO - Started process (PID=9561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:55,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:20:55,514] {logging_mixin.py:95} INFO - [2019-08-28 14:20:55,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:55,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:20:55,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:20:55,909] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:20:55,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:20:55,939] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:20:55,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 14:20:56,056] {scheduler_job.py:146} INFO - Started process (PID=9562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:01,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:01,068] {logging_mixin.py:95} INFO - [2019-08-28 14:21:01,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:01,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:01,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:01,517] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:01,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:01,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-08-28 14:21:01,601] {scheduler_job.py:146} INFO - Started process (PID=9568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:06,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:06,608] {logging_mixin.py:95} INFO - [2019-08-28 14:21:06,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:06,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:06,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:07,005] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:07,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:07,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:21:07,054] {scheduler_job.py:146} INFO - Started process (PID=9569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:12,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:12,061] {logging_mixin.py:95} INFO - [2019-08-28 14:21:12,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:12,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:12,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:12,478] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:12,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:12,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 14:21:12,612] {scheduler_job.py:146} INFO - Started process (PID=9573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:17,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:17,622] {logging_mixin.py:95} INFO - [2019-08-28 14:21:17,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:18,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:18,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:18,070] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:18,094] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:18,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-08-28 14:21:18,165] {scheduler_job.py:146} INFO - Started process (PID=9577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:23,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:23,175] {logging_mixin.py:95} INFO - [2019-08-28 14:21:23,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:23,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:23,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:23,586] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:23,612] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:23,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 14:21:23,715] {scheduler_job.py:146} INFO - Started process (PID=9578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:28,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:28,721] {logging_mixin.py:95} INFO - [2019-08-28 14:21:28,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:29,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:29,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:29,112] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:29,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:29,141] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:21:29,144] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:21:29,146] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:21:29,149] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:21:29,151] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_csco_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:21:29,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 14:21:29,270] {scheduler_job.py:146} INFO - Started process (PID=9580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:34,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:34,281] {logging_mixin.py:95} INFO - [2019-08-28 14:21:34,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:34,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:34,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:34,663] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:34,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:34,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:21:34,717] {scheduler_job.py:146} INFO - Started process (PID=9585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:39,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:39,726] {logging_mixin.py:95} INFO - [2019-08-28 14:21:39,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:40,082] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:40,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:40,106] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:40,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:40,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:21:40,172] {scheduler_job.py:146} INFO - Started process (PID=9586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:45,177] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:45,178] {logging_mixin.py:95} INFO - [2019-08-28 14:21:45,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:45,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:45,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:45,550] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:45,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:45,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:21:45,628] {scheduler_job.py:146} INFO - Started process (PID=9589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:50,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:50,636] {logging_mixin.py:95} INFO - [2019-08-28 14:21:50,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:50,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:51,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:51,011] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:51,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:51,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 14:21:51,084] {scheduler_job.py:146} INFO - Started process (PID=9594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:56,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:21:56,094] {logging_mixin.py:95} INFO - [2019-08-28 14:21:56,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:56,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:21:56,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:21:56,504] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:21:56,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:21:56,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 14:21:56,630] {scheduler_job.py:146} INFO - Started process (PID=9595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:01,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:01,640] {logging_mixin.py:95} INFO - [2019-08-28 14:22:01,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:02,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:02,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:02,054] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:02,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:02,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 14:22:02,174] {scheduler_job.py:146} INFO - Started process (PID=9601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:07,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:07,180] {logging_mixin.py:95} INFO - [2019-08-28 14:22:07,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:07,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:07,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:07,594] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:07,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:07,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 14:22:07,728] {scheduler_job.py:146} INFO - Started process (PID=9602) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:12,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:12,737] {logging_mixin.py:95} INFO - [2019-08-28 14:22:12,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:13,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:13,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:13,141] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:13,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:13,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 14:22:13,276] {scheduler_job.py:146} INFO - Started process (PID=9603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:18,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:18,283] {logging_mixin.py:95} INFO - [2019-08-28 14:22:18,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:18,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:18,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:18,687] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:18,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:18,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:22:18,819] {scheduler_job.py:146} INFO - Started process (PID=9610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:23,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:23,826] {logging_mixin.py:95} INFO - [2019-08-28 14:22:23,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:24,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:24,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:24,223] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:24,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:24,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:22:24,269] {scheduler_job.py:146} INFO - Started process (PID=9611) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:29,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:29,277] {logging_mixin.py:95} INFO - [2019-08-28 14:22:29,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:29,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:29,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:29,687] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:29,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:29,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 14:22:29,817] {scheduler_job.py:146} INFO - Started process (PID=9613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:34,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:34,826] {logging_mixin.py:95} INFO - [2019-08-28 14:22:34,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:35,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:35,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:35,268] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:35,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:35,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-08-28 14:22:35,361] {scheduler_job.py:146} INFO - Started process (PID=9618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:40,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:40,370] {logging_mixin.py:95} INFO - [2019-08-28 14:22:40,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:40,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:40,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:40,771] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:40,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:40,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:22:40,902] {scheduler_job.py:146} INFO - Started process (PID=9619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:45,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:45,909] {logging_mixin.py:95} INFO - [2019-08-28 14:22:45,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:46,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:46,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:46,308] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:46,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:46,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:22:46,350] {scheduler_job.py:146} INFO - Started process (PID=9621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:51,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:22:51,358] {logging_mixin.py:95} INFO - [2019-08-28 14:22:51,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:51,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:22:51,783] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:22:51,792] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:22:51,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:22:51,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 14:24:20,401] {scheduler_job.py:146} INFO - Started process (PID=9654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:25,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:25,406] {logging_mixin.py:95} INFO - [2019-08-28 14:24:25,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:25,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:25,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:25,842] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:25,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:25,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-08-28 14:24:25,946] {scheduler_job.py:146} INFO - Started process (PID=9659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:30,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:30,953] {logging_mixin.py:95} INFO - [2019-08-28 14:24:30,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:31,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:31,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:31,361] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:31,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:31,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 14:24:31,498] {scheduler_job.py:146} INFO - Started process (PID=9661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:36,506] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:36,507] {logging_mixin.py:95} INFO - [2019-08-28 14:24:36,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:36,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:36,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:36,897] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:36,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:36,923] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 14:24:36,950] {scheduler_job.py:146} INFO - Started process (PID=9662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:41,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:41,961] {logging_mixin.py:95} INFO - [2019-08-28 14:24:41,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:42,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:42,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:42,350] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:42,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:42,374] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:24:42,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 14:24:42,406] {scheduler_job.py:146} INFO - Started process (PID=9666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:47,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:47,416] {logging_mixin.py:95} INFO - [2019-08-28 14:24:47,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:47,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:47,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:47,799] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:47,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:47,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:24:47,857] {scheduler_job.py:146} INFO - Started process (PID=9669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:52,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:52,863] {logging_mixin.py:95} INFO - [2019-08-28 14:24:52,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:53,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:53,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:53,249] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:53,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:53,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:24:53,308] {scheduler_job.py:146} INFO - Started process (PID=9670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:58,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:24:58,319] {logging_mixin.py:95} INFO - [2019-08-28 14:24:58,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:58,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:24:58,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:24:58,702] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:24:58,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:24:58,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:24:58,756] {scheduler_job.py:146} INFO - Started process (PID=9675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:03,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:03,763] {logging_mixin.py:95} INFO - [2019-08-28 14:25:03,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:04,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:04,142] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:04,149] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:04,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:04,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:25:04,207] {scheduler_job.py:146} INFO - Started process (PID=9678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:09,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:09,218] {logging_mixin.py:95} INFO - [2019-08-28 14:25:09,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:09,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:09,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:09,602] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:09,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:09,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 14:25:09,662] {scheduler_job.py:146} INFO - Started process (PID=9679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:14,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:14,671] {logging_mixin.py:95} INFO - [2019-08-28 14:25:14,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:15,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:15,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:15,055] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:15,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:15,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:25:15,117] {scheduler_job.py:146} INFO - Started process (PID=9681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:20,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:20,126] {logging_mixin.py:95} INFO - [2019-08-28 14:25:20,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:20,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:20,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:20,511] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:20,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:20,545] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_csco_stock_data 2019-08-28 19:20:55.332807+00:00 [scheduled]> in ORM
[2019-08-28 14:25:20,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 14:25:20,577] {scheduler_job.py:146} INFO - Started process (PID=9685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:25,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:25,582] {logging_mixin.py:95} INFO - [2019-08-28 14:25:25,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:25,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:25,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:25,959] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:25,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:25,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:25:26,033] {scheduler_job.py:146} INFO - Started process (PID=9688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:31,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:31,045] {logging_mixin.py:95} INFO - [2019-08-28 14:25:31,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:31,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:31,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:31,422] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:31,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:31,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:25:31,481] {scheduler_job.py:146} INFO - Started process (PID=9693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:36,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:36,492] {logging_mixin.py:95} INFO - [2019-08-28 14:25:36,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:36,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:36,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:36,905] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:36,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:36,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 14:25:37,031] {scheduler_job.py:146} INFO - Started process (PID=9694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:42,040] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:42,041] {logging_mixin.py:95} INFO - [2019-08-28 14:25:42,041] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:42,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:42,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:42,425] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:42,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:42,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:25:42,482] {scheduler_job.py:146} INFO - Started process (PID=9696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:47,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:47,490] {logging_mixin.py:95} INFO - [2019-08-28 14:25:47,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:47,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:47,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:47,881] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:47,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:47,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:25:47,939] {scheduler_job.py:146} INFO - Started process (PID=9701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:52,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:52,950] {logging_mixin.py:95} INFO - [2019-08-28 14:25:52,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:53,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:53,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:53,334] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True>
[2019-08-28 14:25:53,341] {logging_mixin.py:95} INFO - [2019-08-28 14:25:53,341] {dagrun.py:308} INFO - Marking run <DagRun stock_data @ 2019-08-28 19:20:55.332807+00:00: manual__2019-08-28T19:20:55.332807+00:00, externally triggered: True> failed
[2019-08-28 14:25:53,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:53,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:25:53,395] {scheduler_job.py:146} INFO - Started process (PID=9702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:58,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:25:58,404] {logging_mixin.py:95} INFO - [2019-08-28 14:25:58,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:58,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:25:58,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:25:58,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:25:58,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 14:25:58,852] {scheduler_job.py:146} INFO - Started process (PID=9704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:03,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:03,860] {logging_mixin.py:95} INFO - [2019-08-28 14:26:03,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:04,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:04,245] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:04,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:04,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:26:04,299] {scheduler_job.py:146} INFO - Started process (PID=9709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:09,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:09,308] {logging_mixin.py:95} INFO - [2019-08-28 14:26:09,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:09,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:09,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:09,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:09,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:26:09,748] {scheduler_job.py:146} INFO - Started process (PID=9710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:14,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:14,758] {logging_mixin.py:95} INFO - [2019-08-28 14:26:14,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:15,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:15,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:15,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:15,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 14:26:15,198] {scheduler_job.py:146} INFO - Started process (PID=9712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:20,206] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:20,207] {logging_mixin.py:95} INFO - [2019-08-28 14:26:20,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:20,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:20,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:20,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:20,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:26:20,647] {scheduler_job.py:146} INFO - Started process (PID=9716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:25,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:25,654] {logging_mixin.py:95} INFO - [2019-08-28 14:26:25,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:26,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:26,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:26,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:26,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:26:26,101] {scheduler_job.py:146} INFO - Started process (PID=9717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:31,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:31,108] {logging_mixin.py:95} INFO - [2019-08-28 14:26:31,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:31,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:31,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:31,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:31,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:26:31,558] {scheduler_job.py:146} INFO - Started process (PID=9723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:36,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:36,568] {logging_mixin.py:95} INFO - [2019-08-28 14:26:36,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:36,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:36,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:36,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:36,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:26:37,015] {scheduler_job.py:146} INFO - Started process (PID=9724) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:42,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:42,023] {logging_mixin.py:95} INFO - [2019-08-28 14:26:42,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:42,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:42,432] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:42,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:42,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:26:42,551] {scheduler_job.py:146} INFO - Started process (PID=9725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:47,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:47,560] {logging_mixin.py:95} INFO - [2019-08-28 14:26:47,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:47,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:47,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:47,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:47,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 14:26:48,098] {scheduler_job.py:146} INFO - Started process (PID=9727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:53,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:53,109] {logging_mixin.py:95} INFO - [2019-08-28 14:26:53,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:53,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:53,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:53,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:53,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:26:53,547] {scheduler_job.py:146} INFO - Started process (PID=9731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:58,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:26:58,555] {logging_mixin.py:95} INFO - [2019-08-28 14:26:58,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:58,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:26:58,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:26:58,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:26:58,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 14:26:59,004] {scheduler_job.py:146} INFO - Started process (PID=9732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:04,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:04,014] {logging_mixin.py:95} INFO - [2019-08-28 14:27:04,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:04,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:04,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:04,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:04,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:27:04,464] {scheduler_job.py:146} INFO - Started process (PID=9735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:09,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:09,470] {logging_mixin.py:95} INFO - [2019-08-28 14:27:09,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:09,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:09,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:09,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:09,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:27:09,925] {scheduler_job.py:146} INFO - Started process (PID=9739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:14,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:14,935] {logging_mixin.py:95} INFO - [2019-08-28 14:27:14,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:15,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:15,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:15,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:15,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:27:15,373] {scheduler_job.py:146} INFO - Started process (PID=9741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:20,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:20,380] {logging_mixin.py:95} INFO - [2019-08-28 14:27:20,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:20,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:20,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:20,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:20,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 14:27:20,828] {scheduler_job.py:146} INFO - Started process (PID=9745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:25,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:25,836] {logging_mixin.py:95} INFO - [2019-08-28 14:27:25,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:26,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:26,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:26,217] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:26,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:27:26,287] {scheduler_job.py:146} INFO - Started process (PID=9746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:31,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:31,296] {logging_mixin.py:95} INFO - [2019-08-28 14:27:31,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:31,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:31,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:31,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:31,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:27:31,731] {scheduler_job.py:146} INFO - Started process (PID=9749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:36,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:36,742] {logging_mixin.py:95} INFO - [2019-08-28 14:27:36,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:37,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:37,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:37,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:37,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:27:37,190] {scheduler_job.py:146} INFO - Started process (PID=9750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:42,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:42,211] {logging_mixin.py:95} INFO - [2019-08-28 14:27:42,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:42,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:42,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:42,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:42,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:27:42,649] {scheduler_job.py:146} INFO - Started process (PID=9754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:47,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:47,661] {logging_mixin.py:95} INFO - [2019-08-28 14:27:47,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:48,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:48,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:48,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:48,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:27:48,096] {scheduler_job.py:146} INFO - Started process (PID=9756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:53,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:53,104] {logging_mixin.py:95} INFO - [2019-08-28 14:27:53,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:53,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:53,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:53,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:53,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 14:27:53,551] {scheduler_job.py:146} INFO - Started process (PID=9760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:58,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:27:58,557] {logging_mixin.py:95} INFO - [2019-08-28 14:27:58,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:58,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:27:58,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:27:58,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:27:58,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:27:58,991] {scheduler_job.py:146} INFO - Started process (PID=9761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:04,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:04,007] {logging_mixin.py:95} INFO - [2019-08-28 14:28:04,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:04,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:04,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:04,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:04,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 14:28:04,523] {scheduler_job.py:146} INFO - Started process (PID=9764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:09,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:09,535] {logging_mixin.py:95} INFO - [2019-08-28 14:28:09,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:09,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:09,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:09,922] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:09,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:28:09,975] {scheduler_job.py:146} INFO - Started process (PID=9765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:14,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:14,981] {logging_mixin.py:95} INFO - [2019-08-28 14:28:14,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:15,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:15,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:15,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:15,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:28:15,426] {scheduler_job.py:146} INFO - Started process (PID=9770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:20,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:20,435] {logging_mixin.py:95} INFO - [2019-08-28 14:28:20,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:20,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:20,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:20,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:20,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:28:20,874] {scheduler_job.py:146} INFO - Started process (PID=9771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:25,879] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:25,880] {logging_mixin.py:95} INFO - [2019-08-28 14:28:25,880] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:26,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:26,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:26,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:26,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:28:26,332] {scheduler_job.py:146} INFO - Started process (PID=9772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:31,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:31,340] {logging_mixin.py:95} INFO - [2019-08-28 14:28:31,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:31,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:31,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:31,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:31,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-08-28 14:28:31,881] {scheduler_job.py:146} INFO - Started process (PID=9778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:36,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:36,895] {logging_mixin.py:95} INFO - [2019-08-28 14:28:36,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:37,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:37,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:37,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:37,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:28:37,326] {scheduler_job.py:146} INFO - Started process (PID=9780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:42,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:42,331] {logging_mixin.py:95} INFO - [2019-08-28 14:28:42,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:42,698] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:42,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:42,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:42,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:28:42,760] {scheduler_job.py:146} INFO - Started process (PID=9785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:47,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:47,769] {logging_mixin.py:95} INFO - [2019-08-28 14:28:47,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:48,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:48,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:48,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:48,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 14:28:48,208] {scheduler_job.py:146} INFO - Started process (PID=9787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:53,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:53,217] {logging_mixin.py:95} INFO - [2019-08-28 14:28:53,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:53,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:53,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:53,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:53,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 14:28:53,656] {scheduler_job.py:146} INFO - Started process (PID=9788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:58,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:28:58,668] {logging_mixin.py:95} INFO - [2019-08-28 14:28:58,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:59,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:28:59,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:28:59,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:28:59,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:28:59,104] {scheduler_job.py:146} INFO - Started process (PID=9792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:04,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:04,114] {logging_mixin.py:95} INFO - [2019-08-28 14:29:04,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:04,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:04,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:04,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:04,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:29:04,563] {scheduler_job.py:146} INFO - Started process (PID=9794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:09,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:09,573] {logging_mixin.py:95} INFO - [2019-08-28 14:29:09,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:09,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:09,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:09,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:10,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 14:29:10,110] {scheduler_job.py:146} INFO - Started process (PID=9796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:15,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:15,122] {logging_mixin.py:95} INFO - [2019-08-28 14:29:15,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:15,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:15,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:15,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:15,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:29:15,556] {scheduler_job.py:146} INFO - Started process (PID=9801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:20,562] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:20,563] {logging_mixin.py:95} INFO - [2019-08-28 14:29:20,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:20,927] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:20,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:20,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:20,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:29:20,995] {scheduler_job.py:146} INFO - Started process (PID=9802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:26,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:26,006] {logging_mixin.py:95} INFO - [2019-08-28 14:29:26,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:26,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:26,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:26,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:26,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:29:26,433] {scheduler_job.py:146} INFO - Started process (PID=9803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:31,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:31,441] {logging_mixin.py:95} INFO - [2019-08-28 14:29:31,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:31,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:31,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:31,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:31,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 14:29:31,878] {scheduler_job.py:146} INFO - Started process (PID=9808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:36,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:36,889] {logging_mixin.py:95} INFO - [2019-08-28 14:29:36,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:37,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:37,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:37,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:37,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-08-28 14:29:37,426] {scheduler_job.py:146} INFO - Started process (PID=9810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:42,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:42,436] {logging_mixin.py:95} INFO - [2019-08-28 14:29:42,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:42,795] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:42,816] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:42,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:42,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:29:42,864] {scheduler_job.py:146} INFO - Started process (PID=9811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:47,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:47,872] {logging_mixin.py:95} INFO - [2019-08-28 14:29:47,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:48,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:48,293] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:48,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:48,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 14:29:48,411] {scheduler_job.py:146} INFO - Started process (PID=9820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:53,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:53,422] {logging_mixin.py:95} INFO - [2019-08-28 14:29:53,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:53,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:53,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:53,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:53,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:29:53,853] {scheduler_job.py:146} INFO - Started process (PID=9822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:58,859] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:29:58,860] {logging_mixin.py:95} INFO - [2019-08-28 14:29:58,860] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:59,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:29:59,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:29:59,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:29:59,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.527 seconds
[2019-08-28 14:29:59,401] {scheduler_job.py:146} INFO - Started process (PID=9827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:04,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:04,409] {logging_mixin.py:95} INFO - [2019-08-28 14:30:04,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:04,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:04,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:04,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:04,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:30:04,843] {scheduler_job.py:146} INFO - Started process (PID=9830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:09,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:09,852] {logging_mixin.py:95} INFO - [2019-08-28 14:30:09,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:10,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:10,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:10,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:10,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:30:10,284] {scheduler_job.py:146} INFO - Started process (PID=9832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:15,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:15,292] {logging_mixin.py:95} INFO - [2019-08-28 14:30:15,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:15,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:15,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:15,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:15,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 14:30:15,733] {scheduler_job.py:146} INFO - Started process (PID=9837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:20,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:20,742] {logging_mixin.py:95} INFO - [2019-08-28 14:30:20,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:21,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:21,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:21,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:21,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:30:21,278] {scheduler_job.py:146} INFO - Started process (PID=9838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:26,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:26,286] {logging_mixin.py:95} INFO - [2019-08-28 14:30:26,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:26,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:26,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:26,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:26,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 14:30:26,824] {scheduler_job.py:146} INFO - Started process (PID=9839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:31,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:31,834] {logging_mixin.py:95} INFO - [2019-08-28 14:30:31,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:32,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:32,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:32,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:32,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:30:32,273] {scheduler_job.py:146} INFO - Started process (PID=9841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:37,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:37,281] {logging_mixin.py:95} INFO - [2019-08-28 14:30:37,280] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:37,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:37,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:37,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:37,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:30:37,726] {scheduler_job.py:146} INFO - Started process (PID=9845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:42,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:42,738] {logging_mixin.py:95} INFO - [2019-08-28 14:30:42,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:43,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:43,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:43,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:43,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:30:43,177] {scheduler_job.py:146} INFO - Started process (PID=9847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:48,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:48,184] {logging_mixin.py:95} INFO - [2019-08-28 14:30:48,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:48,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:48,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:48,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:48,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:30:48,632] {scheduler_job.py:146} INFO - Started process (PID=9852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:53,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:53,644] {logging_mixin.py:95} INFO - [2019-08-28 14:30:53,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:54,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:54,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:30:54,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:30:54,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:30:54,089] {scheduler_job.py:146} INFO - Started process (PID=9853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:59,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:30:59,097] {logging_mixin.py:95} INFO - [2019-08-28 14:30:59,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:59,464] {logging_mixin.py:95} INFO - [2019-08-28 14:30:59,455] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 97, in <module>
    get_fb_stock_data, get_googl_stock_data,
NameError: name 'get_googl_stock_data' is not defined
[2019-08-28 14:30:59,465] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:30:59,473] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-08-28 14:30:59,548] {scheduler_job.py:146} INFO - Started process (PID=9855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:04,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:04,554] {logging_mixin.py:95} INFO - [2019-08-28 14:31:04,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:04,929] {logging_mixin.py:95} INFO - [2019-08-28 14:31:04,928] {dagbag.py:205} ERROR - Failed to import: /Users/hdeva/airflow/dags/hello_world_dag.py
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/hdeva/anaconda3/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 97, in <module>
    get_fb_stock_data, get_googl_stock_data,
NameError: name 'get_googl_stock_data' is not defined
[2019-08-28 14:31:04,929] {scheduler_job.py:1507} WARNING - No viable dags retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:04,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:31:04,998] {scheduler_job.py:146} INFO - Started process (PID=9859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:10,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:10,004] {logging_mixin.py:95} INFO - [2019-08-28 14:31:10,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:10,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:10,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:10,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:10,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 14:31:10,452] {scheduler_job.py:146} INFO - Started process (PID=9860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:15,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:15,458] {logging_mixin.py:95} INFO - [2019-08-28 14:31:15,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:15,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:15,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:15,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:15,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 14:31:16,006] {scheduler_job.py:146} INFO - Started process (PID=9863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:21,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:21,013] {logging_mixin.py:95} INFO - [2019-08-28 14:31:21,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:21,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:21,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:21,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:21,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 14:31:21,457] {scheduler_job.py:146} INFO - Started process (PID=9864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:26,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:26,465] {logging_mixin.py:95} INFO - [2019-08-28 14:31:26,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:26,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:26,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:26,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:26,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 14:31:26,916] {scheduler_job.py:146} INFO - Started process (PID=9868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:31,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:31,927] {logging_mixin.py:95} INFO - [2019-08-28 14:31:31,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:32,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:32,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:32,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:32,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 14:31:32,372] {scheduler_job.py:146} INFO - Started process (PID=9870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:37,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:37,377] {logging_mixin.py:95} INFO - [2019-08-28 14:31:37,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:37,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:37,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:37,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:37,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:31:37,827] {scheduler_job.py:146} INFO - Started process (PID=9871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:42,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:42,846] {logging_mixin.py:95} INFO - [2019-08-28 14:31:42,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:43,222] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:43,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:43,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:43,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:31:43,284] {scheduler_job.py:146} INFO - Started process (PID=9876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:48,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:48,296] {logging_mixin.py:95} INFO - [2019-08-28 14:31:48,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:48,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:48,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:48,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:48,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:31:48,732] {scheduler_job.py:146} INFO - Started process (PID=9878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:53,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:53,739] {logging_mixin.py:95} INFO - [2019-08-28 14:31:53,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:54,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:54,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:54,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:54,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:31:54,193] {scheduler_job.py:146} INFO - Started process (PID=9882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:59,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:31:59,204] {logging_mixin.py:95} INFO - [2019-08-28 14:31:59,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:59,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:31:59,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:31:59,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:31:59,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:31:59,643] {scheduler_job.py:146} INFO - Started process (PID=9884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:04,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:04,650] {logging_mixin.py:95} INFO - [2019-08-28 14:32:04,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:05,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:05,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:05,111] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:05,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:05,137] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:32:05,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-08-28 14:32:05,185] {scheduler_job.py:146} INFO - Started process (PID=9885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:10,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:10,193] {logging_mixin.py:95} INFO - [2019-08-28 14:32:10,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:10,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:10,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:10,587] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:10,607] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:10,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 14:32:10,632] {scheduler_job.py:146} INFO - Started process (PID=9890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:15,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:15,640] {logging_mixin.py:95} INFO - [2019-08-28 14:32:15,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:16,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:16,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:16,059] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:16,079] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:16,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-08-28 14:32:16,195] {scheduler_job.py:146} INFO - Started process (PID=9893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:21,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:21,203] {logging_mixin.py:95} INFO - [2019-08-28 14:32:21,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:21,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:21,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:21,601] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:21,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:21,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 14:32:21,655] {scheduler_job.py:146} INFO - Started process (PID=9894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:26,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:26,663] {logging_mixin.py:95} INFO - [2019-08-28 14:32:26,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:27,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:27,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:27,070] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:27,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:27,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 14:32:27,115] {scheduler_job.py:146} INFO - Started process (PID=9896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:32,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:32,126] {logging_mixin.py:95} INFO - [2019-08-28 14:32:32,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:32,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:32,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:32,511] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:32,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:32,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 14:32:32,579] {scheduler_job.py:146} INFO - Started process (PID=9901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:37,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:37,591] {logging_mixin.py:95} INFO - [2019-08-28 14:32:37,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:37,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:38,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:38,027] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:38,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:38,054] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:32:38,056] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:32:38,059] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:32:38,071] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-08-28 14:32:38,145] {scheduler_job.py:146} INFO - Started process (PID=9902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:43,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:43,154] {logging_mixin.py:95} INFO - [2019-08-28 14:32:43,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:43,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:43,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:43,531] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:43,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:43,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:32:43,604] {scheduler_job.py:146} INFO - Started process (PID=9907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:48,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:48,616] {logging_mixin.py:95} INFO - [2019-08-28 14:32:48,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:48,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:48,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:49,005] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:49,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:49,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:32:49,059] {scheduler_job.py:146} INFO - Started process (PID=9910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:54,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:54,069] {logging_mixin.py:95} INFO - [2019-08-28 14:32:54,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:54,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:54,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:54,450] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:54,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:54,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:32:54,520] {scheduler_job.py:146} INFO - Started process (PID=9911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:59,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:32:59,531] {logging_mixin.py:95} INFO - [2019-08-28 14:32:59,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:59,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:32:59,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:32:59,906] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:32:59,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:32:59,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 14:32:59,979] {scheduler_job.py:146} INFO - Started process (PID=9915) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:04,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:04,991] {logging_mixin.py:95} INFO - [2019-08-28 14:33:04,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:05,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:05,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:05,405] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:05,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:05,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 14:33:05,447] {scheduler_job.py:146} INFO - Started process (PID=9919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:10,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:10,455] {logging_mixin.py:95} INFO - [2019-08-28 14:33:10,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:10,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:10,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:10,837] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:10,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:10,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:33:10,914] {scheduler_job.py:146} INFO - Started process (PID=9920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:15,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:15,923] {logging_mixin.py:95} INFO - [2019-08-28 14:33:15,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:16,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:16,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:16,304] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:16,321] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:16,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:33:16,380] {scheduler_job.py:146} INFO - Started process (PID=9925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:21,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:21,394] {logging_mixin.py:95} INFO - [2019-08-28 14:33:21,393] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:21,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:21,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:21,776] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:21,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:21,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:33:21,841] {scheduler_job.py:146} INFO - Started process (PID=9927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:26,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:26,850] {logging_mixin.py:95} INFO - [2019-08-28 14:33:26,850] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:27,195] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:27,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:27,226] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:27,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:27,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:33:27,305] {scheduler_job.py:146} INFO - Started process (PID=9928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:32,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:32,317] {logging_mixin.py:95} INFO - [2019-08-28 14:33:32,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:32,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:32,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:32,698] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:32,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:32,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 14:33:32,772] {scheduler_job.py:146} INFO - Started process (PID=9933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:37,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:37,783] {logging_mixin.py:95} INFO - [2019-08-28 14:33:37,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:38,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:38,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:38,164] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:38,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:38,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:33:38,240] {scheduler_job.py:146} INFO - Started process (PID=9934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:43,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:43,264] {logging_mixin.py:95} INFO - [2019-08-28 14:33:43,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:43,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:43,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:43,645] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:43,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:43,666] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 14:33:43,701] {scheduler_job.py:146} INFO - Started process (PID=9935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:48,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:48,713] {logging_mixin.py:95} INFO - [2019-08-28 14:33:48,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:49,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:49,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:49,110] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:49,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:49,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 14:33:49,153] {scheduler_job.py:146} INFO - Started process (PID=9938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:54,164] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:54,165] {logging_mixin.py:95} INFO - [2019-08-28 14:33:54,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:54,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:54,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:33:54,548] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:33:54,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:33:54,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:33:54,611] {scheduler_job.py:146} INFO - Started process (PID=9942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:59,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:33:59,619] {logging_mixin.py:95} INFO - [2019-08-28 14:33:59,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:33:59,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:00,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:34:00,028] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:34:00,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:34:00,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 14:34:00,075] {scheduler_job.py:146} INFO - Started process (PID=9947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:05,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:34:05,085] {logging_mixin.py:95} INFO - [2019-08-28 14:34:05,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:05,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:05,457] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:34:05,466] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:34:05,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:34:05,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:34:05,530] {scheduler_job.py:146} INFO - Started process (PID=9948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:10,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:34:10,538] {logging_mixin.py:95} INFO - [2019-08-28 14:34:10,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:10,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:34:10,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:34:10,978] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:34:10,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:34:10,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-08-28 14:38:02,641] {scheduler_job.py:146} INFO - Started process (PID=10018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:07,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:07,655] {logging_mixin.py:95} INFO - [2019-08-28 14:38:07,654] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:08,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:08,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:08,052] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:08,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:08,080] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:38:08,084] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:38:08,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 14:38:08,191] {scheduler_job.py:146} INFO - Started process (PID=10023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:13,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:13,212] {logging_mixin.py:95} INFO - [2019-08-28 14:38:13,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:13,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:13,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:13,642] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:13,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:13,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-08-28 14:38:13,750] {scheduler_job.py:146} INFO - Started process (PID=10025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:18,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:18,761] {logging_mixin.py:95} INFO - [2019-08-28 14:38:18,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:19,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:19,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:19,141] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:19,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:19,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 14:38:19,199] {scheduler_job.py:146} INFO - Started process (PID=10030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:24,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:24,213] {logging_mixin.py:95} INFO - [2019-08-28 14:38:24,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:24,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:24,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:24,598] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:24,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:24,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 14:38:24,652] {scheduler_job.py:146} INFO - Started process (PID=10031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:29,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:29,664] {logging_mixin.py:95} INFO - [2019-08-28 14:38:29,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:30,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:30,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:30,125] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:30,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:30,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-08-28 14:38:30,192] {scheduler_job.py:146} INFO - Started process (PID=10036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:35,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:35,203] {logging_mixin.py:95} INFO - [2019-08-28 14:38:35,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:35,599] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:35,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:35,627] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:35,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:35,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-08-28 14:38:35,725] {scheduler_job.py:146} INFO - Started process (PID=10038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:40,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:40,745] {logging_mixin.py:95} INFO - [2019-08-28 14:38:40,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:41,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:41,131] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:41,138] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:41,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:41,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 14:38:41,186] {scheduler_job.py:146} INFO - Started process (PID=10042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:46,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:46,196] {logging_mixin.py:95} INFO - [2019-08-28 14:38:46,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:46,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:46,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:46,572] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:46,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:46,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 14:38:46,641] {scheduler_job.py:146} INFO - Started process (PID=10044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:51,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:51,651] {logging_mixin.py:95} INFO - [2019-08-28 14:38:51,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:52,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:52,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:52,033] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:52,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:52,056] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 14:38:52,099] {scheduler_job.py:146} INFO - Started process (PID=10048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:57,111] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:38:57,112] {logging_mixin.py:95} INFO - [2019-08-28 14:38:57,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:57,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:38:57,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:38:57,491] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:38:57,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:38:57,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:38:57,565] {scheduler_job.py:146} INFO - Started process (PID=10049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:02,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:02,574] {logging_mixin.py:95} INFO - [2019-08-28 14:39:02,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:02,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:02,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:02,973] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:02,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:02,994] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-08-28 19:31:59.615125+00:00 [scheduled]> in ORM
[2019-08-28 14:39:03,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 14:39:03,111] {scheduler_job.py:146} INFO - Started process (PID=10053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:08,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:08,130] {logging_mixin.py:95} INFO - [2019-08-28 14:39:08,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:08,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:08,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:08,542] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:08,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:08,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 14:39:08,666] {scheduler_job.py:146} INFO - Started process (PID=10055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:13,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:13,678] {logging_mixin.py:95} INFO - [2019-08-28 14:39:13,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:14,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:14,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:14,076] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:14,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:14,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 14:39:14,120] {scheduler_job.py:146} INFO - Started process (PID=10059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:19,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:19,129] {logging_mixin.py:95} INFO - [2019-08-28 14:39:19,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:19,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:19,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:19,535] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:19,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:19,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 14:39:19,669] {scheduler_job.py:146} INFO - Started process (PID=10063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:24,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:24,677] {logging_mixin.py:95} INFO - [2019-08-28 14:39:24,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:25,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:25,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:25,081] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:25,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:25,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 14:39:25,125] {scheduler_job.py:146} INFO - Started process (PID=10064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:30,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:30,134] {logging_mixin.py:95} INFO - [2019-08-28 14:39:30,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:30,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:30,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:30,565] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:30,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:30,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 14:39:30,673] {scheduler_job.py:146} INFO - Started process (PID=10070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:35,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:35,682] {logging_mixin.py:95} INFO - [2019-08-28 14:39:35,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:36,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:36,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:36,102] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:36,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:36,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 14:39:36,215] {scheduler_job.py:146} INFO - Started process (PID=10071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:41,226] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:39:41,229] {logging_mixin.py:95} INFO - [2019-08-28 14:39:41,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:41,578] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:39:41,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:39:41,609] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:39:41,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:39:41,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 14:41:45,157] {scheduler_job.py:146} INFO - Started process (PID=10116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:50,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:41:50,166] {logging_mixin.py:95} INFO - [2019-08-28 14:41:50,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:50,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:50,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:41:50,588] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:41:50,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:41:50,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-08-28 14:41:50,708] {scheduler_job.py:146} INFO - Started process (PID=10120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:55,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:41:55,719] {logging_mixin.py:95} INFO - [2019-08-28 14:41:55,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:56,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:41:56,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:41:56,112] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:41:56,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:41:56,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:41:56,167] {scheduler_job.py:146} INFO - Started process (PID=10121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:01,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:01,177] {logging_mixin.py:95} INFO - [2019-08-28 14:42:01,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:01,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:01,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:01,547] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:01,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:01,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:42:01,631] {scheduler_job.py:146} INFO - Started process (PID=10123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:06,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:06,643] {logging_mixin.py:95} INFO - [2019-08-28 14:42:06,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:06,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:07,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:07,024] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:07,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:07,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:42:07,086] {scheduler_job.py:146} INFO - Started process (PID=10128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:12,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:12,093] {logging_mixin.py:95} INFO - [2019-08-28 14:42:12,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:12,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:12,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:12,508] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:12,519] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:12,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 14:42:12,545] {scheduler_job.py:146} INFO - Started process (PID=10129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:17,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:17,555] {logging_mixin.py:95} INFO - [2019-08-28 14:42:17,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:17,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:17,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:17,994] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:18,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:18,020] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-08-28 14:42:18,097] {scheduler_job.py:146} INFO - Started process (PID=10135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:23,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:23,105] {logging_mixin.py:95} INFO - [2019-08-28 14:42:23,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:23,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:23,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:23,509] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:23,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:23,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 14:42:23,641] {scheduler_job.py:146} INFO - Started process (PID=10136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:28,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:28,651] {logging_mixin.py:95} INFO - [2019-08-28 14:42:28,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:29,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:29,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:29,076] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:29,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:29,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 14:42:29,191] {scheduler_job.py:146} INFO - Started process (PID=10137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:34,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:34,200] {logging_mixin.py:95} INFO - [2019-08-28 14:42:34,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:34,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:34,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:34,587] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:34,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:34,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:42:34,648] {scheduler_job.py:146} INFO - Started process (PID=10142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:39,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:39,656] {logging_mixin.py:95} INFO - [2019-08-28 14:42:39,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:40,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:40,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:40,075] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:40,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:40,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 14:42:40,203] {scheduler_job.py:146} INFO - Started process (PID=10143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:45,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:45,211] {logging_mixin.py:95} INFO - [2019-08-28 14:42:45,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:45,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:45,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:45,604] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:45,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:45,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:42:45,660] {scheduler_job.py:146} INFO - Started process (PID=10145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:50,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:50,668] {logging_mixin.py:95} INFO - [2019-08-28 14:42:50,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:51,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:51,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:51,078] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:51,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:51,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 14:42:51,116] {scheduler_job.py:146} INFO - Started process (PID=10148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:56,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:42:56,125] {logging_mixin.py:95} INFO - [2019-08-28 14:42:56,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:56,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:42:56,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:42:56,503] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:42:56,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:42:56,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 14:42:56,562] {scheduler_job.py:146} INFO - Started process (PID=10152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:01,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:01,571] {logging_mixin.py:95} INFO - [2019-08-28 14:43:01,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:01,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:01,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:01,971] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:43:01,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:01,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 14:43:02,012] {scheduler_job.py:146} INFO - Started process (PID=10156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:07,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:07,021] {logging_mixin.py:95} INFO - [2019-08-28 14:43:07,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:07,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:07,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:07,395] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:43:07,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:07,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 14:43:07,466] {scheduler_job.py:146} INFO - Started process (PID=10163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:12,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:12,471] {logging_mixin.py:95} INFO - [2019-08-28 14:43:12,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:12,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:12,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:12,868] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:43:12,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:12,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:43:12,920] {scheduler_job.py:146} INFO - Started process (PID=10164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:17,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:17,926] {logging_mixin.py:95} INFO - [2019-08-28 14:43:17,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:18,366] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:18,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:18,394] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:43:18,409] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:18,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.494 seconds
[2019-08-28 14:43:33,342] {scheduler_job.py:146} INFO - Started process (PID=10171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:38,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:38,353] {logging_mixin.py:95} INFO - [2019-08-28 14:43:38,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:38,718] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:38,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:38,750] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True>
[2019-08-28 14:43:38,757] {logging_mixin.py:95} INFO - [2019-08-28 14:43:38,756] {dagrun.py:308} INFO - Marking run <DagRun stock_data @ 2019-08-28 19:31:59.615125+00:00: manual__2019-08-28T19:31:59.615125+00:00, externally triggered: True> failed
[2019-08-28 14:43:38,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:38,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:43:38,788] {scheduler_job.py:146} INFO - Started process (PID=10175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:43,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:43,794] {logging_mixin.py:95} INFO - [2019-08-28 14:43:43,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:44,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:44,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:44,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:44,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 14:43:44,245] {scheduler_job.py:146} INFO - Started process (PID=10176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:49,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:49,251] {logging_mixin.py:95} INFO - [2019-08-28 14:43:49,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:49,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:49,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:49,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:49,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 14:43:49,688] {scheduler_job.py:146} INFO - Started process (PID=10178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:54,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:43:54,696] {logging_mixin.py:95} INFO - [2019-08-28 14:43:54,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:55,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:43:55,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:43:55,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:43:55,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-08-28 14:43:55,242] {scheduler_job.py:146} INFO - Started process (PID=10184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:00,249] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:00,250] {logging_mixin.py:95} INFO - [2019-08-28 14:44:00,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:00,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:00,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:00,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:00,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 14:44:00,699] {scheduler_job.py:146} INFO - Started process (PID=10186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:05,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:05,706] {logging_mixin.py:95} INFO - [2019-08-28 14:44:05,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:06,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:06,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:06,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:06,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:44:06,153] {scheduler_job.py:146} INFO - Started process (PID=10187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:11,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:11,172] {logging_mixin.py:95} INFO - [2019-08-28 14:44:11,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:11,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:11,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:11,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:11,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 14:44:11,694] {scheduler_job.py:146} INFO - Started process (PID=10188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:16,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:16,702] {logging_mixin.py:95} INFO - [2019-08-28 14:44:16,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:17,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:17,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:17,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:17,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 14:44:17,141] {scheduler_job.py:146} INFO - Started process (PID=10193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:22,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:22,151] {logging_mixin.py:95} INFO - [2019-08-28 14:44:22,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:22,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:22,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:22,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:22,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 14:44:22,591] {scheduler_job.py:146} INFO - Started process (PID=10194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:27,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:27,599] {logging_mixin.py:95} INFO - [2019-08-28 14:44:27,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:27,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:27,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:28,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:28,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 14:44:28,042] {scheduler_job.py:146} INFO - Started process (PID=10196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:33,050] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:33,051] {logging_mixin.py:95} INFO - [2019-08-28 14:44:33,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:33,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:33,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:33,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:33,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 14:44:33,499] {scheduler_job.py:146} INFO - Started process (PID=10201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:38,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:38,508] {logging_mixin.py:95} INFO - [2019-08-28 14:44:38,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:38,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:38,881] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:38,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:38,895] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 14:44:38,952] {scheduler_job.py:146} INFO - Started process (PID=10202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:43,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:43,958] {logging_mixin.py:95} INFO - [2019-08-28 14:44:43,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:44,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:44,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:44,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:44,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 14:44:44,405] {scheduler_job.py:146} INFO - Started process (PID=10206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:49,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:49,410] {logging_mixin.py:95} INFO - [2019-08-28 14:44:49,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:49,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:49,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:49,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:49,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 14:44:49,849] {scheduler_job.py:146} INFO - Started process (PID=10208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:54,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:44:54,856] {logging_mixin.py:95} INFO - [2019-08-28 14:44:54,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:55,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:44:55,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:44:55,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:44:55,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 14:44:55,290] {scheduler_job.py:146} INFO - Started process (PID=10212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:00,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:00,297] {logging_mixin.py:95} INFO - [2019-08-28 14:45:00,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:00,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:00,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:00,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:00,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 14:45:00,737] {scheduler_job.py:146} INFO - Started process (PID=10215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:05,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:05,746] {logging_mixin.py:95} INFO - [2019-08-28 14:45:05,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:06,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:06,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:06,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:06,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 14:45:06,182] {scheduler_job.py:146} INFO - Started process (PID=10216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:11,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:11,200] {logging_mixin.py:95} INFO - [2019-08-28 14:45:11,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:11,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:11,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:11,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:11,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 14:45:11,643] {scheduler_job.py:146} INFO - Started process (PID=10217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:16,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:16,653] {logging_mixin.py:95} INFO - [2019-08-28 14:45:16,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:16,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:16,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:17,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:17,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-08-28 14:45:17,088] {scheduler_job.py:146} INFO - Started process (PID=10222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:22,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:22,094] {logging_mixin.py:95} INFO - [2019-08-28 14:45:22,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:22,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:22,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:22,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:22,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 14:45:22,545] {scheduler_job.py:146} INFO - Started process (PID=10223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:27,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:27,556] {logging_mixin.py:95} INFO - [2019-08-28 14:45:27,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:27,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:27,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:27,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:27,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 14:45:28,003] {scheduler_job.py:146} INFO - Started process (PID=10224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:33,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:33,013] {logging_mixin.py:95} INFO - [2019-08-28 14:45:33,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:33,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:33,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:33,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:33,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 14:45:33,466] {scheduler_job.py:146} INFO - Started process (PID=10230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:38,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:38,474] {logging_mixin.py:95} INFO - [2019-08-28 14:45:38,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:38,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:38,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:38,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:38,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 14:45:38,931] {scheduler_job.py:146} INFO - Started process (PID=10231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:43,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:43,943] {logging_mixin.py:95} INFO - [2019-08-28 14:45:43,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:44,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:44,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:44,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:44,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.633 seconds
[2019-08-28 14:45:44,591] {scheduler_job.py:146} INFO - Started process (PID=10235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:49,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 14:45:49,598] {logging_mixin.py:95} INFO - [2019-08-28 14:45:49,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:49,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 14:45:49,975] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 14:45:49,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 14:45:49,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 14:45:50,050] {scheduler_job.py:146} INFO - Started process (PID=10237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:46,169] {scheduler_job.py:146} INFO - Started process (PID=11357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:51,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:01:51,182] {logging_mixin.py:95} INFO - [2019-08-28 17:01:51,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:51,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:51,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:01:51,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:01:51,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.675 seconds
[2019-08-28 17:01:51,941] {scheduler_job.py:146} INFO - Started process (PID=11359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:56,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:01:56,964] {logging_mixin.py:95} INFO - [2019-08-28 17:01:56,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:57,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:01:57,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:01:57,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:01:57,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 17:01:57,396] {scheduler_job.py:146} INFO - Started process (PID=11360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:02:02,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:02:02,406] {logging_mixin.py:95} INFO - [2019-08-28 17:02:02,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:02:02,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:02:02,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:02:02,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:02:02,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 17:02:02,851] {scheduler_job.py:146} INFO - Started process (PID=11361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:43,060] {scheduler_job.py:146} INFO - Started process (PID=18675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:48,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:26:48,069] {logging_mixin.py:95} INFO - [2019-08-28 17:26:48,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:48,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:48,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:26:48,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:26:48,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.637 seconds
[2019-08-28 17:26:48,803] {scheduler_job.py:146} INFO - Started process (PID=18676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:53,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:26:53,812] {logging_mixin.py:95} INFO - [2019-08-28 17:26:53,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:54,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:54,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:26:54,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:26:54,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.518 seconds
[2019-08-28 17:26:54,349] {scheduler_job.py:146} INFO - Started process (PID=18678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:59,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:26:59,361] {logging_mixin.py:95} INFO - [2019-08-28 17:26:59,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:59,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:26:59,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:26:59,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:26:59,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.569 seconds
[2019-08-28 17:26:59,997] {scheduler_job.py:146} INFO - Started process (PID=18679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:05,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:05,008] {logging_mixin.py:95} INFO - [2019-08-28 17:27:05,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:05,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:05,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:05,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:05,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 17:27:05,452] {scheduler_job.py:146} INFO - Started process (PID=18682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:10,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:10,465] {logging_mixin.py:95} INFO - [2019-08-28 17:27:10,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:10,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:10,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:10,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:10,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 17:27:10,912] {scheduler_job.py:146} INFO - Started process (PID=18684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:15,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:15,923] {logging_mixin.py:95} INFO - [2019-08-28 17:27:15,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:16,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:16,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:16,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:16,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 17:27:16,369] {scheduler_job.py:146} INFO - Started process (PID=18685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:21,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:21,380] {logging_mixin.py:95} INFO - [2019-08-28 17:27:21,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:21,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:21,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:21,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:21,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 17:27:21,821] {scheduler_job.py:146} INFO - Started process (PID=18686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:26,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:26,830] {logging_mixin.py:95} INFO - [2019-08-28 17:27:26,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:27,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:27,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:27,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:27,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 17:27:27,276] {scheduler_job.py:146} INFO - Started process (PID=18688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:32,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:32,285] {logging_mixin.py:95} INFO - [2019-08-28 17:27:32,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:32,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:32,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:32,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:32,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 17:27:32,821] {scheduler_job.py:146} INFO - Started process (PID=18692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:37,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:37,832] {logging_mixin.py:95} INFO - [2019-08-28 17:27:37,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:38,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:38,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:38,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:38,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 17:27:38,364] {scheduler_job.py:146} INFO - Started process (PID=18695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:43,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:43,373] {logging_mixin.py:95} INFO - [2019-08-28 17:27:43,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:43,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:43,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:43,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:43,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:27:43,809] {scheduler_job.py:146} INFO - Started process (PID=18696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:48,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:48,821] {logging_mixin.py:95} INFO - [2019-08-28 17:27:48,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:49,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:49,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:49,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:49,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:27:49,266] {scheduler_job.py:146} INFO - Started process (PID=18697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:54,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:54,279] {logging_mixin.py:95} INFO - [2019-08-28 17:27:54,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:54,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:54,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:27:54,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:27:54,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 17:27:54,714] {scheduler_job.py:146} INFO - Started process (PID=18699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:27:59,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:27:59,722] {logging_mixin.py:95} INFO - [2019-08-28 17:27:59,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:00,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:00,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:00,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:00,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 17:28:00,167] {scheduler_job.py:146} INFO - Started process (PID=18700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:05,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:05,176] {logging_mixin.py:95} INFO - [2019-08-28 17:28:05,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:05,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:05,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:05,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:05,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 17:28:05,620] {scheduler_job.py:146} INFO - Started process (PID=18702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:10,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:10,634] {logging_mixin.py:95} INFO - [2019-08-28 17:28:10,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:11,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:11,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:11,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:11,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 17:28:11,168] {scheduler_job.py:146} INFO - Started process (PID=18705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:16,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:16,176] {logging_mixin.py:95} INFO - [2019-08-28 17:28:16,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:16,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:16,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:16,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:16,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 17:28:16,623] {scheduler_job.py:146} INFO - Started process (PID=18706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:21,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:21,631] {logging_mixin.py:95} INFO - [2019-08-28 17:28:21,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:22,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:22,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:22,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:22,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 17:28:22,072] {scheduler_job.py:146} INFO - Started process (PID=18707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:27,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:27,081] {logging_mixin.py:95} INFO - [2019-08-28 17:28:27,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:27,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:27,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:27,534] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:27,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:27,565] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:28:27,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-08-28 17:28:27,631] {scheduler_job.py:146} INFO - Started process (PID=18709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:32,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:32,650] {logging_mixin.py:95} INFO - [2019-08-28 17:28:32,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:33,031] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:33,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:33,055] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:33,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:33,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 17:28:33,173] {scheduler_job.py:146} INFO - Started process (PID=18711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:38,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:38,180] {logging_mixin.py:95} INFO - [2019-08-28 17:28:38,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:38,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:38,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:38,612] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:38,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:38,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-08-28 17:28:38,714] {scheduler_job.py:146} INFO - Started process (PID=18714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:43,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:43,722] {logging_mixin.py:95} INFO - [2019-08-28 17:28:43,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:44,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:44,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:44,135] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:44,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:44,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 17:28:44,261] {scheduler_job.py:146} INFO - Started process (PID=18715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:49,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:49,271] {logging_mixin.py:95} INFO - [2019-08-28 17:28:49,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:49,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:49,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:49,672] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:49,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:49,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 17:28:49,717] {scheduler_job.py:146} INFO - Started process (PID=18717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:54,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:28:54,725] {logging_mixin.py:95} INFO - [2019-08-28 17:28:54,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:55,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:28:55,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:28:55,154] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:28:55,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:28:55,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 17:28:55,273] {scheduler_job.py:146} INFO - Started process (PID=18719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:00,284] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:00,285] {logging_mixin.py:95} INFO - [2019-08-28 17:29:00,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:00,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:00,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:00,688] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:00,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:00,713] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:29:00,716] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:29:00,718] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:29:00,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-28 17:29:00,839] {scheduler_job.py:146} INFO - Started process (PID=18720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:05,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:05,847] {logging_mixin.py:95} INFO - [2019-08-28 17:29:05,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:06,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:06,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:06,258] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:06,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:06,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 17:29:06,385] {scheduler_job.py:146} INFO - Started process (PID=18723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:11,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:11,394] {logging_mixin.py:95} INFO - [2019-08-28 17:29:11,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:11,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:11,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:11,786] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:11,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:11,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:29:11,839] {scheduler_job.py:146} INFO - Started process (PID=18727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:16,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:16,849] {logging_mixin.py:95} INFO - [2019-08-28 17:29:16,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:17,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:17,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:17,320] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:17,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:17,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.517 seconds
[2019-08-28 17:29:17,392] {scheduler_job.py:146} INFO - Started process (PID=18729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:22,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:22,400] {logging_mixin.py:95} INFO - [2019-08-28 17:29:22,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:22,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:22,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:22,839] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:22,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:22,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-08-28 17:29:22,932] {scheduler_job.py:146} INFO - Started process (PID=18732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:27,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:27,946] {logging_mixin.py:95} INFO - [2019-08-28 17:29:27,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:28,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:28,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:28,347] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:28,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:28,367] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 17:29:28,388] {scheduler_job.py:146} INFO - Started process (PID=18733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:33,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:33,394] {logging_mixin.py:95} INFO - [2019-08-28 17:29:33,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:33,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:33,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:33,771] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:33,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:33,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 17:29:33,848] {scheduler_job.py:146} INFO - Started process (PID=18734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:38,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:38,858] {logging_mixin.py:95} INFO - [2019-08-28 17:29:38,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:39,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:39,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:39,262] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:39,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:39,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 17:29:39,396] {scheduler_job.py:146} INFO - Started process (PID=18737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:44,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:44,403] {logging_mixin.py:95} INFO - [2019-08-28 17:29:44,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:44,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:44,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:44,786] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:44,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:44,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 17:29:44,848] {scheduler_job.py:146} INFO - Started process (PID=18739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:49,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:49,856] {logging_mixin.py:95} INFO - [2019-08-28 17:29:49,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:50,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:50,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:50,240] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:50,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:50,260] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 17:29:50,301] {scheduler_job.py:146} INFO - Started process (PID=18740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:55,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:29:55,311] {logging_mixin.py:95} INFO - [2019-08-28 17:29:55,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:55,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:29:55,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:29:55,694] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:29:55,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:29:55,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 17:29:55,756] {scheduler_job.py:146} INFO - Started process (PID=18743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:00,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:00,768] {logging_mixin.py:95} INFO - [2019-08-28 17:30:00,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:01,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:01,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:01,144] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:01,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:01,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 17:30:01,215] {scheduler_job.py:146} INFO - Started process (PID=18745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:06,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:06,224] {logging_mixin.py:95} INFO - [2019-08-28 17:30:06,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:06,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:06,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:06,611] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:06,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:06,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 17:30:06,673] {scheduler_job.py:146} INFO - Started process (PID=18747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:11,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:11,687] {logging_mixin.py:95} INFO - [2019-08-28 17:30:11,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:12,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:12,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:12,071] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:12,087] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:12,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 17:30:12,126] {scheduler_job.py:146} INFO - Started process (PID=18750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:17,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:17,138] {logging_mixin.py:95} INFO - [2019-08-28 17:30:17,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:17,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:17,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:17,562] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:17,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:17,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-08-28 17:30:17,679] {scheduler_job.py:146} INFO - Started process (PID=18752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:22,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:22,692] {logging_mixin.py:95} INFO - [2019-08-28 17:30:22,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:23,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:23,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:23,068] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:23,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:23,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 17:30:23,141] {scheduler_job.py:146} INFO - Started process (PID=18754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:28,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:28,161] {logging_mixin.py:95} INFO - [2019-08-28 17:30:28,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:28,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:28,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:28,546] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:28,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:28,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 17:30:28,601] {scheduler_job.py:146} INFO - Started process (PID=18756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:33,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:33,612] {logging_mixin.py:95} INFO - [2019-08-28 17:30:33,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:33,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:33,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:33,998] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:34,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:34,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 17:30:40,520] {scheduler_job.py:146} INFO - Started process (PID=18758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:45,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:45,528] {logging_mixin.py:95} INFO - [2019-08-28 17:30:45,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:45,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:45,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:45,911] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:45,927] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:45,930] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:30:45,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 17:30:45,982] {scheduler_job.py:146} INFO - Started process (PID=18759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:50,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:50,994] {logging_mixin.py:95} INFO - [2019-08-28 17:30:50,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:51,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:51,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:51,378] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:51,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:51,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 17:30:51,437] {scheduler_job.py:146} INFO - Started process (PID=18762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:56,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:30:56,449] {logging_mixin.py:95} INFO - [2019-08-28 17:30:56,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:56,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:30:56,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:30:56,837] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:30:56,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:30:56,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:30:56,895] {scheduler_job.py:146} INFO - Started process (PID=18764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:01,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:01,903] {logging_mixin.py:95} INFO - [2019-08-28 17:31:01,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:02,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:02,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:02,320] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:02,334] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:02,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 17:31:02,451] {scheduler_job.py:146} INFO - Started process (PID=18765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:07,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:07,458] {logging_mixin.py:95} INFO - [2019-08-28 17:31:07,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:07,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:07,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:07,872] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:07,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:07,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 17:31:08,000] {scheduler_job.py:146} INFO - Started process (PID=18771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:13,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:13,009] {logging_mixin.py:95} INFO - [2019-08-28 17:31:13,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:13,432] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:13,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:13,456] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:13,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:13,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-08-28 17:31:13,551] {scheduler_job.py:146} INFO - Started process (PID=18772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:18,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:18,563] {logging_mixin.py:95} INFO - [2019-08-28 17:31:18,562] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:18,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:18,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:18,979] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:18,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:19,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 17:31:19,101] {scheduler_job.py:146} INFO - Started process (PID=18774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:24,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:24,113] {logging_mixin.py:95} INFO - [2019-08-28 17:31:24,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:24,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:24,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:24,505] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:24,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:24,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 17:31:24,555] {scheduler_job.py:146} INFO - Started process (PID=18776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:29,564] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:29,565] {logging_mixin.py:95} INFO - [2019-08-28 17:31:29,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:29,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:29,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:29,995] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:30,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:30,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 17:31:30,110] {scheduler_job.py:146} INFO - Started process (PID=18777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:35,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:35,120] {logging_mixin.py:95} INFO - [2019-08-28 17:31:35,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:35,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:35,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:35,499] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:35,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:35,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 17:31:35,563] {scheduler_job.py:146} INFO - Started process (PID=18778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:40,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:40,573] {logging_mixin.py:95} INFO - [2019-08-28 17:31:40,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:40,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:40,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:40,965] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:40,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:40,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 17:31:41,018] {scheduler_job.py:146} INFO - Started process (PID=18780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:46,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:46,024] {logging_mixin.py:95} INFO - [2019-08-28 17:31:46,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:46,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:46,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:46,419] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:46,435] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:46,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 17:31:46,475] {scheduler_job.py:146} INFO - Started process (PID=18781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:51,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:51,484] {logging_mixin.py:95} INFO - [2019-08-28 17:31:51,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:51,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:51,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:51,969] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:51,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:51,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.518 seconds
[2019-08-28 17:31:52,028] {scheduler_job.py:146} INFO - Started process (PID=18783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:57,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:31:57,035] {logging_mixin.py:95} INFO - [2019-08-28 17:31:57,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:57,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:31:57,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:31:57,422] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:31:57,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:31:57,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:31:57,482] {scheduler_job.py:146} INFO - Started process (PID=18785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:02,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:02,489] {logging_mixin.py:95} INFO - [2019-08-28 17:32:02,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:02,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:02,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:02,870] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:02,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:02,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 17:32:02,939] {scheduler_job.py:146} INFO - Started process (PID=18787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:07,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:07,946] {logging_mixin.py:95} INFO - [2019-08-28 17:32:07,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:08,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:08,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:08,333] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:08,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:08,353] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 17:32:08,381] {scheduler_job.py:146} INFO - Started process (PID=18789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:13,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:13,387] {logging_mixin.py:95} INFO - [2019-08-28 17:32:13,386] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:13,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:13,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:13,772] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:13,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:13,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 17:32:13,836] {scheduler_job.py:146} INFO - Started process (PID=18790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:18,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:18,847] {logging_mixin.py:95} INFO - [2019-08-28 17:32:18,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:19,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:19,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:19,231] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:19,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:19,250] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_to_s3 2019-08-28 22:28:22.184591+00:00 [scheduled]> in ORM
[2019-08-28 17:32:19,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 17:32:19,298] {scheduler_job.py:146} INFO - Started process (PID=18791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:24,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:24,306] {logging_mixin.py:95} INFO - [2019-08-28 17:32:24,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:24,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:24,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:24,694] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:24,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:24,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 17:32:24,750] {scheduler_job.py:146} INFO - Started process (PID=18795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:29,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:29,771] {logging_mixin.py:95} INFO - [2019-08-28 17:32:29,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:30,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:30,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:30,154] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:30,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:30,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:32:30,216] {scheduler_job.py:146} INFO - Started process (PID=18796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:35,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:35,224] {logging_mixin.py:95} INFO - [2019-08-28 17:32:35,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:35,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:35,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:35,608] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:35,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:35,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 17:32:35,683] {scheduler_job.py:146} INFO - Started process (PID=18797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:40,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:40,689] {logging_mixin.py:95} INFO - [2019-08-28 17:32:40,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:41,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:41,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:41,066] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:41,079] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:41,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:32:41,148] {scheduler_job.py:146} INFO - Started process (PID=18800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:46,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:46,159] {logging_mixin.py:95} INFO - [2019-08-28 17:32:46,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:46,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:46,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:46,546] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:46,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:46,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 17:32:46,610] {scheduler_job.py:146} INFO - Started process (PID=18801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:51,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:51,619] {logging_mixin.py:95} INFO - [2019-08-28 17:32:51,618] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:51,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:52,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:52,028] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:52,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:52,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 17:32:52,168] {scheduler_job.py:146} INFO - Started process (PID=18802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:57,175] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:32:57,177] {logging_mixin.py:95} INFO - [2019-08-28 17:32:57,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:57,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:57,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:32:57,583] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True>
[2019-08-28 17:32:57,589] {logging_mixin.py:95} INFO - [2019-08-28 17:32:57,589] {dagrun.py:308} INFO - Marking run <DagRun stock_data @ 2019-08-28 22:28:22.184591+00:00: manual__2019-08-28T22:28:22.184591+00:00, externally triggered: True> failed
[2019-08-28 17:32:57,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:32:57,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 17:32:57,620] {scheduler_job.py:146} INFO - Started process (PID=18805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:02,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:02,630] {logging_mixin.py:95} INFO - [2019-08-28 17:33:02,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:02,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:03,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:03,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:03,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 17:33:03,076] {scheduler_job.py:146} INFO - Started process (PID=18807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:08,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:08,083] {logging_mixin.py:95} INFO - [2019-08-28 17:33:08,083] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:08,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:08,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:08,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:08,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 17:33:08,536] {scheduler_job.py:146} INFO - Started process (PID=18809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:13,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:13,543] {logging_mixin.py:95} INFO - [2019-08-28 17:33:13,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:13,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:13,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:13,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:13,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 17:33:13,990] {scheduler_job.py:146} INFO - Started process (PID=18810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:18,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:18,996] {logging_mixin.py:95} INFO - [2019-08-28 17:33:18,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:19,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:19,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:19,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:19,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:33:19,443] {scheduler_job.py:146} INFO - Started process (PID=18811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:24,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:24,450] {logging_mixin.py:95} INFO - [2019-08-28 17:33:24,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:24,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:24,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:24,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:24,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:33:24,901] {scheduler_job.py:146} INFO - Started process (PID=18814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:29,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:29,908] {logging_mixin.py:95} INFO - [2019-08-28 17:33:29,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:30,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:30,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:30,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:30,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 17:33:30,361] {scheduler_job.py:146} INFO - Started process (PID=18815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:35,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:35,372] {logging_mixin.py:95} INFO - [2019-08-28 17:33:35,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:35,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:35,754] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:35,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:35,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 17:33:35,825] {scheduler_job.py:146} INFO - Started process (PID=18816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:40,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:40,831] {logging_mixin.py:95} INFO - [2019-08-28 17:33:40,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:41,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:41,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:41,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:41,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 17:33:41,289] {scheduler_job.py:146} INFO - Started process (PID=18818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:46,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:46,294] {logging_mixin.py:95} INFO - [2019-08-28 17:33:46,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:46,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:46,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:46,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:46,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 17:33:46,742] {scheduler_job.py:146} INFO - Started process (PID=18819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:51,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:51,751] {logging_mixin.py:95} INFO - [2019-08-28 17:33:51,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:52,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:52,131] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:52,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:52,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:33:52,200] {scheduler_job.py:146} INFO - Started process (PID=18820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:57,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:33:57,211] {logging_mixin.py:95} INFO - [2019-08-28 17:33:57,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:57,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:33:57,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:33:57,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:33:57,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-08-28 17:33:57,762] {scheduler_job.py:146} INFO - Started process (PID=18823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:02,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:34:02,773] {logging_mixin.py:95} INFO - [2019-08-28 17:34:02,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:03,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:03,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:34:03,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:34:03,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 17:34:03,224] {scheduler_job.py:146} INFO - Started process (PID=18825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:08,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:34:08,232] {logging_mixin.py:95} INFO - [2019-08-28 17:34:08,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:08,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:08,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:34:08,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:34:08,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 17:34:08,688] {scheduler_job.py:146} INFO - Started process (PID=18827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:13,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:34:13,699] {logging_mixin.py:95} INFO - [2019-08-28 17:34:13,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:14,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:14,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:34:14,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:34:14,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 17:34:14,152] {scheduler_job.py:146} INFO - Started process (PID=18828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:19,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:34:19,158] {logging_mixin.py:95} INFO - [2019-08-28 17:34:19,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:19,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:19,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:34:19,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:34:19,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 17:34:19,606] {scheduler_job.py:146} INFO - Started process (PID=18829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:24,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:34:24,612] {logging_mixin.py:95} INFO - [2019-08-28 17:34:24,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:24,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:34:24,995] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:34:25,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:34:25,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 17:34:25,057] {scheduler_job.py:146} INFO - Started process (PID=18831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:18,687] {scheduler_job.py:146} INFO - Started process (PID=18984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:23,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:23,695] {logging_mixin.py:95} INFO - [2019-08-28 17:57:23,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:24,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:24,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:24,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:24,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.674 seconds
[2019-08-28 17:57:24,456] {scheduler_job.py:146} INFO - Started process (PID=18986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:29,465] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:29,475] {logging_mixin.py:95} INFO - [2019-08-28 17:57:29,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:30,012] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:30,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:30,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:30,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.586 seconds
[2019-08-28 17:57:30,115] {scheduler_job.py:146} INFO - Started process (PID=18987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:35,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:35,124] {logging_mixin.py:95} INFO - [2019-08-28 17:57:35,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:35,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:35,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:35,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:35,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.546 seconds
[2019-08-28 17:57:35,762] {scheduler_job.py:146} INFO - Started process (PID=18988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:40,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:40,771] {logging_mixin.py:95} INFO - [2019-08-28 17:57:40,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:41,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:41,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:41,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:41,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.538 seconds
[2019-08-28 17:57:41,411] {scheduler_job.py:146} INFO - Started process (PID=18994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:46,418] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:46,419] {logging_mixin.py:95} INFO - [2019-08-28 17:57:46,419] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:46,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:46,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:46,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:46,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 17:57:46,871] {scheduler_job.py:146} INFO - Started process (PID=18995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:51,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:51,882] {logging_mixin.py:95} INFO - [2019-08-28 17:57:51,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:52,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:52,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:52,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:52,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 17:57:52,324] {scheduler_job.py:146} INFO - Started process (PID=18996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:57,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:57:57,333] {logging_mixin.py:95} INFO - [2019-08-28 17:57:57,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:57,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:57:57,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:57:57,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:57:57,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-08-28 17:57:57,793] {scheduler_job.py:146} INFO - Started process (PID=18998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:02,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:02,801] {logging_mixin.py:95} INFO - [2019-08-28 17:58:02,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:03,158] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:03,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:03,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:03,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 17:58:03,252] {scheduler_job.py:146} INFO - Started process (PID=18999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:08,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:08,265] {logging_mixin.py:95} INFO - [2019-08-28 17:58:08,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:08,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:08,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:08,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:08,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 17:58:08,804] {scheduler_job.py:146} INFO - Started process (PID=19001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:13,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:13,816] {logging_mixin.py:95} INFO - [2019-08-28 17:58:13,816] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:14,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:14,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:14,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:14,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 17:58:14,264] {scheduler_job.py:146} INFO - Started process (PID=19003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:19,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:19,275] {logging_mixin.py:95} INFO - [2019-08-28 17:58:19,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:19,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:19,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:19,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:19,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 17:58:19,719] {scheduler_job.py:146} INFO - Started process (PID=19005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:24,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:24,727] {logging_mixin.py:95} INFO - [2019-08-28 17:58:24,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:25,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:25,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:25,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:25,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 17:58:25,170] {scheduler_job.py:146} INFO - Started process (PID=19007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:30,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:30,180] {logging_mixin.py:95} INFO - [2019-08-28 17:58:30,180] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:30,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:30,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:30,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:30,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 17:58:30,625] {scheduler_job.py:146} INFO - Started process (PID=19008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:35,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:35,633] {logging_mixin.py:95} INFO - [2019-08-28 17:58:35,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:36,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:36,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:36,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:36,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 17:58:36,080] {scheduler_job.py:146} INFO - Started process (PID=19009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:41,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:41,092] {logging_mixin.py:95} INFO - [2019-08-28 17:58:41,092] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:41,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:41,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:41,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:41,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 17:58:41,533] {scheduler_job.py:146} INFO - Started process (PID=19011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:46,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:46,546] {logging_mixin.py:95} INFO - [2019-08-28 17:58:46,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:46,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:46,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:46,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:46,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 17:58:46,989] {scheduler_job.py:146} INFO - Started process (PID=19012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:51,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:51,999] {logging_mixin.py:95} INFO - [2019-08-28 17:58:51,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:52,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:52,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:52,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:52,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 17:58:52,446] {scheduler_job.py:146} INFO - Started process (PID=19014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:57,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:58:57,458] {logging_mixin.py:95} INFO - [2019-08-28 17:58:57,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:57,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:58:57,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:58:57,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:58:57,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 17:58:57,906] {scheduler_job.py:146} INFO - Started process (PID=19016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:02,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:02,916] {logging_mixin.py:95} INFO - [2019-08-28 17:59:02,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:03,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:03,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:03,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:03,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 17:59:03,367] {scheduler_job.py:146} INFO - Started process (PID=19017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:08,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:08,378] {logging_mixin.py:95} INFO - [2019-08-28 17:59:08,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:08,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:08,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:08,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:08,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-08-28 17:59:08,826] {scheduler_job.py:146} INFO - Started process (PID=19019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:13,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:13,835] {logging_mixin.py:95} INFO - [2019-08-28 17:59:13,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:14,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:14,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:14,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:14,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 17:59:14,274] {scheduler_job.py:146} INFO - Started process (PID=19021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:19,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:19,283] {logging_mixin.py:95} INFO - [2019-08-28 17:59:19,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:19,658] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:19,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:19,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:19,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 17:59:19,726] {scheduler_job.py:146} INFO - Started process (PID=19022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:24,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:24,734] {logging_mixin.py:95} INFO - [2019-08-28 17:59:24,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:25,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:25,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:25,151] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:25,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 17:59:25,177] {scheduler_job.py:146} INFO - Started process (PID=19025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:30,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:30,189] {logging_mixin.py:95} INFO - [2019-08-28 17:59:30,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:30,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:30,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:30,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:30,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 17:59:30,627] {scheduler_job.py:146} INFO - Started process (PID=19026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:35,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:35,635] {logging_mixin.py:95} INFO - [2019-08-28 17:59:35,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:36,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:36,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:36,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:36,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 17:59:36,084] {scheduler_job.py:146} INFO - Started process (PID=19027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:41,091] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:41,092] {logging_mixin.py:95} INFO - [2019-08-28 17:59:41,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:41,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:41,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:41,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:41,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 17:59:41,545] {scheduler_job.py:146} INFO - Started process (PID=19029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:46,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:46,554] {logging_mixin.py:95} INFO - [2019-08-28 17:59:46,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:46,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:46,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:46,940] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:46,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 17:59:47,005] {scheduler_job.py:146} INFO - Started process (PID=19030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:52,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:52,014] {logging_mixin.py:95} INFO - [2019-08-28 17:59:52,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:52,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:52,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:52,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:52,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-08-28 17:59:52,456] {scheduler_job.py:146} INFO - Started process (PID=19032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:57,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 17:59:57,464] {logging_mixin.py:95} INFO - [2019-08-28 17:59:57,464] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:57,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:59:57,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 17:59:57,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 17:59:57,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 17:59:57,915] {scheduler_job.py:146} INFO - Started process (PID=19034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:02,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:02,926] {logging_mixin.py:95} INFO - [2019-08-28 18:00:02,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:03,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:03,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:03,358] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:03,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 18:00:03,467] {scheduler_job.py:146} INFO - Started process (PID=19035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:08,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:08,479] {logging_mixin.py:95} INFO - [2019-08-28 18:00:08,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:08,831] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:08,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:08,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:08,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:00:08,920] {scheduler_job.py:146} INFO - Started process (PID=19037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:13,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:13,929] {logging_mixin.py:95} INFO - [2019-08-28 18:00:13,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:14,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:14,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:14,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:14,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 18:00:14,370] {scheduler_job.py:146} INFO - Started process (PID=19039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:19,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:19,381] {logging_mixin.py:95} INFO - [2019-08-28 18:00:19,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:19,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:19,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:19,785] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:19,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:00:19,816] {scheduler_job.py:146} INFO - Started process (PID=19040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:24,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:24,828] {logging_mixin.py:95} INFO - [2019-08-28 18:00:24,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:25,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:25,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:25,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:25,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:00:25,277] {scheduler_job.py:146} INFO - Started process (PID=19043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:30,285] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:30,297] {logging_mixin.py:95} INFO - [2019-08-28 18:00:30,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:30,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:30,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:30,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:30,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:00:30,739] {scheduler_job.py:146} INFO - Started process (PID=19044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:35,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:35,751] {logging_mixin.py:95} INFO - [2019-08-28 18:00:35,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:36,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:36,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:36,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:36,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:00:36,197] {scheduler_job.py:146} INFO - Started process (PID=19045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:41,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:41,208] {logging_mixin.py:95} INFO - [2019-08-28 18:00:41,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:41,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:41,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:41,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:41,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:00:41,657] {scheduler_job.py:146} INFO - Started process (PID=19047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:46,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:46,666] {logging_mixin.py:95} INFO - [2019-08-28 18:00:46,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:47,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:47,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:47,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:47,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:00:47,111] {scheduler_job.py:146} INFO - Started process (PID=19048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:52,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:52,125] {logging_mixin.py:95} INFO - [2019-08-28 18:00:52,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:52,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:52,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:52,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:52,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:00:52,570] {scheduler_job.py:146} INFO - Started process (PID=19049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:57,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:00:57,585] {logging_mixin.py:95} INFO - [2019-08-28 18:00:57,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:57,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:00:57,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:00:57,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:00:57,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:00:58,023] {scheduler_job.py:146} INFO - Started process (PID=19052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:03,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:03,032] {logging_mixin.py:95} INFO - [2019-08-28 18:01:03,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:03,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:03,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:03,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:03,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:01:03,488] {scheduler_job.py:146} INFO - Started process (PID=19053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:08,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:08,497] {logging_mixin.py:95} INFO - [2019-08-28 18:01:08,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:08,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:08,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:08,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:08,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:01:08,951] {scheduler_job.py:146} INFO - Started process (PID=19055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:13,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:13,964] {logging_mixin.py:95} INFO - [2019-08-28 18:01:13,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:14,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:14,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:14,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:14,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:01:14,418] {scheduler_job.py:146} INFO - Started process (PID=19057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:19,429] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:19,430] {logging_mixin.py:95} INFO - [2019-08-28 18:01:19,430] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:19,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:19,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:19,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:19,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-08-28 18:01:19,887] {scheduler_job.py:146} INFO - Started process (PID=19058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:24,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:24,897] {logging_mixin.py:95} INFO - [2019-08-28 18:01:24,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:25,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:25,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:25,315] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:25,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:01:25,346] {scheduler_job.py:146} INFO - Started process (PID=19060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:30,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:30,366] {logging_mixin.py:95} INFO - [2019-08-28 18:01:30,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:30,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:30,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:30,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:30,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 18:01:30,805] {scheduler_job.py:146} INFO - Started process (PID=19062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:35,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:35,813] {logging_mixin.py:95} INFO - [2019-08-28 18:01:35,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:36,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:36,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:36,190] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:36,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:01:36,268] {scheduler_job.py:146} INFO - Started process (PID=19063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:41,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:41,279] {logging_mixin.py:95} INFO - [2019-08-28 18:01:41,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:41,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:41,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:41,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:41,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 18:01:41,721] {scheduler_job.py:146} INFO - Started process (PID=19065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:46,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:46,728] {logging_mixin.py:95} INFO - [2019-08-28 18:01:46,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:47,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:47,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:47,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:47,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:01:47,178] {scheduler_job.py:146} INFO - Started process (PID=19066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:52,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:52,187] {logging_mixin.py:95} INFO - [2019-08-28 18:01:52,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:52,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:52,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:52,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:52,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:01:52,633] {scheduler_job.py:146} INFO - Started process (PID=19067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:57,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:01:57,644] {logging_mixin.py:95} INFO - [2019-08-28 18:01:57,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:58,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:01:58,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:01:58,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:01:58,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:01:58,084] {scheduler_job.py:146} INFO - Started process (PID=19070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:03,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:03,095] {logging_mixin.py:95} INFO - [2019-08-28 18:02:03,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:03,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:03,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:03,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:03,498] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:02:03,542] {scheduler_job.py:146} INFO - Started process (PID=19071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:08,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:08,549] {logging_mixin.py:95} INFO - [2019-08-28 18:02:08,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:08,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:08,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:08,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:08,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:02:09,001] {scheduler_job.py:146} INFO - Started process (PID=19073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:14,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:14,008] {logging_mixin.py:95} INFO - [2019-08-28 18:02:14,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:14,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:14,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:14,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:14,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:02:14,461] {scheduler_job.py:146} INFO - Started process (PID=19075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:19,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:19,467] {logging_mixin.py:95} INFO - [2019-08-28 18:02:19,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:19,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:19,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:19,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:19,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:02:19,940] {scheduler_job.py:146} INFO - Started process (PID=19076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:24,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:24,947] {logging_mixin.py:95} INFO - [2019-08-28 18:02:24,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:25,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:25,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:25,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:25,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:02:25,403] {scheduler_job.py:146} INFO - Started process (PID=19078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:30,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:30,412] {logging_mixin.py:95} INFO - [2019-08-28 18:02:30,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:30,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:30,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:30,846] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:30,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 18:02:30,952] {scheduler_job.py:146} INFO - Started process (PID=19080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:35,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:35,961] {logging_mixin.py:95} INFO - [2019-08-28 18:02:35,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:36,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:36,328] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:36,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:36,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:02:36,398] {scheduler_job.py:146} INFO - Started process (PID=19081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:41,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:41,405] {logging_mixin.py:95} INFO - [2019-08-28 18:02:41,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:41,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:41,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:41,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:41,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:02:41,855] {scheduler_job.py:146} INFO - Started process (PID=19083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:46,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:46,861] {logging_mixin.py:95} INFO - [2019-08-28 18:02:46,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:47,249] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:47,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:47,275] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:47,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 18:02:47,304] {scheduler_job.py:146} INFO - Started process (PID=19084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:52,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:52,311] {logging_mixin.py:95} INFO - [2019-08-28 18:02:52,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:52,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:52,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:52,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:52,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:02:52,762] {scheduler_job.py:146} INFO - Started process (PID=19085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:57,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:02:57,778] {logging_mixin.py:95} INFO - [2019-08-28 18:02:57,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:58,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:02:58,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:02:58,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:02:58,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:02:58,212] {scheduler_job.py:146} INFO - Started process (PID=19087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:03,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:03,220] {logging_mixin.py:95} INFO - [2019-08-28 18:03:03,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:03,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:03,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:03,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:03,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 18:03:03,666] {scheduler_job.py:146} INFO - Started process (PID=19089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:08,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:08,674] {logging_mixin.py:95} INFO - [2019-08-28 18:03:08,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:09,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:09,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:09,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:09,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:03:09,120] {scheduler_job.py:146} INFO - Started process (PID=19091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:14,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:14,127] {logging_mixin.py:95} INFO - [2019-08-28 18:03:14,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:14,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:14,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:14,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:14,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:03:14,560] {scheduler_job.py:146} INFO - Started process (PID=19093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:19,568] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:19,569] {logging_mixin.py:95} INFO - [2019-08-28 18:03:19,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:19,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:19,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:19,971] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:19,996] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:19,999] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:03:20,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 18:03:20,115] {scheduler_job.py:146} INFO - Started process (PID=19094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:25,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:25,122] {logging_mixin.py:95} INFO - [2019-08-28 18:03:25,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:25,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:25,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:25,547] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:25,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:25,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 18:03:25,670] {scheduler_job.py:146} INFO - Started process (PID=19097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:30,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:30,677] {logging_mixin.py:95} INFO - [2019-08-28 18:03:30,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:31,042] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:31,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:31,070] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:31,094] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:31,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:03:31,128] {scheduler_job.py:146} INFO - Started process (PID=19098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:36,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:36,146] {logging_mixin.py:95} INFO - [2019-08-28 18:03:36,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:36,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:36,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:36,547] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:36,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:36,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 18:03:36,685] {scheduler_job.py:146} INFO - Started process (PID=19100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:41,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:41,693] {logging_mixin.py:95} INFO - [2019-08-28 18:03:41,692] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:42,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:42,110] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:42,117] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:42,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:42,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-08-28 18:03:42,234] {scheduler_job.py:146} INFO - Started process (PID=19103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:47,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:47,242] {logging_mixin.py:95} INFO - [2019-08-28 18:03:47,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:47,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:47,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:47,658] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:47,684] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:47,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-08-28 18:03:47,786] {scheduler_job.py:146} INFO - Started process (PID=19104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:52,792] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:52,793] {logging_mixin.py:95} INFO - [2019-08-28 18:03:52,793] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:53,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:53,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:53,185] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:53,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:53,213] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:03:53,215] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:03:53,218] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:03:53,228] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 18:03:53,340] {scheduler_job.py:146} INFO - Started process (PID=19105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:58,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:03:58,347] {logging_mixin.py:95} INFO - [2019-08-28 18:03:58,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:58,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:03:58,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:03:58,722] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:03:58,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:03:58,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:03:58,793] {scheduler_job.py:146} INFO - Started process (PID=19110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:03,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:03,801] {logging_mixin.py:95} INFO - [2019-08-28 18:04:03,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:04,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:04,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:04,224] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:04,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:04,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 18:04:04,340] {scheduler_job.py:146} INFO - Started process (PID=19112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:09,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:09,351] {logging_mixin.py:95} INFO - [2019-08-28 18:04:09,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:09,729] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:09,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:09,755] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:09,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:09,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-08-28 18:04:09,892] {scheduler_job.py:146} INFO - Started process (PID=19115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:14,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:14,903] {logging_mixin.py:95} INFO - [2019-08-28 18:04:14,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:15,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:15,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:15,293] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:15,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:15,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 18:04:15,343] {scheduler_job.py:146} INFO - Started process (PID=19117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:20,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:20,352] {logging_mixin.py:95} INFO - [2019-08-28 18:04:20,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:20,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:20,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:20,737] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:20,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:20,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 18:04:20,805] {scheduler_job.py:146} INFO - Started process (PID=19118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:25,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:25,814] {logging_mixin.py:95} INFO - [2019-08-28 18:04:25,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:26,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:26,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:26,225] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:26,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:26,249] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_amzn_to_s3 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:04:26,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 18:04:26,365] {scheduler_job.py:146} INFO - Started process (PID=19121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:31,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:31,371] {logging_mixin.py:95} INFO - [2019-08-28 18:04:31,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:31,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:31,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:31,778] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:31,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:31,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 18:04:31,824] {scheduler_job.py:146} INFO - Started process (PID=19122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:36,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:36,830] {logging_mixin.py:95} INFO - [2019-08-28 18:04:36,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:37,175] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:37,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:37,207] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:37,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:37,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:04:37,285] {scheduler_job.py:146} INFO - Started process (PID=19124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:42,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:42,291] {logging_mixin.py:95} INFO - [2019-08-28 18:04:42,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:42,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:42,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:42,672] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:42,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:42,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:04:42,745] {scheduler_job.py:146} INFO - Started process (PID=19127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:47,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:47,752] {logging_mixin.py:95} INFO - [2019-08-28 18:04:47,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:48,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:48,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:48,137] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:48,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:48,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:04:48,205] {scheduler_job.py:146} INFO - Started process (PID=19128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:53,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:53,212] {logging_mixin.py:95} INFO - [2019-08-28 18:04:53,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:53,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:53,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:53,597] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:53,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:53,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:04:53,660] {scheduler_job.py:146} INFO - Started process (PID=19129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:58,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:04:58,669] {logging_mixin.py:95} INFO - [2019-08-28 18:04:58,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:59,018] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:04:59,035] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:04:59,043] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:04:59,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:04:59,069] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_msft_to_s3 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:04:59,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:04:59,115] {scheduler_job.py:146} INFO - Started process (PID=19132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:04,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:04,126] {logging_mixin.py:95} INFO - [2019-08-28 18:05:04,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:04,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:04,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:04,509] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:04,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:04,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:05:04,570] {scheduler_job.py:146} INFO - Started process (PID=19133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:09,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:09,577] {logging_mixin.py:95} INFO - [2019-08-28 18:05:09,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:09,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:09,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:09,981] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:09,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:10,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:05:10,025] {scheduler_job.py:146} INFO - Started process (PID=19137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:15,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:15,034] {logging_mixin.py:95} INFO - [2019-08-28 18:05:15,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:15,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:15,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:15,421] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:15,439] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:15,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:05:30,709] {scheduler_job.py:146} INFO - Started process (PID=19140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:35,714] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:35,715] {logging_mixin.py:95} INFO - [2019-08-28 18:05:35,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:36,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:36,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:36,094] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:36,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:36,115] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_fb_to_s3 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:05:36,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 18:05:36,174] {scheduler_job.py:146} INFO - Started process (PID=19142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:41,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:41,185] {logging_mixin.py:95} INFO - [2019-08-28 18:05:41,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:41,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:41,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:41,567] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:41,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:41,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:05:41,635] {scheduler_job.py:146} INFO - Started process (PID=19145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:46,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:46,642] {logging_mixin.py:95} INFO - [2019-08-28 18:05:46,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:47,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:47,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:47,033] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:47,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:47,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:05:47,098] {scheduler_job.py:146} INFO - Started process (PID=19146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:52,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:52,108] {logging_mixin.py:95} INFO - [2019-08-28 18:05:52,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:52,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:52,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:52,491] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:52,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:52,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:05:52,551] {scheduler_job.py:146} INFO - Started process (PID=19148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:57,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:05:57,563] {logging_mixin.py:95} INFO - [2019-08-28 18:05:57,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:57,923] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:05:57,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:05:57,953] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:05:57,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:05:57,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:05:58,000] {scheduler_job.py:146} INFO - Started process (PID=19150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:03,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:03,006] {logging_mixin.py:95} INFO - [2019-08-28 18:06:03,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:03,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:03,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:03,422] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:03,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:03,447] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-28 18:06:03,548] {scheduler_job.py:146} INFO - Started process (PID=19154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:08,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:08,558] {logging_mixin.py:95} INFO - [2019-08-28 18:06:08,558] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:08,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:08,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:08,966] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:08,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:08,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 18:06:09,009] {scheduler_job.py:146} INFO - Started process (PID=19156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:14,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:14,018] {logging_mixin.py:95} INFO - [2019-08-28 18:06:14,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:14,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:14,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:14,408] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:14,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:14,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 18:06:14,453] {scheduler_job.py:146} INFO - Started process (PID=19159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:19,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:19,462] {logging_mixin.py:95} INFO - [2019-08-28 18:06:19,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:19,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:19,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:19,839] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:19,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:19,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:06:19,901] {scheduler_job.py:146} INFO - Started process (PID=19161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:24,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:24,907] {logging_mixin.py:95} INFO - [2019-08-28 18:06:24,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:25,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:25,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:25,308] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:25,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:25,327] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-08-28 18:06:25,361] {scheduler_job.py:146} INFO - Started process (PID=19163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:30,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:30,372] {logging_mixin.py:95} INFO - [2019-08-28 18:06:30,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:30,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:30,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:30,806] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:30,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:30,823] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 18:06:30,920] {scheduler_job.py:146} INFO - Started process (PID=19166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:35,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:35,925] {logging_mixin.py:95} INFO - [2019-08-28 18:06:35,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:36,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:36,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:36,299] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:36,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:36,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:06:36,378] {scheduler_job.py:146} INFO - Started process (PID=19168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:41,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:41,384] {logging_mixin.py:95} INFO - [2019-08-28 18:06:41,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:41,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:41,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:41,753] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:41,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:41,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:06:41,832] {scheduler_job.py:146} INFO - Started process (PID=19171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:46,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:46,848] {logging_mixin.py:95} INFO - [2019-08-28 18:06:46,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:47,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:47,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:47,249] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:47,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:47,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 18:06:47,292] {scheduler_job.py:146} INFO - Started process (PID=19172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:52,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:52,299] {logging_mixin.py:95} INFO - [2019-08-28 18:06:52,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:52,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:52,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:52,679] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:52,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:52,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:06:52,744] {scheduler_job.py:146} INFO - Started process (PID=19174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:57,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:06:57,751] {logging_mixin.py:95} INFO - [2019-08-28 18:06:57,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:58,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:06:58,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:06:58,174] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:06:58,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:06:58,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-08-28 18:06:58,307] {scheduler_job.py:146} INFO - Started process (PID=19176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:03,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:03,316] {logging_mixin.py:95} INFO - [2019-08-28 18:07:03,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:03,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:03,710] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:03,718] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:03,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:03,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:07:03,765] {scheduler_job.py:146} INFO - Started process (PID=19177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:08,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:08,774] {logging_mixin.py:95} INFO - [2019-08-28 18:07:08,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:09,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:09,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:09,160] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:09,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:09,178] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.end 2019-08-28 23:03:15.168509+00:00 [scheduled]> in ORM
[2019-08-28 18:07:09,189] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:07:09,216] {scheduler_job.py:146} INFO - Started process (PID=19181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:14,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:14,224] {logging_mixin.py:95} INFO - [2019-08-28 18:07:14,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:14,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:14,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:14,599] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:14,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:14,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:07:14,671] {scheduler_job.py:146} INFO - Started process (PID=19185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:19,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:19,677] {logging_mixin.py:95} INFO - [2019-08-28 18:07:19,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:20,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:20,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:20,066] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:20,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:20,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:07:20,135] {scheduler_job.py:146} INFO - Started process (PID=19186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:25,144] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:25,145] {logging_mixin.py:95} INFO - [2019-08-28 18:07:25,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:25,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:25,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:25,532] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:25,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:25,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:07:25,596] {scheduler_job.py:146} INFO - Started process (PID=19188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:30,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:30,607] {logging_mixin.py:95} INFO - [2019-08-28 18:07:30,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:30,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:30,986] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:30,994] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:31,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:31,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:07:31,050] {scheduler_job.py:146} INFO - Started process (PID=19190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:36,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:36,057] {logging_mixin.py:95} INFO - [2019-08-28 18:07:36,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:36,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:36,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:36,501] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:36,512] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:36,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-08-28 18:07:36,600] {scheduler_job.py:146} INFO - Started process (PID=19194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:41,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:41,612] {logging_mixin.py:95} INFO - [2019-08-28 18:07:41,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:41,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:41,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:42,001] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True>
[2019-08-28 18:07:42,008] {logging_mixin.py:95} INFO - [2019-08-28 18:07:42,008] {dagrun.py:316} INFO - Marking run <DagRun stock_data @ 2019-08-28 23:03:15.168509+00:00: manual__2019-08-28T23:03:15.168509+00:00, externally triggered: True> successful
[2019-08-28 18:07:42,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:42,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:07:42,065] {scheduler_job.py:146} INFO - Started process (PID=19197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:47,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:47,071] {logging_mixin.py:95} INFO - [2019-08-28 18:07:47,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:47,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:47,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:47,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:47,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:07:47,527] {scheduler_job.py:146} INFO - Started process (PID=19199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:52,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:52,533] {logging_mixin.py:95} INFO - [2019-08-28 18:07:52,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:52,875] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:52,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:52,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:52,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-08-28 18:07:52,981] {scheduler_job.py:146} INFO - Started process (PID=19202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:57,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:07:58,000] {logging_mixin.py:95} INFO - [2019-08-28 18:07:58,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:58,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:07:58,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:07:58,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:07:58,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:07:58,435] {scheduler_job.py:146} INFO - Started process (PID=19204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:03,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:03,445] {logging_mixin.py:95} INFO - [2019-08-28 18:08:03,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:03,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:03,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:03,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:03,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 18:08:03,893] {scheduler_job.py:146} INFO - Started process (PID=19205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:08,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:08,901] {logging_mixin.py:95} INFO - [2019-08-28 18:08:08,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:09,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:09,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:09,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:09,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:08:09,350] {scheduler_job.py:146} INFO - Started process (PID=19207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:14,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:14,357] {logging_mixin.py:95} INFO - [2019-08-28 18:08:14,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:14,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:14,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:14,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:14,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 18:08:14,803] {scheduler_job.py:146} INFO - Started process (PID=19209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:19,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:19,809] {logging_mixin.py:95} INFO - [2019-08-28 18:08:19,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:20,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:20,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:20,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:20,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:08:20,253] {scheduler_job.py:146} INFO - Started process (PID=19211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:25,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:25,263] {logging_mixin.py:95} INFO - [2019-08-28 18:08:25,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:25,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:25,711] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:25,719] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:25,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-08-28 18:08:25,806] {scheduler_job.py:146} INFO - Started process (PID=19213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:30,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:30,816] {logging_mixin.py:95} INFO - [2019-08-28 18:08:30,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:31,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:31,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:31,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:31,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 18:08:31,262] {scheduler_job.py:146} INFO - Started process (PID=19216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:36,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:36,270] {logging_mixin.py:95} INFO - [2019-08-28 18:08:36,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:36,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:36,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:36,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:36,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 18:08:36,710] {scheduler_job.py:146} INFO - Started process (PID=19217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:41,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:41,720] {logging_mixin.py:95} INFO - [2019-08-28 18:08:41,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:42,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:42,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:42,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:42,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 18:08:42,158] {scheduler_job.py:146} INFO - Started process (PID=19219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:47,164] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:47,165] {logging_mixin.py:95} INFO - [2019-08-28 18:08:47,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:47,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:47,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:47,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:47,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:08:47,605] {scheduler_job.py:146} INFO - Started process (PID=19221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:52,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:52,612] {logging_mixin.py:95} INFO - [2019-08-28 18:08:52,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:53,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:53,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:53,037] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:53,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 18:08:53,073] {scheduler_job.py:146} INFO - Started process (PID=19222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:58,078] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:08:58,079] {logging_mixin.py:95} INFO - [2019-08-28 18:08:58,079] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:58,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:08:58,476] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:08:58,484] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:08:58,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:08:58,515] {scheduler_job.py:146} INFO - Started process (PID=19227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:03,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:03,522] {logging_mixin.py:95} INFO - [2019-08-28 18:09:03,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:03,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:03,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:03,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:03,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:09:03,969] {scheduler_job.py:146} INFO - Started process (PID=19229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:08,975] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:08,976] {logging_mixin.py:95} INFO - [2019-08-28 18:09:08,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:09,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:09,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:09,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:09,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:09:09,419] {scheduler_job.py:146} INFO - Started process (PID=19231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:14,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:14,428] {logging_mixin.py:95} INFO - [2019-08-28 18:09:14,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:14,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:14,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:14,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:14,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 18:09:14,965] {scheduler_job.py:146} INFO - Started process (PID=19233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:19,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:19,973] {logging_mixin.py:95} INFO - [2019-08-28 18:09:19,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:20,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:20,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:20,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:20,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:09:20,413] {scheduler_job.py:146} INFO - Started process (PID=19237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:25,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:25,422] {logging_mixin.py:95} INFO - [2019-08-28 18:09:25,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:25,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:25,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:25,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:25,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:09:25,869] {scheduler_job.py:146} INFO - Started process (PID=19239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:30,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:30,875] {logging_mixin.py:95} INFO - [2019-08-28 18:09:30,875] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:31,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:31,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:31,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:31,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 18:09:31,326] {scheduler_job.py:146} INFO - Started process (PID=19240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:36,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:36,336] {logging_mixin.py:95} INFO - [2019-08-28 18:09:36,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:36,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:36,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:36,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:36,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:09:36,784] {scheduler_job.py:146} INFO - Started process (PID=19241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:41,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:41,791] {logging_mixin.py:95} INFO - [2019-08-28 18:09:41,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:42,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:42,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:42,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:42,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:09:42,244] {scheduler_job.py:146} INFO - Started process (PID=19243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:47,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:47,253] {logging_mixin.py:95} INFO - [2019-08-28 18:09:47,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:47,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:47,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:47,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:47,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 18:09:47,694] {scheduler_job.py:146} INFO - Started process (PID=19244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:52,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:52,705] {logging_mixin.py:95} INFO - [2019-08-28 18:09:52,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:53,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:53,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:53,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:53,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-08-28 18:09:53,245] {scheduler_job.py:146} INFO - Started process (PID=19248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:58,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:09:58,252] {logging_mixin.py:95} INFO - [2019-08-28 18:09:58,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:58,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:09:58,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:09:58,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:09:58,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:09:58,695] {scheduler_job.py:146} INFO - Started process (PID=19251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:03,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:03,702] {logging_mixin.py:95} INFO - [2019-08-28 18:10:03,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:04,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:04,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:04,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:04,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-08-28 18:10:04,251] {scheduler_job.py:146} INFO - Started process (PID=19252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:09,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:09,260] {logging_mixin.py:95} INFO - [2019-08-28 18:10:09,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:09,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:09,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:09,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:09,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:10:09,698] {scheduler_job.py:146} INFO - Started process (PID=19255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:14,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:14,704] {logging_mixin.py:95} INFO - [2019-08-28 18:10:14,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:15,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:15,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:15,129] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:15,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 18:10:15,247] {scheduler_job.py:146} INFO - Started process (PID=19256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:20,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:20,257] {logging_mixin.py:95} INFO - [2019-08-28 18:10:20,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:20,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:20,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:20,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:20,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-08-28 18:10:20,798] {scheduler_job.py:146} INFO - Started process (PID=19257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:25,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:25,807] {logging_mixin.py:95} INFO - [2019-08-28 18:10:25,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:26,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:26,199] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:26,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:26,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 18:10:26,249] {scheduler_job.py:146} INFO - Started process (PID=19260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:31,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:31,256] {logging_mixin.py:95} INFO - [2019-08-28 18:10:31,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:31,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:31,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:31,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:31,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 18:10:31,700] {scheduler_job.py:146} INFO - Started process (PID=19261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:36,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:36,708] {logging_mixin.py:95} INFO - [2019-08-28 18:10:36,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:37,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:37,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:37,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:37,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:10:37,165] {scheduler_job.py:146} INFO - Started process (PID=19262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:42,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:42,172] {logging_mixin.py:95} INFO - [2019-08-28 18:10:42,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:42,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:42,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:42,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:42,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-08-28 18:10:42,614] {scheduler_job.py:146} INFO - Started process (PID=19266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:47,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:47,623] {logging_mixin.py:95} INFO - [2019-08-28 18:10:47,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:47,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:48,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:48,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:48,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:10:48,072] {scheduler_job.py:146} INFO - Started process (PID=19267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:53,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:53,077] {logging_mixin.py:95} INFO - [2019-08-28 18:10:53,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:53,460] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:53,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:53,484] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:53,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 18:10:53,522] {scheduler_job.py:146} INFO - Started process (PID=19269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:58,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:10:58,529] {logging_mixin.py:95} INFO - [2019-08-28 18:10:58,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:58,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:10:58,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:10:58,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:10:58,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 18:10:58,977] {scheduler_job.py:146} INFO - Started process (PID=19271) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:03,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:03,984] {logging_mixin.py:95} INFO - [2019-08-28 18:11:03,983] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:04,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:04,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:04,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:04,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:11:04,431] {scheduler_job.py:146} INFO - Started process (PID=19272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:09,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:09,438] {logging_mixin.py:95} INFO - [2019-08-28 18:11:09,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:09,801] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:09,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:09,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:09,836] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:11:09,885] {scheduler_job.py:146} INFO - Started process (PID=19275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:14,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:14,896] {logging_mixin.py:95} INFO - [2019-08-28 18:11:14,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:15,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:15,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:15,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:15,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:11:15,340] {scheduler_job.py:146} INFO - Started process (PID=19276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:20,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:20,346] {logging_mixin.py:95} INFO - [2019-08-28 18:11:20,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:20,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:20,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:20,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:20,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:11:20,795] {scheduler_job.py:146} INFO - Started process (PID=19277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:25,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:25,802] {logging_mixin.py:95} INFO - [2019-08-28 18:11:25,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:26,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:26,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:26,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:26,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:11:26,254] {scheduler_job.py:146} INFO - Started process (PID=19280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:31,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:31,264] {logging_mixin.py:95} INFO - [2019-08-28 18:11:31,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:31,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:31,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:31,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:31,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:11:31,713] {scheduler_job.py:146} INFO - Started process (PID=19281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:36,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:36,720] {logging_mixin.py:95} INFO - [2019-08-28 18:11:36,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:37,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:37,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:37,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:37,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:11:37,168] {scheduler_job.py:146} INFO - Started process (PID=19282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:42,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:42,177] {logging_mixin.py:95} INFO - [2019-08-28 18:11:42,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:42,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:42,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:42,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:42,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:11:42,623] {scheduler_job.py:146} INFO - Started process (PID=19286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:47,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:47,633] {logging_mixin.py:95} INFO - [2019-08-28 18:11:47,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:47,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:48,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:48,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:48,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:11:48,080] {scheduler_job.py:146} INFO - Started process (PID=19287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:53,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:53,087] {logging_mixin.py:95} INFO - [2019-08-28 18:11:53,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:53,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:53,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:53,512] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:53,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 18:11:53,541] {scheduler_job.py:146} INFO - Started process (PID=19288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:58,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:11:58,556] {logging_mixin.py:95} INFO - [2019-08-28 18:11:58,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:58,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:11:58,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:11:58,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:11:58,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 18:11:58,997] {scheduler_job.py:146} INFO - Started process (PID=19291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:04,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:04,003] {logging_mixin.py:95} INFO - [2019-08-28 18:12:04,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:04,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:04,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:04,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:04,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:12:04,449] {scheduler_job.py:146} INFO - Started process (PID=19292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:09,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:09,459] {logging_mixin.py:95} INFO - [2019-08-28 18:12:09,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:09,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:09,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:09,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:09,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 18:12:09,905] {scheduler_job.py:146} INFO - Started process (PID=19295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:14,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:14,912] {logging_mixin.py:95} INFO - [2019-08-28 18:12:14,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:15,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:15,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:15,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:15,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:12:15,360] {scheduler_job.py:146} INFO - Started process (PID=19296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:20,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:20,369] {logging_mixin.py:95} INFO - [2019-08-28 18:12:20,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:20,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:20,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:20,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:20,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:12:20,823] {scheduler_job.py:146} INFO - Started process (PID=19297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:25,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:25,831] {logging_mixin.py:95} INFO - [2019-08-28 18:12:25,831] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:26,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:26,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:26,231] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:26,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:12:26,275] {scheduler_job.py:146} INFO - Started process (PID=19301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:31,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:31,281] {logging_mixin.py:95} INFO - [2019-08-28 18:12:31,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:31,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:31,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:31,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:31,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 18:12:31,825] {scheduler_job.py:146} INFO - Started process (PID=19303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:36,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:36,832] {logging_mixin.py:95} INFO - [2019-08-28 18:12:36,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:37,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:37,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:37,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:37,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:12:37,272] {scheduler_job.py:146} INFO - Started process (PID=19304) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:42,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:42,282] {logging_mixin.py:95} INFO - [2019-08-28 18:12:42,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:42,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:42,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:42,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:42,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 18:12:42,728] {scheduler_job.py:146} INFO - Started process (PID=19306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:47,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:47,736] {logging_mixin.py:95} INFO - [2019-08-28 18:12:47,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:48,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:48,129] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:48,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:48,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:12:48,180] {scheduler_job.py:146} INFO - Started process (PID=19307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:53,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:53,189] {logging_mixin.py:95} INFO - [2019-08-28 18:12:53,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:53,567] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:53,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:53,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:53,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 18:12:53,633] {scheduler_job.py:146} INFO - Started process (PID=19308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:58,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:12:58,642] {logging_mixin.py:95} INFO - [2019-08-28 18:12:58,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:59,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:12:59,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:12:59,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:12:59,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:12:59,089] {scheduler_job.py:146} INFO - Started process (PID=19311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:04,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:04,100] {logging_mixin.py:95} INFO - [2019-08-28 18:13:04,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:04,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:04,483] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:04,491] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:04,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:13:04,545] {scheduler_job.py:146} INFO - Started process (PID=19314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:09,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:09,554] {logging_mixin.py:95} INFO - [2019-08-28 18:13:09,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:09,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:09,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:09,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:09,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:13:09,996] {scheduler_job.py:146} INFO - Started process (PID=19318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:15,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:15,004] {logging_mixin.py:95} INFO - [2019-08-28 18:13:15,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:15,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:15,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:15,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:15,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-08-28 18:13:15,546] {scheduler_job.py:146} INFO - Started process (PID=19319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:20,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:20,553] {logging_mixin.py:95} INFO - [2019-08-28 18:13:20,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:20,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:20,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:20,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:20,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:13:20,997] {scheduler_job.py:146} INFO - Started process (PID=19320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:26,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:26,008] {logging_mixin.py:95} INFO - [2019-08-28 18:13:26,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:26,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:26,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:26,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:26,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 18:13:26,452] {scheduler_job.py:146} INFO - Started process (PID=19322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:31,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:31,461] {logging_mixin.py:95} INFO - [2019-08-28 18:13:31,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:31,901] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:31,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:31,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:31,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-08-28 18:13:32,002] {scheduler_job.py:146} INFO - Started process (PID=19324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:37,011] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:37,012] {logging_mixin.py:95} INFO - [2019-08-28 18:13:37,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:37,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:37,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:37,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:37,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:13:37,457] {scheduler_job.py:146} INFO - Started process (PID=19325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:42,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:42,467] {logging_mixin.py:95} INFO - [2019-08-28 18:13:42,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:42,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:42,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:42,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:42,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:13:42,917] {scheduler_job.py:146} INFO - Started process (PID=19327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:47,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:47,926] {logging_mixin.py:95} INFO - [2019-08-28 18:13:47,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:48,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:48,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:48,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:48,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:13:48,387] {scheduler_job.py:146} INFO - Started process (PID=19328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:53,394] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:53,395] {logging_mixin.py:95} INFO - [2019-08-28 18:13:53,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:53,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:53,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:53,779] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:53,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:13:53,846] {scheduler_job.py:146} INFO - Started process (PID=19329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:58,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:13:58,864] {logging_mixin.py:95} INFO - [2019-08-28 18:13:58,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:59,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:13:59,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:13:59,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:13:59,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:13:59,298] {scheduler_job.py:146} INFO - Started process (PID=19331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:04,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:04,307] {logging_mixin.py:95} INFO - [2019-08-28 18:14:04,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:04,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:04,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:04,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:04,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:14:04,754] {scheduler_job.py:146} INFO - Started process (PID=19333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:09,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:09,761] {logging_mixin.py:95} INFO - [2019-08-28 18:14:09,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:10,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:10,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:10,141] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:10,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:14:10,212] {scheduler_job.py:146} INFO - Started process (PID=19336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:15,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:15,218] {logging_mixin.py:95} INFO - [2019-08-28 18:14:15,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:15,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:15,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:15,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:15,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:14:15,672] {scheduler_job.py:146} INFO - Started process (PID=19337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:20,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:20,678] {logging_mixin.py:95} INFO - [2019-08-28 18:14:20,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:21,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:21,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:21,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:21,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:14:21,130] {scheduler_job.py:146} INFO - Started process (PID=19338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:26,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:26,138] {logging_mixin.py:95} INFO - [2019-08-28 18:14:26,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:26,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:26,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:26,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:26,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 18:14:26,580] {scheduler_job.py:146} INFO - Started process (PID=19340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:31,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:31,589] {logging_mixin.py:95} INFO - [2019-08-28 18:14:31,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:31,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:31,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:31,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:32,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 18:14:32,030] {scheduler_job.py:146} INFO - Started process (PID=19341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:37,035] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:37,036] {logging_mixin.py:95} INFO - [2019-08-28 18:14:37,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:37,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:37,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:37,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:37,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-08-28 18:14:37,570] {scheduler_job.py:146} INFO - Started process (PID=19343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:42,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:42,581] {logging_mixin.py:95} INFO - [2019-08-28 18:14:42,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:42,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:42,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:42,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:42,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:14:43,021] {scheduler_job.py:146} INFO - Started process (PID=19345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:48,032] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:48,033] {logging_mixin.py:95} INFO - [2019-08-28 18:14:48,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:48,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:48,413] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:48,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:48,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:14:48,467] {scheduler_job.py:146} INFO - Started process (PID=19346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:53,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:53,476] {logging_mixin.py:95} INFO - [2019-08-28 18:14:53,475] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:53,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:53,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:53,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:53,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 18:14:54,016] {scheduler_job.py:146} INFO - Started process (PID=19348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:59,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:14:59,023] {logging_mixin.py:95} INFO - [2019-08-28 18:14:59,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:59,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:14:59,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:14:59,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:14:59,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 18:14:59,456] {scheduler_job.py:146} INFO - Started process (PID=19350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:04,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:04,464] {logging_mixin.py:95} INFO - [2019-08-28 18:15:04,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:04,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:04,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:04,876] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:04,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-08-28 18:15:04,906] {scheduler_job.py:146} INFO - Started process (PID=19352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:09,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:09,916] {logging_mixin.py:95} INFO - [2019-08-28 18:15:09,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:10,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:10,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:10,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:10,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 18:15:10,360] {scheduler_job.py:146} INFO - Started process (PID=19355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:15,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:15,367] {logging_mixin.py:95} INFO - [2019-08-28 18:15:15,367] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:15,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:15,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:15,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:15,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:15:15,809] {scheduler_job.py:146} INFO - Started process (PID=19356) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:20,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:20,818] {logging_mixin.py:95} INFO - [2019-08-28 18:15:20,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:21,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:21,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:21,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:21,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-08-28 18:15:21,261] {scheduler_job.py:146} INFO - Started process (PID=19357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:26,268] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:26,269] {logging_mixin.py:95} INFO - [2019-08-28 18:15:26,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:26,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:26,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:26,728] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:26,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-08-28 18:15:26,812] {scheduler_job.py:146} INFO - Started process (PID=19360) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:31,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:31,819] {logging_mixin.py:95} INFO - [2019-08-28 18:15:31,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:32,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:32,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:32,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:32,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:15:32,260] {scheduler_job.py:146} INFO - Started process (PID=19361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:37,266] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:37,267] {logging_mixin.py:95} INFO - [2019-08-28 18:15:37,267] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:37,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:37,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:37,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:37,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.530 seconds
[2019-08-28 18:15:37,814] {scheduler_job.py:146} INFO - Started process (PID=19363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:42,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:42,824] {logging_mixin.py:95} INFO - [2019-08-28 18:15:42,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:43,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:43,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:43,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:43,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-28 18:15:43,372] {scheduler_job.py:146} INFO - Started process (PID=19365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:48,377] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:48,378] {logging_mixin.py:95} INFO - [2019-08-28 18:15:48,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:48,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:48,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:48,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:48,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:15:48,827] {scheduler_job.py:146} INFO - Started process (PID=19366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:53,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:53,835] {logging_mixin.py:95} INFO - [2019-08-28 18:15:53,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:54,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:54,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:54,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:54,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:15:54,281] {scheduler_job.py:146} INFO - Started process (PID=19367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:59,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:15:59,303] {logging_mixin.py:95} INFO - [2019-08-28 18:15:59,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:59,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:15:59,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:15:59,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:15:59,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:15:59,742] {scheduler_job.py:146} INFO - Started process (PID=19369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:04,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:04,750] {logging_mixin.py:95} INFO - [2019-08-28 18:16:04,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:05,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:05,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:05,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:05,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-08-28 18:16:05,313] {scheduler_job.py:146} INFO - Started process (PID=19370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:10,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:10,326] {logging_mixin.py:95} INFO - [2019-08-28 18:16:10,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:10,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:10,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:10,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:10,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 18:16:10,863] {scheduler_job.py:146} INFO - Started process (PID=19374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:15,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:15,878] {logging_mixin.py:95} INFO - [2019-08-28 18:16:15,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:16,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:16,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:16,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:16,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 18:16:16,409] {scheduler_job.py:146} INFO - Started process (PID=19379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:21,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:21,416] {logging_mixin.py:95} INFO - [2019-08-28 18:16:21,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:21,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:21,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:21,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:21,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:16:21,857] {scheduler_job.py:146} INFO - Started process (PID=19382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:26,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:26,862] {logging_mixin.py:95} INFO - [2019-08-28 18:16:26,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:27,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:27,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:27,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:27,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:16:27,310] {scheduler_job.py:146} INFO - Started process (PID=19384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:32,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:32,320] {logging_mixin.py:95} INFO - [2019-08-28 18:16:32,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:32,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:32,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:32,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:32,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:16:32,770] {scheduler_job.py:146} INFO - Started process (PID=19385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:37,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:37,777] {logging_mixin.py:95} INFO - [2019-08-28 18:16:37,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:38,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:38,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:38,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:38,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-08-28 18:16:38,322] {scheduler_job.py:146} INFO - Started process (PID=19386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:43,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:43,333] {logging_mixin.py:95} INFO - [2019-08-28 18:16:43,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:43,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:43,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:43,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:43,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-08-28 18:16:43,867] {scheduler_job.py:146} INFO - Started process (PID=19389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:48,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:48,876] {logging_mixin.py:95} INFO - [2019-08-28 18:16:48,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:49,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:49,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:49,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:49,286] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:16:49,322] {scheduler_job.py:146} INFO - Started process (PID=19390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:54,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:54,329] {logging_mixin.py:95} INFO - [2019-08-28 18:16:54,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:54,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:54,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:16:54,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:16:54,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:16:54,772] {scheduler_job.py:146} INFO - Started process (PID=19391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:16:59,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:16:59,779] {logging_mixin.py:95} INFO - [2019-08-28 18:16:59,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:00,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:00,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:00,223] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:00,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-08-28 18:17:00,330] {scheduler_job.py:146} INFO - Started process (PID=19393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:05,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:05,339] {logging_mixin.py:95} INFO - [2019-08-28 18:17:05,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:05,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:05,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:05,782] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:05,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-08-28 18:17:05,869] {scheduler_job.py:146} INFO - Started process (PID=19394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:10,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:10,879] {logging_mixin.py:95} INFO - [2019-08-28 18:17:10,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:11,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:11,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:11,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:11,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-08-28 18:17:11,410] {scheduler_job.py:146} INFO - Started process (PID=19398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:16,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:16,427] {logging_mixin.py:95} INFO - [2019-08-28 18:17:16,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:16,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:16,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:16,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:16,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-08-28 18:17:16,961] {scheduler_job.py:146} INFO - Started process (PID=19399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:21,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:21,972] {logging_mixin.py:95} INFO - [2019-08-28 18:17:21,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:22,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:22,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:22,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:22,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 18:17:22,531] {scheduler_job.py:146} INFO - Started process (PID=19400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:27,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:27,550] {logging_mixin.py:95} INFO - [2019-08-28 18:17:27,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:27,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:27,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:27,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:27,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:17:27,989] {scheduler_job.py:146} INFO - Started process (PID=19402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:32,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:33,000] {logging_mixin.py:95} INFO - [2019-08-28 18:17:33,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:33,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:33,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:33,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:33,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:17:33,452] {scheduler_job.py:146} INFO - Started process (PID=19403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:38,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:38,461] {logging_mixin.py:95} INFO - [2019-08-28 18:17:38,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:38,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:38,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:38,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:38,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:17:38,913] {scheduler_job.py:146} INFO - Started process (PID=19404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:43,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:43,926] {logging_mixin.py:95} INFO - [2019-08-28 18:17:43,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:44,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:44,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:44,305] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:44,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:17:44,362] {scheduler_job.py:146} INFO - Started process (PID=19407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:49,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:49,373] {logging_mixin.py:95} INFO - [2019-08-28 18:17:49,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:49,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:49,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:49,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:49,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:17:49,823] {scheduler_job.py:146} INFO - Started process (PID=19408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:54,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:17:54,833] {logging_mixin.py:95} INFO - [2019-08-28 18:17:54,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:55,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:17:55,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:17:55,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:17:55,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:17:55,287] {scheduler_job.py:146} INFO - Started process (PID=19410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:00,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:00,295] {logging_mixin.py:95} INFO - [2019-08-28 18:18:00,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:00,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:00,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:00,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:00,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:18:00,752] {scheduler_job.py:146} INFO - Started process (PID=19411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:05,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:05,764] {logging_mixin.py:95} INFO - [2019-08-28 18:18:05,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:06,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:06,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:06,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:06,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:18:06,209] {scheduler_job.py:146} INFO - Started process (PID=19417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:11,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:11,218] {logging_mixin.py:95} INFO - [2019-08-28 18:18:11,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:11,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:11,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:11,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:11,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:18:11,677] {scheduler_job.py:146} INFO - Started process (PID=19419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:16,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:16,690] {logging_mixin.py:95} INFO - [2019-08-28 18:18:16,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:17,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:17,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:17,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:17,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-08-28 18:18:17,139] {scheduler_job.py:146} INFO - Started process (PID=19421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:22,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:22,150] {logging_mixin.py:95} INFO - [2019-08-28 18:18:22,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:22,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:22,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:22,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:22,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:18:22,600] {scheduler_job.py:146} INFO - Started process (PID=19422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:27,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:27,614] {logging_mixin.py:95} INFO - [2019-08-28 18:18:27,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:27,964] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:27,988] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:27,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:28,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:18:28,066] {scheduler_job.py:146} INFO - Started process (PID=19424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:33,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:33,078] {logging_mixin.py:95} INFO - [2019-08-28 18:18:33,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:33,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:33,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:33,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:33,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:18:33,522] {scheduler_job.py:146} INFO - Started process (PID=19425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:38,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:38,533] {logging_mixin.py:95} INFO - [2019-08-28 18:18:38,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:38,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:38,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:38,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:38,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-28 18:18:39,082] {scheduler_job.py:146} INFO - Started process (PID=19426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:44,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:44,091] {logging_mixin.py:95} INFO - [2019-08-28 18:18:44,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:44,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:44,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:44,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:44,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:18:44,542] {scheduler_job.py:146} INFO - Started process (PID=19428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:49,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:49,556] {logging_mixin.py:95} INFO - [2019-08-28 18:18:49,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:49,940] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:49,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:49,966] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:49,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:18:50,003] {scheduler_job.py:146} INFO - Started process (PID=19430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:55,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:18:55,013] {logging_mixin.py:95} INFO - [2019-08-28 18:18:55,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:55,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:18:55,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:18:55,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:18:55,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:18:55,463] {scheduler_job.py:146} INFO - Started process (PID=19432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:00,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:00,472] {logging_mixin.py:95} INFO - [2019-08-28 18:19:00,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:00,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:00,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:00,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:00,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:19:00,926] {scheduler_job.py:146} INFO - Started process (PID=19433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:05,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:05,938] {logging_mixin.py:95} INFO - [2019-08-28 18:19:05,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:06,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:06,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:06,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:06,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:19:06,390] {scheduler_job.py:146} INFO - Started process (PID=19435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:11,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:11,399] {logging_mixin.py:95} INFO - [2019-08-28 18:19:11,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:11,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:11,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:11,785] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:11,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:19:11,855] {scheduler_job.py:146} INFO - Started process (PID=19437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:16,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:16,865] {logging_mixin.py:95} INFO - [2019-08-28 18:19:16,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:17,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:17,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:17,249] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:17,255] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:19:17,319] {scheduler_job.py:146} INFO - Started process (PID=19439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:22,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:22,331] {logging_mixin.py:95} INFO - [2019-08-28 18:19:22,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:22,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:22,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:22,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:22,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:19:22,775] {scheduler_job.py:146} INFO - Started process (PID=19440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:27,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:27,796] {logging_mixin.py:95} INFO - [2019-08-28 18:19:27,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:28,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:28,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:28,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:28,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:19:28,237] {scheduler_job.py:146} INFO - Started process (PID=19442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:33,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:33,244] {logging_mixin.py:95} INFO - [2019-08-28 18:19:33,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:33,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:33,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:33,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:33,630] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:19:33,699] {scheduler_job.py:146} INFO - Started process (PID=19443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:38,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:38,712] {logging_mixin.py:95} INFO - [2019-08-28 18:19:38,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:39,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:39,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:39,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:39,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:19:39,158] {scheduler_job.py:146} INFO - Started process (PID=19444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:44,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:44,171] {logging_mixin.py:95} INFO - [2019-08-28 18:19:44,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:44,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:44,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:44,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:44,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:19:44,622] {scheduler_job.py:146} INFO - Started process (PID=19446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:49,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:49,630] {logging_mixin.py:95} INFO - [2019-08-28 18:19:49,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:49,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:49,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:49,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:50,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-08-28 18:19:50,081] {scheduler_job.py:146} INFO - Started process (PID=19448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:55,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:19:55,090] {logging_mixin.py:95} INFO - [2019-08-28 18:19:55,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:55,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:19:55,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:19:55,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:19:55,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:19:55,541] {scheduler_job.py:146} INFO - Started process (PID=19450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:00,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:00,563] {logging_mixin.py:95} INFO - [2019-08-28 18:20:00,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:00,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:00,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:00,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:00,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-08-28 18:20:01,007] {scheduler_job.py:146} INFO - Started process (PID=19451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:06,018] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:06,019] {logging_mixin.py:95} INFO - [2019-08-28 18:20:06,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:06,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:06,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:06,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:06,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:20:06,466] {scheduler_job.py:146} INFO - Started process (PID=19453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:11,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:11,473] {logging_mixin.py:95} INFO - [2019-08-28 18:20:11,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:11,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:11,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:11,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:11,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:20:11,930] {scheduler_job.py:146} INFO - Started process (PID=19455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:16,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:16,938] {logging_mixin.py:95} INFO - [2019-08-28 18:20:16,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:17,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:17,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:17,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:17,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:20:17,391] {scheduler_job.py:146} INFO - Started process (PID=19456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:22,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:22,400] {logging_mixin.py:95} INFO - [2019-08-28 18:20:22,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:22,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:22,776] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:22,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:22,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:20:22,851] {scheduler_job.py:146} INFO - Started process (PID=19458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:27,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:27,875] {logging_mixin.py:95} INFO - [2019-08-28 18:20:27,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:28,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:28,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:28,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:28,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:20:28,312] {scheduler_job.py:146} INFO - Started process (PID=19460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:33,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:33,323] {logging_mixin.py:95} INFO - [2019-08-28 18:20:33,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:33,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:33,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:33,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:33,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:20:33,771] {scheduler_job.py:146} INFO - Started process (PID=19461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:38,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:38,779] {logging_mixin.py:95} INFO - [2019-08-28 18:20:38,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:39,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:39,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:39,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:39,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:20:39,233] {scheduler_job.py:146} INFO - Started process (PID=19462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:44,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:44,243] {logging_mixin.py:95} INFO - [2019-08-28 18:20:44,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:44,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:44,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:44,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:44,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:20:44,696] {scheduler_job.py:146} INFO - Started process (PID=19464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:49,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:49,704] {logging_mixin.py:95} INFO - [2019-08-28 18:20:49,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:50,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:50,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:50,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:50,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:20:50,154] {scheduler_job.py:146} INFO - Started process (PID=19465) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:55,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:20:55,162] {logging_mixin.py:95} INFO - [2019-08-28 18:20:55,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:55,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:20:55,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:20:55,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:20:55,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:20:55,621] {scheduler_job.py:146} INFO - Started process (PID=19468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:00,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:00,642] {logging_mixin.py:95} INFO - [2019-08-28 18:21:00,641] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:01,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:01,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:01,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:01,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:21:01,087] {scheduler_job.py:146} INFO - Started process (PID=19469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:06,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:06,098] {logging_mixin.py:95} INFO - [2019-08-28 18:21:06,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:06,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:06,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:06,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:06,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:21:06,540] {scheduler_job.py:146} INFO - Started process (PID=19471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:11,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:11,552] {logging_mixin.py:95} INFO - [2019-08-28 18:21:11,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:11,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:11,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:11,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:11,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:21:12,005] {scheduler_job.py:146} INFO - Started process (PID=19473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:17,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:17,016] {logging_mixin.py:95} INFO - [2019-08-28 18:21:17,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:17,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:17,399] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:17,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:17,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:21:17,462] {scheduler_job.py:146} INFO - Started process (PID=19474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:22,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:22,469] {logging_mixin.py:95} INFO - [2019-08-28 18:21:22,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:22,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:22,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:22,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:22,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-08-28 18:21:22,917] {scheduler_job.py:146} INFO - Started process (PID=19476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:27,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:27,936] {logging_mixin.py:95} INFO - [2019-08-28 18:21:27,935] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:28,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:28,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:28,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:28,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:21:28,376] {scheduler_job.py:146} INFO - Started process (PID=19478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:33,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:33,388] {logging_mixin.py:95} INFO - [2019-08-28 18:21:33,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:33,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:33,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:33,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:33,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:21:33,838] {scheduler_job.py:146} INFO - Started process (PID=19479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:38,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:38,847] {logging_mixin.py:95} INFO - [2019-08-28 18:21:38,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:39,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:39,214] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:39,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:39,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 18:21:39,303] {scheduler_job.py:146} INFO - Started process (PID=19480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:44,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:44,314] {logging_mixin.py:95} INFO - [2019-08-28 18:21:44,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:44,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:44,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:44,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:44,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:21:44,765] {scheduler_job.py:146} INFO - Started process (PID=19482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:49,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:49,775] {logging_mixin.py:95} INFO - [2019-08-28 18:21:49,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:50,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:50,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:50,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:50,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:21:50,228] {scheduler_job.py:146} INFO - Started process (PID=19483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:55,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:21:55,240] {logging_mixin.py:95} INFO - [2019-08-28 18:21:55,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:55,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:21:55,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:21:55,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:21:55,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-08-28 18:21:55,785] {scheduler_job.py:146} INFO - Started process (PID=19486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:00,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:00,807] {logging_mixin.py:95} INFO - [2019-08-28 18:22:00,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:01,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:01,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:01,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:01,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:22:01,249] {scheduler_job.py:146} INFO - Started process (PID=19487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:06,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:06,259] {logging_mixin.py:95} INFO - [2019-08-28 18:22:06,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:06,615] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:06,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:06,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:06,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:22:06,708] {scheduler_job.py:146} INFO - Started process (PID=19489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:11,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:11,716] {logging_mixin.py:95} INFO - [2019-08-28 18:22:11,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:12,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:12,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:12,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:12,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 18:22:12,161] {scheduler_job.py:146} INFO - Started process (PID=19491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:17,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:17,175] {logging_mixin.py:95} INFO - [2019-08-28 18:22:17,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:17,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:17,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:17,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:17,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:22:17,622] {scheduler_job.py:146} INFO - Started process (PID=19492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:22,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:22,630] {logging_mixin.py:95} INFO - [2019-08-28 18:22:22,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:22,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:22,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:23,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:23,011] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 18:22:23,094] {scheduler_job.py:146} INFO - Started process (PID=19493) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:28,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:28,115] {logging_mixin.py:95} INFO - [2019-08-28 18:22:28,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:28,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:28,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:28,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:28,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 18:22:28,549] {scheduler_job.py:146} INFO - Started process (PID=19496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:33,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:33,562] {logging_mixin.py:95} INFO - [2019-08-28 18:22:33,562] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:33,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:33,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:33,953] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:33,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:22:34,010] {scheduler_job.py:146} INFO - Started process (PID=19497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:39,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:39,018] {logging_mixin.py:95} INFO - [2019-08-28 18:22:39,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:39,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:39,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:39,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:39,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:22:39,473] {scheduler_job.py:146} INFO - Started process (PID=19498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:44,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:44,482] {logging_mixin.py:95} INFO - [2019-08-28 18:22:44,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:44,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:44,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:44,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:44,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:22:44,927] {scheduler_job.py:146} INFO - Started process (PID=19500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:49,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:49,935] {logging_mixin.py:95} INFO - [2019-08-28 18:22:49,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:50,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:50,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:50,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:50,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:22:50,377] {scheduler_job.py:146} INFO - Started process (PID=19501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:55,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:22:55,385] {logging_mixin.py:95} INFO - [2019-08-28 18:22:55,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:55,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:22:55,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:22:55,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:22:55,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:22:55,824] {scheduler_job.py:146} INFO - Started process (PID=19503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:00,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:00,833] {logging_mixin.py:95} INFO - [2019-08-28 18:23:00,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:01,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:01,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:01,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:01,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:23:01,280] {scheduler_job.py:146} INFO - Started process (PID=19505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:06,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:06,292] {logging_mixin.py:95} INFO - [2019-08-28 18:23:06,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:06,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:06,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:06,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:06,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:23:06,741] {scheduler_job.py:146} INFO - Started process (PID=19507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:11,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:11,751] {logging_mixin.py:95} INFO - [2019-08-28 18:23:11,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:12,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:12,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:12,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:12,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-08-28 18:23:12,203] {scheduler_job.py:146} INFO - Started process (PID=19509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:17,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:17,213] {logging_mixin.py:95} INFO - [2019-08-28 18:23:17,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:17,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:17,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:17,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:17,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:23:17,662] {scheduler_job.py:146} INFO - Started process (PID=19510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:22,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:22,672] {logging_mixin.py:95} INFO - [2019-08-28 18:23:22,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:23,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:23,044] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:23,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:23,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:23:23,122] {scheduler_job.py:146} INFO - Started process (PID=19511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:28,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:28,143] {logging_mixin.py:95} INFO - [2019-08-28 18:23:28,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:28,493] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:28,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:28,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:28,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:23:28,581] {scheduler_job.py:146} INFO - Started process (PID=19514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:33,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:33,591] {logging_mixin.py:95} INFO - [2019-08-28 18:23:33,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:33,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:33,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:33,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:33,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:23:34,036] {scheduler_job.py:146} INFO - Started process (PID=19515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:39,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:39,045] {logging_mixin.py:95} INFO - [2019-08-28 18:23:39,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:39,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:39,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:39,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:39,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:23:39,502] {scheduler_job.py:146} INFO - Started process (PID=19516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:44,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:44,512] {logging_mixin.py:95} INFO - [2019-08-28 18:23:44,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:44,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:44,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:44,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:44,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:23:44,968] {scheduler_job.py:146} INFO - Started process (PID=19518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:49,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:49,979] {logging_mixin.py:95} INFO - [2019-08-28 18:23:49,979] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:50,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:50,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:50,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:50,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:23:50,430] {scheduler_job.py:146} INFO - Started process (PID=19519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:55,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:23:55,438] {logging_mixin.py:95} INFO - [2019-08-28 18:23:55,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:55,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:23:55,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:23:55,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:23:55,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.510 seconds
[2019-08-28 18:23:55,981] {scheduler_job.py:146} INFO - Started process (PID=19521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:00,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:00,987] {logging_mixin.py:95} INFO - [2019-08-28 18:24:00,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:01,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:01,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:01,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:01,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-08-28 18:24:01,539] {scheduler_job.py:146} INFO - Started process (PID=19523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:06,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:06,546] {logging_mixin.py:95} INFO - [2019-08-28 18:24:06,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:06,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:06,963] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:06,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:06,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-08-28 18:24:07,091] {scheduler_job.py:146} INFO - Started process (PID=19525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:12,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:12,098] {logging_mixin.py:95} INFO - [2019-08-28 18:24:12,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:12,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:12,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:12,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:12,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-08-28 18:24:12,647] {scheduler_job.py:146} INFO - Started process (PID=19529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:17,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:17,656] {logging_mixin.py:95} INFO - [2019-08-28 18:24:17,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:18,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:18,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:18,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:18,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:24:18,098] {scheduler_job.py:146} INFO - Started process (PID=19531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:23,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:23,106] {logging_mixin.py:95} INFO - [2019-08-28 18:24:23,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:23,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:23,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:23,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:23,507] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:24:23,549] {scheduler_job.py:146} INFO - Started process (PID=19533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:28,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:28,560] {logging_mixin.py:95} INFO - [2019-08-28 18:24:28,559] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:28,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:28,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:28,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:28,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 18:24:29,097] {scheduler_job.py:146} INFO - Started process (PID=19535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:34,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:34,107] {logging_mixin.py:95} INFO - [2019-08-28 18:24:34,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:34,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:34,507] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:34,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:34,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 18:24:34,541] {scheduler_job.py:146} INFO - Started process (PID=19537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:39,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:39,549] {logging_mixin.py:95} INFO - [2019-08-28 18:24:39,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:39,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:39,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:39,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:39,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:24:39,993] {scheduler_job.py:146} INFO - Started process (PID=19538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:45,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:45,002] {logging_mixin.py:95} INFO - [2019-08-28 18:24:45,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:45,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:45,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:45,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:45,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:24:45,443] {scheduler_job.py:146} INFO - Started process (PID=19540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:50,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:50,454] {logging_mixin.py:95} INFO - [2019-08-28 18:24:50,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:50,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:50,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:50,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:50,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:24:50,901] {scheduler_job.py:146} INFO - Started process (PID=19541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:55,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:24:55,912] {logging_mixin.py:95} INFO - [2019-08-28 18:24:55,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:56,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:24:56,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:24:56,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:24:56,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:24:56,358] {scheduler_job.py:146} INFO - Started process (PID=19543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:01,365] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:01,366] {logging_mixin.py:95} INFO - [2019-08-28 18:25:01,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:01,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:01,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:01,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:01,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 18:25:01,811] {scheduler_job.py:146} INFO - Started process (PID=19544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:06,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:06,820] {logging_mixin.py:95} INFO - [2019-08-28 18:25:06,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:07,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:07,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:07,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:07,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:25:07,260] {scheduler_job.py:146} INFO - Started process (PID=19547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:12,271] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:12,272] {logging_mixin.py:95} INFO - [2019-08-28 18:25:12,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:12,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:12,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:12,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:12,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:25:12,721] {scheduler_job.py:146} INFO - Started process (PID=19549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:17,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:17,731] {logging_mixin.py:95} INFO - [2019-08-28 18:25:17,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:18,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:18,101] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:18,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:18,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:25:18,182] {scheduler_job.py:146} INFO - Started process (PID=19550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:23,191] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:23,192] {logging_mixin.py:95} INFO - [2019-08-28 18:25:23,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:23,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:23,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:23,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:23,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:25:23,645] {scheduler_job.py:146} INFO - Started process (PID=19551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:28,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:28,664] {logging_mixin.py:95} INFO - [2019-08-28 18:25:28,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:29,013] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:29,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:29,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:29,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:25:29,104] {scheduler_job.py:146} INFO - Started process (PID=19553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:34,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:34,113] {logging_mixin.py:95} INFO - [2019-08-28 18:25:34,112] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:34,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:34,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:34,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:34,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:25:34,563] {scheduler_job.py:146} INFO - Started process (PID=19555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:39,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:39,576] {logging_mixin.py:95} INFO - [2019-08-28 18:25:39,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:39,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:39,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:39,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:39,968] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:25:40,026] {scheduler_job.py:146} INFO - Started process (PID=19556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:45,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:45,036] {logging_mixin.py:95} INFO - [2019-08-28 18:25:45,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:45,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:45,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:45,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:45,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:25:45,485] {scheduler_job.py:146} INFO - Started process (PID=19558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:50,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:50,495] {logging_mixin.py:95} INFO - [2019-08-28 18:25:50,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:50,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:50,873] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:50,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:50,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:25:50,949] {scheduler_job.py:146} INFO - Started process (PID=19559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:55,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:25:55,960] {logging_mixin.py:95} INFO - [2019-08-28 18:25:55,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:56,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:25:56,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:25:56,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:25:56,340] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:25:56,410] {scheduler_job.py:146} INFO - Started process (PID=19561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:01,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:01,421] {logging_mixin.py:95} INFO - [2019-08-28 18:26:01,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:01,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:01,795] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:01,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:01,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:26:01,870] {scheduler_job.py:146} INFO - Started process (PID=19562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:06,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:06,877] {logging_mixin.py:95} INFO - [2019-08-28 18:26:06,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:07,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:07,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:07,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:07,323] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 18:26:07,425] {scheduler_job.py:146} INFO - Started process (PID=19565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:12,432] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:12,433] {logging_mixin.py:95} INFO - [2019-08-28 18:26:12,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:12,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:12,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:12,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:12,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:26:12,879] {scheduler_job.py:146} INFO - Started process (PID=19567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:17,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:17,887] {logging_mixin.py:95} INFO - [2019-08-28 18:26:17,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:18,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:18,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:18,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:18,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:26:18,337] {scheduler_job.py:146} INFO - Started process (PID=19568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:23,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:23,348] {logging_mixin.py:95} INFO - [2019-08-28 18:26:23,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:23,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:23,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:23,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:23,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:26:23,797] {scheduler_job.py:146} INFO - Started process (PID=19569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:28,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:28,821] {logging_mixin.py:95} INFO - [2019-08-28 18:26:28,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:29,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:29,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:29,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:29,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:26:29,256] {scheduler_job.py:146} INFO - Started process (PID=19571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:34,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:34,265] {logging_mixin.py:95} INFO - [2019-08-28 18:26:34,265] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:34,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:34,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:34,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:34,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:26:34,713] {scheduler_job.py:146} INFO - Started process (PID=19572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:39,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:39,729] {logging_mixin.py:95} INFO - [2019-08-28 18:26:39,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:40,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:40,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:40,169] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:40,174] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-08-28 18:26:40,273] {scheduler_job.py:146} INFO - Started process (PID=19574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:45,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:45,284] {logging_mixin.py:95} INFO - [2019-08-28 18:26:45,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:45,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:45,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:45,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:45,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:26:45,728] {scheduler_job.py:146} INFO - Started process (PID=19576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:50,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:50,741] {logging_mixin.py:95} INFO - [2019-08-28 18:26:50,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:51,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:51,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:51,129] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:51,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:26:51,186] {scheduler_job.py:146} INFO - Started process (PID=19577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:56,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:26:56,196] {logging_mixin.py:95} INFO - [2019-08-28 18:26:56,196] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:56,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:26:56,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:26:56,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:26:56,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:26:56,652] {scheduler_job.py:146} INFO - Started process (PID=19579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:01,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:01,664] {logging_mixin.py:95} INFO - [2019-08-28 18:27:01,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:02,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:02,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:02,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:02,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:27:02,114] {scheduler_job.py:146} INFO - Started process (PID=19580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:07,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:07,122] {logging_mixin.py:95} INFO - [2019-08-28 18:27:07,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:07,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:07,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:07,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:07,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:27:07,566] {scheduler_job.py:146} INFO - Started process (PID=19582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:12,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:12,575] {logging_mixin.py:95} INFO - [2019-08-28 18:27:12,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:12,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:12,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:12,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:12,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-08-28 18:27:13,028] {scheduler_job.py:146} INFO - Started process (PID=19585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:18,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:18,040] {logging_mixin.py:95} INFO - [2019-08-28 18:27:18,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:18,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:18,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:18,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:18,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:27:18,489] {scheduler_job.py:146} INFO - Started process (PID=19586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:23,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:23,498] {logging_mixin.py:95} INFO - [2019-08-28 18:27:23,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:23,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:23,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:23,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:23,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-08-28 18:27:23,953] {scheduler_job.py:146} INFO - Started process (PID=19587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:28,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:28,961] {logging_mixin.py:95} INFO - [2019-08-28 18:27:28,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:29,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:29,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:29,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:29,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:27:29,417] {scheduler_job.py:146} INFO - Started process (PID=19589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:34,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:34,423] {logging_mixin.py:95} INFO - [2019-08-28 18:27:34,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:34,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:34,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:34,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:34,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:27:34,880] {scheduler_job.py:146} INFO - Started process (PID=19590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:39,889] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:39,890] {logging_mixin.py:95} INFO - [2019-08-28 18:27:39,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:40,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:40,263] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:40,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:40,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:27:40,339] {scheduler_job.py:146} INFO - Started process (PID=19591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:45,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:45,346] {logging_mixin.py:95} INFO - [2019-08-28 18:27:45,346] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:45,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:45,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:45,772] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:45,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 18:27:45,800] {scheduler_job.py:146} INFO - Started process (PID=19594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:50,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:50,810] {logging_mixin.py:95} INFO - [2019-08-28 18:27:50,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:51,155] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:51,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:51,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:51,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:27:51,263] {scheduler_job.py:146} INFO - Started process (PID=19595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:56,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:27:56,270] {logging_mixin.py:95} INFO - [2019-08-28 18:27:56,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:56,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:27:56,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:27:56,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:27:56,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:27:56,728] {scheduler_job.py:146} INFO - Started process (PID=19597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:01,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:01,737] {logging_mixin.py:95} INFO - [2019-08-28 18:28:01,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:02,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:02,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:02,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:02,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:28:02,192] {scheduler_job.py:146} INFO - Started process (PID=19598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:07,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:07,200] {logging_mixin.py:95} INFO - [2019-08-28 18:28:07,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:07,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:07,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:07,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:07,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:28:07,653] {scheduler_job.py:146} INFO - Started process (PID=19600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:12,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:12,659] {logging_mixin.py:95} INFO - [2019-08-28 18:28:12,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:13,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:13,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:13,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:13,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:28:13,114] {scheduler_job.py:146} INFO - Started process (PID=19603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:18,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:18,125] {logging_mixin.py:95} INFO - [2019-08-28 18:28:18,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:18,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:18,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:18,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:18,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:28:18,566] {scheduler_job.py:146} INFO - Started process (PID=19604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:23,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:23,573] {logging_mixin.py:95} INFO - [2019-08-28 18:28:23,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:23,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:23,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:23,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:23,961] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:28:24,032] {scheduler_job.py:146} INFO - Started process (PID=19605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:29,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:29,049] {logging_mixin.py:95} INFO - [2019-08-28 18:28:29,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:29,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:29,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:29,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:29,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:28:29,495] {scheduler_job.py:146} INFO - Started process (PID=19607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:34,504] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:34,505] {logging_mixin.py:95} INFO - [2019-08-28 18:28:34,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:34,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:34,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:34,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:34,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:28:34,960] {scheduler_job.py:146} INFO - Started process (PID=19608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:39,970] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:39,971] {logging_mixin.py:95} INFO - [2019-08-28 18:28:39,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:40,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:40,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:40,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:40,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:28:40,425] {scheduler_job.py:146} INFO - Started process (PID=19609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:45,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:45,436] {logging_mixin.py:95} INFO - [2019-08-28 18:28:45,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:45,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:45,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:45,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:45,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-08-28 18:28:45,882] {scheduler_job.py:146} INFO - Started process (PID=19612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:50,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:50,891] {logging_mixin.py:95} INFO - [2019-08-28 18:28:50,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:51,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:51,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:51,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:51,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:28:51,341] {scheduler_job.py:146} INFO - Started process (PID=19613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:56,351] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:28:56,352] {logging_mixin.py:95} INFO - [2019-08-28 18:28:56,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:56,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:28:56,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:28:56,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:28:56,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-08-28 18:28:56,799] {scheduler_job.py:146} INFO - Started process (PID=19615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:01,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:01,807] {logging_mixin.py:95} INFO - [2019-08-28 18:29:01,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:02,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:02,172] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:02,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:02,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-08-28 18:29:02,260] {scheduler_job.py:146} INFO - Started process (PID=19616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:07,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:07,271] {logging_mixin.py:95} INFO - [2019-08-28 18:29:07,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:07,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:07,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:07,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:07,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:29:07,720] {scheduler_job.py:146} INFO - Started process (PID=19618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:12,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:12,726] {logging_mixin.py:95} INFO - [2019-08-28 18:29:12,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:13,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:13,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:13,094] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:13,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-08-28 18:29:13,173] {scheduler_job.py:146} INFO - Started process (PID=19620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:18,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:18,184] {logging_mixin.py:95} INFO - [2019-08-28 18:29:18,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:18,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:18,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:18,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:18,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:29:18,633] {scheduler_job.py:146} INFO - Started process (PID=19622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:23,639] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:23,640] {logging_mixin.py:95} INFO - [2019-08-28 18:29:23,640] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:23,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:24,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:24,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:24,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:29:24,094] {scheduler_job.py:146} INFO - Started process (PID=19623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:29,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:29,114] {logging_mixin.py:95} INFO - [2019-08-28 18:29:29,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:29,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:29,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:29,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:29,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:29:29,549] {scheduler_job.py:146} INFO - Started process (PID=19625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:34,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:34,557] {logging_mixin.py:95} INFO - [2019-08-28 18:29:34,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:34,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:34,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:34,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:34,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:29:35,013] {scheduler_job.py:146} INFO - Started process (PID=19626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:40,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:40,023] {logging_mixin.py:95} INFO - [2019-08-28 18:29:40,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:40,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:40,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:40,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:40,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:29:40,475] {scheduler_job.py:146} INFO - Started process (PID=19627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:45,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:45,483] {logging_mixin.py:95} INFO - [2019-08-28 18:29:45,483] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:45,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:45,853] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:45,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:45,866] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:29:45,934] {scheduler_job.py:146} INFO - Started process (PID=19629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:50,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:50,940] {logging_mixin.py:95} INFO - [2019-08-28 18:29:50,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:51,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:51,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:51,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:51,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:29:51,398] {scheduler_job.py:146} INFO - Started process (PID=19631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:56,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:29:56,406] {logging_mixin.py:95} INFO - [2019-08-28 18:29:56,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:56,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:29:56,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:29:56,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:29:56,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-08-28 18:29:56,850] {scheduler_job.py:146} INFO - Started process (PID=19633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:01,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:01,858] {logging_mixin.py:95} INFO - [2019-08-28 18:30:01,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:02,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:02,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:02,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:02,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:30:02,300] {scheduler_job.py:146} INFO - Started process (PID=19635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:07,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:07,307] {logging_mixin.py:95} INFO - [2019-08-28 18:30:07,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:07,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:07,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:07,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:07,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-08-28 18:30:07,763] {scheduler_job.py:146} INFO - Started process (PID=19637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:12,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:12,771] {logging_mixin.py:95} INFO - [2019-08-28 18:30:12,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:13,135] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:13,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:13,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:13,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:30:13,217] {scheduler_job.py:146} INFO - Started process (PID=19639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:18,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:18,224] {logging_mixin.py:95} INFO - [2019-08-28 18:30:18,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:18,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:18,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:18,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:18,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:30:18,670] {scheduler_job.py:146} INFO - Started process (PID=19641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:23,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:23,676] {logging_mixin.py:95} INFO - [2019-08-28 18:30:23,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:24,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:24,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:24,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:24,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:30:24,122] {scheduler_job.py:146} INFO - Started process (PID=19642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:29,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:29,130] {logging_mixin.py:95} INFO - [2019-08-28 18:30:29,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:29,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:29,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:29,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:29,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:30:29,586] {scheduler_job.py:146} INFO - Started process (PID=19644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:34,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:34,595] {logging_mixin.py:95} INFO - [2019-08-28 18:30:34,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:34,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:34,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:34,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:34,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:30:35,046] {scheduler_job.py:146} INFO - Started process (PID=19645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:40,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:40,054] {logging_mixin.py:95} INFO - [2019-08-28 18:30:40,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:40,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:40,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:40,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:40,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:30:40,510] {scheduler_job.py:146} INFO - Started process (PID=19646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:45,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:45,521] {logging_mixin.py:95} INFO - [2019-08-28 18:30:45,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:45,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:45,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:45,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:45,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:30:45,979] {scheduler_job.py:146} INFO - Started process (PID=19648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:50,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:50,986] {logging_mixin.py:95} INFO - [2019-08-28 18:30:50,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:51,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:51,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:51,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:51,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-08-28 18:30:51,436] {scheduler_job.py:146} INFO - Started process (PID=19650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:56,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:30:56,446] {logging_mixin.py:95} INFO - [2019-08-28 18:30:56,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:56,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:30:56,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:30:56,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:30:56,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 18:30:56,899] {scheduler_job.py:146} INFO - Started process (PID=19652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:01,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:01,905] {logging_mixin.py:95} INFO - [2019-08-28 18:31:01,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:02,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:02,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:02,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:02,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:31:02,359] {scheduler_job.py:146} INFO - Started process (PID=19653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:07,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:07,367] {logging_mixin.py:95} INFO - [2019-08-28 18:31:07,367] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:07,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:07,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:07,750] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:07,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:31:07,819] {scheduler_job.py:146} INFO - Started process (PID=19655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:12,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:12,826] {logging_mixin.py:95} INFO - [2019-08-28 18:31:12,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:13,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:13,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:13,205] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:13,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:31:13,283] {scheduler_job.py:146} INFO - Started process (PID=19657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:18,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:18,292] {logging_mixin.py:95} INFO - [2019-08-28 18:31:18,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:18,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:18,678] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:18,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:18,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 18:31:18,738] {scheduler_job.py:146} INFO - Started process (PID=19658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:23,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:23,748] {logging_mixin.py:95} INFO - [2019-08-28 18:31:23,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:24,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:24,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:24,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:24,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:31:24,187] {scheduler_job.py:146} INFO - Started process (PID=19660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:29,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:29,207] {logging_mixin.py:95} INFO - [2019-08-28 18:31:29,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:29,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:29,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:29,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:29,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-08-28 18:31:29,646] {scheduler_job.py:146} INFO - Started process (PID=19662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:34,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:34,655] {logging_mixin.py:95} INFO - [2019-08-28 18:31:34,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:35,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:35,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:35,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:35,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:31:35,112] {scheduler_job.py:146} INFO - Started process (PID=19663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:40,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:40,119] {logging_mixin.py:95} INFO - [2019-08-28 18:31:40,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:40,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:40,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:40,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:40,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:31:40,569] {scheduler_job.py:146} INFO - Started process (PID=19664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:45,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:45,578] {logging_mixin.py:95} INFO - [2019-08-28 18:31:45,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:45,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:45,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:45,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:45,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-08-28 18:31:46,022] {scheduler_job.py:146} INFO - Started process (PID=19666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:51,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:51,029] {logging_mixin.py:95} INFO - [2019-08-28 18:31:51,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:51,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:51,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:51,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:51,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:31:51,481] {scheduler_job.py:146} INFO - Started process (PID=19667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:56,487] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:31:56,488] {logging_mixin.py:95} INFO - [2019-08-28 18:31:56,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:56,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:31:56,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:31:56,876] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:31:56,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:31:56,940] {scheduler_job.py:146} INFO - Started process (PID=19670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:01,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:01,949] {logging_mixin.py:95} INFO - [2019-08-28 18:32:01,949] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:02,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:02,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:02,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:02,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:32:02,391] {scheduler_job.py:146} INFO - Started process (PID=19671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:07,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:07,398] {logging_mixin.py:95} INFO - [2019-08-28 18:32:07,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:07,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:07,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:07,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:07,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:32:07,847] {scheduler_job.py:146} INFO - Started process (PID=19673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:12,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:12,855] {logging_mixin.py:95} INFO - [2019-08-28 18:32:12,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:13,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:13,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:13,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:13,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:32:13,312] {scheduler_job.py:146} INFO - Started process (PID=19675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:18,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:18,322] {logging_mixin.py:95} INFO - [2019-08-28 18:32:18,321] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:18,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:18,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:18,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:18,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:32:18,766] {scheduler_job.py:146} INFO - Started process (PID=19676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:23,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:23,772] {logging_mixin.py:95} INFO - [2019-08-28 18:32:23,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:24,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:24,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:24,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:24,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:32:24,218] {scheduler_job.py:146} INFO - Started process (PID=19678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:29,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:29,239] {logging_mixin.py:95} INFO - [2019-08-28 18:32:29,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:29,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:29,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:29,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:29,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:32:29,673] {scheduler_job.py:146} INFO - Started process (PID=19680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:34,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:34,686] {logging_mixin.py:95} INFO - [2019-08-28 18:32:34,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:35,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:35,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:35,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:35,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:32:35,132] {scheduler_job.py:146} INFO - Started process (PID=19681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:40,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:40,138] {logging_mixin.py:95} INFO - [2019-08-28 18:32:40,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:40,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:40,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:40,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:40,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:32:40,588] {scheduler_job.py:146} INFO - Started process (PID=19682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:45,596] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:45,597] {logging_mixin.py:95} INFO - [2019-08-28 18:32:45,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:45,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:45,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:45,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:45,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:32:46,041] {scheduler_job.py:146} INFO - Started process (PID=19684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:51,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:51,048] {logging_mixin.py:95} INFO - [2019-08-28 18:32:51,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:51,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:51,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:51,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:51,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:32:51,499] {scheduler_job.py:146} INFO - Started process (PID=19685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:56,509] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:32:56,511] {logging_mixin.py:95} INFO - [2019-08-28 18:32:56,510] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:56,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:32:56,959] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:32:56,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:32:56,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-08-28 18:32:57,055] {scheduler_job.py:146} INFO - Started process (PID=19688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:02,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:02,064] {logging_mixin.py:95} INFO - [2019-08-28 18:33:02,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:02,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:02,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:02,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:02,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:33:02,513] {scheduler_job.py:146} INFO - Started process (PID=19689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:07,519] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:07,520] {logging_mixin.py:95} INFO - [2019-08-28 18:33:07,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:07,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:07,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:07,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:07,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:33:07,969] {scheduler_job.py:146} INFO - Started process (PID=19691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:12,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:12,981] {logging_mixin.py:95} INFO - [2019-08-28 18:33:12,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:13,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:13,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:13,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:13,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:33:13,428] {scheduler_job.py:146} INFO - Started process (PID=19693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:18,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:18,436] {logging_mixin.py:95} INFO - [2019-08-28 18:33:18,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:18,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:18,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:18,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:18,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-08-28 18:33:18,886] {scheduler_job.py:146} INFO - Started process (PID=19694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:23,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:23,893] {logging_mixin.py:95} INFO - [2019-08-28 18:33:23,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:24,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:24,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:24,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:24,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:33:24,341] {scheduler_job.py:146} INFO - Started process (PID=19695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:29,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:29,348] {logging_mixin.py:95} INFO - [2019-08-28 18:33:29,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:29,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:29,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:29,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:29,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-08-28 18:33:29,799] {scheduler_job.py:146} INFO - Started process (PID=19698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:34,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:34,806] {logging_mixin.py:95} INFO - [2019-08-28 18:33:34,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:35,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:35,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:35,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:35,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:33:35,253] {scheduler_job.py:146} INFO - Started process (PID=19699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:40,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:40,263] {logging_mixin.py:95} INFO - [2019-08-28 18:33:40,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:40,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:40,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:40,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:40,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:33:40,710] {scheduler_job.py:146} INFO - Started process (PID=19700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:45,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:45,721] {logging_mixin.py:95} INFO - [2019-08-28 18:33:45,720] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:46,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:46,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:46,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:46,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:33:46,169] {scheduler_job.py:146} INFO - Started process (PID=19702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:51,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:51,177] {logging_mixin.py:95} INFO - [2019-08-28 18:33:51,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:51,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:51,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:51,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:51,568] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:33:51,626] {scheduler_job.py:146} INFO - Started process (PID=19703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:56,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:33:56,634] {logging_mixin.py:95} INFO - [2019-08-28 18:33:56,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:57,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:33:57,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:33:57,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:33:57,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:33:57,080] {scheduler_job.py:146} INFO - Started process (PID=19705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:02,087] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:02,089] {logging_mixin.py:95} INFO - [2019-08-28 18:34:02,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:02,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:02,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:02,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:02,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-08-28 18:34:02,542] {scheduler_job.py:146} INFO - Started process (PID=19707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:07,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:07,549] {logging_mixin.py:95} INFO - [2019-08-28 18:34:07,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:07,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:07,977] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:07,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:07,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 18:34:08,103] {scheduler_job.py:146} INFO - Started process (PID=19709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:13,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:13,110] {logging_mixin.py:95} INFO - [2019-08-28 18:34:13,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:13,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:13,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:13,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:13,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-08-28 18:34:13,648] {scheduler_job.py:146} INFO - Started process (PID=19721) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:18,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:18,657] {logging_mixin.py:95} INFO - [2019-08-28 18:34:18,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:19,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:19,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:19,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:19,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-08-28 18:34:19,105] {scheduler_job.py:146} INFO - Started process (PID=19722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:24,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:24,113] {logging_mixin.py:95} INFO - [2019-08-28 18:34:24,112] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:24,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:24,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:24,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:24,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 18:34:24,661] {scheduler_job.py:146} INFO - Started process (PID=19723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:29,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:29,669] {logging_mixin.py:95} INFO - [2019-08-28 18:34:29,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:30,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:30,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:30,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:30,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-08-28 18:34:30,204] {scheduler_job.py:146} INFO - Started process (PID=19728) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:35,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:35,218] {logging_mixin.py:95} INFO - [2019-08-28 18:34:35,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:35,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:35,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:35,626] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:35,632] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:34:35,752] {scheduler_job.py:146} INFO - Started process (PID=19729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:40,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:40,763] {logging_mixin.py:95} INFO - [2019-08-28 18:34:40,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:41,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:41,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:41,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:41,181] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-08-28 18:34:41,206] {scheduler_job.py:146} INFO - Started process (PID=19731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:46,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:46,211] {logging_mixin.py:95} INFO - [2019-08-28 18:34:46,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:46,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:46,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:46,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:46,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:34:46,652] {scheduler_job.py:146} INFO - Started process (PID=19732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:51,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:51,658] {logging_mixin.py:95} INFO - [2019-08-28 18:34:51,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:52,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:52,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:52,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:52,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:34:52,100] {scheduler_job.py:146} INFO - Started process (PID=19733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:57,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:34:57,108] {logging_mixin.py:95} INFO - [2019-08-28 18:34:57,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:57,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:34:57,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:34:57,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:34:57,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-08-28 18:34:57,655] {scheduler_job.py:146} INFO - Started process (PID=19735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:02,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:02,668] {logging_mixin.py:95} INFO - [2019-08-28 18:35:02,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:03,054] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:03,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:03,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:03,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:35:03,196] {scheduler_job.py:146} INFO - Started process (PID=19737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:08,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:08,202] {logging_mixin.py:95} INFO - [2019-08-28 18:35:08,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:08,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:08,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:08,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:08,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-08-28 18:35:08,748] {scheduler_job.py:146} INFO - Started process (PID=19739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:13,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:13,758] {logging_mixin.py:95} INFO - [2019-08-28 18:35:13,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:14,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:14,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:14,141] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:14,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:35:14,205] {scheduler_job.py:146} INFO - Started process (PID=19741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:19,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:19,216] {logging_mixin.py:95} INFO - [2019-08-28 18:35:19,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:19,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:19,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:19,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:19,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-08-28 18:35:19,759] {scheduler_job.py:146} INFO - Started process (PID=19743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:24,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:24,765] {logging_mixin.py:95} INFO - [2019-08-28 18:35:24,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:25,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:25,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:25,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:25,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-08-28 18:35:25,210] {scheduler_job.py:146} INFO - Started process (PID=19744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:30,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:30,215] {logging_mixin.py:95} INFO - [2019-08-28 18:35:30,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:30,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:30,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:30,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:30,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-08-28 18:35:30,756] {scheduler_job.py:146} INFO - Started process (PID=19746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:35,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:35,768] {logging_mixin.py:95} INFO - [2019-08-28 18:35:35,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:36,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:36,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:36,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:36,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-08-28 18:35:36,299] {scheduler_job.py:146} INFO - Started process (PID=19749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:41,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:41,308] {logging_mixin.py:95} INFO - [2019-08-28 18:35:41,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:41,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:41,702] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:41,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:41,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-08-28 18:35:41,754] {scheduler_job.py:146} INFO - Started process (PID=19751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:46,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:46,765] {logging_mixin.py:95} INFO - [2019-08-28 18:35:46,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:47,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:47,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:47,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:47,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:35:47,220] {scheduler_job.py:146} INFO - Started process (PID=19752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:52,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:52,233] {logging_mixin.py:95} INFO - [2019-08-28 18:35:52,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:52,592] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:52,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:52,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:52,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:35:52,672] {scheduler_job.py:146} INFO - Started process (PID=19753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:57,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:35:57,682] {logging_mixin.py:95} INFO - [2019-08-28 18:35:57,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:58,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:35:58,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:35:58,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:35:58,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:35:58,133] {scheduler_job.py:146} INFO - Started process (PID=19755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:03,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:03,148] {logging_mixin.py:95} INFO - [2019-08-28 18:36:03,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:03,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:03,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:03,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:03,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-08-28 18:36:03,593] {scheduler_job.py:146} INFO - Started process (PID=19756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:08,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:08,602] {logging_mixin.py:95} INFO - [2019-08-28 18:36:08,601] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:08,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:09,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:09,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:09,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:36:09,044] {scheduler_job.py:146} INFO - Started process (PID=19759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:14,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:14,052] {logging_mixin.py:95} INFO - [2019-08-28 18:36:14,051] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:14,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:14,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:14,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:14,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-08-28 18:36:14,506] {scheduler_job.py:146} INFO - Started process (PID=19761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:19,513] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:19,514] {logging_mixin.py:95} INFO - [2019-08-28 18:36:19,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:19,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:19,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:19,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:19,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 18:36:19,964] {scheduler_job.py:146} INFO - Started process (PID=19762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:24,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:24,973] {logging_mixin.py:95} INFO - [2019-08-28 18:36:24,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:25,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:25,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:25,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:25,357] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:36:25,429] {scheduler_job.py:146} INFO - Started process (PID=19763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:30,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:30,445] {logging_mixin.py:95} INFO - [2019-08-28 18:36:30,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:30,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:30,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:30,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:30,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:36:30,884] {scheduler_job.py:146} INFO - Started process (PID=19765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:35,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:35,894] {logging_mixin.py:95} INFO - [2019-08-28 18:36:35,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:36,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:36,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:36,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:36,281] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-08-28 18:36:36,333] {scheduler_job.py:146} INFO - Started process (PID=19766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:41,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:41,344] {logging_mixin.py:95} INFO - [2019-08-28 18:36:41,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:41,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:41,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:41,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:41,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-08-28 18:36:41,795] {scheduler_job.py:146} INFO - Started process (PID=19769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:46,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:46,802] {logging_mixin.py:95} INFO - [2019-08-28 18:36:46,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:47,152] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:47,175] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:47,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:47,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:36:47,264] {scheduler_job.py:146} INFO - Started process (PID=19770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:52,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:52,276] {logging_mixin.py:95} INFO - [2019-08-28 18:36:52,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:52,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:52,649] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:52,656] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:52,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:36:52,723] {scheduler_job.py:146} INFO - Started process (PID=19771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:57,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:36:57,743] {logging_mixin.py:95} INFO - [2019-08-28 18:36:57,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:58,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:36:58,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:36:58,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:36:58,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:36:58,186] {scheduler_job.py:146} INFO - Started process (PID=19773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:03,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:03,201] {logging_mixin.py:95} INFO - [2019-08-28 18:37:03,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:03,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:03,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:03,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:03,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:37:03,645] {scheduler_job.py:146} INFO - Started process (PID=19774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:08,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:08,651] {logging_mixin.py:95} INFO - [2019-08-28 18:37:08,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:09,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:09,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:09,071] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:09,076] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-08-28 18:37:09,098] {scheduler_job.py:146} INFO - Started process (PID=19777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:14,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:14,105] {logging_mixin.py:95} INFO - [2019-08-28 18:37:14,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:14,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:14,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:14,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:14,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 18:37:14,545] {scheduler_job.py:146} INFO - Started process (PID=19779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:19,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:19,551] {logging_mixin.py:95} INFO - [2019-08-28 18:37:19,551] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:19,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:19,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:19,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:19,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:37:20,008] {scheduler_job.py:146} INFO - Started process (PID=19780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:25,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:25,018] {logging_mixin.py:95} INFO - [2019-08-28 18:37:25,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:25,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:25,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:25,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:25,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:37:25,474] {scheduler_job.py:146} INFO - Started process (PID=19781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:30,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:30,481] {logging_mixin.py:95} INFO - [2019-08-28 18:37:30,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:30,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:30,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:30,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:30,871] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-08-28 18:37:30,936] {scheduler_job.py:146} INFO - Started process (PID=19783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:35,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:35,947] {logging_mixin.py:95} INFO - [2019-08-28 18:37:35,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:36,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:36,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:36,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:36,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-08-28 18:37:36,394] {scheduler_job.py:146} INFO - Started process (PID=19784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:41,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:41,401] {logging_mixin.py:95} INFO - [2019-08-28 18:37:41,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:41,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:41,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:41,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:41,792] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:37:41,853] {scheduler_job.py:146} INFO - Started process (PID=19787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:46,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:46,865] {logging_mixin.py:95} INFO - [2019-08-28 18:37:46,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:47,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:47,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:47,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:47,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-08-28 18:37:47,401] {scheduler_job.py:146} INFO - Started process (PID=19788) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:52,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:52,411] {logging_mixin.py:95} INFO - [2019-08-28 18:37:52,411] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:52,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:52,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:52,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:52,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-08-28 18:37:52,962] {scheduler_job.py:146} INFO - Started process (PID=19789) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:57,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:37:57,983] {logging_mixin.py:95} INFO - [2019-08-28 18:37:57,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:58,380] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:37:58,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:37:58,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:37:58,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-08-28 18:37:58,514] {scheduler_job.py:146} INFO - Started process (PID=19791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:03,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:03,525] {logging_mixin.py:95} INFO - [2019-08-28 18:38:03,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:03,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:03,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:03,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:03,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-08-28 18:38:03,970] {scheduler_job.py:146} INFO - Started process (PID=19792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:08,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:08,979] {logging_mixin.py:95} INFO - [2019-08-28 18:38:08,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:09,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:09,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:09,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:09,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-08-28 18:38:09,512] {scheduler_job.py:146} INFO - Started process (PID=19794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:14,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:14,518] {logging_mixin.py:95} INFO - [2019-08-28 18:38:14,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:14,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:14,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:14,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:14,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:38:14,960] {scheduler_job.py:146} INFO - Started process (PID=19797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:19,967] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:19,969] {logging_mixin.py:95} INFO - [2019-08-28 18:38:19,968] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:20,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:20,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:20,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:20,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-08-28 18:38:20,412] {scheduler_job.py:146} INFO - Started process (PID=19798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:25,418] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:25,419] {logging_mixin.py:95} INFO - [2019-08-28 18:38:25,419] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:25,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:25,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:25,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:25,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:38:25,863] {scheduler_job.py:146} INFO - Started process (PID=19799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:30,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:30,872] {logging_mixin.py:95} INFO - [2019-08-28 18:38:30,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:31,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:31,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:31,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:31,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-08-28 18:38:31,400] {scheduler_job.py:146} INFO - Started process (PID=19801) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:36,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:36,407] {logging_mixin.py:95} INFO - [2019-08-28 18:38:36,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:36,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:36,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:36,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:36,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-08-28 18:38:36,847] {scheduler_job.py:146} INFO - Started process (PID=19802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:41,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:41,853] {logging_mixin.py:95} INFO - [2019-08-28 18:38:41,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:42,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:42,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:42,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:42,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-08-28 18:38:42,290] {scheduler_job.py:146} INFO - Started process (PID=19805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:47,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:47,297] {logging_mixin.py:95} INFO - [2019-08-28 18:38:47,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:47,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:47,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:47,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:47,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-08-28 18:38:47,740] {scheduler_job.py:146} INFO - Started process (PID=19807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:52,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:52,750] {logging_mixin.py:95} INFO - [2019-08-28 18:38:52,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:53,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:53,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:53,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:53,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-08-28 18:38:53,193] {scheduler_job.py:146} INFO - Started process (PID=19808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:58,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:38:58,210] {logging_mixin.py:95} INFO - [2019-08-28 18:38:58,209] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:58,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:38:58,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:38:58,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:38:58,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-08-28 18:38:58,647] {scheduler_job.py:146} INFO - Started process (PID=19810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:03,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:03,662] {logging_mixin.py:95} INFO - [2019-08-28 18:39:03,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:04,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:04,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:04,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:04,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-08-28 18:39:04,099] {scheduler_job.py:146} INFO - Started process (PID=19811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:09,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:09,106] {logging_mixin.py:95} INFO - [2019-08-28 18:39:09,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:09,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:09,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:09,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:09,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-08-28 18:39:09,562] {scheduler_job.py:146} INFO - Started process (PID=19813) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:14,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:14,568] {logging_mixin.py:95} INFO - [2019-08-28 18:39:14,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:14,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:14,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:14,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:14,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-08-28 18:39:15,018] {scheduler_job.py:146} INFO - Started process (PID=19816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:20,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:20,030] {logging_mixin.py:95} INFO - [2019-08-28 18:39:20,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:20,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:20,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:20,463] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:20,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-08-28 18:39:20,578] {scheduler_job.py:146} INFO - Started process (PID=19817) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:25,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:25,585] {logging_mixin.py:95} INFO - [2019-08-28 18:39:25,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:25,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:25,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:25,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:25,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-08-28 18:39:26,041] {scheduler_job.py:146} INFO - Started process (PID=19818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:31,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:31,058] {logging_mixin.py:95} INFO - [2019-08-28 18:39:31,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:31,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:31,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:31,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:31,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:39:31,501] {scheduler_job.py:146} INFO - Started process (PID=19820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:36,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:36,511] {logging_mixin.py:95} INFO - [2019-08-28 18:39:36,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:36,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:36,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:36,910] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:36,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:39:36,954] {scheduler_job.py:146} INFO - Started process (PID=19821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:41,959] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:41,960] {logging_mixin.py:95} INFO - [2019-08-28 18:39:41,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:42,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:42,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:42,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:42,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:39:42,397] {scheduler_job.py:146} INFO - Started process (PID=19823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:47,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:47,413] {logging_mixin.py:95} INFO - [2019-08-28 18:39:47,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:47,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:47,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:47,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:47,829] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-08-28 18:39:47,853] {scheduler_job.py:146} INFO - Started process (PID=19825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:52,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:52,862] {logging_mixin.py:95} INFO - [2019-08-28 18:39:52,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:53,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:53,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:53,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:53,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-08-28 18:39:53,306] {scheduler_job.py:146} INFO - Started process (PID=19826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:58,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:39:58,323] {logging_mixin.py:95} INFO - [2019-08-28 18:39:58,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:58,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:39:58,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:39:58,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:39:58,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-08-28 18:39:58,760] {scheduler_job.py:146} INFO - Started process (PID=19828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:03,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:03,768] {logging_mixin.py:95} INFO - [2019-08-28 18:40:03,767] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:04,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:04,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:04,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:04,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:40:04,216] {scheduler_job.py:146} INFO - Started process (PID=19829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:09,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:09,226] {logging_mixin.py:95} INFO - [2019-08-28 18:40:09,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:09,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:09,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:09,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:09,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-08-28 18:40:09,762] {scheduler_job.py:146} INFO - Started process (PID=19831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:14,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:14,771] {logging_mixin.py:95} INFO - [2019-08-28 18:40:14,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:15,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:15,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:15,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:15,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-08-28 18:40:15,219] {scheduler_job.py:146} INFO - Started process (PID=19833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:20,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:20,232] {logging_mixin.py:95} INFO - [2019-08-28 18:40:20,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:20,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:20,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:20,632] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:20,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-08-28 18:40:20,664] {scheduler_job.py:146} INFO - Started process (PID=19835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:25,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:25,676] {logging_mixin.py:95} INFO - [2019-08-28 18:40:25,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:26,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:26,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:26,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:26,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-08-28 18:40:26,117] {scheduler_job.py:146} INFO - Started process (PID=19836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:31,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:31,129] {logging_mixin.py:95} INFO - [2019-08-28 18:40:31,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:31,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:31,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:31,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:31,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-08-28 18:40:31,575] {scheduler_job.py:146} INFO - Started process (PID=19838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:36,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:36,583] {logging_mixin.py:95} INFO - [2019-08-28 18:40:36,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:36,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:36,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:36,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:36,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-08-28 18:40:37,029] {scheduler_job.py:146} INFO - Started process (PID=19839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:42,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:42,039] {logging_mixin.py:95} INFO - [2019-08-28 18:40:42,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:42,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:42,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:42,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:42,464] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-08-28 18:40:42,485] {scheduler_job.py:146} INFO - Started process (PID=19841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:47,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:47,494] {logging_mixin.py:95} INFO - [2019-08-28 18:40:47,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:47,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:47,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:47,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:47,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-08-28 18:40:47,937] {scheduler_job.py:146} INFO - Started process (PID=19842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:52,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-08-28 18:40:52,947] {logging_mixin.py:95} INFO - [2019-08-28 18:40:52,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:53,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 18:40:53,367] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-08-28 18:40:53,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-08-28 18:40:53,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-08-28 18:40:53,494] {scheduler_job.py:146} INFO - Started process (PID=19844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
