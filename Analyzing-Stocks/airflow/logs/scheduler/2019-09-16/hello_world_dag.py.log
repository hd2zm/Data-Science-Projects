[2019-09-15 19:00:04,046] {scheduler_job.py:146} INFO - Started process (PID=22305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:09,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:09,062] {logging_mixin.py:95} INFO - [2019-09-15 19:00:09,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:09,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:09,454] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:09,463] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:09,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 19:00:09,524] {scheduler_job.py:146} INFO - Started process (PID=22306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:14,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:14,536] {logging_mixin.py:95} INFO - [2019-09-15 19:00:14,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:14,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:14,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:14,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:14,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:00:14,992] {scheduler_job.py:146} INFO - Started process (PID=22307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:20,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:20,006] {logging_mixin.py:95} INFO - [2019-09-15 19:00:20,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:20,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:20,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:20,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:20,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:00:20,467] {scheduler_job.py:146} INFO - Started process (PID=22309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:25,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:25,482] {logging_mixin.py:95} INFO - [2019-09-15 19:00:25,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:25,840] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:25,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:25,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:25,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 19:00:25,933] {scheduler_job.py:146} INFO - Started process (PID=22310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:30,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:30,943] {logging_mixin.py:95} INFO - [2019-09-15 19:00:30,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:31,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:31,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:31,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:31,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 19:00:31,394] {scheduler_job.py:146} INFO - Started process (PID=22311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:36,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:36,413] {logging_mixin.py:95} INFO - [2019-09-15 19:00:36,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:36,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:36,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:36,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:36,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:00:36,870] {scheduler_job.py:146} INFO - Started process (PID=22313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:41,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:41,882] {logging_mixin.py:95} INFO - [2019-09-15 19:00:41,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:42,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:42,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:42,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:42,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 19:00:42,342] {scheduler_job.py:146} INFO - Started process (PID=22314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:47,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:47,355] {logging_mixin.py:95} INFO - [2019-09-15 19:00:47,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:47,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:47,745] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:47,754] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:47,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:00:47,806] {scheduler_job.py:146} INFO - Started process (PID=22315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:52,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:52,818] {logging_mixin.py:95} INFO - [2019-09-15 19:00:52,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:53,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:53,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:53,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:53,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 19:00:53,280] {scheduler_job.py:146} INFO - Started process (PID=22317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:58,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:00:58,297] {logging_mixin.py:95} INFO - [2019-09-15 19:00:58,297] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:58,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:00:58,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:00:58,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:00:58,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 19:00:58,744] {scheduler_job.py:146} INFO - Started process (PID=22318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:03,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:03,755] {logging_mixin.py:95} INFO - [2019-09-15 19:01:03,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:04,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:04,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:04,146] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:04,152] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 19:01:04,208] {scheduler_job.py:146} INFO - Started process (PID=22321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:09,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:09,220] {logging_mixin.py:95} INFO - [2019-09-15 19:01:09,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:09,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:09,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:09,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:09,626] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:01:09,689] {scheduler_job.py:146} INFO - Started process (PID=22322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:14,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:14,701] {logging_mixin.py:95} INFO - [2019-09-15 19:01:14,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:15,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:15,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:15,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:15,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:01:15,168] {scheduler_job.py:146} INFO - Started process (PID=22323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:20,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:20,181] {logging_mixin.py:95} INFO - [2019-09-15 19:01:20,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:20,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:20,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:20,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:20,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 19:01:20,640] {scheduler_job.py:146} INFO - Started process (PID=22325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:25,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:25,665] {logging_mixin.py:95} INFO - [2019-09-15 19:01:25,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:26,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:26,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:26,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:26,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:01:26,110] {scheduler_job.py:146} INFO - Started process (PID=22326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:31,122] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:31,132] {logging_mixin.py:95} INFO - [2019-09-15 19:01:31,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:31,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:31,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:31,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:31,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 19:01:31,584] {scheduler_job.py:146} INFO - Started process (PID=22327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:36,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:36,607] {logging_mixin.py:95} INFO - [2019-09-15 19:01:36,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:36,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:36,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:37,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:37,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 19:01:37,058] {scheduler_job.py:146} INFO - Started process (PID=22329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:42,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:42,070] {logging_mixin.py:95} INFO - [2019-09-15 19:01:42,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:42,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:42,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:42,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:42,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 19:01:42,530] {scheduler_job.py:146} INFO - Started process (PID=22330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:47,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:47,547] {logging_mixin.py:95} INFO - [2019-09-15 19:01:47,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:47,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:47,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:47,935] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:47,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 19:01:48,008] {scheduler_job.py:146} INFO - Started process (PID=22331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:53,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:53,017] {logging_mixin.py:95} INFO - [2019-09-15 19:01:53,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:53,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:53,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:53,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:53,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 19:01:53,484] {scheduler_job.py:146} INFO - Started process (PID=22333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:58,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:01:58,499] {logging_mixin.py:95} INFO - [2019-09-15 19:01:58,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:58,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:01:58,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:01:58,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:01:58,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 19:01:58,952] {scheduler_job.py:146} INFO - Started process (PID=22334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:03,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:03,966] {logging_mixin.py:95} INFO - [2019-09-15 19:02:03,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:04,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:04,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:04,373] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:04,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:02:04,427] {scheduler_job.py:146} INFO - Started process (PID=22337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:09,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:09,438] {logging_mixin.py:95} INFO - [2019-09-15 19:02:09,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:09,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:09,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:09,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:09,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:02:09,892] {scheduler_job.py:146} INFO - Started process (PID=22338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:14,898] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:14,899] {logging_mixin.py:95} INFO - [2019-09-15 19:02:14,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:15,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:15,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:15,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:15,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:02:15,360] {scheduler_job.py:146} INFO - Started process (PID=22339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:20,369] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:20,370] {logging_mixin.py:95} INFO - [2019-09-15 19:02:20,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:20,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:20,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:20,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:20,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 19:02:20,832] {scheduler_job.py:146} INFO - Started process (PID=22341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:25,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:25,855] {logging_mixin.py:95} INFO - [2019-09-15 19:02:25,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:26,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:26,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:26,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:26,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 19:02:26,300] {scheduler_job.py:146} INFO - Started process (PID=22342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:31,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:31,310] {logging_mixin.py:95} INFO - [2019-09-15 19:02:31,310] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:31,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:31,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:31,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:31,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 19:02:31,777] {scheduler_job.py:146} INFO - Started process (PID=22343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:36,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:36,793] {logging_mixin.py:95} INFO - [2019-09-15 19:02:36,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:37,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:37,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:37,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:37,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 19:02:37,258] {scheduler_job.py:146} INFO - Started process (PID=22345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:42,263] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:42,264] {logging_mixin.py:95} INFO - [2019-09-15 19:02:42,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:42,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:42,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:42,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:42,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:02:42,733] {scheduler_job.py:146} INFO - Started process (PID=22346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:47,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:47,757] {logging_mixin.py:95} INFO - [2019-09-15 19:02:47,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:48,118] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:48,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:48,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:48,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 19:02:48,214] {scheduler_job.py:146} INFO - Started process (PID=22347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:53,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:53,221] {logging_mixin.py:95} INFO - [2019-09-15 19:02:53,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:53,604] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:53,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:53,638] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:53,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 19:02:53,689] {scheduler_job.py:146} INFO - Started process (PID=22349) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:58,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:02:58,706] {logging_mixin.py:95} INFO - [2019-09-15 19:02:58,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:59,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:02:59,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:02:59,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:02:59,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 19:02:59,158] {scheduler_job.py:146} INFO - Started process (PID=22350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:04,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:04,173] {logging_mixin.py:95} INFO - [2019-09-15 19:03:04,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:04,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:04,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:04,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:04,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 19:03:04,642] {scheduler_job.py:146} INFO - Started process (PID=22353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:09,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:09,648] {logging_mixin.py:95} INFO - [2019-09-15 19:03:09,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:10,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:10,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:10,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:10,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 19:03:10,110] {scheduler_job.py:146} INFO - Started process (PID=22354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:15,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:15,122] {logging_mixin.py:95} INFO - [2019-09-15 19:03:15,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:15,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:15,516] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:15,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:15,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:03:15,591] {scheduler_job.py:146} INFO - Started process (PID=22355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:20,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:20,598] {logging_mixin.py:95} INFO - [2019-09-15 19:03:20,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:20,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:20,982] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:20,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:20,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 19:03:21,058] {scheduler_job.py:146} INFO - Started process (PID=22357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:26,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:26,065] {logging_mixin.py:95} INFO - [2019-09-15 19:03:26,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:26,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:26,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:26,477] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:26,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 19:03:26,519] {scheduler_job.py:146} INFO - Started process (PID=22358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:31,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:31,530] {logging_mixin.py:95} INFO - [2019-09-15 19:03:31,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:31,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:31,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:31,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:31,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 19:03:31,990] {scheduler_job.py:146} INFO - Started process (PID=22359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:37,000] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:37,001] {logging_mixin.py:95} INFO - [2019-09-15 19:03:37,001] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:37,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:37,396] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:37,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:37,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:03:37,475] {scheduler_job.py:146} INFO - Started process (PID=22361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:42,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:42,481] {logging_mixin.py:95} INFO - [2019-09-15 19:03:42,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:42,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:42,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:42,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:42,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 19:03:42,942] {scheduler_job.py:146} INFO - Started process (PID=22362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:47,951] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:47,961] {logging_mixin.py:95} INFO - [2019-09-15 19:03:47,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:48,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:48,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:48,362] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:48,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 19:03:48,406] {scheduler_job.py:146} INFO - Started process (PID=22363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:53,411] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:53,412] {logging_mixin.py:95} INFO - [2019-09-15 19:03:53,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:53,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:53,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:53,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:53,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:03:53,882] {scheduler_job.py:146} INFO - Started process (PID=22365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:58,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:03:58,906] {logging_mixin.py:95} INFO - [2019-09-15 19:03:58,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:59,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:03:59,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:03:59,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:03:59,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 19:03:59,357] {scheduler_job.py:146} INFO - Started process (PID=22366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:04,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:04,367] {logging_mixin.py:95} INFO - [2019-09-15 19:04:04,366] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:04,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:04,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:04,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:04,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:04:04,837] {scheduler_job.py:146} INFO - Started process (PID=22369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:09,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:09,859] {logging_mixin.py:95} INFO - [2019-09-15 19:04:09,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:10,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:10,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:10,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:10,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 19:04:10,305] {scheduler_job.py:146} INFO - Started process (PID=22370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:15,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:15,317] {logging_mixin.py:95} INFO - [2019-09-15 19:04:15,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:15,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:15,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:15,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:15,718] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 19:04:15,771] {scheduler_job.py:146} INFO - Started process (PID=22371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:20,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:20,781] {logging_mixin.py:95} INFO - [2019-09-15 19:04:20,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:21,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:21,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:21,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:21,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:04:21,241] {scheduler_job.py:146} INFO - Started process (PID=22373) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:26,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:26,248] {logging_mixin.py:95} INFO - [2019-09-15 19:04:26,248] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:26,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:26,640] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:26,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:26,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 19:04:26,709] {scheduler_job.py:146} INFO - Started process (PID=22374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:31,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:31,731] {logging_mixin.py:95} INFO - [2019-09-15 19:04:31,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:32,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:32,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:32,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:32,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 19:04:32,178] {scheduler_job.py:146} INFO - Started process (PID=22375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:37,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:37,192] {logging_mixin.py:95} INFO - [2019-09-15 19:04:37,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:37,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:37,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:37,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:37,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:04:37,649] {scheduler_job.py:146} INFO - Started process (PID=22377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:42,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:42,662] {logging_mixin.py:95} INFO - [2019-09-15 19:04:42,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:43,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:43,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:43,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:43,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 19:04:43,121] {scheduler_job.py:146} INFO - Started process (PID=22378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:48,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:48,129] {logging_mixin.py:95} INFO - [2019-09-15 19:04:48,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:48,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:48,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:48,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:48,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 19:04:48,581] {scheduler_job.py:146} INFO - Started process (PID=22379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:53,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:53,595] {logging_mixin.py:95} INFO - [2019-09-15 19:04:53,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:53,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:53,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:53,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:53,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:04:54,047] {scheduler_job.py:146} INFO - Started process (PID=22381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:59,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:04:59,056] {logging_mixin.py:95} INFO - [2019-09-15 19:04:59,055] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:59,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:04:59,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:04:59,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:04:59,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:04:59,517] {scheduler_job.py:146} INFO - Started process (PID=22382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:04,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:04,531] {logging_mixin.py:95} INFO - [2019-09-15 19:05:04,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:04,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:04,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:04,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:04,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 19:05:04,971] {scheduler_job.py:146} INFO - Started process (PID=22385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:09,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:09,991] {logging_mixin.py:95} INFO - [2019-09-15 19:05:09,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:10,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:10,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:10,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:10,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 19:05:10,437] {scheduler_job.py:146} INFO - Started process (PID=22386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:15,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:15,446] {logging_mixin.py:95} INFO - [2019-09-15 19:05:15,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:15,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:15,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:15,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:15,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:05:15,910] {scheduler_job.py:146} INFO - Started process (PID=22387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:20,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:20,925] {logging_mixin.py:95} INFO - [2019-09-15 19:05:20,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:21,290] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:21,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:21,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:21,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:05:21,377] {scheduler_job.py:146} INFO - Started process (PID=22389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:26,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:26,391] {logging_mixin.py:95} INFO - [2019-09-15 19:05:26,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:26,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:26,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:26,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:26,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:05:26,851] {scheduler_job.py:146} INFO - Started process (PID=22390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:31,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:31,862] {logging_mixin.py:95} INFO - [2019-09-15 19:05:31,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:32,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:32,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:32,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:32,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 19:05:32,327] {scheduler_job.py:146} INFO - Started process (PID=22391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:37,340] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:37,341] {logging_mixin.py:95} INFO - [2019-09-15 19:05:37,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:37,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:37,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:37,742] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:37,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 19:05:37,787] {scheduler_job.py:146} INFO - Started process (PID=22393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:42,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:42,812] {logging_mixin.py:95} INFO - [2019-09-15 19:05:42,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:43,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:43,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:43,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:43,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 19:05:43,263] {scheduler_job.py:146} INFO - Started process (PID=22394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:48,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:48,284] {logging_mixin.py:95} INFO - [2019-09-15 19:05:48,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:48,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:48,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:48,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:48,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 19:05:48,742] {scheduler_job.py:146} INFO - Started process (PID=22395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:53,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:53,755] {logging_mixin.py:95} INFO - [2019-09-15 19:05:53,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:54,118] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:54,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:54,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:54,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 19:05:54,220] {scheduler_job.py:146} INFO - Started process (PID=22397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:59,230] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:05:59,231] {logging_mixin.py:95} INFO - [2019-09-15 19:05:59,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:59,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:05:59,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:05:59,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:05:59,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 19:05:59,682] {scheduler_job.py:146} INFO - Started process (PID=22398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:04,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:04,695] {logging_mixin.py:95} INFO - [2019-09-15 19:06:04,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:05,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:05,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:05,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:05,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:06:05,150] {scheduler_job.py:146} INFO - Started process (PID=22401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:10,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:10,173] {logging_mixin.py:95} INFO - [2019-09-15 19:06:10,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:10,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:10,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:10,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:10,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 19:06:10,627] {scheduler_job.py:146} INFO - Started process (PID=22402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:15,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:15,652] {logging_mixin.py:95} INFO - [2019-09-15 19:06:15,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:16,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:16,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:16,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:16,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:06:16,102] {scheduler_job.py:146} INFO - Started process (PID=22403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:21,115] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:21,116] {logging_mixin.py:95} INFO - [2019-09-15 19:06:21,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:21,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:21,531] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:21,540] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:21,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 19:06:21,575] {scheduler_job.py:146} INFO - Started process (PID=22405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:26,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:26,588] {logging_mixin.py:95} INFO - [2019-09-15 19:06:26,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:26,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:26,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:26,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:26,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 19:06:27,040] {scheduler_job.py:146} INFO - Started process (PID=22406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:32,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:32,059] {logging_mixin.py:95} INFO - [2019-09-15 19:06:32,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:32,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:32,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:32,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:32,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 19:06:32,519] {scheduler_job.py:146} INFO - Started process (PID=22407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:37,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:37,532] {logging_mixin.py:95} INFO - [2019-09-15 19:06:37,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:37,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:37,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:37,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:37,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:06:37,988] {scheduler_job.py:146} INFO - Started process (PID=22409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:43,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:43,011] {logging_mixin.py:95} INFO - [2019-09-15 19:06:43,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:43,403] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:43,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:43,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:43,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 19:06:43,562] {scheduler_job.py:146} INFO - Started process (PID=22410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:48,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:48,570] {logging_mixin.py:95} INFO - [2019-09-15 19:06:48,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:48,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:48,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:48,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:48,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:06:49,036] {scheduler_job.py:146} INFO - Started process (PID=22411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:54,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:54,044] {logging_mixin.py:95} INFO - [2019-09-15 19:06:54,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:54,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:54,434] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:54,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:54,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:06:54,509] {scheduler_job.py:146} INFO - Started process (PID=22413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:59,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:06:59,524] {logging_mixin.py:95} INFO - [2019-09-15 19:06:59,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:59,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:06:59,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:06:59,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:06:59,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:06:59,989] {scheduler_job.py:146} INFO - Started process (PID=22414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:05,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:05,005] {logging_mixin.py:95} INFO - [2019-09-15 19:07:05,004] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:05,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:05,397] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:05,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:05,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 19:07:05,460] {scheduler_job.py:146} INFO - Started process (PID=22417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:10,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:10,482] {logging_mixin.py:95} INFO - [2019-09-15 19:07:10,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:10,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:10,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:10,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:10,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 19:07:10,937] {scheduler_job.py:146} INFO - Started process (PID=22418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:15,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:15,954] {logging_mixin.py:95} INFO - [2019-09-15 19:07:15,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:16,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:16,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:16,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:16,366] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 19:07:16,407] {scheduler_job.py:146} INFO - Started process (PID=22419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:21,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:21,414] {logging_mixin.py:95} INFO - [2019-09-15 19:07:21,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:21,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:21,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:21,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:21,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 19:07:21,876] {scheduler_job.py:146} INFO - Started process (PID=22421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:26,886] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:26,896] {logging_mixin.py:95} INFO - [2019-09-15 19:07:26,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:27,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:27,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:27,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:27,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 19:07:27,353] {scheduler_job.py:146} INFO - Started process (PID=22422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:32,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:32,360] {logging_mixin.py:95} INFO - [2019-09-15 19:07:32,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:32,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:32,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:32,759] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:32,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 19:07:32,822] {scheduler_job.py:146} INFO - Started process (PID=22423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:37,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:37,836] {logging_mixin.py:95} INFO - [2019-09-15 19:07:37,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:38,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:38,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:38,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:38,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:07:38,299] {scheduler_job.py:146} INFO - Started process (PID=22425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:43,309] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:43,319] {logging_mixin.py:95} INFO - [2019-09-15 19:07:43,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:43,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:43,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:43,723] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:43,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 19:07:43,774] {scheduler_job.py:146} INFO - Started process (PID=22426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:48,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:48,792] {logging_mixin.py:95} INFO - [2019-09-15 19:07:48,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:49,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:49,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:49,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:49,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:07:49,251] {scheduler_job.py:146} INFO - Started process (PID=22427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:54,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:54,263] {logging_mixin.py:95} INFO - [2019-09-15 19:07:54,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:54,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:54,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:07:54,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:07:54,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 19:07:54,721] {scheduler_job.py:146} INFO - Started process (PID=22429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:07:59,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:07:59,728] {logging_mixin.py:95} INFO - [2019-09-15 19:07:59,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:00,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:00,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:00,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:00,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 19:08:00,194] {scheduler_job.py:146} INFO - Started process (PID=22430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:05,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:05,200] {logging_mixin.py:95} INFO - [2019-09-15 19:08:05,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:05,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:05,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:05,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:05,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:08:05,672] {scheduler_job.py:146} INFO - Started process (PID=22433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:10,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:10,684] {logging_mixin.py:95} INFO - [2019-09-15 19:08:10,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:11,044] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:11,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:11,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:11,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:08:11,149] {scheduler_job.py:146} INFO - Started process (PID=22434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:16,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:16,168] {logging_mixin.py:95} INFO - [2019-09-15 19:08:16,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:16,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:16,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:16,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:16,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 19:08:16,712] {scheduler_job.py:146} INFO - Started process (PID=22435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:21,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:21,719] {logging_mixin.py:95} INFO - [2019-09-15 19:08:21,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:22,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:22,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:22,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:22,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:08:22,181] {scheduler_job.py:146} INFO - Started process (PID=22437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:27,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:27,202] {logging_mixin.py:95} INFO - [2019-09-15 19:08:27,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:27,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:27,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:27,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:27,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 19:08:27,653] {scheduler_job.py:146} INFO - Started process (PID=22438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:32,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:32,667] {logging_mixin.py:95} INFO - [2019-09-15 19:08:32,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:33,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:33,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:33,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:33,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:08:33,127] {scheduler_job.py:146} INFO - Started process (PID=22439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:38,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:38,133] {logging_mixin.py:95} INFO - [2019-09-15 19:08:38,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:38,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:38,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:38,538] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:38,545] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:08:38,604] {scheduler_job.py:146} INFO - Started process (PID=22441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:43,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:43,613] {logging_mixin.py:95} INFO - [2019-09-15 19:08:43,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:43,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:43,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:44,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:44,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:08:44,073] {scheduler_job.py:146} INFO - Started process (PID=22442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:49,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:49,096] {logging_mixin.py:95} INFO - [2019-09-15 19:08:49,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:49,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:49,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:49,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:49,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 19:08:49,557] {scheduler_job.py:146} INFO - Started process (PID=22444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:54,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:08:54,572] {logging_mixin.py:95} INFO - [2019-09-15 19:08:54,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:54,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:08:54,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:08:54,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:08:54,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 19:08:55,035] {scheduler_job.py:146} INFO - Started process (PID=22445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:00,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:00,043] {logging_mixin.py:95} INFO - [2019-09-15 19:09:00,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:00,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:00,434] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:00,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:00,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 19:09:00,511] {scheduler_job.py:146} INFO - Started process (PID=22446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:05,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:05,525] {logging_mixin.py:95} INFO - [2019-09-15 19:09:05,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:05,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:05,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:05,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:05,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:09:05,986] {scheduler_job.py:146} INFO - Started process (PID=22449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:10,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:11,007] {logging_mixin.py:95} INFO - [2019-09-15 19:09:11,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:11,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:11,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:11,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:11,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:09:11,454] {scheduler_job.py:146} INFO - Started process (PID=22450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:16,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:16,472] {logging_mixin.py:95} INFO - [2019-09-15 19:09:16,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:16,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:16,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:16,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:16,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 19:09:16,909] {scheduler_job.py:146} INFO - Started process (PID=22451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:21,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:21,916] {logging_mixin.py:95} INFO - [2019-09-15 19:09:21,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:22,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:22,304] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:22,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:22,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 19:09:22,361] {scheduler_job.py:146} INFO - Started process (PID=22454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:27,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:27,368] {logging_mixin.py:95} INFO - [2019-09-15 19:09:27,367] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:27,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:27,762] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:27,771] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:27,777] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 19:09:27,804] {scheduler_job.py:146} INFO - Started process (PID=22455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:32,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:32,811] {logging_mixin.py:95} INFO - [2019-09-15 19:09:32,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:33,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:33,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:33,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:33,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 19:09:33,347] {scheduler_job.py:146} INFO - Started process (PID=22456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:38,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:38,358] {logging_mixin.py:95} INFO - [2019-09-15 19:09:38,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:38,718] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:38,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:38,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:38,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 19:09:38,791] {scheduler_job.py:146} INFO - Started process (PID=22458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:43,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:43,798] {logging_mixin.py:95} INFO - [2019-09-15 19:09:43,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:44,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:44,212] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:44,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:44,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 19:09:44,337] {scheduler_job.py:146} INFO - Started process (PID=22460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:49,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:49,344] {logging_mixin.py:95} INFO - [2019-09-15 19:09:49,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:49,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:49,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:49,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:49,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-15 19:09:49,882] {scheduler_job.py:146} INFO - Started process (PID=22462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:54,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:09:54,894] {logging_mixin.py:95} INFO - [2019-09-15 19:09:54,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:55,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:09:55,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:09:55,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:09:55,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 19:09:55,439] {scheduler_job.py:146} INFO - Started process (PID=22463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:00,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:00,450] {logging_mixin.py:95} INFO - [2019-09-15 19:10:00,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:00,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:00,860] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:00,868] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:00,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 19:10:00,894] {scheduler_job.py:146} INFO - Started process (PID=22464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:05,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:05,903] {logging_mixin.py:95} INFO - [2019-09-15 19:10:05,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:06,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:06,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:06,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:06,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:10:06,351] {scheduler_job.py:146} INFO - Started process (PID=22467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:11,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:11,368] {logging_mixin.py:95} INFO - [2019-09-15 19:10:11,367] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:11,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:11,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:11,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:11,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 19:10:11,805] {scheduler_job.py:146} INFO - Started process (PID=22468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:16,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:16,822] {logging_mixin.py:95} INFO - [2019-09-15 19:10:16,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:17,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:17,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:17,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:17,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 19:10:17,266] {scheduler_job.py:146} INFO - Started process (PID=22469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:22,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:22,275] {logging_mixin.py:95} INFO - [2019-09-15 19:10:22,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:22,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:22,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:22,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:22,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:10:22,719] {scheduler_job.py:146} INFO - Started process (PID=22471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:27,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:27,726] {logging_mixin.py:95} INFO - [2019-09-15 19:10:27,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:28,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:28,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:28,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:28,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:10:28,175] {scheduler_job.py:146} INFO - Started process (PID=22472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:33,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:33,186] {logging_mixin.py:95} INFO - [2019-09-15 19:10:33,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:33,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:33,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:33,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:33,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:10:33,629] {scheduler_job.py:146} INFO - Started process (PID=22473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:38,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:38,637] {logging_mixin.py:95} INFO - [2019-09-15 19:10:38,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:39,012] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:39,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:39,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:39,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 19:10:39,084] {scheduler_job.py:146} INFO - Started process (PID=22475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:44,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:44,102] {logging_mixin.py:95} INFO - [2019-09-15 19:10:44,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:44,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:44,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:44,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:44,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 19:10:44,538] {scheduler_job.py:146} INFO - Started process (PID=22476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:49,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:49,544] {logging_mixin.py:95} INFO - [2019-09-15 19:10:49,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:49,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:49,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:49,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:49,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:10:49,992] {scheduler_job.py:146} INFO - Started process (PID=22478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:55,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:10:55,002] {logging_mixin.py:95} INFO - [2019-09-15 19:10:55,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:55,388] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:10:55,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:10:55,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:10:55,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 19:10:55,532] {scheduler_job.py:146} INFO - Started process (PID=22479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:00,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:00,539] {logging_mixin.py:95} INFO - [2019-09-15 19:11:00,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:00,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:00,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:00,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:00,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 19:11:01,077] {scheduler_job.py:146} INFO - Started process (PID=22480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:06,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:06,085] {logging_mixin.py:95} INFO - [2019-09-15 19:11:06,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:06,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:06,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:06,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:06,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-15 19:11:06,613] {scheduler_job.py:146} INFO - Started process (PID=22483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:11,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:11,620] {logging_mixin.py:95} INFO - [2019-09-15 19:11:11,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:12,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:12,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:12,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:12,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.522 seconds
[2019-09-15 19:11:12,162] {scheduler_job.py:146} INFO - Started process (PID=22484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:17,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:17,174] {logging_mixin.py:95} INFO - [2019-09-15 19:11:17,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:17,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:17,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:17,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:17,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:11:17,609] {scheduler_job.py:146} INFO - Started process (PID=22485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:22,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:22,617] {logging_mixin.py:95} INFO - [2019-09-15 19:11:22,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:22,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:22,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:22,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:23,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:11:23,057] {scheduler_job.py:146} INFO - Started process (PID=22487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:28,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:28,074] {logging_mixin.py:95} INFO - [2019-09-15 19:11:28,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:28,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:28,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:28,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:28,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:11:28,498] {scheduler_job.py:146} INFO - Started process (PID=22488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:33,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:33,508] {logging_mixin.py:95} INFO - [2019-09-15 19:11:33,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:33,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:33,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:33,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:33,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:11:33,951] {scheduler_job.py:146} INFO - Started process (PID=22489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:38,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:38,957] {logging_mixin.py:95} INFO - [2019-09-15 19:11:38,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:39,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:39,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:39,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:39,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:11:39,393] {scheduler_job.py:146} INFO - Started process (PID=22491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:44,399] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:44,400] {logging_mixin.py:95} INFO - [2019-09-15 19:11:44,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:44,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:44,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:44,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:44,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 19:11:44,945] {scheduler_job.py:146} INFO - Started process (PID=22492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:49,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:49,956] {logging_mixin.py:95} INFO - [2019-09-15 19:11:49,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:50,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:50,383] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:50,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:50,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 19:11:50,490] {scheduler_job.py:146} INFO - Started process (PID=22494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:55,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:11:55,498] {logging_mixin.py:95} INFO - [2019-09-15 19:11:55,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:55,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:11:55,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:11:55,927] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:11:55,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 19:11:56,034] {scheduler_job.py:146} INFO - Started process (PID=22495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:01,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:01,040] {logging_mixin.py:95} INFO - [2019-09-15 19:12:01,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:01,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:01,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:01,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:01,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 19:12:01,579] {scheduler_job.py:146} INFO - Started process (PID=22496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:06,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:06,591] {logging_mixin.py:95} INFO - [2019-09-15 19:12:06,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:06,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:07,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:07,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:07,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 19:12:07,122] {scheduler_job.py:146} INFO - Started process (PID=22499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:12,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:12,132] {logging_mixin.py:95} INFO - [2019-09-15 19:12:12,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:12,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:12,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:12,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:12,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 19:12:12,669] {scheduler_job.py:146} INFO - Started process (PID=22500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:17,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:17,677] {logging_mixin.py:95} INFO - [2019-09-15 19:12:17,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:18,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:18,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:18,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:18,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 19:12:18,120] {scheduler_job.py:146} INFO - Started process (PID=22501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:23,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:23,127] {logging_mixin.py:95} INFO - [2019-09-15 19:12:23,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:23,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:23,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:23,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:23,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 19:12:23,668] {scheduler_job.py:146} INFO - Started process (PID=22503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:28,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:28,675] {logging_mixin.py:95} INFO - [2019-09-15 19:12:28,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:29,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:29,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:29,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:29,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 19:12:29,111] {scheduler_job.py:146} INFO - Started process (PID=22504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:34,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:34,121] {logging_mixin.py:95} INFO - [2019-09-15 19:12:34,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:34,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:34,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:34,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:34,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:12:34,558] {scheduler_job.py:146} INFO - Started process (PID=22505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:39,564] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:39,575] {logging_mixin.py:95} INFO - [2019-09-15 19:12:39,574] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:39,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:39,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:39,971] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:39,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 19:12:40,007] {scheduler_job.py:146} INFO - Started process (PID=22507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:45,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:45,024] {logging_mixin.py:95} INFO - [2019-09-15 19:12:45,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:45,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:45,396] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:45,405] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:45,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 19:12:45,464] {scheduler_job.py:146} INFO - Started process (PID=22508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:50,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:50,473] {logging_mixin.py:95} INFO - [2019-09-15 19:12:50,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:50,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:50,846] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:50,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:50,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:12:50,927] {scheduler_job.py:146} INFO - Started process (PID=22510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:55,935] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:12:55,945] {logging_mixin.py:95} INFO - [2019-09-15 19:12:55,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:56,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:12:56,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:12:56,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:12:56,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 19:12:56,487] {scheduler_job.py:146} INFO - Started process (PID=22511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:01,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:01,495] {logging_mixin.py:95} INFO - [2019-09-15 19:13:01,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:01,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:01,977] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:01,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:01,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.506 seconds
[2019-09-15 19:13:02,035] {scheduler_job.py:146} INFO - Started process (PID=22514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:07,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:07,044] {logging_mixin.py:95} INFO - [2019-09-15 19:13:07,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:07,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:07,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:07,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:07,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:13:07,483] {scheduler_job.py:146} INFO - Started process (PID=22517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:12,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:12,490] {logging_mixin.py:95} INFO - [2019-09-15 19:13:12,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:12,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:12,914] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:12,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:12,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-15 19:13:13,033] {scheduler_job.py:146} INFO - Started process (PID=22518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:18,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:18,040] {logging_mixin.py:95} INFO - [2019-09-15 19:13:18,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:18,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:18,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:18,426] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:18,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:13:18,483] {scheduler_job.py:146} INFO - Started process (PID=22519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:23,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:23,489] {logging_mixin.py:95} INFO - [2019-09-15 19:13:23,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:23,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:23,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:23,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:23,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 19:13:23,934] {scheduler_job.py:146} INFO - Started process (PID=22521) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:28,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:28,943] {logging_mixin.py:95} INFO - [2019-09-15 19:13:28,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:29,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:29,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:29,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:29,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:13:29,383] {scheduler_job.py:146} INFO - Started process (PID=22522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:34,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:34,391] {logging_mixin.py:95} INFO - [2019-09-15 19:13:34,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:34,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:34,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:34,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:34,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-15 19:13:34,934] {scheduler_job.py:146} INFO - Started process (PID=22524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:39,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:39,951] {logging_mixin.py:95} INFO - [2019-09-15 19:13:39,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:40,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:40,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:40,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:40,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 19:13:40,472] {scheduler_job.py:146} INFO - Started process (PID=22525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:45,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:45,479] {logging_mixin.py:95} INFO - [2019-09-15 19:13:45,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:45,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:45,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:45,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:45,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 19:13:46,017] {scheduler_job.py:146} INFO - Started process (PID=22526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:51,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:51,025] {logging_mixin.py:95} INFO - [2019-09-15 19:13:51,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:51,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:51,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:51,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:51,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:13:51,458] {scheduler_job.py:146} INFO - Started process (PID=22528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:56,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:13:56,470] {logging_mixin.py:95} INFO - [2019-09-15 19:13:56,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:56,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:13:56,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:13:56,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:13:56,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 19:13:56,908] {scheduler_job.py:146} INFO - Started process (PID=22529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:01,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:01,915] {logging_mixin.py:95} INFO - [2019-09-15 19:14:01,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:02,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:02,332] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:02,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:02,350] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 19:14:02,464] {scheduler_job.py:146} INFO - Started process (PID=22530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:07,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:07,483] {logging_mixin.py:95} INFO - [2019-09-15 19:14:07,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:07,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:07,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:07,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:07,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 19:14:07,904] {scheduler_job.py:146} INFO - Started process (PID=22533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:12,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:12,911] {logging_mixin.py:95} INFO - [2019-09-15 19:14:12,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:13,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:13,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:13,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:13,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.525 seconds
[2019-09-15 19:14:13,453] {scheduler_job.py:146} INFO - Started process (PID=22535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:18,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:18,463] {logging_mixin.py:95} INFO - [2019-09-15 19:14:18,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:18,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:18,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:18,868] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:18,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 19:14:18,902] {scheduler_job.py:146} INFO - Started process (PID=22536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:23,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:23,908] {logging_mixin.py:95} INFO - [2019-09-15 19:14:23,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:24,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:24,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:24,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:24,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:14:24,355] {scheduler_job.py:146} INFO - Started process (PID=22538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:29,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:29,365] {logging_mixin.py:95} INFO - [2019-09-15 19:14:29,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:29,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:29,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:29,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:29,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 19:14:29,806] {scheduler_job.py:146} INFO - Started process (PID=22539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:34,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:34,813] {logging_mixin.py:95} INFO - [2019-09-15 19:14:34,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:35,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:35,182] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:35,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:35,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:14:35,261] {scheduler_job.py:146} INFO - Started process (PID=22541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:40,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:40,279] {logging_mixin.py:95} INFO - [2019-09-15 19:14:40,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:40,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:40,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:40,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:40,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 19:14:40,711] {scheduler_job.py:146} INFO - Started process (PID=22542) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:45,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:45,731] {logging_mixin.py:95} INFO - [2019-09-15 19:14:45,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:46,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:46,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:46,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:46,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:14:46,168] {scheduler_job.py:146} INFO - Started process (PID=22543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:51,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:51,177] {logging_mixin.py:95} INFO - [2019-09-15 19:14:51,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:51,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:51,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:51,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:51,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:14:51,621] {scheduler_job.py:146} INFO - Started process (PID=22545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:56,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:14:56,632] {logging_mixin.py:95} INFO - [2019-09-15 19:14:56,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:57,046] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:14:57,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:14:57,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:14:57,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-09-15 19:14:57,175] {scheduler_job.py:146} INFO - Started process (PID=22546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:02,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:02,187] {logging_mixin.py:95} INFO - [2019-09-15 19:15:02,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:02,571] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:02,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:02,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:02,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 19:15:02,720] {scheduler_job.py:146} INFO - Started process (PID=22547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:07,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:07,733] {logging_mixin.py:95} INFO - [2019-09-15 19:15:07,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:08,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:08,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:08,195] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:08,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-15 19:15:08,273] {scheduler_job.py:146} INFO - Started process (PID=22550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:13,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:13,283] {logging_mixin.py:95} INFO - [2019-09-15 19:15:13,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:13,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:13,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:13,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:13,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 19:15:13,725] {scheduler_job.py:146} INFO - Started process (PID=22551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:18,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:18,733] {logging_mixin.py:95} INFO - [2019-09-15 19:15:18,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:19,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:19,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:19,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:19,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:15:19,168] {scheduler_job.py:146} INFO - Started process (PID=22552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:24,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:24,179] {logging_mixin.py:95} INFO - [2019-09-15 19:15:24,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:24,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:24,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:24,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:24,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:15:24,616] {scheduler_job.py:146} INFO - Started process (PID=22554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:29,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:29,628] {logging_mixin.py:95} INFO - [2019-09-15 19:15:29,627] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:29,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:29,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:30,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:30,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:15:30,075] {scheduler_job.py:146} INFO - Started process (PID=22555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:35,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:35,082] {logging_mixin.py:95} INFO - [2019-09-15 19:15:35,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:35,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:35,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:35,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:35,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:15:35,534] {scheduler_job.py:146} INFO - Started process (PID=22557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:40,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:40,545] {logging_mixin.py:95} INFO - [2019-09-15 19:15:40,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:40,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:40,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:40,921] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:40,927] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:15:40,999] {scheduler_job.py:146} INFO - Started process (PID=22558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:46,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:46,006] {logging_mixin.py:95} INFO - [2019-09-15 19:15:46,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:46,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:46,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:46,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:46,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 19:15:46,458] {scheduler_job.py:146} INFO - Started process (PID=22559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:51,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:51,474] {logging_mixin.py:95} INFO - [2019-09-15 19:15:51,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:51,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:51,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:51,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:51,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:15:51,914] {scheduler_job.py:146} INFO - Started process (PID=22561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:56,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:15:56,921] {logging_mixin.py:95} INFO - [2019-09-15 19:15:56,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:57,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:15:57,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:15:57,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:15:57,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:15:57,376] {scheduler_job.py:146} INFO - Started process (PID=22562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:02,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:02,383] {logging_mixin.py:95} INFO - [2019-09-15 19:16:02,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:02,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:02,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:02,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:02,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:16:02,840] {scheduler_job.py:146} INFO - Started process (PID=22563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:07,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:07,858] {logging_mixin.py:95} INFO - [2019-09-15 19:16:07,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:08,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:08,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:08,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:08,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 19:16:08,303] {scheduler_job.py:146} INFO - Started process (PID=22566) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:13,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:13,314] {logging_mixin.py:95} INFO - [2019-09-15 19:16:13,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:13,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:13,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:13,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:13,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:16:13,767] {scheduler_job.py:146} INFO - Started process (PID=22568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:18,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:18,785] {logging_mixin.py:95} INFO - [2019-09-15 19:16:18,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:19,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:19,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:19,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:19,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:16:19,232] {scheduler_job.py:146} INFO - Started process (PID=22569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:24,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:24,256] {logging_mixin.py:95} INFO - [2019-09-15 19:16:24,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:24,604] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:24,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:24,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:24,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:16:24,694] {scheduler_job.py:146} INFO - Started process (PID=22571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:29,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:29,714] {logging_mixin.py:95} INFO - [2019-09-15 19:16:29,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:30,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:30,077] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:30,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:30,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:16:30,145] {scheduler_job.py:146} INFO - Started process (PID=22572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:35,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:35,154] {logging_mixin.py:95} INFO - [2019-09-15 19:16:35,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:35,510] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:35,538] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:35,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:35,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 19:16:35,609] {scheduler_job.py:146} INFO - Started process (PID=22574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:40,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:40,630] {logging_mixin.py:95} INFO - [2019-09-15 19:16:40,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:40,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:40,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:41,005] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:41,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:16:41,066] {scheduler_job.py:146} INFO - Started process (PID=22575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:46,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:46,078] {logging_mixin.py:95} INFO - [2019-09-15 19:16:46,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:46,459] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:46,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:46,488] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:46,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 19:16:46,523] {scheduler_job.py:146} INFO - Started process (PID=22576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:51,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:51,544] {logging_mixin.py:95} INFO - [2019-09-15 19:16:51,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:51,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:51,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:51,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:51,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:16:51,985] {scheduler_job.py:146} INFO - Started process (PID=22578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:56,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:16:56,996] {logging_mixin.py:95} INFO - [2019-09-15 19:16:56,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:57,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:16:57,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:16:57,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:16:57,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:16:57,449] {scheduler_job.py:146} INFO - Started process (PID=22579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:02,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:02,455] {logging_mixin.py:95} INFO - [2019-09-15 19:17:02,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:02,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:02,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:02,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:02,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:17:02,905] {scheduler_job.py:146} INFO - Started process (PID=22582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:07,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:07,925] {logging_mixin.py:95} INFO - [2019-09-15 19:17:07,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:08,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:08,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:08,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:08,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 19:17:08,362] {scheduler_job.py:146} INFO - Started process (PID=22587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:13,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:13,371] {logging_mixin.py:95} INFO - [2019-09-15 19:17:13,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:13,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:13,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:13,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:13,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:17:13,823] {scheduler_job.py:146} INFO - Started process (PID=22588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:18,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:18,831] {logging_mixin.py:95} INFO - [2019-09-15 19:17:18,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:19,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:19,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:19,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:19,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:17:19,289] {scheduler_job.py:146} INFO - Started process (PID=22589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:24,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:24,307] {logging_mixin.py:95} INFO - [2019-09-15 19:17:24,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:24,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:24,667] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:24,676] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:24,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:17:24,746] {scheduler_job.py:146} INFO - Started process (PID=22591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:29,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:29,753] {logging_mixin.py:95} INFO - [2019-09-15 19:17:29,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:30,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:30,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:30,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:30,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 19:17:30,208] {scheduler_job.py:146} INFO - Started process (PID=22592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:35,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:35,218] {logging_mixin.py:95} INFO - [2019-09-15 19:17:35,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:35,564] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:35,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:35,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:35,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:17:35,672] {scheduler_job.py:146} INFO - Started process (PID=22594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:40,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:40,694] {logging_mixin.py:95} INFO - [2019-09-15 19:17:40,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:41,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:41,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:41,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:41,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:17:41,131] {scheduler_job.py:146} INFO - Started process (PID=22595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:46,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:46,142] {logging_mixin.py:95} INFO - [2019-09-15 19:17:46,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:46,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:46,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:46,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:46,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 19:17:46,589] {scheduler_job.py:146} INFO - Started process (PID=22596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:51,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:51,607] {logging_mixin.py:95} INFO - [2019-09-15 19:17:51,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:51,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:51,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:51,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:51,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:17:52,055] {scheduler_job.py:146} INFO - Started process (PID=22598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:57,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:17:57,066] {logging_mixin.py:95} INFO - [2019-09-15 19:17:57,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:57,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:17:57,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:17:57,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:17:57,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:17:57,514] {scheduler_job.py:146} INFO - Started process (PID=22599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:02,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:02,527] {logging_mixin.py:95} INFO - [2019-09-15 19:18:02,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:02,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:02,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:02,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:02,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:18:02,971] {scheduler_job.py:146} INFO - Started process (PID=22600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:07,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:07,981] {logging_mixin.py:95} INFO - [2019-09-15 19:18:07,980] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:08,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:08,355] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:08,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:08,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:18:08,434] {scheduler_job.py:146} INFO - Started process (PID=22603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:13,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:13,444] {logging_mixin.py:95} INFO - [2019-09-15 19:18:13,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:13,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:13,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:13,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:13,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:18:13,895] {scheduler_job.py:146} INFO - Started process (PID=22604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:18,901] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:18,902] {logging_mixin.py:95} INFO - [2019-09-15 19:18:18,902] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:19,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:19,271] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:19,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:19,286] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:18:19,356] {scheduler_job.py:146} INFO - Started process (PID=22605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:24,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:24,362] {logging_mixin.py:95} INFO - [2019-09-15 19:18:24,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:24,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:24,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:24,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:24,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:18:24,814] {scheduler_job.py:146} INFO - Started process (PID=22607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:29,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:29,824] {logging_mixin.py:95} INFO - [2019-09-15 19:18:29,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:30,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:30,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:30,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:30,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:18:30,272] {scheduler_job.py:146} INFO - Started process (PID=22608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:35,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:35,292] {logging_mixin.py:95} INFO - [2019-09-15 19:18:35,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:35,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:35,659] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:35,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:35,674] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:18:35,732] {scheduler_job.py:146} INFO - Started process (PID=22610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:40,739] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:40,740] {logging_mixin.py:95} INFO - [2019-09-15 19:18:40,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:41,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:41,131] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:41,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:41,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 19:18:41,178] {scheduler_job.py:146} INFO - Started process (PID=22617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:46,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:46,186] {logging_mixin.py:95} INFO - [2019-09-15 19:18:46,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:46,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:46,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:46,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:46,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 19:18:46,721] {scheduler_job.py:146} INFO - Started process (PID=22619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:51,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:51,733] {logging_mixin.py:95} INFO - [2019-09-15 19:18:51,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:52,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:52,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:52,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:52,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 19:18:52,179] {scheduler_job.py:146} INFO - Started process (PID=22621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:57,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:18:57,186] {logging_mixin.py:95} INFO - [2019-09-15 19:18:57,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:57,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:18:57,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:18:57,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:18:57,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:18:57,639] {scheduler_job.py:146} INFO - Started process (PID=22622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:02,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:02,648] {logging_mixin.py:95} INFO - [2019-09-15 19:19:02,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:02,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:03,015] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:03,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:03,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:19:03,096] {scheduler_job.py:146} INFO - Started process (PID=22623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:08,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:08,103] {logging_mixin.py:95} INFO - [2019-09-15 19:19:08,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:08,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:08,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:08,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:08,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:19:08,558] {scheduler_job.py:146} INFO - Started process (PID=22626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:13,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:13,569] {logging_mixin.py:95} INFO - [2019-09-15 19:19:13,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:13,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:13,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:13,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:13,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:19:14,013] {scheduler_job.py:146} INFO - Started process (PID=22627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:19,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:19,025] {logging_mixin.py:95} INFO - [2019-09-15 19:19:19,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:19,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:19,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:19,413] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:19,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 19:19:19,474] {scheduler_job.py:146} INFO - Started process (PID=22628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:24,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:24,485] {logging_mixin.py:95} INFO - [2019-09-15 19:19:24,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:24,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:24,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:24,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:24,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:19:24,934] {scheduler_job.py:146} INFO - Started process (PID=22630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:29,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:29,942] {logging_mixin.py:95} INFO - [2019-09-15 19:19:29,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:30,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:30,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:30,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:30,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:19:30,398] {scheduler_job.py:146} INFO - Started process (PID=22631) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:35,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:35,417] {logging_mixin.py:95} INFO - [2019-09-15 19:19:35,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:35,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:35,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:35,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:35,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:19:35,856] {scheduler_job.py:146} INFO - Started process (PID=22633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:40,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:40,865] {logging_mixin.py:95} INFO - [2019-09-15 19:19:40,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:41,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:41,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:41,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:41,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:19:41,313] {scheduler_job.py:146} INFO - Started process (PID=22634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:46,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:46,319] {logging_mixin.py:95} INFO - [2019-09-15 19:19:46,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:46,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:46,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:46,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:46,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 19:19:46,777] {scheduler_job.py:146} INFO - Started process (PID=22635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:51,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:51,794] {logging_mixin.py:95} INFO - [2019-09-15 19:19:51,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:52,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:52,159] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:52,169] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:52,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:19:52,233] {scheduler_job.py:146} INFO - Started process (PID=22637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:57,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:19:57,243] {logging_mixin.py:95} INFO - [2019-09-15 19:19:57,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:57,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:19:57,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:19:57,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:19:57,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:19:57,693] {scheduler_job.py:146} INFO - Started process (PID=22638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:02,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:02,701] {logging_mixin.py:95} INFO - [2019-09-15 19:20:02,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:03,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:03,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:03,071] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:03,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:20:03,155] {scheduler_job.py:146} INFO - Started process (PID=22639) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:08,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:08,164] {logging_mixin.py:95} INFO - [2019-09-15 19:20:08,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:08,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:08,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:08,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:08,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:20:08,613] {scheduler_job.py:146} INFO - Started process (PID=22642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:13,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:13,621] {logging_mixin.py:95} INFO - [2019-09-15 19:20:13,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:13,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:13,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:13,998] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:14,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:20:14,072] {scheduler_job.py:146} INFO - Started process (PID=22643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:19,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:19,078] {logging_mixin.py:95} INFO - [2019-09-15 19:20:19,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:19,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:19,457] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:19,466] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:19,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:20:19,532] {scheduler_job.py:146} INFO - Started process (PID=22644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:24,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:24,540] {logging_mixin.py:95} INFO - [2019-09-15 19:20:24,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:24,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:24,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:24,914] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:24,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:20:24,995] {scheduler_job.py:146} INFO - Started process (PID=22646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:30,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:30,005] {logging_mixin.py:95} INFO - [2019-09-15 19:20:30,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:30,357] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:30,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:30,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:30,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 19:20:30,450] {scheduler_job.py:146} INFO - Started process (PID=22647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:35,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:35,467] {logging_mixin.py:95} INFO - [2019-09-15 19:20:35,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:35,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:35,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:35,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:35,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:20:35,914] {scheduler_job.py:146} INFO - Started process (PID=22649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:40,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:40,924] {logging_mixin.py:95} INFO - [2019-09-15 19:20:40,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:41,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:41,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:41,303] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:41,308] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:20:41,370] {scheduler_job.py:146} INFO - Started process (PID=22650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:46,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:46,379] {logging_mixin.py:95} INFO - [2019-09-15 19:20:46,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:46,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:46,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:46,770] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:46,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 19:20:46,828] {scheduler_job.py:146} INFO - Started process (PID=22651) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:51,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:51,845] {logging_mixin.py:95} INFO - [2019-09-15 19:20:51,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:52,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:52,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:52,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:52,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:20:52,290] {scheduler_job.py:146} INFO - Started process (PID=22653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:57,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:20:57,299] {logging_mixin.py:95} INFO - [2019-09-15 19:20:57,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:57,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:20:57,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:20:57,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:20:57,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:20:57,747] {scheduler_job.py:146} INFO - Started process (PID=22654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:02,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:02,754] {logging_mixin.py:95} INFO - [2019-09-15 19:21:02,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:03,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:03,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:03,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:03,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:21:03,212] {scheduler_job.py:146} INFO - Started process (PID=22655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:08,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:08,231] {logging_mixin.py:95} INFO - [2019-09-15 19:21:08,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:08,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:08,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:08,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:08,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 19:21:08,677] {scheduler_job.py:146} INFO - Started process (PID=22658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:13,683] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:13,684] {logging_mixin.py:95} INFO - [2019-09-15 19:21:13,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:14,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:14,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:14,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:14,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 19:21:14,141] {scheduler_job.py:146} INFO - Started process (PID=22659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:19,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:19,151] {logging_mixin.py:95} INFO - [2019-09-15 19:21:19,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:19,504] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:19,532] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:19,541] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:19,546] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 19:21:19,604] {scheduler_job.py:146} INFO - Started process (PID=22660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:24,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:24,616] {logging_mixin.py:95} INFO - [2019-09-15 19:21:24,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:24,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:24,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:24,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:24,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:21:25,069] {scheduler_job.py:146} INFO - Started process (PID=22662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:30,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:30,078] {logging_mixin.py:95} INFO - [2019-09-15 19:21:30,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:30,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:30,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:30,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:30,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:21:30,528] {scheduler_job.py:146} INFO - Started process (PID=22663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:35,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:35,545] {logging_mixin.py:95} INFO - [2019-09-15 19:21:35,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:35,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:35,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:35,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:35,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:21:35,992] {scheduler_job.py:146} INFO - Started process (PID=22665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:40,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:41,009] {logging_mixin.py:95} INFO - [2019-09-15 19:21:41,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:41,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:41,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:41,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:41,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 19:21:41,459] {scheduler_job.py:146} INFO - Started process (PID=22666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:46,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:46,471] {logging_mixin.py:95} INFO - [2019-09-15 19:21:46,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:46,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:46,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:46,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:46,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:21:46,912] {scheduler_job.py:146} INFO - Started process (PID=22667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:51,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:51,933] {logging_mixin.py:95} INFO - [2019-09-15 19:21:51,932] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:52,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:52,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:52,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:52,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:21:52,375] {scheduler_job.py:146} INFO - Started process (PID=22669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:57,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:21:57,383] {logging_mixin.py:95} INFO - [2019-09-15 19:21:57,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:57,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:21:57,752] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:21:57,762] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:21:57,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:21:57,835] {scheduler_job.py:146} INFO - Started process (PID=22670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:02,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:02,846] {logging_mixin.py:95} INFO - [2019-09-15 19:22:02,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:03,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:03,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:03,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:03,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 19:22:03,295] {scheduler_job.py:146} INFO - Started process (PID=22671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:08,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:08,306] {logging_mixin.py:95} INFO - [2019-09-15 19:22:08,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:08,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:08,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:08,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:08,690] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:22:08,757] {scheduler_job.py:146} INFO - Started process (PID=22675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:13,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:13,767] {logging_mixin.py:95} INFO - [2019-09-15 19:22:13,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:14,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:14,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:14,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:14,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:22:14,216] {scheduler_job.py:146} INFO - Started process (PID=22676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:19,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:19,234] {logging_mixin.py:95} INFO - [2019-09-15 19:22:19,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:19,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:19,600] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:19,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:19,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:22:19,670] {scheduler_job.py:146} INFO - Started process (PID=22684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:24,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:24,678] {logging_mixin.py:95} INFO - [2019-09-15 19:22:24,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:25,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:25,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:25,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:25,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:22:25,129] {scheduler_job.py:146} INFO - Started process (PID=22687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:30,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:30,137] {logging_mixin.py:95} INFO - [2019-09-15 19:22:30,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:30,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:30,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:30,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:30,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:22:30,586] {scheduler_job.py:146} INFO - Started process (PID=22688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:35,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:35,594] {logging_mixin.py:95} INFO - [2019-09-15 19:22:35,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:35,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:35,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:35,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:35,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:22:36,047] {scheduler_job.py:146} INFO - Started process (PID=22690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:41,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:41,058] {logging_mixin.py:95} INFO - [2019-09-15 19:22:41,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:41,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:41,432] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:41,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:41,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:22:41,501] {scheduler_job.py:146} INFO - Started process (PID=22693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:46,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:46,520] {logging_mixin.py:95} INFO - [2019-09-15 19:22:46,520] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:46,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:46,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:46,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:46,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:22:46,962] {scheduler_job.py:146} INFO - Started process (PID=22694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:51,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:51,974] {logging_mixin.py:95} INFO - [2019-09-15 19:22:51,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:52,327] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:52,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:52,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:52,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 19:22:52,426] {scheduler_job.py:146} INFO - Started process (PID=22696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:57,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:22:57,433] {logging_mixin.py:95} INFO - [2019-09-15 19:22:57,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:57,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:22:57,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:22:57,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:22:57,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:22:57,881] {scheduler_job.py:146} INFO - Started process (PID=22758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:02,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:02,892] {logging_mixin.py:95} INFO - [2019-09-15 19:23:02,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:03,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:03,260] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:03,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:03,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:23:03,342] {scheduler_job.py:146} INFO - Started process (PID=22764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:08,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:08,350] {logging_mixin.py:95} INFO - [2019-09-15 19:23:08,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:08,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:08,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:08,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:08,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:23:08,804] {scheduler_job.py:146} INFO - Started process (PID=22767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:13,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:13,813] {logging_mixin.py:95} INFO - [2019-09-15 19:23:13,812] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:14,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:14,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:14,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:14,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:23:14,265] {scheduler_job.py:146} INFO - Started process (PID=22768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:19,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:19,282] {logging_mixin.py:95} INFO - [2019-09-15 19:23:19,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:19,625] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:19,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:19,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:19,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 19:23:19,728] {scheduler_job.py:146} INFO - Started process (PID=22769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:24,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:24,736] {logging_mixin.py:95} INFO - [2019-09-15 19:23:24,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:25,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:25,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:25,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:25,116] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 19:23:25,186] {scheduler_job.py:146} INFO - Started process (PID=22771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:30,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:30,193] {logging_mixin.py:95} INFO - [2019-09-15 19:23:30,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:30,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:30,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:30,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:30,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:23:30,643] {scheduler_job.py:146} INFO - Started process (PID=22772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:35,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:35,649] {logging_mixin.py:95} INFO - [2019-09-15 19:23:35,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:35,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:36,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:36,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:36,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 19:23:36,104] {scheduler_job.py:146} INFO - Started process (PID=22774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:41,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:41,111] {logging_mixin.py:95} INFO - [2019-09-15 19:23:41,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:41,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:41,488] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:41,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:41,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:23:41,568] {scheduler_job.py:146} INFO - Started process (PID=22775) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:46,578] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:46,589] {logging_mixin.py:95} INFO - [2019-09-15 19:23:46,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:46,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:46,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:46,961] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:46,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:23:47,027] {scheduler_job.py:146} INFO - Started process (PID=22776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:52,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:52,037] {logging_mixin.py:95} INFO - [2019-09-15 19:23:52,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:52,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:52,414] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:52,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:52,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:23:52,519] {scheduler_job.py:146} INFO - Started process (PID=22780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:57,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:23:57,532] {logging_mixin.py:95} INFO - [2019-09-15 19:23:57,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:57,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:23:57,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:23:57,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:23:57,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 19:23:57,993] {scheduler_job.py:146} INFO - Started process (PID=22786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:02,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:03,000] {logging_mixin.py:95} INFO - [2019-09-15 19:24:03,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:03,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:03,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:03,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:03,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:24:03,476] {scheduler_job.py:146} INFO - Started process (PID=22787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:08,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:08,484] {logging_mixin.py:95} INFO - [2019-09-15 19:24:08,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:08,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:08,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:08,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:08,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-15 19:24:08,953] {scheduler_job.py:146} INFO - Started process (PID=22790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:13,965] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:13,966] {logging_mixin.py:95} INFO - [2019-09-15 19:24:13,965] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:14,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:14,322] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:14,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:14,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:24:14,425] {scheduler_job.py:146} INFO - Started process (PID=22791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:19,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:19,440] {logging_mixin.py:95} INFO - [2019-09-15 19:24:19,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:19,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:19,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:19,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:19,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-15 19:24:19,902] {scheduler_job.py:146} INFO - Started process (PID=22792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:24,914] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:24,915] {logging_mixin.py:95} INFO - [2019-09-15 19:24:24,914] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:25,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:25,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:25,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:25,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 19:24:25,384] {scheduler_job.py:146} INFO - Started process (PID=22794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:30,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:30,399] {logging_mixin.py:95} INFO - [2019-09-15 19:24:30,398] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:30,722] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:30,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:30,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:30,758] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 19:24:30,859] {scheduler_job.py:146} INFO - Started process (PID=22795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:35,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:35,866] {logging_mixin.py:95} INFO - [2019-09-15 19:24:35,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:36,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:36,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:36,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:36,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 19:24:36,337] {scheduler_job.py:146} INFO - Started process (PID=22797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:41,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:41,349] {logging_mixin.py:95} INFO - [2019-09-15 19:24:41,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:41,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:41,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:41,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:41,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 19:24:41,822] {scheduler_job.py:146} INFO - Started process (PID=22799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:46,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:46,841] {logging_mixin.py:95} INFO - [2019-09-15 19:24:46,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:47,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:47,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:47,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:47,208] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 19:24:47,307] {scheduler_job.py:146} INFO - Started process (PID=22800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:52,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:52,333] {logging_mixin.py:95} INFO - [2019-09-15 19:24:52,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:52,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:52,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:52,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:52,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:24:52,789] {scheduler_job.py:146} INFO - Started process (PID=22802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:57,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:24:57,797] {logging_mixin.py:95} INFO - [2019-09-15 19:24:57,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:58,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:24:58,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:24:58,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:24:58,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-15 19:24:58,267] {scheduler_job.py:146} INFO - Started process (PID=22803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:03,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:03,282] {logging_mixin.py:95} INFO - [2019-09-15 19:25:03,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:03,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:03,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:03,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:03,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-15 19:25:03,742] {scheduler_job.py:146} INFO - Started process (PID=22804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:08,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:08,749] {logging_mixin.py:95} INFO - [2019-09-15 19:25:08,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:09,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:09,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:09,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:09,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-15 19:25:09,216] {scheduler_job.py:146} INFO - Started process (PID=22808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:14,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:14,223] {logging_mixin.py:95} INFO - [2019-09-15 19:25:14,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:14,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:14,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:14,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:14,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 19:25:14,605] {scheduler_job.py:146} INFO - Started process (PID=22809) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:19,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:19,623] {logging_mixin.py:95} INFO - [2019-09-15 19:25:19,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:19,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:19,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:19,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:19,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 19:25:20,092] {scheduler_job.py:146} INFO - Started process (PID=22810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:25,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:25,104] {logging_mixin.py:95} INFO - [2019-09-15 19:25:25,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:25,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:25,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:25,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:25,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:25:25,566] {scheduler_job.py:146} INFO - Started process (PID=22837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:30,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:30,573] {logging_mixin.py:95} INFO - [2019-09-15 19:25:30,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:30,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:30,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:30,927] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:30,932] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-15 19:25:31,039] {scheduler_job.py:146} INFO - Started process (PID=22838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:36,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:36,046] {logging_mixin.py:95} INFO - [2019-09-15 19:25:36,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:36,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:36,394] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:36,403] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:36,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-15 19:25:36,520] {scheduler_job.py:146} INFO - Started process (PID=22840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:41,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:41,531] {logging_mixin.py:95} INFO - [2019-09-15 19:25:41,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:41,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:41,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:41,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:41,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 19:25:42,092] {scheduler_job.py:146} INFO - Started process (PID=22842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:47,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:47,109] {logging_mixin.py:95} INFO - [2019-09-15 19:25:47,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:47,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:47,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:47,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:47,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 19:25:47,560] {scheduler_job.py:146} INFO - Started process (PID=22843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:52,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:52,576] {logging_mixin.py:95} INFO - [2019-09-15 19:25:52,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:52,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:52,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:52,944] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:52,949] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:25:53,047] {scheduler_job.py:146} INFO - Started process (PID=22845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:58,062] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:25:58,063] {logging_mixin.py:95} INFO - [2019-09-15 19:25:58,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:58,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:25:58,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:25:58,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:25:58,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 19:25:58,534] {scheduler_job.py:146} INFO - Started process (PID=22846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:03,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:03,560] {logging_mixin.py:95} INFO - [2019-09-15 19:26:03,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:03,897] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:03,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:03,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:03,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:26:04,025] {scheduler_job.py:146} INFO - Started process (PID=22847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:09,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:09,038] {logging_mixin.py:95} INFO - [2019-09-15 19:26:09,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:09,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:09,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:09,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:09,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:26:09,517] {scheduler_job.py:146} INFO - Started process (PID=22850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:14,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:14,526] {logging_mixin.py:95} INFO - [2019-09-15 19:26:14,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:14,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:14,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:14,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:14,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 19:26:15,008] {scheduler_job.py:146} INFO - Started process (PID=22851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:20,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:20,017] {logging_mixin.py:95} INFO - [2019-09-15 19:26:20,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:20,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:20,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:20,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:20,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:26:20,503] {scheduler_job.py:146} INFO - Started process (PID=22853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:25,513] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:25,514] {logging_mixin.py:95} INFO - [2019-09-15 19:26:25,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:25,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:25,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:25,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:25,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:26:25,996] {scheduler_job.py:146} INFO - Started process (PID=22854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:31,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:31,007] {logging_mixin.py:95} INFO - [2019-09-15 19:26:31,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:31,365] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:31,389] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:31,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:31,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 19:26:31,492] {scheduler_job.py:146} INFO - Started process (PID=22855) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:36,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:36,502] {logging_mixin.py:95} INFO - [2019-09-15 19:26:36,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:36,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:36,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:36,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:36,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:26:36,988] {scheduler_job.py:146} INFO - Started process (PID=22857) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:42,001] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:42,002] {logging_mixin.py:95} INFO - [2019-09-15 19:26:42,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:42,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:42,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:42,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:42,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:26:42,482] {scheduler_job.py:146} INFO - Started process (PID=22858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:47,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:47,499] {logging_mixin.py:95} INFO - [2019-09-15 19:26:47,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:47,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:47,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:47,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:47,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:26:47,975] {scheduler_job.py:146} INFO - Started process (PID=22859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:52,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:52,991] {logging_mixin.py:95} INFO - [2019-09-15 19:26:52,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:53,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:53,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:53,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:53,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 19:26:53,467] {scheduler_job.py:146} INFO - Started process (PID=22861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:58,478] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:26:58,479] {logging_mixin.py:95} INFO - [2019-09-15 19:26:58,479] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:58,821] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:26:58,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:26:58,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:26:58,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:26:58,954] {scheduler_job.py:146} INFO - Started process (PID=22862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:03,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:03,975] {logging_mixin.py:95} INFO - [2019-09-15 19:27:03,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:04,326] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:04,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:04,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:04,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:27:04,445] {scheduler_job.py:146} INFO - Started process (PID=22863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:09,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:09,452] {logging_mixin.py:95} INFO - [2019-09-15 19:27:09,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:09,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:09,816] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:09,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:09,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 19:27:09,938] {scheduler_job.py:146} INFO - Started process (PID=22866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:14,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:14,945] {logging_mixin.py:95} INFO - [2019-09-15 19:27:14,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:15,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:15,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:15,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:15,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 19:27:15,432] {scheduler_job.py:146} INFO - Started process (PID=22867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:20,442] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:20,453] {logging_mixin.py:95} INFO - [2019-09-15 19:27:20,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:20,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:20,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:20,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:20,836] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 19:27:20,927] {scheduler_job.py:146} INFO - Started process (PID=22869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:25,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:25,943] {logging_mixin.py:95} INFO - [2019-09-15 19:27:25,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:26,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:26,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:26,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:26,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:27:26,423] {scheduler_job.py:146} INFO - Started process (PID=22870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:31,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:31,439] {logging_mixin.py:95} INFO - [2019-09-15 19:27:31,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:31,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:31,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:31,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:31,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:27:31,906] {scheduler_job.py:146} INFO - Started process (PID=22871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:36,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:36,920] {logging_mixin.py:95} INFO - [2019-09-15 19:27:36,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:37,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:37,293] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:37,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:37,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:27:37,397] {scheduler_job.py:146} INFO - Started process (PID=22873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:42,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:42,404] {logging_mixin.py:95} INFO - [2019-09-15 19:27:42,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:42,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:42,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:42,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:42,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 19:27:42,898] {scheduler_job.py:146} INFO - Started process (PID=22874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:47,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:47,924] {logging_mixin.py:95} INFO - [2019-09-15 19:27:47,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:48,267] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:48,290] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:48,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:48,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 19:27:48,392] {scheduler_job.py:146} INFO - Started process (PID=22875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:53,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:53,408] {logging_mixin.py:95} INFO - [2019-09-15 19:27:53,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:53,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:53,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:53,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:53,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 19:27:53,892] {scheduler_job.py:146} INFO - Started process (PID=22877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:58,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:27:58,909] {logging_mixin.py:95} INFO - [2019-09-15 19:27:58,908] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:59,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:27:59,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:27:59,285] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:27:59,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:27:59,383] {scheduler_job.py:146} INFO - Started process (PID=22878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:04,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:04,397] {logging_mixin.py:95} INFO - [2019-09-15 19:28:04,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:04,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:04,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:04,764] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:04,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:28:04,879] {scheduler_job.py:146} INFO - Started process (PID=22880) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:09,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:09,892] {logging_mixin.py:95} INFO - [2019-09-15 19:28:09,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:10,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:10,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:10,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:10,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 19:28:10,378] {scheduler_job.py:146} INFO - Started process (PID=22882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:15,385] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:15,395] {logging_mixin.py:95} INFO - [2019-09-15 19:28:15,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:15,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:15,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:15,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:15,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 19:28:15,871] {scheduler_job.py:146} INFO - Started process (PID=22883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:20,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:20,884] {logging_mixin.py:95} INFO - [2019-09-15 19:28:20,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:21,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:21,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:21,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:21,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:28:21,368] {scheduler_job.py:146} INFO - Started process (PID=22885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:26,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:26,380] {logging_mixin.py:95} INFO - [2019-09-15 19:28:26,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:26,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:26,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:26,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:26,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:28:26,862] {scheduler_job.py:146} INFO - Started process (PID=22886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:31,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:31,874] {logging_mixin.py:95} INFO - [2019-09-15 19:28:31,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:32,222] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:32,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:32,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:32,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:28:32,348] {scheduler_job.py:146} INFO - Started process (PID=22887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:37,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:37,361] {logging_mixin.py:95} INFO - [2019-09-15 19:28:37,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:37,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:37,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:37,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:37,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:28:37,835] {scheduler_job.py:146} INFO - Started process (PID=22889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:42,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:42,855] {logging_mixin.py:95} INFO - [2019-09-15 19:28:42,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:43,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:43,225] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:43,235] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:43,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 19:28:43,336] {scheduler_job.py:146} INFO - Started process (PID=22890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:48,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:48,351] {logging_mixin.py:95} INFO - [2019-09-15 19:28:48,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:48,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:48,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:48,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:48,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 19:28:48,826] {scheduler_job.py:146} INFO - Started process (PID=22891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:53,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:53,832] {logging_mixin.py:95} INFO - [2019-09-15 19:28:53,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:54,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:54,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:54,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:54,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:28:54,324] {scheduler_job.py:146} INFO - Started process (PID=22893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:59,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:28:59,340] {logging_mixin.py:95} INFO - [2019-09-15 19:28:59,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:59,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:28:59,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:28:59,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:28:59,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:28:59,807] {scheduler_job.py:146} INFO - Started process (PID=22894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:04,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:04,818] {logging_mixin.py:95} INFO - [2019-09-15 19:29:04,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:05,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:05,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:05,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:05,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:29:05,299] {scheduler_job.py:146} INFO - Started process (PID=22896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:10,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:10,308] {logging_mixin.py:95} INFO - [2019-09-15 19:29:10,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:10,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:10,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:10,676] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:10,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 19:29:10,790] {scheduler_job.py:146} INFO - Started process (PID=22898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:15,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:15,806] {logging_mixin.py:95} INFO - [2019-09-15 19:29:15,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:16,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:16,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:16,178] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:16,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:29:16,281] {scheduler_job.py:146} INFO - Started process (PID=22899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:21,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:21,291] {logging_mixin.py:95} INFO - [2019-09-15 19:29:21,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:21,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:21,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:21,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:21,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:29:21,784] {scheduler_job.py:146} INFO - Started process (PID=22901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:26,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:26,805] {logging_mixin.py:95} INFO - [2019-09-15 19:29:26,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:27,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:27,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:27,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:27,182] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:29:27,276] {scheduler_job.py:146} INFO - Started process (PID=22902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:32,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:32,288] {logging_mixin.py:95} INFO - [2019-09-15 19:29:32,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:32,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:32,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:32,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:32,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 19:29:32,772] {scheduler_job.py:146} INFO - Started process (PID=22904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:37,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:37,786] {logging_mixin.py:95} INFO - [2019-09-15 19:29:37,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:38,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:38,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:38,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:38,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 19:29:38,261] {scheduler_job.py:146} INFO - Started process (PID=22906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:43,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:43,272] {logging_mixin.py:95} INFO - [2019-09-15 19:29:43,271] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:43,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:43,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:43,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:43,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:29:43,755] {scheduler_job.py:146} INFO - Started process (PID=22907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:48,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:29:48,762] {logging_mixin.py:95} INFO - [2019-09-15 19:29:48,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:49,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:29:49,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:29:49,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:29:49,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 19:29:49,240] {scheduler_job.py:146} INFO - Started process (PID=22908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:47,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:37:47,009] {logging_mixin.py:95} INFO - [2019-09-15 19:37:47,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:47,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:47,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:37:47,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:37:47,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 478.223 seconds
[2019-09-15 19:37:47,546] {scheduler_job.py:146} INFO - Started process (PID=22911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:47,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:37:47,557] {logging_mixin.py:95} INFO - [2019-09-15 19:37:47,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:48,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:48,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:37:48,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:37:48,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.758 seconds
[2019-09-15 19:37:48,350] {scheduler_job.py:146} INFO - Started process (PID=22916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:53,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:37:53,358] {logging_mixin.py:95} INFO - [2019-09-15 19:37:53,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:53,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:53,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:37:53,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:37:53,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 19:37:53,815] {scheduler_job.py:146} INFO - Started process (PID=22923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:58,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:37:58,821] {logging_mixin.py:95} INFO - [2019-09-15 19:37:58,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:59,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:37:59,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:37:59,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:37:59,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 19:37:59,260] {scheduler_job.py:146} INFO - Started process (PID=22926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:04,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:04,268] {logging_mixin.py:95} INFO - [2019-09-15 19:38:04,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:04,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:04,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:04,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:04,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:38:04,705] {scheduler_job.py:146} INFO - Started process (PID=22929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:09,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:09,726] {logging_mixin.py:95} INFO - [2019-09-15 19:38:09,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:10,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:10,100] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:10,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:10,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 19:38:10,153] {scheduler_job.py:146} INFO - Started process (PID=22930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:15,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:15,162] {logging_mixin.py:95} INFO - [2019-09-15 19:38:15,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:15,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:15,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:15,538] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:15,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:38:15,598] {scheduler_job.py:146} INFO - Started process (PID=22932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:20,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:20,610] {logging_mixin.py:95} INFO - [2019-09-15 19:38:20,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:20,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:20,975] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:20,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:20,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 19:38:21,062] {scheduler_job.py:146} INFO - Started process (PID=22933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:26,071] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:26,072] {logging_mixin.py:95} INFO - [2019-09-15 19:38:26,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:26,414] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:26,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:26,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:26,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 19:38:26,552] {scheduler_job.py:146} INFO - Started process (PID=22934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:31,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:31,561] {logging_mixin.py:95} INFO - [2019-09-15 19:38:31,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:31,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:31,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:31,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:31,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:38:32,045] {scheduler_job.py:146} INFO - Started process (PID=22936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:37,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:37,057] {logging_mixin.py:95} INFO - [2019-09-15 19:38:37,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:37,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:37,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:37,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:37,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 19:38:37,529] {scheduler_job.py:146} INFO - Started process (PID=22937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:42,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:42,542] {logging_mixin.py:95} INFO - [2019-09-15 19:38:42,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:42,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:42,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:42,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:42,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 19:38:43,017] {scheduler_job.py:146} INFO - Started process (PID=22938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:48,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:48,037] {logging_mixin.py:95} INFO - [2019-09-15 19:38:48,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:48,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:48,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:48,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:48,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:38:48,508] {scheduler_job.py:146} INFO - Started process (PID=22940) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:53,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:53,519] {logging_mixin.py:95} INFO - [2019-09-15 19:38:53,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:53,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:53,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:53,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:53,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 19:38:53,988] {scheduler_job.py:146} INFO - Started process (PID=22941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:59,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:38:59,006] {logging_mixin.py:95} INFO - [2019-09-15 19:38:59,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:59,348] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:38:59,371] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:38:59,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:38:59,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:38:59,485] {scheduler_job.py:146} INFO - Started process (PID=22944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:04,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:04,499] {logging_mixin.py:95} INFO - [2019-09-15 19:39:04,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:04,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:04,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:04,864] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:04,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 19:39:04,977] {scheduler_job.py:146} INFO - Started process (PID=22945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:09,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:09,990] {logging_mixin.py:95} INFO - [2019-09-15 19:39:09,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:10,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:10,350] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:10,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:10,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 19:39:10,477] {scheduler_job.py:146} INFO - Started process (PID=22946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:15,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:15,492] {logging_mixin.py:95} INFO - [2019-09-15 19:39:15,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:15,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:15,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:15,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:15,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 19:39:15,980] {scheduler_job.py:146} INFO - Started process (PID=22948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:20,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:20,996] {logging_mixin.py:95} INFO - [2019-09-15 19:39:20,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:21,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:21,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:21,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:21,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:39:21,478] {scheduler_job.py:146} INFO - Started process (PID=22949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:26,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:26,492] {logging_mixin.py:95} INFO - [2019-09-15 19:39:26,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:26,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:26,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:26,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:26,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 19:39:26,970] {scheduler_job.py:146} INFO - Started process (PID=22950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:31,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:31,988] {logging_mixin.py:95} INFO - [2019-09-15 19:39:31,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:32,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:32,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:32,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:32,370] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 19:39:32,460] {scheduler_job.py:146} INFO - Started process (PID=22952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:37,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:37,473] {logging_mixin.py:95} INFO - [2019-09-15 19:39:37,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:37,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:37,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:37,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:37,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 19:39:37,958] {scheduler_job.py:146} INFO - Started process (PID=22953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:42,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:42,973] {logging_mixin.py:95} INFO - [2019-09-15 19:39:42,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:43,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:43,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:43,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:43,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:39:43,454] {scheduler_job.py:146} INFO - Started process (PID=22955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:48,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:48,472] {logging_mixin.py:95} INFO - [2019-09-15 19:39:48,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:48,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:48,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:48,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:48,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 19:39:48,952] {scheduler_job.py:146} INFO - Started process (PID=22956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:53,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:53,970] {logging_mixin.py:95} INFO - [2019-09-15 19:39:53,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:54,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:54,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:54,344] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:54,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:39:54,443] {scheduler_job.py:146} INFO - Started process (PID=22958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:59,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:39:59,459] {logging_mixin.py:95} INFO - [2019-09-15 19:39:59,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:59,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:39:59,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:39:59,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:39:59,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 19:39:59,935] {scheduler_job.py:146} INFO - Started process (PID=22961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:04,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:40:04,948] {logging_mixin.py:95} INFO - [2019-09-15 19:40:04,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:05,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:05,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:40:05,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:40:05,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 19:40:05,423] {scheduler_job.py:146} INFO - Started process (PID=22962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:10,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:40:10,434] {logging_mixin.py:95} INFO - [2019-09-15 19:40:10,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:10,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:10,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:40:10,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:40:10,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-15 19:40:10,815] {scheduler_job.py:146} INFO - Started process (PID=22963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:10,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:40:10,821] {logging_mixin.py:95} INFO - [2019-09-15 19:40:10,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:40:11,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:40:11,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 19:40:11,228] {scheduler_job.py:146} INFO - Started process (PID=22964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:40:11,235] {logging_mixin.py:95} INFO - [2019-09-15 19:40:11,235] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 19:40:11,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 19:40:11,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-15 19:40:11,638] {scheduler_job.py:146} INFO - Started process (PID=22965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 19:40:11,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 19:40:11,645] {logging_mixin.py:95} INFO - [2019-09-15 19:40:11,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:26,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:26,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:26,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:26,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2354.845 seconds
[2019-09-15 20:19:26,531] {scheduler_job.py:146} INFO - Started process (PID=22967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:31,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:19:31,540] {logging_mixin.py:95} INFO - [2019-09-15 20:19:31,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:31,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:31,920] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:31,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:31,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 20:19:32,013] {scheduler_job.py:146} INFO - Started process (PID=22975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:37,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:19:37,077] {logging_mixin.py:95} INFO - [2019-09-15 20:19:37,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:38,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:38,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:38,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:38,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.511 seconds
[2019-09-15 20:19:38,653] {scheduler_job.py:146} INFO - Started process (PID=22978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:43,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:19:43,682] {logging_mixin.py:95} INFO - [2019-09-15 20:19:43,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:45,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:45,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:45,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:45,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.451 seconds
[2019-09-15 20:19:45,167] {scheduler_job.py:146} INFO - Started process (PID=22980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:50,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:19:50,188] {logging_mixin.py:95} INFO - [2019-09-15 20:19:50,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:50,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:50,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:50,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:50,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 20:19:50,650] {scheduler_job.py:146} INFO - Started process (PID=22981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:55,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:19:55,666] {logging_mixin.py:95} INFO - [2019-09-15 20:19:55,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:56,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:19:56,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:19:56,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:19:56,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 20:19:56,147] {scheduler_job.py:146} INFO - Started process (PID=22982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:01,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:01,162] {logging_mixin.py:95} INFO - [2019-09-15 20:20:01,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:01,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:01,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:01,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:01,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 20:20:01,642] {scheduler_job.py:146} INFO - Started process (PID=22984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:06,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:06,657] {logging_mixin.py:95} INFO - [2019-09-15 20:20:06,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:06,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:07,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:07,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:07,029] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:20:07,140] {scheduler_job.py:146} INFO - Started process (PID=22985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:12,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:12,157] {logging_mixin.py:95} INFO - [2019-09-15 20:20:12,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:12,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:12,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:12,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:12,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 20:20:12,632] {scheduler_job.py:146} INFO - Started process (PID=22988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:17,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:17,638] {logging_mixin.py:95} INFO - [2019-09-15 20:20:17,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:17,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:17,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:17,998] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:18,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-15 20:20:18,022] {scheduler_job.py:146} INFO - Started process (PID=22989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:18,028] {logging_mixin.py:95} INFO - [2019-09-15 20:20:18,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,359] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:18,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:18,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 20:20:18,432] {scheduler_job.py:146} INFO - Started process (PID=22990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:20:18,439] {logging_mixin.py:95} INFO - [2019-09-15 20:20:18,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:20:18,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:20:18,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:20:18,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-15 20:26:27,016] {scheduler_job.py:146} INFO - Started process (PID=22991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:27,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:27,023] {logging_mixin.py:95} INFO - [2019-09-15 20:26:27,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:27,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:27,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:27,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:27,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.405 seconds
[2019-09-15 20:26:27,524] {scheduler_job.py:146} INFO - Started process (PID=22992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:27,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:27,529] {logging_mixin.py:95} INFO - [2019-09-15 20:26:27,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:28,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:28,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:28,254] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:28,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.737 seconds
[2019-09-15 20:26:28,339] {scheduler_job.py:146} INFO - Started process (PID=22999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:33,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:33,348] {logging_mixin.py:95} INFO - [2019-09-15 20:26:33,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:33,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:33,731] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:33,740] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:33,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 20:26:33,779] {scheduler_job.py:146} INFO - Started process (PID=23003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:38,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:38,785] {logging_mixin.py:95} INFO - [2019-09-15 20:26:38,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:39,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:39,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:39,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:39,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:26:39,236] {scheduler_job.py:146} INFO - Started process (PID=23006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:44,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:44,241] {logging_mixin.py:95} INFO - [2019-09-15 20:26:44,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:44,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:44,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:44,607] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:44,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-15 20:26:44,689] {scheduler_job.py:146} INFO - Started process (PID=23007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:49,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:49,697] {logging_mixin.py:95} INFO - [2019-09-15 20:26:49,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:50,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:50,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:50,065] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:50,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 20:26:50,142] {scheduler_job.py:146} INFO - Started process (PID=23008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:55,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:26:55,150] {logging_mixin.py:95} INFO - [2019-09-15 20:26:55,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:55,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:26:55,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:26:55,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:26:55,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 20:26:55,596] {scheduler_job.py:146} INFO - Started process (PID=23011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:00,604] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:00,605] {logging_mixin.py:95} INFO - [2019-09-15 20:27:00,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:01,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:01,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:01,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:01,100] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-09-15 20:27:01,136] {scheduler_job.py:146} INFO - Started process (PID=23012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:06,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:06,151] {logging_mixin.py:95} INFO - [2019-09-15 20:27:06,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:06,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:06,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:06,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:06,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.508 seconds
[2019-09-15 20:27:06,675] {scheduler_job.py:146} INFO - Started process (PID=23014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:11,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:11,681] {logging_mixin.py:95} INFO - [2019-09-15 20:27:11,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:12,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:12,054] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:12,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:12,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 20:27:12,121] {scheduler_job.py:146} INFO - Started process (PID=23015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:17,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:17,132] {logging_mixin.py:95} INFO - [2019-09-15 20:27:17,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:17,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:17,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:17,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:17,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-15 20:27:17,659] {scheduler_job.py:146} INFO - Started process (PID=23016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:22,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:22,668] {logging_mixin.py:95} INFO - [2019-09-15 20:27:22,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:23,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:23,062] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:23,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:23,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:27:23,189] {scheduler_job.py:146} INFO - Started process (PID=23020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:28,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:28,199] {logging_mixin.py:95} INFO - [2019-09-15 20:27:28,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:28,621] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:28,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:28,648] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:28,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 20:27:28,712] {scheduler_job.py:146} INFO - Started process (PID=23021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:33,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:33,717] {logging_mixin.py:95} INFO - [2019-09-15 20:27:33,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:34,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:34,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:34,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:34,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 20:27:34,248] {scheduler_job.py:146} INFO - Started process (PID=23022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:39,257] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:39,267] {logging_mixin.py:95} INFO - [2019-09-15 20:27:39,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:39,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:39,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:39,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:39,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 20:27:39,794] {scheduler_job.py:146} INFO - Started process (PID=23024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:44,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:44,804] {logging_mixin.py:95} INFO - [2019-09-15 20:27:44,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:45,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:45,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:45,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:45,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:27:45,244] {scheduler_job.py:146} INFO - Started process (PID=23025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:50,249] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:50,250] {logging_mixin.py:95} INFO - [2019-09-15 20:27:50,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:50,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:50,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:50,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:50,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 20:27:50,780] {scheduler_job.py:146} INFO - Started process (PID=23027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:55,786] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:27:55,796] {logging_mixin.py:95} INFO - [2019-09-15 20:27:55,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:56,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:27:56,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:27:56,182] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:27:56,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:27:56,220] {scheduler_job.py:146} INFO - Started process (PID=23028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:01,230] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:01,231] {logging_mixin.py:95} INFO - [2019-09-15 20:28:01,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:01,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:01,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:01,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:01,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-15 20:28:01,767] {scheduler_job.py:146} INFO - Started process (PID=23029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:06,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:06,783] {logging_mixin.py:95} INFO - [2019-09-15 20:28:06,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:07,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:07,175] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:07,186] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:07,192] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:28:07,304] {scheduler_job.py:146} INFO - Started process (PID=23031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:12,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:12,314] {logging_mixin.py:95} INFO - [2019-09-15 20:28:12,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:12,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:12,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:12,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:12,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:28:12,749] {scheduler_job.py:146} INFO - Started process (PID=23032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:17,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:17,758] {logging_mixin.py:95} INFO - [2019-09-15 20:28:17,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:18,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:18,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:18,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:18,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 20:28:18,294] {scheduler_job.py:146} INFO - Started process (PID=23033) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:23,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:23,305] {logging_mixin.py:95} INFO - [2019-09-15 20:28:23,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:23,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:23,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:23,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:23,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:28:23,738] {scheduler_job.py:146} INFO - Started process (PID=23036) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:28,747] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:28,749] {logging_mixin.py:95} INFO - [2019-09-15 20:28:28,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:29,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:29,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:29,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:29,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 20:28:29,286] {scheduler_job.py:146} INFO - Started process (PID=23037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:34,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:34,296] {logging_mixin.py:95} INFO - [2019-09-15 20:28:34,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:34,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:34,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:34,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:34,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 20:28:34,727] {scheduler_job.py:146} INFO - Started process (PID=23038) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:39,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:39,736] {logging_mixin.py:95} INFO - [2019-09-15 20:28:39,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:40,091] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:40,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:40,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:40,130] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 20:28:40,181] {scheduler_job.py:146} INFO - Started process (PID=23040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:45,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:45,192] {logging_mixin.py:95} INFO - [2019-09-15 20:28:45,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:45,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:45,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:45,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:45,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.533 seconds
[2019-09-15 20:28:45,824] {scheduler_job.py:146} INFO - Started process (PID=23041) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:50,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:50,833] {logging_mixin.py:95} INFO - [2019-09-15 20:28:50,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:51,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:51,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:51,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:51,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:28:51,274] {scheduler_job.py:146} INFO - Started process (PID=23043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:56,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:28:56,292] {logging_mixin.py:95} INFO - [2019-09-15 20:28:56,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:56,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:28:56,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:28:56,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:28:56,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:28:56,718] {scheduler_job.py:146} INFO - Started process (PID=23044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:01,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:01,735] {logging_mixin.py:95} INFO - [2019-09-15 20:29:01,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:02,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:02,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:02,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:02,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 20:29:02,167] {scheduler_job.py:146} INFO - Started process (PID=23045) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:07,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:07,178] {logging_mixin.py:95} INFO - [2019-09-15 20:29:07,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:07,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:07,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:07,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:07,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:29:07,624] {scheduler_job.py:146} INFO - Started process (PID=23047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:12,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:12,632] {logging_mixin.py:95} INFO - [2019-09-15 20:29:12,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:12,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:13,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:13,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:13,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:29:13,083] {scheduler_job.py:146} INFO - Started process (PID=23048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:18,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:18,089] {logging_mixin.py:95} INFO - [2019-09-15 20:29:18,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:18,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:18,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:18,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:18,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 20:29:18,631] {scheduler_job.py:146} INFO - Started process (PID=23049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:23,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:23,638] {logging_mixin.py:95} INFO - [2019-09-15 20:29:23,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:24,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:24,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:24,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:24,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.538 seconds
[2019-09-15 20:29:24,263] {scheduler_job.py:146} INFO - Started process (PID=23052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:29,268] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:29,269] {logging_mixin.py:95} INFO - [2019-09-15 20:29:29,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:29,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:29,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:29,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:29,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 20:29:29,799] {scheduler_job.py:146} INFO - Started process (PID=23054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:34,804] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:34,805] {logging_mixin.py:95} INFO - [2019-09-15 20:29:34,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:35,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:35,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:35,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:35,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.536 seconds
[2019-09-15 20:29:35,424] {scheduler_job.py:146} INFO - Started process (PID=23055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:40,429] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:40,442] {logging_mixin.py:95} INFO - [2019-09-15 20:29:40,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:40,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:40,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:40,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:40,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 20:29:40,970] {scheduler_job.py:146} INFO - Started process (PID=23057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:45,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:45,979] {logging_mixin.py:95} INFO - [2019-09-15 20:29:45,979] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:46,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:46,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:46,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:46,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 20:29:46,414] {scheduler_job.py:146} INFO - Started process (PID=23058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:51,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:51,423] {logging_mixin.py:95} INFO - [2019-09-15 20:29:51,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:51,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:51,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:51,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:51,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:29:51,859] {scheduler_job.py:146} INFO - Started process (PID=23060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:56,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:29:56,878] {logging_mixin.py:95} INFO - [2019-09-15 20:29:56,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:57,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:29:57,265] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:29:57,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:29:57,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:29:57,308] {scheduler_job.py:146} INFO - Started process (PID=23061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:02,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:02,325] {logging_mixin.py:95} INFO - [2019-09-15 20:30:02,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:02,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:02,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:02,723] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:02,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:30:02,761] {scheduler_job.py:146} INFO - Started process (PID=23063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:07,768] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:07,769] {logging_mixin.py:95} INFO - [2019-09-15 20:30:07,768] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:08,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:08,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:08,164] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:08,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:30:08,211] {scheduler_job.py:146} INFO - Started process (PID=23065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:13,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:13,218] {logging_mixin.py:95} INFO - [2019-09-15 20:30:13,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:13,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:13,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:13,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:13,618] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:30:13,663] {scheduler_job.py:146} INFO - Started process (PID=23066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:18,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:18,672] {logging_mixin.py:95} INFO - [2019-09-15 20:30:18,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:19,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:19,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:19,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:19,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 20:30:19,113] {scheduler_job.py:146} INFO - Started process (PID=23067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:24,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:24,124] {logging_mixin.py:95} INFO - [2019-09-15 20:30:24,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:24,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:24,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:24,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:24,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:30:24,564] {scheduler_job.py:146} INFO - Started process (PID=23070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:29,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:29,574] {logging_mixin.py:95} INFO - [2019-09-15 20:30:29,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:29,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:29,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:29,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:29,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:30:30,016] {scheduler_job.py:146} INFO - Started process (PID=23071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:35,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:35,023] {logging_mixin.py:95} INFO - [2019-09-15 20:30:35,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:35,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:35,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:35,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:35,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:30:35,463] {scheduler_job.py:146} INFO - Started process (PID=23072) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:40,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:40,478] {logging_mixin.py:95} INFO - [2019-09-15 20:30:40,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:40,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:40,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:40,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:40,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:30:40,915] {scheduler_job.py:146} INFO - Started process (PID=23074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:45,926] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:45,927] {logging_mixin.py:95} INFO - [2019-09-15 20:30:45,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:46,292] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:46,315] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:46,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:46,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:30:46,361] {scheduler_job.py:146} INFO - Started process (PID=23075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:51,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:51,368] {logging_mixin.py:95} INFO - [2019-09-15 20:30:51,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:51,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:51,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:51,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:51,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:30:51,811] {scheduler_job.py:146} INFO - Started process (PID=23077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:56,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:30:56,819] {logging_mixin.py:95} INFO - [2019-09-15 20:30:56,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:57,181] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:30:57,202] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:30:57,211] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:30:57,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 20:30:57,258] {scheduler_job.py:146} INFO - Started process (PID=23078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:02,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:02,266] {logging_mixin.py:95} INFO - [2019-09-15 20:31:02,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:02,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:02,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:02,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:02,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:31:02,709] {scheduler_job.py:146} INFO - Started process (PID=23079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:07,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:07,718] {logging_mixin.py:95} INFO - [2019-09-15 20:31:07,718] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:08,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:08,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:08,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:08,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:31:08,161] {scheduler_job.py:146} INFO - Started process (PID=23081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:13,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:13,169] {logging_mixin.py:95} INFO - [2019-09-15 20:31:13,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:13,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:13,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:13,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:13,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 20:31:13,709] {scheduler_job.py:146} INFO - Started process (PID=23082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:18,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:18,725] {logging_mixin.py:95} INFO - [2019-09-15 20:31:18,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:19,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:19,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:19,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:19,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:31:19,163] {scheduler_job.py:146} INFO - Started process (PID=23083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:24,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:24,170] {logging_mixin.py:95} INFO - [2019-09-15 20:31:24,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:24,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:24,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:24,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:24,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:31:24,613] {scheduler_job.py:146} INFO - Started process (PID=23086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:29,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:29,620] {logging_mixin.py:95} INFO - [2019-09-15 20:31:29,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:29,985] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:30,007] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:30,017] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:30,022] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:31:30,063] {scheduler_job.py:146} INFO - Started process (PID=23087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:35,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:35,070] {logging_mixin.py:95} INFO - [2019-09-15 20:31:35,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:35,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:35,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:35,465] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:35,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:31:35,516] {scheduler_job.py:146} INFO - Started process (PID=23088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:40,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:40,526] {logging_mixin.py:95} INFO - [2019-09-15 20:31:40,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:40,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:40,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:40,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:40,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:31:40,965] {scheduler_job.py:146} INFO - Started process (PID=23090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:45,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:45,973] {logging_mixin.py:95} INFO - [2019-09-15 20:31:45,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:46,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:46,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:46,373] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:46,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:31:46,408] {scheduler_job.py:146} INFO - Started process (PID=23091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:51,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:51,416] {logging_mixin.py:95} INFO - [2019-09-15 20:31:51,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:51,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:51,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:51,816] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:51,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:31:51,858] {scheduler_job.py:146} INFO - Started process (PID=23093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:56,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:31:56,877] {logging_mixin.py:95} INFO - [2019-09-15 20:31:56,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:57,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:31:57,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:31:57,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:31:57,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:31:57,311] {scheduler_job.py:146} INFO - Started process (PID=23094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:02,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:02,318] {logging_mixin.py:95} INFO - [2019-09-15 20:32:02,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:02,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:02,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:02,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:02,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:32:02,758] {scheduler_job.py:146} INFO - Started process (PID=23095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:07,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:07,773] {logging_mixin.py:95} INFO - [2019-09-15 20:32:07,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:08,135] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:08,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:08,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:08,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:32:08,209] {scheduler_job.py:146} INFO - Started process (PID=23097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:13,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:13,219] {logging_mixin.py:95} INFO - [2019-09-15 20:32:13,219] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:13,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:13,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:13,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:13,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:32:13,660] {scheduler_job.py:146} INFO - Started process (PID=23098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:18,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:18,666] {logging_mixin.py:95} INFO - [2019-09-15 20:32:18,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:19,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:19,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:19,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:19,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:32:19,108] {scheduler_job.py:146} INFO - Started process (PID=23099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:24,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:24,117] {logging_mixin.py:95} INFO - [2019-09-15 20:32:24,117] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:24,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:24,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:24,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:24,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 20:32:24,547] {scheduler_job.py:146} INFO - Started process (PID=23109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:29,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:29,556] {logging_mixin.py:95} INFO - [2019-09-15 20:32:29,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:29,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:29,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:29,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:29,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 20:32:30,089] {scheduler_job.py:146} INFO - Started process (PID=23111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:35,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:35,099] {logging_mixin.py:95} INFO - [2019-09-15 20:32:35,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:35,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:35,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:35,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:35,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:32:35,535] {scheduler_job.py:146} INFO - Started process (PID=23112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:40,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:40,553] {logging_mixin.py:95} INFO - [2019-09-15 20:32:40,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:40,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:40,946] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:40,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:40,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:32:40,986] {scheduler_job.py:146} INFO - Started process (PID=23114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:45,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:45,996] {logging_mixin.py:95} INFO - [2019-09-15 20:32:45,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:46,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:46,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:46,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:46,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:32:46,433] {scheduler_job.py:146} INFO - Started process (PID=23115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:51,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:51,441] {logging_mixin.py:95} INFO - [2019-09-15 20:32:51,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:51,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:51,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:51,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:51,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 20:32:51,883] {scheduler_job.py:146} INFO - Started process (PID=23117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:56,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:32:56,901] {logging_mixin.py:95} INFO - [2019-09-15 20:32:56,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:57,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:32:57,287] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:32:57,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:32:57,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:32:57,341] {scheduler_job.py:146} INFO - Started process (PID=23118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:02,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:02,348] {logging_mixin.py:95} INFO - [2019-09-15 20:33:02,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:02,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:02,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:02,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:02,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:33:02,789] {scheduler_job.py:146} INFO - Started process (PID=23119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:07,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:07,809] {logging_mixin.py:95} INFO - [2019-09-15 20:33:07,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:08,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:08,199] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:08,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:08,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:33:08,243] {scheduler_job.py:146} INFO - Started process (PID=23121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:13,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:13,255] {logging_mixin.py:95} INFO - [2019-09-15 20:33:13,255] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:13,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:13,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:13,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:13,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:33:13,691] {scheduler_job.py:146} INFO - Started process (PID=23122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:18,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:18,700] {logging_mixin.py:95} INFO - [2019-09-15 20:33:18,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:19,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:19,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:19,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:19,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:33:19,139] {scheduler_job.py:146} INFO - Started process (PID=23123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:24,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:24,150] {logging_mixin.py:95} INFO - [2019-09-15 20:33:24,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:24,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:24,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:24,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:24,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:33:24,589] {scheduler_job.py:146} INFO - Started process (PID=23126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:29,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:29,599] {logging_mixin.py:95} INFO - [2019-09-15 20:33:29,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:29,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:29,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:29,996] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:30,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:33:30,042] {scheduler_job.py:146} INFO - Started process (PID=23127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:35,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:35,053] {logging_mixin.py:95} INFO - [2019-09-15 20:33:35,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:35,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:35,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:35,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:35,461] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:33:35,492] {scheduler_job.py:146} INFO - Started process (PID=23128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:40,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:40,500] {logging_mixin.py:95} INFO - [2019-09-15 20:33:40,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:40,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:40,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:40,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:40,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:33:40,948] {scheduler_job.py:146} INFO - Started process (PID=23130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:45,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:45,955] {logging_mixin.py:95} INFO - [2019-09-15 20:33:45,955] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:46,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:46,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:46,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:46,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:33:46,402] {scheduler_job.py:146} INFO - Started process (PID=23131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:51,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:51,411] {logging_mixin.py:95} INFO - [2019-09-15 20:33:51,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:51,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:51,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:51,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:51,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:33:51,852] {scheduler_job.py:146} INFO - Started process (PID=23133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:56,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:33:56,870] {logging_mixin.py:95} INFO - [2019-09-15 20:33:56,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:57,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:33:57,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:33:57,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:33:57,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:33:57,298] {scheduler_job.py:146} INFO - Started process (PID=23134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:02,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:02,307] {logging_mixin.py:95} INFO - [2019-09-15 20:34:02,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:02,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:02,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:02,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:02,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 20:34:02,752] {scheduler_job.py:146} INFO - Started process (PID=23135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:07,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:07,769] {logging_mixin.py:95} INFO - [2019-09-15 20:34:07,769] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:08,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:08,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:08,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:08,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:34:08,196] {scheduler_job.py:146} INFO - Started process (PID=23137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:13,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:13,203] {logging_mixin.py:95} INFO - [2019-09-15 20:34:13,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:13,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:13,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:13,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:13,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 20:34:13,647] {scheduler_job.py:146} INFO - Started process (PID=23138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:18,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:18,653] {logging_mixin.py:95} INFO - [2019-09-15 20:34:18,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:19,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:19,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:19,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:19,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 20:34:19,091] {scheduler_job.py:146} INFO - Started process (PID=23139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:24,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:24,100] {logging_mixin.py:95} INFO - [2019-09-15 20:34:24,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:24,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:24,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:24,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:24,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 20:34:24,534] {scheduler_job.py:146} INFO - Started process (PID=23142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:29,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:29,544] {logging_mixin.py:95} INFO - [2019-09-15 20:34:29,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:29,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:29,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:29,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:29,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 20:34:29,987] {scheduler_job.py:146} INFO - Started process (PID=23143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:34,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:34,994] {logging_mixin.py:95} INFO - [2019-09-15 20:34:34,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:35,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:35,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:35,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:35,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:34:35,442] {scheduler_job.py:146} INFO - Started process (PID=23144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:40,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:40,450] {logging_mixin.py:95} INFO - [2019-09-15 20:34:40,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:40,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:40,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:40,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:40,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:34:40,887] {scheduler_job.py:146} INFO - Started process (PID=23146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:45,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:45,896] {logging_mixin.py:95} INFO - [2019-09-15 20:34:45,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:46,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:46,284] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:46,294] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:46,300] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:34:46,337] {scheduler_job.py:146} INFO - Started process (PID=23147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:51,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:51,346] {logging_mixin.py:95} INFO - [2019-09-15 20:34:51,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:51,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:51,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:51,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:51,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:34:51,788] {scheduler_job.py:146} INFO - Started process (PID=23149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:56,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:34:56,805] {logging_mixin.py:95} INFO - [2019-09-15 20:34:56,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:57,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:34:57,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:34:57,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:34:57,214] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:34:57,240] {scheduler_job.py:146} INFO - Started process (PID=23150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:02,249] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:02,260] {logging_mixin.py:95} INFO - [2019-09-15 20:35:02,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:02,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:02,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:02,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:02,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:35:02,690] {scheduler_job.py:146} INFO - Started process (PID=23151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:07,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:07,705] {logging_mixin.py:95} INFO - [2019-09-15 20:35:07,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:08,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:08,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:08,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:08,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:35:08,143] {scheduler_job.py:146} INFO - Started process (PID=23153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:13,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:13,159] {logging_mixin.py:95} INFO - [2019-09-15 20:35:13,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:13,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:13,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:13,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:13,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:35:13,597] {scheduler_job.py:146} INFO - Started process (PID=23154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:18,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:18,607] {logging_mixin.py:95} INFO - [2019-09-15 20:35:18,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:18,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:19,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:19,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:19,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:35:19,040] {scheduler_job.py:146} INFO - Started process (PID=23155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:24,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:24,047] {logging_mixin.py:95} INFO - [2019-09-15 20:35:24,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:24,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:24,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:24,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:24,447] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:35:24,489] {scheduler_job.py:146} INFO - Started process (PID=23158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:29,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:29,500] {logging_mixin.py:95} INFO - [2019-09-15 20:35:29,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:29,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:29,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:29,894] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:29,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:35:29,938] {scheduler_job.py:146} INFO - Started process (PID=23159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:34,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:34,946] {logging_mixin.py:95} INFO - [2019-09-15 20:35:34,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:35,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:35,332] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:35,342] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:35,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:35:35,388] {scheduler_job.py:146} INFO - Started process (PID=23160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:40,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:40,408] {logging_mixin.py:95} INFO - [2019-09-15 20:35:40,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:40,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:40,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:40,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:40,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:35:40,837] {scheduler_job.py:146} INFO - Started process (PID=23162) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:45,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:45,843] {logging_mixin.py:95} INFO - [2019-09-15 20:35:45,843] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:46,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:46,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:46,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:46,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:35:46,293] {scheduler_job.py:146} INFO - Started process (PID=23163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:51,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:51,299] {logging_mixin.py:95} INFO - [2019-09-15 20:35:51,298] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:51,666] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:51,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:51,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:51,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:35:51,747] {scheduler_job.py:146} INFO - Started process (PID=23165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:56,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:35:56,754] {logging_mixin.py:95} INFO - [2019-09-15 20:35:56,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:57,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:35:57,143] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:35:57,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:35:57,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:35:57,194] {scheduler_job.py:146} INFO - Started process (PID=23166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:02,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:02,213] {logging_mixin.py:95} INFO - [2019-09-15 20:36:02,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:02,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:02,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:02,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:02,616] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:36:02,643] {scheduler_job.py:146} INFO - Started process (PID=23167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:07,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:07,660] {logging_mixin.py:95} INFO - [2019-09-15 20:36:07,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:08,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:08,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:08,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:08,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:36:08,087] {scheduler_job.py:146} INFO - Started process (PID=23169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:13,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:13,102] {logging_mixin.py:95} INFO - [2019-09-15 20:36:13,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:13,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:13,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:13,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:13,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 20:36:13,636] {scheduler_job.py:146} INFO - Started process (PID=23170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:18,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:18,644] {logging_mixin.py:95} INFO - [2019-09-15 20:36:18,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:19,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:19,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:19,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:19,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-15 20:36:19,184] {scheduler_job.py:146} INFO - Started process (PID=23171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:24,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:24,193] {logging_mixin.py:95} INFO - [2019-09-15 20:36:24,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:24,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:24,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:24,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:24,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:36:24,638] {scheduler_job.py:146} INFO - Started process (PID=23174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:29,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:29,644] {logging_mixin.py:95} INFO - [2019-09-15 20:36:29,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:30,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:30,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:30,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:30,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 20:36:30,195] {scheduler_job.py:146} INFO - Started process (PID=23179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:35,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:35,200] {logging_mixin.py:95} INFO - [2019-09-15 20:36:35,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:35,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:35,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:35,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:35,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:36:35,637] {scheduler_job.py:146} INFO - Started process (PID=23181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:40,641] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:40,642] {logging_mixin.py:95} INFO - [2019-09-15 20:36:40,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:41,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:41,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:41,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:41,050] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:36:41,086] {scheduler_job.py:146} INFO - Started process (PID=23183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:46,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:46,098] {logging_mixin.py:95} INFO - [2019-09-15 20:36:46,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:46,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:46,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:46,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:46,510] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:36:46,532] {scheduler_job.py:146} INFO - Started process (PID=23184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:51,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:51,546] {logging_mixin.py:95} INFO - [2019-09-15 20:36:51,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:51,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:51,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:51,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:51,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:36:51,985] {scheduler_job.py:146} INFO - Started process (PID=23186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:56,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:36:56,994] {logging_mixin.py:95} INFO - [2019-09-15 20:36:56,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:57,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:36:57,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:36:57,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:36:57,400] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:36:57,437] {scheduler_job.py:146} INFO - Started process (PID=23188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:02,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:02,444] {logging_mixin.py:95} INFO - [2019-09-15 20:37:02,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:02,817] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:02,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:02,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:02,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:37:02,884] {scheduler_job.py:146} INFO - Started process (PID=23189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:07,891] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:07,892] {logging_mixin.py:95} INFO - [2019-09-15 20:37:07,891] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:08,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:08,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:08,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:08,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 20:37:08,334] {scheduler_job.py:146} INFO - Started process (PID=23191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:13,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:13,351] {logging_mixin.py:95} INFO - [2019-09-15 20:37:13,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:13,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:13,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:13,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:13,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:37:13,785] {scheduler_job.py:146} INFO - Started process (PID=23192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:18,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:18,791] {logging_mixin.py:95} INFO - [2019-09-15 20:37:18,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:19,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:19,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:19,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:19,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:37:19,237] {scheduler_job.py:146} INFO - Started process (PID=23193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:24,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:24,244] {logging_mixin.py:95} INFO - [2019-09-15 20:37:24,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:24,609] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:24,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:24,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:24,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:37:24,687] {scheduler_job.py:146} INFO - Started process (PID=23196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:29,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:29,698] {logging_mixin.py:95} INFO - [2019-09-15 20:37:29,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:30,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:30,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:30,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:30,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:37:30,137] {scheduler_job.py:146} INFO - Started process (PID=23197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:35,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:35,153] {logging_mixin.py:95} INFO - [2019-09-15 20:37:35,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:35,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:35,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:35,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:35,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:37:35,595] {scheduler_job.py:146} INFO - Started process (PID=23198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:40,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:40,618] {logging_mixin.py:95} INFO - [2019-09-15 20:37:40,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:40,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:41,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:41,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:41,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 20:37:41,064] {scheduler_job.py:146} INFO - Started process (PID=23200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:46,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:46,074] {logging_mixin.py:95} INFO - [2019-09-15 20:37:46,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:46,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:46,463] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:46,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:46,479] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:37:46,529] {scheduler_job.py:146} INFO - Started process (PID=23201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:51,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:51,549] {logging_mixin.py:95} INFO - [2019-09-15 20:37:51,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:51,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:51,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:51,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:51,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:37:51,999] {scheduler_job.py:146} INFO - Started process (PID=23203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:57,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:37:57,024] {logging_mixin.py:95} INFO - [2019-09-15 20:37:57,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:57,388] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:37:57,411] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:37:57,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:37:57,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:37:57,484] {scheduler_job.py:146} INFO - Started process (PID=23204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:02,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:02,491] {logging_mixin.py:95} INFO - [2019-09-15 20:38:02,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:02,857] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:02,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:02,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:02,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:38:02,954] {scheduler_job.py:146} INFO - Started process (PID=23205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:07,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:07,962] {logging_mixin.py:95} INFO - [2019-09-15 20:38:07,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:08,327] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:08,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:08,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:08,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:38:08,432] {scheduler_job.py:146} INFO - Started process (PID=23207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:13,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:13,441] {logging_mixin.py:95} INFO - [2019-09-15 20:38:13,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:13,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:13,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:13,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:13,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:38:13,914] {scheduler_job.py:146} INFO - Started process (PID=23208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:18,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:18,931] {logging_mixin.py:95} INFO - [2019-09-15 20:38:18,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:19,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:19,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:19,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:19,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:38:19,379] {scheduler_job.py:146} INFO - Started process (PID=23209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:24,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:24,392] {logging_mixin.py:95} INFO - [2019-09-15 20:38:24,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:24,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:24,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:24,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:24,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:38:24,841] {scheduler_job.py:146} INFO - Started process (PID=23212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:29,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:29,856] {logging_mixin.py:95} INFO - [2019-09-15 20:38:29,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:30,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:30,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:30,253] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:30,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:38:30,308] {scheduler_job.py:146} INFO - Started process (PID=23213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:35,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:35,324] {logging_mixin.py:95} INFO - [2019-09-15 20:38:35,323] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:35,691] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:35,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:35,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:35,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:38:35,771] {scheduler_job.py:146} INFO - Started process (PID=23214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:40,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:40,781] {logging_mixin.py:95} INFO - [2019-09-15 20:38:40,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:41,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:41,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:41,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:41,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:38:41,255] {scheduler_job.py:146} INFO - Started process (PID=23216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:46,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:46,261] {logging_mixin.py:95} INFO - [2019-09-15 20:38:46,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:46,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:46,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:46,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:46,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:38:46,720] {scheduler_job.py:146} INFO - Started process (PID=23217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:51,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:51,742] {logging_mixin.py:95} INFO - [2019-09-15 20:38:51,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:52,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:52,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:52,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:52,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:38:52,201] {scheduler_job.py:146} INFO - Started process (PID=23219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:57,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:38:57,220] {logging_mixin.py:95} INFO - [2019-09-15 20:38:57,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:57,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:38:57,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:38:57,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:38:57,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:38:57,669] {scheduler_job.py:146} INFO - Started process (PID=23220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:02,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:02,690] {logging_mixin.py:95} INFO - [2019-09-15 20:39:02,690] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:03,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:03,077] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:03,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:03,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:39:03,151] {scheduler_job.py:146} INFO - Started process (PID=23221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:08,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:08,158] {logging_mixin.py:95} INFO - [2019-09-15 20:39:08,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:08,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:08,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:08,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:08,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:39:08,624] {scheduler_job.py:146} INFO - Started process (PID=23223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:13,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:13,646] {logging_mixin.py:95} INFO - [2019-09-15 20:39:13,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:14,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:14,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:14,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:14,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:39:14,092] {scheduler_job.py:146} INFO - Started process (PID=23224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:19,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:19,102] {logging_mixin.py:95} INFO - [2019-09-15 20:39:19,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:19,466] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:19,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:19,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:19,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:39:19,581] {scheduler_job.py:146} INFO - Started process (PID=23225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:24,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:24,598] {logging_mixin.py:95} INFO - [2019-09-15 20:39:24,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:24,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:24,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:24,996] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:25,001] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:39:25,047] {scheduler_job.py:146} INFO - Started process (PID=23228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:30,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:30,058] {logging_mixin.py:95} INFO - [2019-09-15 20:39:30,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:30,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:30,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:30,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:30,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:39:30,502] {scheduler_job.py:146} INFO - Started process (PID=23229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:35,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:35,517] {logging_mixin.py:95} INFO - [2019-09-15 20:39:35,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:35,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:35,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:35,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:35,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:39:35,969] {scheduler_job.py:146} INFO - Started process (PID=23231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:40,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:40,981] {logging_mixin.py:95} INFO - [2019-09-15 20:39:40,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:41,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:41,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:41,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:41,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:39:41,437] {scheduler_job.py:146} INFO - Started process (PID=23232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:46,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:46,448] {logging_mixin.py:95} INFO - [2019-09-15 20:39:46,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:46,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:46,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:46,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:46,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:39:46,898] {scheduler_job.py:146} INFO - Started process (PID=23233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:51,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:51,924] {logging_mixin.py:95} INFO - [2019-09-15 20:39:51,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:52,287] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:52,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:52,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:52,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:39:52,368] {scheduler_job.py:146} INFO - Started process (PID=23235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:57,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:39:57,385] {logging_mixin.py:95} INFO - [2019-09-15 20:39:57,385] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:57,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:39:57,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:39:57,818] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:39:57,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 20:39:57,850] {scheduler_job.py:146} INFO - Started process (PID=23236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:02,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:02,864] {logging_mixin.py:95} INFO - [2019-09-15 20:40:02,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:03,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:03,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:03,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:03,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:40:03,318] {scheduler_job.py:146} INFO - Started process (PID=23237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:08,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:08,332] {logging_mixin.py:95} INFO - [2019-09-15 20:40:08,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:08,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:08,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:08,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:08,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:40:08,797] {scheduler_job.py:146} INFO - Started process (PID=23239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:13,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:13,807] {logging_mixin.py:95} INFO - [2019-09-15 20:40:13,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:14,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:14,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:14,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:14,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:40:14,264] {scheduler_job.py:146} INFO - Started process (PID=23240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:19,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:19,278] {logging_mixin.py:95} INFO - [2019-09-15 20:40:19,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:19,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:19,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:19,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:19,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:40:19,733] {scheduler_job.py:146} INFO - Started process (PID=23241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:24,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:24,747] {logging_mixin.py:95} INFO - [2019-09-15 20:40:24,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:25,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:25,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:25,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:25,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:40:25,203] {scheduler_job.py:146} INFO - Started process (PID=23244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:30,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:30,210] {logging_mixin.py:95} INFO - [2019-09-15 20:40:30,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:30,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:30,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:30,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:30,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:40:30,668] {scheduler_job.py:146} INFO - Started process (PID=23245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:35,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:35,674] {logging_mixin.py:95} INFO - [2019-09-15 20:40:35,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:36,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:36,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:36,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:36,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 20:40:36,136] {scheduler_job.py:146} INFO - Started process (PID=23247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:41,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:41,159] {logging_mixin.py:95} INFO - [2019-09-15 20:40:41,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:41,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:41,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:41,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:41,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:40:41,608] {scheduler_job.py:146} INFO - Started process (PID=23248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:46,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:46,623] {logging_mixin.py:95} INFO - [2019-09-15 20:40:46,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:46,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:47,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:47,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:47,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:40:47,069] {scheduler_job.py:146} INFO - Started process (PID=23249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:52,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:52,076] {logging_mixin.py:95} INFO - [2019-09-15 20:40:52,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:52,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:52,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:52,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:52,476] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:40:52,534] {scheduler_job.py:146} INFO - Started process (PID=23251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:57,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:40:57,547] {logging_mixin.py:95} INFO - [2019-09-15 20:40:57,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:57,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:40:57,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:40:57,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:40:57,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:40:58,007] {scheduler_job.py:146} INFO - Started process (PID=23252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:03,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:03,022] {logging_mixin.py:95} INFO - [2019-09-15 20:41:03,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:03,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:03,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:03,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:03,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:41:03,479] {scheduler_job.py:146} INFO - Started process (PID=23253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:08,491] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:08,492] {logging_mixin.py:95} INFO - [2019-09-15 20:41:08,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:08,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:08,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:08,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:08,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:41:08,948] {scheduler_job.py:146} INFO - Started process (PID=23255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:13,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:13,957] {logging_mixin.py:95} INFO - [2019-09-15 20:41:13,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:14,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:14,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:14,346] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:14,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:41:14,412] {scheduler_job.py:146} INFO - Started process (PID=23256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:19,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:19,422] {logging_mixin.py:95} INFO - [2019-09-15 20:41:19,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:19,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:19,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:19,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:19,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:41:19,876] {scheduler_job.py:146} INFO - Started process (PID=23257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:24,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:24,891] {logging_mixin.py:95} INFO - [2019-09-15 20:41:24,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:25,252] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:25,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:25,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:25,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:41:25,348] {scheduler_job.py:146} INFO - Started process (PID=23260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:30,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:30,357] {logging_mixin.py:95} INFO - [2019-09-15 20:41:30,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:30,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:30,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:30,767] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:30,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:41:30,824] {scheduler_job.py:146} INFO - Started process (PID=23261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:35,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:35,839] {logging_mixin.py:95} INFO - [2019-09-15 20:41:35,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:36,201] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:36,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:36,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:36,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:41:36,286] {scheduler_job.py:146} INFO - Started process (PID=23263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:41,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:41,301] {logging_mixin.py:95} INFO - [2019-09-15 20:41:41,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:41,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:41,695] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:41,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:41,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:41:41,768] {scheduler_job.py:146} INFO - Started process (PID=23264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:46,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:46,784] {logging_mixin.py:95} INFO - [2019-09-15 20:41:46,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:47,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:47,175] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:47,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:47,190] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:41:47,240] {scheduler_job.py:146} INFO - Started process (PID=23265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:52,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:52,264] {logging_mixin.py:95} INFO - [2019-09-15 20:41:52,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:52,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:52,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:52,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:52,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 20:41:52,712] {scheduler_job.py:146} INFO - Started process (PID=23267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:57,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:41:57,733] {logging_mixin.py:95} INFO - [2019-09-15 20:41:57,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:58,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:41:58,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:41:58,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:41:58,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:41:58,187] {scheduler_job.py:146} INFO - Started process (PID=23268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:03,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:03,197] {logging_mixin.py:95} INFO - [2019-09-15 20:42:03,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:03,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:03,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:03,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:03,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 20:42:03,668] {scheduler_job.py:146} INFO - Started process (PID=23269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:08,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:08,680] {logging_mixin.py:95} INFO - [2019-09-15 20:42:08,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:09,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:09,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:09,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:09,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 20:42:09,144] {scheduler_job.py:146} INFO - Started process (PID=23271) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:14,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:14,160] {logging_mixin.py:95} INFO - [2019-09-15 20:42:14,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:14,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:14,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:14,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:14,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:42:14,611] {scheduler_job.py:146} INFO - Started process (PID=23272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:19,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:19,623] {logging_mixin.py:95} INFO - [2019-09-15 20:42:19,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:19,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:20,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:20,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:20,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:42:20,087] {scheduler_job.py:146} INFO - Started process (PID=23273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:25,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:25,103] {logging_mixin.py:95} INFO - [2019-09-15 20:42:25,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:25,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:25,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:25,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:25,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:42:25,545] {scheduler_job.py:146} INFO - Started process (PID=23276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:30,557] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:30,558] {logging_mixin.py:95} INFO - [2019-09-15 20:42:30,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:30,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:30,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:30,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:30,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 20:42:31,016] {scheduler_job.py:146} INFO - Started process (PID=23277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:36,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:36,037] {logging_mixin.py:95} INFO - [2019-09-15 20:42:36,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:36,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:36,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:36,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:36,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:42:36,492] {scheduler_job.py:146} INFO - Started process (PID=23279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:41,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:41,513] {logging_mixin.py:95} INFO - [2019-09-15 20:42:41,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:41,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:41,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:41,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:41,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:42:41,958] {scheduler_job.py:146} INFO - Started process (PID=23280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:46,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:46,974] {logging_mixin.py:95} INFO - [2019-09-15 20:42:46,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:47,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:47,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:47,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:47,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:42:47,432] {scheduler_job.py:146} INFO - Started process (PID=23281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:52,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:52,440] {logging_mixin.py:95} INFO - [2019-09-15 20:42:52,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:52,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:52,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:52,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:52,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:42:52,901] {scheduler_job.py:146} INFO - Started process (PID=23283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:57,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:42:57,921] {logging_mixin.py:95} INFO - [2019-09-15 20:42:57,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:58,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:42:58,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:42:58,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:42:58,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:42:58,372] {scheduler_job.py:146} INFO - Started process (PID=23284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:03,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:03,379] {logging_mixin.py:95} INFO - [2019-09-15 20:43:03,378] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:03,748] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:03,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:03,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:03,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:43:03,838] {scheduler_job.py:146} INFO - Started process (PID=23285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:08,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:08,852] {logging_mixin.py:95} INFO - [2019-09-15 20:43:08,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:09,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:09,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:09,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:09,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:43:09,311] {scheduler_job.py:146} INFO - Started process (PID=23287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:14,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:14,321] {logging_mixin.py:95} INFO - [2019-09-15 20:43:14,321] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:14,689] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:14,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:14,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:14,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:43:14,776] {scheduler_job.py:146} INFO - Started process (PID=23288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:19,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:19,801] {logging_mixin.py:95} INFO - [2019-09-15 20:43:19,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:20,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:20,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:20,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:20,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 20:43:20,246] {scheduler_job.py:146} INFO - Started process (PID=23289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:25,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:25,260] {logging_mixin.py:95} INFO - [2019-09-15 20:43:25,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:25,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:25,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:25,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:25,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:43:25,728] {scheduler_job.py:146} INFO - Started process (PID=23292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:30,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:30,738] {logging_mixin.py:95} INFO - [2019-09-15 20:43:30,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:31,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:31,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:31,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:31,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 20:43:31,210] {scheduler_job.py:146} INFO - Started process (PID=23293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:36,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:36,221] {logging_mixin.py:95} INFO - [2019-09-15 20:43:36,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:36,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:36,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:36,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:36,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:43:36,681] {scheduler_job.py:146} INFO - Started process (PID=23295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:41,689] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:41,699] {logging_mixin.py:95} INFO - [2019-09-15 20:43:41,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:42,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:42,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:42,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:42,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 20:43:42,161] {scheduler_job.py:146} INFO - Started process (PID=23296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:47,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:47,172] {logging_mixin.py:95} INFO - [2019-09-15 20:43:47,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:47,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:47,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:47,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:47,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:43:47,624] {scheduler_job.py:146} INFO - Started process (PID=23297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:52,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:52,638] {logging_mixin.py:95} INFO - [2019-09-15 20:43:52,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:53,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:53,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:53,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:53,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:43:53,098] {scheduler_job.py:146} INFO - Started process (PID=23299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:58,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:43:58,106] {logging_mixin.py:95} INFO - [2019-09-15 20:43:58,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:58,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:43:58,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:43:58,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:43:58,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-15 20:43:58,656] {scheduler_job.py:146} INFO - Started process (PID=23318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:03,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:03,679] {logging_mixin.py:95} INFO - [2019-09-15 20:44:03,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:04,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:04,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:04,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:04,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:44:04,129] {scheduler_job.py:146} INFO - Started process (PID=23319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:09,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:09,138] {logging_mixin.py:95} INFO - [2019-09-15 20:44:09,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:09,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:09,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:09,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:09,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:44:09,608] {scheduler_job.py:146} INFO - Started process (PID=23321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:14,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:14,620] {logging_mixin.py:95} INFO - [2019-09-15 20:44:14,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:14,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:15,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:15,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:15,025] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:44:15,071] {scheduler_job.py:146} INFO - Started process (PID=23322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:20,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:20,095] {logging_mixin.py:95} INFO - [2019-09-15 20:44:20,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:20,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:20,487] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:20,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:20,502] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 20:44:20,547] {scheduler_job.py:146} INFO - Started process (PID=23323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:25,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:25,554] {logging_mixin.py:95} INFO - [2019-09-15 20:44:25,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:25,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:25,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:25,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:25,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:44:26,026] {scheduler_job.py:146} INFO - Started process (PID=23326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:31,035] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:31,042] {logging_mixin.py:95} INFO - [2019-09-15 20:44:31,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:31,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:31,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:31,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:31,445] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:44:31,499] {scheduler_job.py:146} INFO - Started process (PID=23327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:36,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:36,512] {logging_mixin.py:95} INFO - [2019-09-15 20:44:36,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:36,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:36,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:36,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:36,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:44:36,973] {scheduler_job.py:146} INFO - Started process (PID=23329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:41,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:41,997] {logging_mixin.py:95} INFO - [2019-09-15 20:44:41,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:42,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:42,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:42,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:42,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 20:44:42,442] {scheduler_job.py:146} INFO - Started process (PID=23330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:47,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:47,449] {logging_mixin.py:95} INFO - [2019-09-15 20:44:47,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:47,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:47,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:47,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:47,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:44:47,912] {scheduler_job.py:146} INFO - Started process (PID=23331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:52,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:52,924] {logging_mixin.py:95} INFO - [2019-09-15 20:44:52,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:53,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:53,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:53,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:53,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 20:44:53,381] {scheduler_job.py:146} INFO - Started process (PID=23333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:58,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:44:58,387] {logging_mixin.py:95} INFO - [2019-09-15 20:44:58,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:58,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:44:58,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:44:58,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:44:58,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:44:58,861] {scheduler_job.py:146} INFO - Started process (PID=23334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:03,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:03,880] {logging_mixin.py:95} INFO - [2019-09-15 20:45:03,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:04,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:04,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:04,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:04,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:45:04,327] {scheduler_job.py:146} INFO - Started process (PID=23335) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:09,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:09,340] {logging_mixin.py:95} INFO - [2019-09-15 20:45:09,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:09,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:09,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:09,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:09,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:45:09,798] {scheduler_job.py:146} INFO - Started process (PID=23337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:14,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:14,809] {logging_mixin.py:95} INFO - [2019-09-15 20:45:14,809] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:15,171] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:15,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:15,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:15,210] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:45:15,265] {scheduler_job.py:146} INFO - Started process (PID=23338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:20,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:20,285] {logging_mixin.py:95} INFO - [2019-09-15 20:45:20,285] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:20,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:20,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:20,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:20,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:45:20,739] {scheduler_job.py:146} INFO - Started process (PID=23339) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:25,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:25,753] {logging_mixin.py:95} INFO - [2019-09-15 20:45:25,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:26,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:26,142] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:26,151] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:26,157] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:45:26,212] {scheduler_job.py:146} INFO - Started process (PID=23342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:31,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:31,225] {logging_mixin.py:95} INFO - [2019-09-15 20:45:31,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:31,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:31,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:31,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:31,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:45:31,682] {scheduler_job.py:146} INFO - Started process (PID=23343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:36,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:36,687] {logging_mixin.py:95} INFO - [2019-09-15 20:45:36,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:37,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:37,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:37,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:37,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:45:37,149] {scheduler_job.py:146} INFO - Started process (PID=23345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:42,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:42,168] {logging_mixin.py:95} INFO - [2019-09-15 20:45:42,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:42,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:42,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:42,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:42,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:45:42,631] {scheduler_job.py:146} INFO - Started process (PID=23346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:47,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:47,651] {logging_mixin.py:95} INFO - [2019-09-15 20:45:47,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:48,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:48,038] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:48,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:48,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:45:48,101] {scheduler_job.py:146} INFO - Started process (PID=23347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:53,114] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:53,116] {logging_mixin.py:95} INFO - [2019-09-15 20:45:53,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:53,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:53,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:53,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:53,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:45:53,568] {scheduler_job.py:146} INFO - Started process (PID=23349) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:58,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:45:58,587] {logging_mixin.py:95} INFO - [2019-09-15 20:45:58,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:58,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:45:58,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:45:58,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:45:58,988] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:45:59,047] {scheduler_job.py:146} INFO - Started process (PID=23350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:04,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:04,053] {logging_mixin.py:95} INFO - [2019-09-15 20:46:04,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:04,422] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:04,445] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:04,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:04,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:46:04,520] {scheduler_job.py:146} INFO - Started process (PID=23351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:09,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:09,528] {logging_mixin.py:95} INFO - [2019-09-15 20:46:09,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:09,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:10,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:10,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:10,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.528 seconds
[2019-09-15 20:46:10,168] {scheduler_job.py:146} INFO - Started process (PID=23353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:15,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:15,175] {logging_mixin.py:95} INFO - [2019-09-15 20:46:15,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:15,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:15,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:15,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:15,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 20:46:15,694] {scheduler_job.py:146} INFO - Started process (PID=23354) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:20,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:20,702] {logging_mixin.py:95} INFO - [2019-09-15 20:46:20,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:21,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:21,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:21,103] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:21,109] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:46:21,224] {scheduler_job.py:146} INFO - Started process (PID=23355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:26,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:26,232] {logging_mixin.py:95} INFO - [2019-09-15 20:46:26,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:26,599] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:26,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:26,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:26,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:46:26,668] {scheduler_job.py:146} INFO - Started process (PID=23358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:31,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:31,684] {logging_mixin.py:95} INFO - [2019-09-15 20:46:31,684] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:32,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:32,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:32,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:32,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:46:32,124] {scheduler_job.py:146} INFO - Started process (PID=23359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:37,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:37,133] {logging_mixin.py:95} INFO - [2019-09-15 20:46:37,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:37,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:37,526] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:37,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:37,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:46:37,564] {scheduler_job.py:146} INFO - Started process (PID=23361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:42,569] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:42,571] {logging_mixin.py:95} INFO - [2019-09-15 20:46:42,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:42,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:42,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:42,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:42,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:46:43,017] {scheduler_job.py:146} INFO - Started process (PID=23362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:48,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:48,035] {logging_mixin.py:95} INFO - [2019-09-15 20:46:48,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:48,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:48,424] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:48,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:48,440] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:46:48,467] {scheduler_job.py:146} INFO - Started process (PID=23363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:53,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:53,474] {logging_mixin.py:95} INFO - [2019-09-15 20:46:53,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:53,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:53,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:53,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:53,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:46:53,914] {scheduler_job.py:146} INFO - Started process (PID=23365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:58,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:46:58,921] {logging_mixin.py:95} INFO - [2019-09-15 20:46:58,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:59,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:46:59,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:46:59,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:46:59,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:46:59,365] {scheduler_job.py:146} INFO - Started process (PID=23366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:04,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:04,372] {logging_mixin.py:95} INFO - [2019-09-15 20:47:04,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:04,738] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:04,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:04,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:04,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:47:04,820] {scheduler_job.py:146} INFO - Started process (PID=23367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:09,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:09,827] {logging_mixin.py:95} INFO - [2019-09-15 20:47:09,826] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:10,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:10,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:10,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:10,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:47:10,263] {scheduler_job.py:146} INFO - Started process (PID=23369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:15,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:15,268] {logging_mixin.py:95} INFO - [2019-09-15 20:47:15,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:15,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:15,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:15,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:15,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 20:47:15,718] {scheduler_job.py:146} INFO - Started process (PID=23370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:20,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:20,736] {logging_mixin.py:95} INFO - [2019-09-15 20:47:20,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:21,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:21,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:21,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:21,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:47:21,170] {scheduler_job.py:146} INFO - Started process (PID=23371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:26,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:26,181] {logging_mixin.py:95} INFO - [2019-09-15 20:47:26,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:26,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:26,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:26,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:26,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:47:26,622] {scheduler_job.py:146} INFO - Started process (PID=23374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:31,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:31,644] {logging_mixin.py:95} INFO - [2019-09-15 20:47:31,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:32,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:32,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:32,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:32,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:47:32,076] {scheduler_job.py:146} INFO - Started process (PID=23375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:37,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:37,085] {logging_mixin.py:95} INFO - [2019-09-15 20:47:37,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:37,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:37,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:37,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:37,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 20:47:37,521] {scheduler_job.py:146} INFO - Started process (PID=23377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:42,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:42,528] {logging_mixin.py:95} INFO - [2019-09-15 20:47:42,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:42,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:42,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:42,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:42,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 20:47:42,966] {scheduler_job.py:146} INFO - Started process (PID=23378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:47,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:47,972] {logging_mixin.py:95} INFO - [2019-09-15 20:47:47,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:48,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:48,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:48,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:48,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:47:48,417] {scheduler_job.py:146} INFO - Started process (PID=23379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:53,423] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:53,424] {logging_mixin.py:95} INFO - [2019-09-15 20:47:53,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:53,793] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:53,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:53,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:53,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:47:53,864] {scheduler_job.py:146} INFO - Started process (PID=23381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:58,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:47:58,872] {logging_mixin.py:95} INFO - [2019-09-15 20:47:58,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:59,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:47:59,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:47:59,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:47:59,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:47:59,314] {scheduler_job.py:146} INFO - Started process (PID=23382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:04,322] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:04,332] {logging_mixin.py:95} INFO - [2019-09-15 20:48:04,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:04,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:04,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:04,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:04,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:48:04,762] {scheduler_job.py:146} INFO - Started process (PID=23383) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:09,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:09,772] {logging_mixin.py:95} INFO - [2019-09-15 20:48:09,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:10,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:10,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:10,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:10,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 20:48:10,215] {scheduler_job.py:146} INFO - Started process (PID=23385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:15,221] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:15,222] {logging_mixin.py:95} INFO - [2019-09-15 20:48:15,222] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:15,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:15,614] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:15,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:15,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:48:15,667] {scheduler_job.py:146} INFO - Started process (PID=23386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:20,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:20,683] {logging_mixin.py:95} INFO - [2019-09-15 20:48:20,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:21,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:21,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:21,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:21,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:48:21,115] {scheduler_job.py:146} INFO - Started process (PID=23387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:26,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:26,126] {logging_mixin.py:95} INFO - [2019-09-15 20:48:26,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:26,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:26,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:26,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:26,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 20:48:26,565] {scheduler_job.py:146} INFO - Started process (PID=23390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:31,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:31,577] {logging_mixin.py:95} INFO - [2019-09-15 20:48:31,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:31,945] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:31,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:31,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:31,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:48:32,010] {scheduler_job.py:146} INFO - Started process (PID=23391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:37,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:37,020] {logging_mixin.py:95} INFO - [2019-09-15 20:48:37,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:37,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:37,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:37,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:37,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:48:37,458] {scheduler_job.py:146} INFO - Started process (PID=23393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:42,466] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:42,467] {logging_mixin.py:95} INFO - [2019-09-15 20:48:42,466] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:42,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:42,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:42,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:42,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:48:42,911] {scheduler_job.py:146} INFO - Started process (PID=23394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:47,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:47,932] {logging_mixin.py:95} INFO - [2019-09-15 20:48:47,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:48,296] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:48,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:48,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:48,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 20:48:48,363] {scheduler_job.py:146} INFO - Started process (PID=23395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:53,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:53,373] {logging_mixin.py:95} INFO - [2019-09-15 20:48:53,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:53,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:53,760] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:53,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:53,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:48:53,815] {scheduler_job.py:146} INFO - Started process (PID=23397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:58,825] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:48:58,834] {logging_mixin.py:95} INFO - [2019-09-15 20:48:58,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:59,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:48:59,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:48:59,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:48:59,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 20:48:59,265] {scheduler_job.py:146} INFO - Started process (PID=23398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:04,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:04,273] {logging_mixin.py:95} INFO - [2019-09-15 20:49:04,272] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:04,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:04,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:04,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:04,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:49:04,722] {scheduler_job.py:146} INFO - Started process (PID=23399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:09,727] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:09,728] {logging_mixin.py:95} INFO - [2019-09-15 20:49:09,728] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:10,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:10,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:10,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:10,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:49:10,167] {scheduler_job.py:146} INFO - Started process (PID=23401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:15,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:15,177] {logging_mixin.py:95} INFO - [2019-09-15 20:49:15,177] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:15,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:15,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:15,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:15,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:49:15,617] {scheduler_job.py:146} INFO - Started process (PID=23402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:20,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:20,633] {logging_mixin.py:95} INFO - [2019-09-15 20:49:20,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:20,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:21,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:21,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:21,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 20:49:21,068] {scheduler_job.py:146} INFO - Started process (PID=23403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:26,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:26,078] {logging_mixin.py:95} INFO - [2019-09-15 20:49:26,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:26,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:26,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:26,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:26,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 20:49:26,526] {scheduler_job.py:146} INFO - Started process (PID=23406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:31,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:31,545] {logging_mixin.py:95} INFO - [2019-09-15 20:49:31,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:31,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:31,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:31,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:31,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 20:49:31,978] {scheduler_job.py:146} INFO - Started process (PID=23407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:36,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:36,985] {logging_mixin.py:95} INFO - [2019-09-15 20:49:36,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:37,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:37,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:37,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:37,389] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 20:49:37,432] {scheduler_job.py:146} INFO - Started process (PID=23409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:42,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:42,448] {logging_mixin.py:95} INFO - [2019-09-15 20:49:42,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:42,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:42,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:42,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:42,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:49:42,881] {scheduler_job.py:146} INFO - Started process (PID=23410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:47,887] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:47,888] {logging_mixin.py:95} INFO - [2019-09-15 20:49:47,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:48,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:48,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:48,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:48,288] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 20:49:48,335] {scheduler_job.py:146} INFO - Started process (PID=23411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:53,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:53,347] {logging_mixin.py:95} INFO - [2019-09-15 20:49:53,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:53,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:53,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:53,748] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:53,753] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:49:53,781] {scheduler_job.py:146} INFO - Started process (PID=23413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:58,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:49:58,793] {logging_mixin.py:95} INFO - [2019-09-15 20:49:58,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:59,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:49:59,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:49:59,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:49:59,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 20:49:59,236] {scheduler_job.py:146} INFO - Started process (PID=23414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:04,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:04,243] {logging_mixin.py:95} INFO - [2019-09-15 20:50:04,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:04,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:04,638] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:04,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:04,654] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:50:04,684] {scheduler_job.py:146} INFO - Started process (PID=23415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:09,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:09,696] {logging_mixin.py:95} INFO - [2019-09-15 20:50:09,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:10,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:10,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:10,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:10,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:50:10,134] {scheduler_job.py:146} INFO - Started process (PID=23417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:15,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:15,143] {logging_mixin.py:95} INFO - [2019-09-15 20:50:15,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:15,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:15,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:15,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:15,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:50:15,579] {scheduler_job.py:146} INFO - Started process (PID=23418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:20,586] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:20,588] {logging_mixin.py:95} INFO - [2019-09-15 20:50:20,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:20,952] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:20,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:20,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:20,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 20:50:21,032] {scheduler_job.py:146} INFO - Started process (PID=23419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:26,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:26,039] {logging_mixin.py:95} INFO - [2019-09-15 20:50:26,039] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:26,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:26,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:26,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:26,437] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 20:50:26,480] {scheduler_job.py:146} INFO - Started process (PID=23422) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:31,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:31,490] {logging_mixin.py:95} INFO - [2019-09-15 20:50:31,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:31,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:31,884] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:31,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:31,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:50:31,929] {scheduler_job.py:146} INFO - Started process (PID=23423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:36,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:36,944] {logging_mixin.py:95} INFO - [2019-09-15 20:50:36,944] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:37,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:37,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:37,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:37,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 20:50:37,375] {scheduler_job.py:146} INFO - Started process (PID=23425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:42,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:42,392] {logging_mixin.py:95} INFO - [2019-09-15 20:50:42,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:42,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:42,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:42,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:42,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 20:50:42,822] {scheduler_job.py:146} INFO - Started process (PID=23426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:47,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:47,842] {logging_mixin.py:95} INFO - [2019-09-15 20:50:47,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:48,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:48,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:48,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:48,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 20:50:48,276] {scheduler_job.py:146} INFO - Started process (PID=23427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:53,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:53,283] {logging_mixin.py:95} INFO - [2019-09-15 20:50:53,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:53,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:53,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:53,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:53,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:50:53,729] {scheduler_job.py:146} INFO - Started process (PID=23429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:58,736] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:50:58,737] {logging_mixin.py:95} INFO - [2019-09-15 20:50:58,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:59,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:50:59,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:50:59,135] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:50:59,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 20:50:59,180] {scheduler_job.py:146} INFO - Started process (PID=23430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:04,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:04,188] {logging_mixin.py:95} INFO - [2019-09-15 20:51:04,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:04,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:04,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:04,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:04,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 20:51:04,632] {scheduler_job.py:146} INFO - Started process (PID=23431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:09,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:09,648] {logging_mixin.py:95} INFO - [2019-09-15 20:51:09,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:10,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:10,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:10,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:10,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:51:10,079] {scheduler_job.py:146} INFO - Started process (PID=23433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:15,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:15,085] {logging_mixin.py:95} INFO - [2019-09-15 20:51:15,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:15,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:15,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:15,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:15,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:51:15,544] {scheduler_job.py:146} INFO - Started process (PID=23434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:20,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:20,568] {logging_mixin.py:95} INFO - [2019-09-15 20:51:20,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:20,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:20,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:20,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:20,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 20:51:21,012] {scheduler_job.py:146} INFO - Started process (PID=23435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:26,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:26,021] {logging_mixin.py:95} INFO - [2019-09-15 20:51:26,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:26,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:26,410] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:26,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:26,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 20:51:26,491] {scheduler_job.py:146} INFO - Started process (PID=23438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:31,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:31,504] {logging_mixin.py:95} INFO - [2019-09-15 20:51:31,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:31,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:31,895] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:31,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:31,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 20:51:31,964] {scheduler_job.py:146} INFO - Started process (PID=23439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:36,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:36,986] {logging_mixin.py:95} INFO - [2019-09-15 20:51:36,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:37,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:37,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:37,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:37,393] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 20:51:37,443] {scheduler_job.py:146} INFO - Started process (PID=23441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:42,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:42,449] {logging_mixin.py:95} INFO - [2019-09-15 20:51:42,449] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:42,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:42,838] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:42,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:42,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 20:51:42,908] {scheduler_job.py:146} INFO - Started process (PID=23442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:47,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:47,928] {logging_mixin.py:95} INFO - [2019-09-15 20:51:47,927] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:48,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:48,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:48,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:48,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-09-15 20:51:48,476] {scheduler_job.py:146} INFO - Started process (PID=23443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:53,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:53,485] {logging_mixin.py:95} INFO - [2019-09-15 20:51:53,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:53,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:53,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:53,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:53,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.510 seconds
[2019-09-15 20:51:54,018] {scheduler_job.py:146} INFO - Started process (PID=23446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:59,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:51:59,031] {logging_mixin.py:95} INFO - [2019-09-15 20:51:59,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:59,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:51:59,398] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:51:59,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:51:59,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 20:51:59,464] {scheduler_job.py:146} INFO - Started process (PID=23448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:04,474] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:04,475] {logging_mixin.py:95} INFO - [2019-09-15 20:52:04,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:04,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:04,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:04,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:04,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:52:04,918] {scheduler_job.py:146} INFO - Started process (PID=23449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:09,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:09,925] {logging_mixin.py:95} INFO - [2019-09-15 20:52:09,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:10,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:10,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:10,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:10,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:52:10,384] {scheduler_job.py:146} INFO - Started process (PID=23451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:15,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:15,392] {logging_mixin.py:95} INFO - [2019-09-15 20:52:15,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:15,737] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:15,760] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:15,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:15,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:52:15,848] {scheduler_job.py:146} INFO - Started process (PID=23453) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:20,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:20,855] {logging_mixin.py:95} INFO - [2019-09-15 20:52:20,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:21,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:21,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:21,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:21,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 20:52:21,306] {scheduler_job.py:146} INFO - Started process (PID=23454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:26,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:26,315] {logging_mixin.py:95} INFO - [2019-09-15 20:52:26,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:26,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:26,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:26,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:26,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 20:52:26,764] {scheduler_job.py:146} INFO - Started process (PID=23459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:31,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:31,772] {logging_mixin.py:95} INFO - [2019-09-15 20:52:31,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:32,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:32,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:32,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:32,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 20:52:32,225] {scheduler_job.py:146} INFO - Started process (PID=23460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:37,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:37,233] {logging_mixin.py:95} INFO - [2019-09-15 20:52:37,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:37,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:37,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:37,606] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:37,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:52:37,681] {scheduler_job.py:146} INFO - Started process (PID=23462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:42,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:42,688] {logging_mixin.py:95} INFO - [2019-09-15 20:52:42,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:43,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:43,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:43,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:43,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:52:43,140] {scheduler_job.py:146} INFO - Started process (PID=23463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:48,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:48,149] {logging_mixin.py:95} INFO - [2019-09-15 20:52:48,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:48,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:48,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:48,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:48,532] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 20:52:48,603] {scheduler_job.py:146} INFO - Started process (PID=23464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:53,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:53,613] {logging_mixin.py:95} INFO - [2019-09-15 20:52:53,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:53,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:53,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:53,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:53,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 20:52:54,060] {scheduler_job.py:146} INFO - Started process (PID=23466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:59,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:52:59,071] {logging_mixin.py:95} INFO - [2019-09-15 20:52:59,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:59,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:52:59,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:52:59,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:52:59,453] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 20:52:59,522] {scheduler_job.py:146} INFO - Started process (PID=23467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:04,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:04,531] {logging_mixin.py:95} INFO - [2019-09-15 20:53:04,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:04,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:04,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:04,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:04,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 20:53:04,984] {scheduler_job.py:146} INFO - Started process (PID=23468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:09,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:09,995] {logging_mixin.py:95} INFO - [2019-09-15 20:53:09,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:10,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:10,359] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:10,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:10,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:53:10,451] {scheduler_job.py:146} INFO - Started process (PID=23470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:15,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:15,458] {logging_mixin.py:95} INFO - [2019-09-15 20:53:15,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:15,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:15,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:15,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:15,841] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:53:15,910] {scheduler_job.py:146} INFO - Started process (PID=23471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:20,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:20,922] {logging_mixin.py:95} INFO - [2019-09-15 20:53:20,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:21,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:21,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:21,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:21,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 20:53:21,376] {scheduler_job.py:146} INFO - Started process (PID=23472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:26,387] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:26,388] {logging_mixin.py:95} INFO - [2019-09-15 20:53:26,387] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:26,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:26,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:26,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:26,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 20:53:26,835] {scheduler_job.py:146} INFO - Started process (PID=23475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:31,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:31,847] {logging_mixin.py:95} INFO - [2019-09-15 20:53:31,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:32,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:32,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:32,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:32,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 20:53:32,296] {scheduler_job.py:146} INFO - Started process (PID=23476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:37,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:37,308] {logging_mixin.py:95} INFO - [2019-09-15 20:53:37,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:37,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:37,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:37,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:37,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 20:53:37,754] {scheduler_job.py:146} INFO - Started process (PID=23478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:42,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:42,764] {logging_mixin.py:95} INFO - [2019-09-15 20:53:42,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:43,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:43,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:43,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:43,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 20:53:43,215] {scheduler_job.py:146} INFO - Started process (PID=23479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:48,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:48,223] {logging_mixin.py:95} INFO - [2019-09-15 20:53:48,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:48,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:48,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:48,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:48,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:53:48,678] {scheduler_job.py:146} INFO - Started process (PID=23480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:53,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:53,689] {logging_mixin.py:95} INFO - [2019-09-15 20:53:53,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:54,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:54,054] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:54,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:54,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:53:54,138] {scheduler_job.py:146} INFO - Started process (PID=23482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:59,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:53:59,147] {logging_mixin.py:95} INFO - [2019-09-15 20:53:59,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:59,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:53:59,515] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:53:59,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:53:59,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 20:53:59,599] {scheduler_job.py:146} INFO - Started process (PID=23483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:04,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:04,606] {logging_mixin.py:95} INFO - [2019-09-15 20:54:04,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:04,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:04,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:04,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:04,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 20:54:05,058] {scheduler_job.py:146} INFO - Started process (PID=23484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:10,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:10,065] {logging_mixin.py:95} INFO - [2019-09-15 20:54:10,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:10,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:10,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:10,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:10,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 20:54:10,520] {scheduler_job.py:146} INFO - Started process (PID=23486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:15,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:15,540] {logging_mixin.py:95} INFO - [2019-09-15 20:54:15,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:15,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:15,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:15,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:15,923] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 20:54:15,975] {scheduler_job.py:146} INFO - Started process (PID=23487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:20,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:20,982] {logging_mixin.py:95} INFO - [2019-09-15 20:54:20,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:21,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:21,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:21,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:21,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 20:54:21,437] {scheduler_job.py:146} INFO - Started process (PID=23488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:26,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:26,447] {logging_mixin.py:95} INFO - [2019-09-15 20:54:26,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:26,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:26,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:26,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:26,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 20:54:26,896] {scheduler_job.py:146} INFO - Started process (PID=23491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:31,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:31,906] {logging_mixin.py:95} INFO - [2019-09-15 20:54:31,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:32,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:32,273] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:32,282] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:32,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 20:54:32,357] {scheduler_job.py:146} INFO - Started process (PID=23492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:37,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:37,365] {logging_mixin.py:95} INFO - [2019-09-15 20:54:37,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:37,703] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:37,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:37,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:37,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:54:37,818] {scheduler_job.py:146} INFO - Started process (PID=23494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:42,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:42,824] {logging_mixin.py:95} INFO - [2019-09-15 20:54:42,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:43,168] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:43,191] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:43,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:43,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 20:54:43,291] {scheduler_job.py:146} INFO - Started process (PID=23496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:48,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:48,302] {logging_mixin.py:95} INFO - [2019-09-15 20:54:48,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:48,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:48,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:48,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:48,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-15 20:54:48,689] {scheduler_job.py:146} INFO - Started process (PID=23497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:53,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:53,701] {logging_mixin.py:95} INFO - [2019-09-15 20:54:53,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:54,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:54,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:54,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:54,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 20:54:54,192] {scheduler_job.py:146} INFO - Started process (PID=23499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:59,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:59,203] {logging_mixin.py:95} INFO - [2019-09-15 20:54:59,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:59,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:59,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:54:59,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:54:59,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 20:54:59,689] {scheduler_job.py:146} INFO - Started process (PID=23500) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:54:59,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:54:59,695] {logging_mixin.py:95} INFO - [2019-09-15 20:54:59,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:00,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:00,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.384 seconds
[2019-09-15 20:55:00,099] {scheduler_job.py:146} INFO - Started process (PID=23501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:00,105] {logging_mixin.py:95} INFO - [2019-09-15 20:55:00,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,441] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:00,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:00,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.379 seconds
[2019-09-15 20:55:00,507] {scheduler_job.py:146} INFO - Started process (PID=23502) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:00,512] {logging_mixin.py:95} INFO - [2019-09-15 20:55:00,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:00,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:00,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:00,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.402 seconds
[2019-09-15 20:55:01,018] {scheduler_job.py:146} INFO - Started process (PID=23504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:01,023] {logging_mixin.py:95} INFO - [2019-09-15 20:55:01,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:01,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:01,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-09-15 20:55:01,428] {scheduler_job.py:146} INFO - Started process (PID=23505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:01,433] {logging_mixin.py:95} INFO - [2019-09-15 20:55:01,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:01,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:01,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.389 seconds
[2019-09-15 20:55:01,835] {scheduler_job.py:146} INFO - Started process (PID=23506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:01,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:01,840] {logging_mixin.py:95} INFO - [2019-09-15 20:55:01,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:02,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:02,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.364 seconds
[2019-09-15 20:55:02,249] {scheduler_job.py:146} INFO - Started process (PID=23507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:02,254] {logging_mixin.py:95} INFO - [2019-09-15 20:55:02,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:02,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:02,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-15 20:55:02,656] {scheduler_job.py:146} INFO - Started process (PID=23508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:02,661] {logging_mixin.py:95} INFO - [2019-09-15 20:55:02,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:02,993] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:03,014] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:55:03,023] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:55:03,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.372 seconds
[2019-09-15 20:55:03,068] {scheduler_job.py:146} INFO - Started process (PID=23509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:55:03,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:55:03,072] {logging_mixin.py:95} INFO - [2019-09-15 20:55:03,072] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:29,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:29,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:29,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:29,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 266.154 seconds
[2019-09-15 20:59:29,327] {scheduler_job.py:146} INFO - Started process (PID=23510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:29,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:29,335] {logging_mixin.py:95} INFO - [2019-09-15 20:59:29,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:30,120] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:30,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:30,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:30,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.839 seconds
[2019-09-15 20:59:30,238] {scheduler_job.py:146} INFO - Started process (PID=23515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:35,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:35,245] {logging_mixin.py:95} INFO - [2019-09-15 20:59:35,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:35,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:35,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:35,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:35,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 20:59:35,743] {scheduler_job.py:146} INFO - Started process (PID=23520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:40,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:40,755] {logging_mixin.py:95} INFO - [2019-09-15 20:59:40,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:41,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:41,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:41,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:41,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.505 seconds
[2019-09-15 20:59:41,284] {scheduler_job.py:146} INFO - Started process (PID=23524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:46,289] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:46,291] {logging_mixin.py:95} INFO - [2019-09-15 20:59:46,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:46,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:46,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:46,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:46,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 20:59:46,727] {scheduler_job.py:146} INFO - Started process (PID=23525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:51,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:51,735] {logging_mixin.py:95} INFO - [2019-09-15 20:59:51,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:52,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:52,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:52,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:52,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 20:59:52,274] {scheduler_job.py:146} INFO - Started process (PID=23528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:57,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 20:59:57,281] {logging_mixin.py:95} INFO - [2019-09-15 20:59:57,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:57,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 20:59:57,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 20:59:57,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 20:59:57,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 20:59:57,716] {scheduler_job.py:146} INFO - Started process (PID=23529) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:02,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:02,727] {logging_mixin.py:95} INFO - [2019-09-15 21:00:02,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:03,071] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:03,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:03,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:03,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:00:03,171] {scheduler_job.py:146} INFO - Started process (PID=23531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:08,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:08,181] {logging_mixin.py:95} INFO - [2019-09-15 21:00:08,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:08,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:08,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:08,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:08,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:00:08,633] {scheduler_job.py:146} INFO - Started process (PID=23532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:13,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:13,639] {logging_mixin.py:95} INFO - [2019-09-15 21:00:13,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:13,968] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:13,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:13,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:14,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-15 21:00:14,096] {scheduler_job.py:146} INFO - Started process (PID=23533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:19,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:19,105] {logging_mixin.py:95} INFO - [2019-09-15 21:00:19,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:19,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:19,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:19,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:19,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:00:19,557] {scheduler_job.py:146} INFO - Started process (PID=23535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:24,565] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:24,566] {logging_mixin.py:95} INFO - [2019-09-15 21:00:24,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:24,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:24,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:24,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:24,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:00:25,023] {scheduler_job.py:146} INFO - Started process (PID=23536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:30,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:30,030] {logging_mixin.py:95} INFO - [2019-09-15 21:00:30,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:30,379] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:30,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:30,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:30,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:00:30,486] {scheduler_job.py:146} INFO - Started process (PID=23537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:35,496] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:35,497] {logging_mixin.py:95} INFO - [2019-09-15 21:00:35,497] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:35,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:35,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:35,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:35,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:00:35,936] {scheduler_job.py:146} INFO - Started process (PID=23539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:40,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:40,947] {logging_mixin.py:95} INFO - [2019-09-15 21:00:40,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:41,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:41,320] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:41,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:41,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:00:41,399] {scheduler_job.py:146} INFO - Started process (PID=23540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:46,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:46,409] {logging_mixin.py:95} INFO - [2019-09-15 21:00:46,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:46,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:46,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:46,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:46,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 21:00:46,859] {scheduler_job.py:146} INFO - Started process (PID=23541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:51,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:51,867] {logging_mixin.py:95} INFO - [2019-09-15 21:00:51,867] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:52,211] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:52,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:52,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:52,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:00:52,313] {scheduler_job.py:146} INFO - Started process (PID=23544) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:57,323] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:00:57,324] {logging_mixin.py:95} INFO - [2019-09-15 21:00:57,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:57,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:00:57,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:00:57,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:00:57,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:00:57,775] {scheduler_job.py:146} INFO - Started process (PID=23545) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:02,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:02,782] {logging_mixin.py:95} INFO - [2019-09-15 21:01:02,782] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:03,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:03,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:03,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:03,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:01:03,235] {scheduler_job.py:146} INFO - Started process (PID=23547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:08,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:08,244] {logging_mixin.py:95} INFO - [2019-09-15 21:01:08,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:08,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:08,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:08,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:08,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:01:08,698] {scheduler_job.py:146} INFO - Started process (PID=23548) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:13,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:13,710] {logging_mixin.py:95} INFO - [2019-09-15 21:01:13,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:14,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:14,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:14,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:14,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:01:14,156] {scheduler_job.py:146} INFO - Started process (PID=23549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:19,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:19,163] {logging_mixin.py:95} INFO - [2019-09-15 21:01:19,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:19,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:19,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:19,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:19,542] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:01:19,617] {scheduler_job.py:146} INFO - Started process (PID=23551) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:24,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:24,629] {logging_mixin.py:95} INFO - [2019-09-15 21:01:24,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:24,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:24,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:24,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:25,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:01:25,076] {scheduler_job.py:146} INFO - Started process (PID=23552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:30,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:30,087] {logging_mixin.py:95} INFO - [2019-09-15 21:01:30,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:30,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:30,459] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:30,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:30,473] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:01:30,538] {scheduler_job.py:146} INFO - Started process (PID=23553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:35,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:35,547] {logging_mixin.py:95} INFO - [2019-09-15 21:01:35,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:35,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:35,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:35,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:35,930] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:01:35,999] {scheduler_job.py:146} INFO - Started process (PID=23555) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:41,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:41,008] {logging_mixin.py:95} INFO - [2019-09-15 21:01:41,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:41,361] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:41,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:41,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:41,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:01:41,461] {scheduler_job.py:146} INFO - Started process (PID=23556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:46,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:46,472] {logging_mixin.py:95} INFO - [2019-09-15 21:01:46,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:46,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:46,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:46,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:46,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:01:46,924] {scheduler_job.py:146} INFO - Started process (PID=23557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:51,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:51,935] {logging_mixin.py:95} INFO - [2019-09-15 21:01:51,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:52,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:52,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:52,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:52,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:01:52,389] {scheduler_job.py:146} INFO - Started process (PID=23560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:57,397] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:01:57,408] {logging_mixin.py:95} INFO - [2019-09-15 21:01:57,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:57,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:01:57,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:01:57,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:01:57,788] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:01:57,848] {scheduler_job.py:146} INFO - Started process (PID=23561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:02,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:02,859] {logging_mixin.py:95} INFO - [2019-09-15 21:02:02,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:03,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:03,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:03,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:03,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:02:03,313] {scheduler_job.py:146} INFO - Started process (PID=23563) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:08,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:08,321] {logging_mixin.py:95} INFO - [2019-09-15 21:02:08,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:08,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:08,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:08,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:08,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 21:02:08,775] {scheduler_job.py:146} INFO - Started process (PID=23564) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:13,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:13,781] {logging_mixin.py:95} INFO - [2019-09-15 21:02:13,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:14,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:14,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:14,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:14,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:02:14,234] {scheduler_job.py:146} INFO - Started process (PID=23565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:19,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:19,244] {logging_mixin.py:95} INFO - [2019-09-15 21:02:19,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:19,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:19,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:19,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:19,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:02:19,693] {scheduler_job.py:146} INFO - Started process (PID=23567) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:24,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:24,704] {logging_mixin.py:95} INFO - [2019-09-15 21:02:24,704] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:25,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:25,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:25,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:25,078] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:02:25,158] {scheduler_job.py:146} INFO - Started process (PID=23568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:30,164] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:30,165] {logging_mixin.py:95} INFO - [2019-09-15 21:02:30,165] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:30,520] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:30,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:30,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:30,558] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:02:30,612] {scheduler_job.py:146} INFO - Started process (PID=23569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:35,618] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:35,620] {logging_mixin.py:95} INFO - [2019-09-15 21:02:35,619] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:35,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:35,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:36,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:36,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:02:36,068] {scheduler_job.py:146} INFO - Started process (PID=23571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:41,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:41,075] {logging_mixin.py:95} INFO - [2019-09-15 21:02:41,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:41,443] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:41,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:41,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:41,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:02:41,521] {scheduler_job.py:146} INFO - Started process (PID=23572) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:46,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:46,528] {logging_mixin.py:95} INFO - [2019-09-15 21:02:46,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:46,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:46,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:46,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:46,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:02:46,982] {scheduler_job.py:146} INFO - Started process (PID=23573) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:51,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:51,988] {logging_mixin.py:95} INFO - [2019-09-15 21:02:51,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:52,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:52,359] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:52,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:52,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:02:52,444] {scheduler_job.py:146} INFO - Started process (PID=23576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:57,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:02:57,451] {logging_mixin.py:95} INFO - [2019-09-15 21:02:57,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:57,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:02:57,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:02:57,860] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:02:57,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 21:02:57,901] {scheduler_job.py:146} INFO - Started process (PID=23577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:02,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:02,907] {logging_mixin.py:95} INFO - [2019-09-15 21:03:02,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:03,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:03,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:03,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:03,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:03:03,354] {scheduler_job.py:146} INFO - Started process (PID=23579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:08,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:08,363] {logging_mixin.py:95} INFO - [2019-09-15 21:03:08,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:08,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:08,730] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:08,739] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:08,745] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:03:08,812] {scheduler_job.py:146} INFO - Started process (PID=23580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:13,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:13,822] {logging_mixin.py:95} INFO - [2019-09-15 21:03:13,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:14,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:14,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:14,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:14,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:03:14,265] {scheduler_job.py:146} INFO - Started process (PID=23581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:19,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:19,277] {logging_mixin.py:95} INFO - [2019-09-15 21:03:19,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:19,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:19,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:19,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:19,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:03:19,722] {scheduler_job.py:146} INFO - Started process (PID=23583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:24,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:24,731] {logging_mixin.py:95} INFO - [2019-09-15 21:03:24,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:25,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:25,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:25,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:25,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 21:03:25,182] {scheduler_job.py:146} INFO - Started process (PID=23584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:30,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:30,193] {logging_mixin.py:95} INFO - [2019-09-15 21:03:30,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:30,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:30,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:30,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:30,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:03:30,644] {scheduler_job.py:146} INFO - Started process (PID=23585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:35,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:35,653] {logging_mixin.py:95} INFO - [2019-09-15 21:03:35,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:35,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:36,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:36,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:36,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 21:03:36,096] {scheduler_job.py:146} INFO - Started process (PID=23587) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:41,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:41,114] {logging_mixin.py:95} INFO - [2019-09-15 21:03:41,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:41,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:41,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:41,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:41,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 21:03:41,549] {scheduler_job.py:146} INFO - Started process (PID=23588) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:46,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:46,561] {logging_mixin.py:95} INFO - [2019-09-15 21:03:46,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:46,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:46,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:46,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:46,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:03:47,001] {scheduler_job.py:146} INFO - Started process (PID=23589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:52,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:52,009] {logging_mixin.py:95} INFO - [2019-09-15 21:03:52,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:52,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:52,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:52,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:52,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:03:52,459] {scheduler_job.py:146} INFO - Started process (PID=23592) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:57,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:03:57,471] {logging_mixin.py:95} INFO - [2019-09-15 21:03:57,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:57,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:03:57,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:03:57,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:03:57,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:03:57,921] {scheduler_job.py:146} INFO - Started process (PID=23593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:02,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:02,930] {logging_mixin.py:95} INFO - [2019-09-15 21:04:02,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:03,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:03,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:03,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:03,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:04:03,381] {scheduler_job.py:146} INFO - Started process (PID=23595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:08,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:08,392] {logging_mixin.py:95} INFO - [2019-09-15 21:04:08,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:08,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:08,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:08,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:08,773] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:04:08,835] {scheduler_job.py:146} INFO - Started process (PID=23596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:13,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:13,842] {logging_mixin.py:95} INFO - [2019-09-15 21:04:13,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:14,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:14,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:14,221] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:14,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:04:14,294] {scheduler_job.py:146} INFO - Started process (PID=23597) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:19,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:19,306] {logging_mixin.py:95} INFO - [2019-09-15 21:04:19,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:19,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:19,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:19,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:19,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:04:19,752] {scheduler_job.py:146} INFO - Started process (PID=23599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:24,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:24,760] {logging_mixin.py:95} INFO - [2019-09-15 21:04:24,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:25,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:25,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:25,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:25,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:04:25,212] {scheduler_job.py:146} INFO - Started process (PID=23600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:30,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:30,224] {logging_mixin.py:95} INFO - [2019-09-15 21:04:30,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:30,570] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:30,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:30,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:30,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:04:30,680] {scheduler_job.py:146} INFO - Started process (PID=23601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:35,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:35,691] {logging_mixin.py:95} INFO - [2019-09-15 21:04:35,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:36,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:36,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:36,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:36,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:04:36,141] {scheduler_job.py:146} INFO - Started process (PID=23603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:41,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:41,153] {logging_mixin.py:95} INFO - [2019-09-15 21:04:41,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:41,501] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:41,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:41,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:41,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:04:41,598] {scheduler_job.py:146} INFO - Started process (PID=23604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:46,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:46,606] {logging_mixin.py:95} INFO - [2019-09-15 21:04:46,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:46,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:46,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:46,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:46,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:04:47,065] {scheduler_job.py:146} INFO - Started process (PID=23605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:52,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:52,076] {logging_mixin.py:95} INFO - [2019-09-15 21:04:52,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:52,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:52,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:52,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:52,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:04:52,524] {scheduler_job.py:146} INFO - Started process (PID=23608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:57,530] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:04:57,531] {logging_mixin.py:95} INFO - [2019-09-15 21:04:57,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:57,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:04:57,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:04:57,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:04:57,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:04:57,988] {scheduler_job.py:146} INFO - Started process (PID=23609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:02,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:02,995] {logging_mixin.py:95} INFO - [2019-09-15 21:05:02,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:03,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:03,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:03,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:03,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:05:03,452] {scheduler_job.py:146} INFO - Started process (PID=23611) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:08,461] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:08,462] {logging_mixin.py:95} INFO - [2019-09-15 21:05:08,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:08,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:08,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:08,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:08,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:05:08,912] {scheduler_job.py:146} INFO - Started process (PID=23612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:13,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:13,923] {logging_mixin.py:95} INFO - [2019-09-15 21:05:13,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:14,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:14,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:14,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:14,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 21:05:14,371] {scheduler_job.py:146} INFO - Started process (PID=23613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:19,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:19,379] {logging_mixin.py:95} INFO - [2019-09-15 21:05:19,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:19,714] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:19,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:19,747] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:19,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 21:05:19,833] {scheduler_job.py:146} INFO - Started process (PID=23615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:24,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:24,840] {logging_mixin.py:95} INFO - [2019-09-15 21:05:24,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:25,182] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:25,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:25,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:25,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:05:25,293] {scheduler_job.py:146} INFO - Started process (PID=23616) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:30,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:30,301] {logging_mixin.py:95} INFO - [2019-09-15 21:05:30,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:30,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:30,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:30,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:30,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:05:30,750] {scheduler_job.py:146} INFO - Started process (PID=23617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:35,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:35,758] {logging_mixin.py:95} INFO - [2019-09-15 21:05:35,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:36,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:36,110] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:36,119] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:36,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-15 21:05:36,208] {scheduler_job.py:146} INFO - Started process (PID=23619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:41,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:41,215] {logging_mixin.py:95} INFO - [2019-09-15 21:05:41,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:41,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:41,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:41,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:41,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:05:41,673] {scheduler_job.py:146} INFO - Started process (PID=23620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:46,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:46,683] {logging_mixin.py:95} INFO - [2019-09-15 21:05:46,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:47,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:47,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:47,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:47,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 21:05:47,134] {scheduler_job.py:146} INFO - Started process (PID=23621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:52,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:52,142] {logging_mixin.py:95} INFO - [2019-09-15 21:05:52,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:52,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:52,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:52,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:52,526] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:05:52,599] {scheduler_job.py:146} INFO - Started process (PID=23624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:57,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:05:57,610] {logging_mixin.py:95} INFO - [2019-09-15 21:05:57,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:57,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:05:57,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:05:57,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:05:57,985] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:05:58,058] {scheduler_job.py:146} INFO - Started process (PID=23625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:03,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:03,065] {logging_mixin.py:95} INFO - [2019-09-15 21:06:03,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:03,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:03,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:03,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:03,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:06:03,519] {scheduler_job.py:146} INFO - Started process (PID=23628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:08,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:08,526] {logging_mixin.py:95} INFO - [2019-09-15 21:06:08,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:08,863] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:08,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:08,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:08,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 21:06:08,981] {scheduler_job.py:146} INFO - Started process (PID=23629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:13,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:13,992] {logging_mixin.py:95} INFO - [2019-09-15 21:06:13,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:14,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:14,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:14,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:14,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 21:06:14,442] {scheduler_job.py:146} INFO - Started process (PID=23630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:19,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:19,454] {logging_mixin.py:95} INFO - [2019-09-15 21:06:19,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:19,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:19,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:19,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:19,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:06:19,902] {scheduler_job.py:146} INFO - Started process (PID=23632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:24,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:24,910] {logging_mixin.py:95} INFO - [2019-09-15 21:06:24,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:25,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:25,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:25,290] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:25,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:06:25,362] {scheduler_job.py:146} INFO - Started process (PID=23633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:30,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:30,372] {logging_mixin.py:95} INFO - [2019-09-15 21:06:30,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:30,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:30,734] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:30,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:30,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:06:30,823] {scheduler_job.py:146} INFO - Started process (PID=23634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:35,829] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:35,830] {logging_mixin.py:95} INFO - [2019-09-15 21:06:35,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:36,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:36,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:36,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:36,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 21:06:36,287] {scheduler_job.py:146} INFO - Started process (PID=23636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:41,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:41,295] {logging_mixin.py:95} INFO - [2019-09-15 21:06:41,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:41,641] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:41,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:41,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:41,679] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:06:41,735] {scheduler_job.py:146} INFO - Started process (PID=23637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:46,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:46,741] {logging_mixin.py:95} INFO - [2019-09-15 21:06:46,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:47,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:47,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:47,115] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:47,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:06:47,194] {scheduler_job.py:146} INFO - Started process (PID=23638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:52,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:52,205] {logging_mixin.py:95} INFO - [2019-09-15 21:06:52,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:52,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:52,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:52,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:52,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:06:52,658] {scheduler_job.py:146} INFO - Started process (PID=23641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:57,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:06:57,669] {logging_mixin.py:95} INFO - [2019-09-15 21:06:57,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:58,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:06:58,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:06:58,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:06:58,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:06:58,121] {scheduler_job.py:146} INFO - Started process (PID=23642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:03,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:03,128] {logging_mixin.py:95} INFO - [2019-09-15 21:07:03,128] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:03,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:03,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:03,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:03,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:07:03,581] {scheduler_job.py:146} INFO - Started process (PID=23644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:08,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:08,588] {logging_mixin.py:95} INFO - [2019-09-15 21:07:08,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:08,925] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:08,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:08,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:08,963] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 21:07:09,042] {scheduler_job.py:146} INFO - Started process (PID=23645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:14,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:14,050] {logging_mixin.py:95} INFO - [2019-09-15 21:07:14,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:14,400] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:14,422] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:14,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:14,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:07:14,507] {scheduler_job.py:146} INFO - Started process (PID=23646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:19,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:19,518] {logging_mixin.py:95} INFO - [2019-09-15 21:07:19,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:19,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:19,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:19,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:19,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:07:19,968] {scheduler_job.py:146} INFO - Started process (PID=23648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:24,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:24,978] {logging_mixin.py:95} INFO - [2019-09-15 21:07:24,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:25,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:25,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:25,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:25,366] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:07:25,422] {scheduler_job.py:146} INFO - Started process (PID=23649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:30,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:30,431] {logging_mixin.py:95} INFO - [2019-09-15 21:07:30,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:30,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:30,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:30,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:30,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:07:30,885] {scheduler_job.py:146} INFO - Started process (PID=23650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:35,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:35,895] {logging_mixin.py:95} INFO - [2019-09-15 21:07:35,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:36,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:36,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:36,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:36,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:07:36,346] {scheduler_job.py:146} INFO - Started process (PID=23652) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:41,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:41,357] {logging_mixin.py:95} INFO - [2019-09-15 21:07:41,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:41,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:41,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:41,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:41,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:07:41,811] {scheduler_job.py:146} INFO - Started process (PID=23653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:46,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:46,822] {logging_mixin.py:95} INFO - [2019-09-15 21:07:46,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:47,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:47,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:47,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:47,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:07:47,272] {scheduler_job.py:146} INFO - Started process (PID=23654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:52,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:52,280] {logging_mixin.py:95} INFO - [2019-09-15 21:07:52,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:52,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:52,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:52,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:52,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:07:52,736] {scheduler_job.py:146} INFO - Started process (PID=23657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:57,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:07:57,754] {logging_mixin.py:95} INFO - [2019-09-15 21:07:57,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:58,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:07:58,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:07:58,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:07:58,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:07:58,202] {scheduler_job.py:146} INFO - Started process (PID=23658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:03,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:03,211] {logging_mixin.py:95} INFO - [2019-09-15 21:08:03,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:03,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:03,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:03,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:03,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:08:03,665] {scheduler_job.py:146} INFO - Started process (PID=23660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:08,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:08,677] {logging_mixin.py:95} INFO - [2019-09-15 21:08:08,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:09,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:09,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:09,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:09,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:08:09,121] {scheduler_job.py:146} INFO - Started process (PID=23661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:14,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:14,128] {logging_mixin.py:95} INFO - [2019-09-15 21:08:14,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:14,475] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:14,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:14,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:14,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:08:14,583] {scheduler_job.py:146} INFO - Started process (PID=23662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:19,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:19,590] {logging_mixin.py:95} INFO - [2019-09-15 21:08:19,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:19,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:19,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:19,964] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:19,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:08:20,045] {scheduler_job.py:146} INFO - Started process (PID=23664) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:25,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:25,053] {logging_mixin.py:95} INFO - [2019-09-15 21:08:25,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:25,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:25,423] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:25,433] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:25,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:08:25,506] {scheduler_job.py:146} INFO - Started process (PID=23665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:30,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:30,517] {logging_mixin.py:95} INFO - [2019-09-15 21:08:30,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:30,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:30,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:30,885] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:30,891] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:08:30,970] {scheduler_job.py:146} INFO - Started process (PID=23666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:35,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:35,978] {logging_mixin.py:95} INFO - [2019-09-15 21:08:35,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:36,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:36,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:36,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:36,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:08:36,433] {scheduler_job.py:146} INFO - Started process (PID=23668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:41,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:41,454] {logging_mixin.py:95} INFO - [2019-09-15 21:08:41,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:41,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:41,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:41,823] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:41,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:08:41,891] {scheduler_job.py:146} INFO - Started process (PID=23669) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:46,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:46,900] {logging_mixin.py:95} INFO - [2019-09-15 21:08:46,900] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:47,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:47,275] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:47,284] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:47,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:08:47,356] {scheduler_job.py:146} INFO - Started process (PID=23670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:52,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:52,366] {logging_mixin.py:95} INFO - [2019-09-15 21:08:52,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:52,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:52,754] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:52,763] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:52,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 21:08:52,810] {scheduler_job.py:146} INFO - Started process (PID=23673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:57,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:08:57,833] {logging_mixin.py:95} INFO - [2019-09-15 21:08:57,832] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:58,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:08:58,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:08:58,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:08:58,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 21:08:58,269] {scheduler_job.py:146} INFO - Started process (PID=23674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:03,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:03,279] {logging_mixin.py:95} INFO - [2019-09-15 21:09:03,279] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:03,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:03,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:03,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:03,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:09:03,727] {scheduler_job.py:146} INFO - Started process (PID=23676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:08,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:08,738] {logging_mixin.py:95} INFO - [2019-09-15 21:09:08,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:09,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:09,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:09,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:09,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:09:09,182] {scheduler_job.py:146} INFO - Started process (PID=23677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:14,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:14,189] {logging_mixin.py:95} INFO - [2019-09-15 21:09:14,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:14,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:14,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:14,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:14,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:09:14,647] {scheduler_job.py:146} INFO - Started process (PID=23678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:19,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:19,659] {logging_mixin.py:95} INFO - [2019-09-15 21:09:19,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:19,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:20,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:20,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:20,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:09:20,111] {scheduler_job.py:146} INFO - Started process (PID=23681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:25,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:25,122] {logging_mixin.py:95} INFO - [2019-09-15 21:09:25,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:25,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:25,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:25,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:25,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:09:25,571] {scheduler_job.py:146} INFO - Started process (PID=23682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:30,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:30,580] {logging_mixin.py:95} INFO - [2019-09-15 21:09:30,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:30,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:30,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:30,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:30,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:09:31,039] {scheduler_job.py:146} INFO - Started process (PID=23683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:36,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:36,046] {logging_mixin.py:95} INFO - [2019-09-15 21:09:36,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:36,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:36,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:36,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:36,439] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:09:36,494] {scheduler_job.py:146} INFO - Started process (PID=23685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:41,500] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:41,501] {logging_mixin.py:95} INFO - [2019-09-15 21:09:41,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:41,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:41,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:41,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:41,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:09:41,951] {scheduler_job.py:146} INFO - Started process (PID=23686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:46,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:46,961] {logging_mixin.py:95} INFO - [2019-09-15 21:09:46,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:47,322] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:47,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:47,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:47,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:09:47,400] {scheduler_job.py:146} INFO - Started process (PID=23687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:52,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:52,410] {logging_mixin.py:95} INFO - [2019-09-15 21:09:52,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:52,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:52,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:52,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:52,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:09:52,856] {scheduler_job.py:146} INFO - Started process (PID=23690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:57,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:09:57,867] {logging_mixin.py:95} INFO - [2019-09-15 21:09:57,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:58,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:09:58,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:09:58,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:09:58,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 21:09:58,310] {scheduler_job.py:146} INFO - Started process (PID=23691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:03,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:03,319] {logging_mixin.py:95} INFO - [2019-09-15 21:10:03,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:03,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:03,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:03,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:03,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:10:03,770] {scheduler_job.py:146} INFO - Started process (PID=23693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:08,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:08,781] {logging_mixin.py:95} INFO - [2019-09-15 21:10:08,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:09,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:09,142] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:09,151] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:09,157] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:10:09,230] {scheduler_job.py:146} INFO - Started process (PID=23694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:14,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:14,240] {logging_mixin.py:95} INFO - [2019-09-15 21:10:14,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:14,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:14,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:14,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:14,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:10:14,684] {scheduler_job.py:146} INFO - Started process (PID=23695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:19,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:19,693] {logging_mixin.py:95} INFO - [2019-09-15 21:10:19,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:20,069] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:20,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:20,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:20,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 21:10:20,144] {scheduler_job.py:146} INFO - Started process (PID=23697) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:25,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:25,152] {logging_mixin.py:95} INFO - [2019-09-15 21:10:25,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:25,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:25,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:25,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:25,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:10:25,602] {scheduler_job.py:146} INFO - Started process (PID=23698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:30,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:30,615] {logging_mixin.py:95} INFO - [2019-09-15 21:10:30,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:30,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:30,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:30,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:30,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:10:31,054] {scheduler_job.py:146} INFO - Started process (PID=23699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:36,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:36,067] {logging_mixin.py:95} INFO - [2019-09-15 21:10:36,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:36,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:36,435] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:36,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:36,449] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:10:36,516] {scheduler_job.py:146} INFO - Started process (PID=23701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:41,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:41,528] {logging_mixin.py:95} INFO - [2019-09-15 21:10:41,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:41,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:41,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:41,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:41,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:10:41,976] {scheduler_job.py:146} INFO - Started process (PID=23702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:46,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:46,986] {logging_mixin.py:95} INFO - [2019-09-15 21:10:46,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:47,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:47,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:47,382] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:47,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 21:10:47,434] {scheduler_job.py:146} INFO - Started process (PID=23703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:52,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:52,445] {logging_mixin.py:95} INFO - [2019-09-15 21:10:52,444] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:52,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:52,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:52,819] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:52,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:10:52,896] {scheduler_job.py:146} INFO - Started process (PID=23706) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:57,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:10:57,907] {logging_mixin.py:95} INFO - [2019-09-15 21:10:57,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:58,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:10:58,280] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:10:58,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:10:58,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:10:58,361] {scheduler_job.py:146} INFO - Started process (PID=23707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:03,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:03,373] {logging_mixin.py:95} INFO - [2019-09-15 21:11:03,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:03,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:03,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:03,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:03,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:11:03,820] {scheduler_job.py:146} INFO - Started process (PID=23709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:08,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:08,831] {logging_mixin.py:95} INFO - [2019-09-15 21:11:08,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:09,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:09,193] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:09,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:09,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:11:09,283] {scheduler_job.py:146} INFO - Started process (PID=23710) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:14,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:14,294] {logging_mixin.py:95} INFO - [2019-09-15 21:11:14,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:14,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:14,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:14,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:14,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:11:14,749] {scheduler_job.py:146} INFO - Started process (PID=23711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:19,758] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:19,759] {logging_mixin.py:95} INFO - [2019-09-15 21:11:19,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:20,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:20,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:20,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:20,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:11:20,211] {scheduler_job.py:146} INFO - Started process (PID=23713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:25,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:25,223] {logging_mixin.py:95} INFO - [2019-09-15 21:11:25,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:25,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:25,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:25,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:25,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:11:25,674] {scheduler_job.py:146} INFO - Started process (PID=23714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:30,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:30,686] {logging_mixin.py:95} INFO - [2019-09-15 21:11:30,685] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:31,023] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:31,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:31,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:31,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:11:31,138] {scheduler_job.py:146} INFO - Started process (PID=23715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:36,150] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:36,151] {logging_mixin.py:95} INFO - [2019-09-15 21:11:36,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:36,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:36,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:36,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:36,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:11:36,600] {scheduler_job.py:146} INFO - Started process (PID=23717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:41,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:41,609] {logging_mixin.py:95} INFO - [2019-09-15 21:11:41,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:41,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:41,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:41,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:41,980] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-15 21:11:42,053] {scheduler_job.py:146} INFO - Started process (PID=23718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:47,061] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:47,062] {logging_mixin.py:95} INFO - [2019-09-15 21:11:47,062] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:47,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:47,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:47,446] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:47,452] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:11:47,517] {scheduler_job.py:146} INFO - Started process (PID=23719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:52,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:52,527] {logging_mixin.py:95} INFO - [2019-09-15 21:11:52,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:52,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:52,886] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:52,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:52,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 21:11:52,984] {scheduler_job.py:146} INFO - Started process (PID=23722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:57,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:11:58,003] {logging_mixin.py:95} INFO - [2019-09-15 21:11:58,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:58,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:11:58,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:11:58,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:11:58,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:11:58,445] {scheduler_job.py:146} INFO - Started process (PID=23723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:03,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:03,453] {logging_mixin.py:95} INFO - [2019-09-15 21:12:03,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:03,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:03,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:03,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:03,834] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:12:03,911] {scheduler_job.py:146} INFO - Started process (PID=23725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:08,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:08,923] {logging_mixin.py:95} INFO - [2019-09-15 21:12:08,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:09,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:09,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:09,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:09,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:12:09,373] {scheduler_job.py:146} INFO - Started process (PID=23726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:14,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:14,382] {logging_mixin.py:95} INFO - [2019-09-15 21:12:14,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:14,720] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:14,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:14,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:14,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:12:14,836] {scheduler_job.py:146} INFO - Started process (PID=23727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:19,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:19,844] {logging_mixin.py:95} INFO - [2019-09-15 21:12:19,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:20,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:20,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:20,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:20,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:12:20,296] {scheduler_job.py:146} INFO - Started process (PID=23729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:25,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:25,308] {logging_mixin.py:95} INFO - [2019-09-15 21:12:25,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:25,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:25,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:25,677] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:25,682] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:12:25,758] {scheduler_job.py:146} INFO - Started process (PID=23730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:30,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:30,771] {logging_mixin.py:95} INFO - [2019-09-15 21:12:30,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:31,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:31,136] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:31,145] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:31,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:12:31,219] {scheduler_job.py:146} INFO - Started process (PID=23731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:36,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:36,228] {logging_mixin.py:95} INFO - [2019-09-15 21:12:36,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:36,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:36,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:36,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:36,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:12:36,685] {scheduler_job.py:146} INFO - Started process (PID=23733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:41,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:41,693] {logging_mixin.py:95} INFO - [2019-09-15 21:12:41,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:42,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:42,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:42,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:42,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:12:42,147] {scheduler_job.py:146} INFO - Started process (PID=23734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:47,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:47,160] {logging_mixin.py:95} INFO - [2019-09-15 21:12:47,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:47,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:47,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:47,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:47,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:12:47,606] {scheduler_job.py:146} INFO - Started process (PID=23735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:52,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:52,615] {logging_mixin.py:95} INFO - [2019-09-15 21:12:52,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:52,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:52,970] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:52,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:52,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 21:12:53,069] {scheduler_job.py:146} INFO - Started process (PID=23738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:58,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:12:58,078] {logging_mixin.py:95} INFO - [2019-09-15 21:12:58,078] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:58,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:12:58,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:12:58,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:12:58,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:12:58,536] {scheduler_job.py:146} INFO - Started process (PID=23739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:03,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:03,549] {logging_mixin.py:95} INFO - [2019-09-15 21:13:03,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:03,892] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:03,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:03,924] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:03,929] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:13:03,996] {scheduler_job.py:146} INFO - Started process (PID=23741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:09,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:09,009] {logging_mixin.py:95} INFO - [2019-09-15 21:13:09,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:09,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:09,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:09,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:09,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:13:09,456] {scheduler_job.py:146} INFO - Started process (PID=23742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:14,468] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:14,469] {logging_mixin.py:95} INFO - [2019-09-15 21:13:14,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:14,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:14,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:14,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:14,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:13:14,918] {scheduler_job.py:146} INFO - Started process (PID=23743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:19,925] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:19,926] {logging_mixin.py:95} INFO - [2019-09-15 21:13:19,926] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:20,275] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:20,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:20,308] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:20,313] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:13:20,380] {scheduler_job.py:146} INFO - Started process (PID=23745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:25,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:25,391] {logging_mixin.py:95} INFO - [2019-09-15 21:13:25,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:25,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:25,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:25,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:25,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 21:13:25,842] {scheduler_job.py:146} INFO - Started process (PID=23746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:30,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:30,852] {logging_mixin.py:95} INFO - [2019-09-15 21:13:30,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:31,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:31,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:31,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:31,304] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 21:13:31,396] {scheduler_job.py:146} INFO - Started process (PID=23748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:36,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:36,404] {logging_mixin.py:95} INFO - [2019-09-15 21:13:36,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:36,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:36,760] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:36,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:36,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-15 21:13:36,794] {scheduler_job.py:146} INFO - Started process (PID=23750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:41,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:41,823] {logging_mixin.py:95} INFO - [2019-09-15 21:13:41,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:42,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:42,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:42,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:42,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:13:42,288] {scheduler_job.py:146} INFO - Started process (PID=23751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:47,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:47,303] {logging_mixin.py:95} INFO - [2019-09-15 21:13:47,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:47,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:47,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:47,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:47,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:13:47,783] {scheduler_job.py:146} INFO - Started process (PID=23752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:47,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:47,790] {logging_mixin.py:95} INFO - [2019-09-15 21:13:47,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:48,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:48,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-09-15 21:13:48,194] {scheduler_job.py:146} INFO - Started process (PID=23754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:48,201] {logging_mixin.py:95} INFO - [2019-09-15 21:13:48,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:48,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:48,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.384 seconds
[2019-09-15 21:13:48,600] {scheduler_job.py:146} INFO - Started process (PID=23755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:48,606] {logging_mixin.py:95} INFO - [2019-09-15 21:13:48,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:48,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:48,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:48,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.369 seconds
[2019-09-15 21:13:49,014] {scheduler_job.py:146} INFO - Started process (PID=23757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:49,021] {logging_mixin.py:95} INFO - [2019-09-15 21:13:49,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,389] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:49,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:49,403] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.389 seconds
[2019-09-15 21:13:49,422] {scheduler_job.py:146} INFO - Started process (PID=23758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:49,428] {logging_mixin.py:95} INFO - [2019-09-15 21:13:49,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:49,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:49,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 21:13:49,835] {scheduler_job.py:146} INFO - Started process (PID=23759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:49,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:49,841] {logging_mixin.py:95} INFO - [2019-09-15 21:13:49,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:50,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:50,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.381 seconds
[2019-09-15 21:13:50,248] {scheduler_job.py:146} INFO - Started process (PID=23760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:50,255] {logging_mixin.py:95} INFO - [2019-09-15 21:13:50,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:50,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:50,624] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-15 21:13:50,658] {scheduler_job.py:146} INFO - Started process (PID=23761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:50,665] {logging_mixin.py:95} INFO - [2019-09-15 21:13:50,665] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:50,995] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:51,026] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:51,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.373 seconds
[2019-09-15 21:13:51,069] {scheduler_job.py:146} INFO - Started process (PID=23762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:51,075] {logging_mixin.py:95} INFO - [2019-09-15 21:13:51,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:51,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:51,469] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.401 seconds
[2019-09-15 21:13:51,576] {scheduler_job.py:146} INFO - Started process (PID=23763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:51,582] {logging_mixin.py:95} INFO - [2019-09-15 21:13:51,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:51,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:51,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.363 seconds
[2019-09-15 21:13:51,988] {scheduler_job.py:146} INFO - Started process (PID=23764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:51,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:51,994] {logging_mixin.py:95} INFO - [2019-09-15 21:13:51,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:52,363] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:52,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-09-15 21:13:52,401] {scheduler_job.py:146} INFO - Started process (PID=23765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:52,408] {logging_mixin.py:95} INFO - [2019-09-15 21:13:52,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:13:52,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:13:52,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-15 21:13:52,813] {scheduler_job.py:146} INFO - Started process (PID=23766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:13:52,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:13:52,820] {logging_mixin.py:95} INFO - [2019-09-15 21:13:52,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:38,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:38,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:16:38,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:16:38,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 165.455 seconds
[2019-09-15 21:16:38,322] {scheduler_job.py:146} INFO - Started process (PID=23767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:38,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:16:38,328] {logging_mixin.py:95} INFO - [2019-09-15 21:16:38,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:38,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:39,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:16:39,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:16:39,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.767 seconds
[2019-09-15 21:16:39,139] {scheduler_job.py:146} INFO - Started process (PID=23772) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:44,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:16:44,152] {logging_mixin.py:95} INFO - [2019-09-15 21:16:44,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:44,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:44,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:16:44,517] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:16:44,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 21:16:44,588] {scheduler_job.py:146} INFO - Started process (PID=23774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:49,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:16:49,598] {logging_mixin.py:95} INFO - [2019-09-15 21:16:49,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:49,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:49,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:16:49,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:16:49,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:16:50,044] {scheduler_job.py:146} INFO - Started process (PID=23776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:55,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:16:55,054] {logging_mixin.py:95} INFO - [2019-09-15 21:16:55,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:55,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:16:55,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:16:55,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:16:55,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:16:55,497] {scheduler_job.py:146} INFO - Started process (PID=23779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:00,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:00,504] {logging_mixin.py:95} INFO - [2019-09-15 21:17:00,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:00,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:00,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:00,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:00,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 21:17:00,960] {scheduler_job.py:146} INFO - Started process (PID=23780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:05,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:05,970] {logging_mixin.py:95} INFO - [2019-09-15 21:17:05,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:06,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:06,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:06,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:06,350] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:17:06,418] {scheduler_job.py:146} INFO - Started process (PID=23782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:11,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:11,429] {logging_mixin.py:95} INFO - [2019-09-15 21:17:11,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:11,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:11,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:11,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:11,805] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:17:11,881] {scheduler_job.py:146} INFO - Started process (PID=23783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:16,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:16,893] {logging_mixin.py:95} INFO - [2019-09-15 21:17:16,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:17,239] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:17,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:17,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:17,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:17:17,343] {scheduler_job.py:146} INFO - Started process (PID=23784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:22,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:22,355] {logging_mixin.py:95} INFO - [2019-09-15 21:17:22,354] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:22,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:22,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:22,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:22,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:17:22,806] {scheduler_job.py:146} INFO - Started process (PID=23786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:27,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:27,819] {logging_mixin.py:95} INFO - [2019-09-15 21:17:27,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:28,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:28,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:28,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:28,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:17:28,269] {scheduler_job.py:146} INFO - Started process (PID=23787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:33,278] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:33,279] {logging_mixin.py:95} INFO - [2019-09-15 21:17:33,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:33,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:33,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:33,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:33,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:17:33,729] {scheduler_job.py:146} INFO - Started process (PID=23790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:38,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:38,738] {logging_mixin.py:95} INFO - [2019-09-15 21:17:38,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:39,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:39,107] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:39,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:39,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:17:39,189] {scheduler_job.py:146} INFO - Started process (PID=23791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:44,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:44,201] {logging_mixin.py:95} INFO - [2019-09-15 21:17:44,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:44,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:44,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:44,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:44,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:17:44,647] {scheduler_job.py:146} INFO - Started process (PID=23792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:49,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:49,659] {logging_mixin.py:95} INFO - [2019-09-15 21:17:49,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:50,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:50,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:50,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:50,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:17:50,110] {scheduler_job.py:146} INFO - Started process (PID=23794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:55,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:17:55,119] {logging_mixin.py:95} INFO - [2019-09-15 21:17:55,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:55,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:17:55,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:17:55,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:17:55,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:17:55,569] {scheduler_job.py:146} INFO - Started process (PID=23795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:00,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:00,581] {logging_mixin.py:95} INFO - [2019-09-15 21:18:00,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:00,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:00,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:00,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:00,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:18:01,032] {scheduler_job.py:146} INFO - Started process (PID=23796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:06,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:06,045] {logging_mixin.py:95} INFO - [2019-09-15 21:18:06,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:06,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:06,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:06,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:06,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:18:06,492] {scheduler_job.py:146} INFO - Started process (PID=23798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:11,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:11,502] {logging_mixin.py:95} INFO - [2019-09-15 21:18:11,502] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:11,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:11,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:11,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:11,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:18:11,944] {scheduler_job.py:146} INFO - Started process (PID=23799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:16,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:16,953] {logging_mixin.py:95} INFO - [2019-09-15 21:18:16,952] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:17,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:17,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:17,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:17,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:18:17,407] {scheduler_job.py:146} INFO - Started process (PID=23800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:22,418] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:22,419] {logging_mixin.py:95} INFO - [2019-09-15 21:18:22,419] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:22,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:22,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:22,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:22,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:18:22,870] {scheduler_job.py:146} INFO - Started process (PID=23802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:27,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:27,883] {logging_mixin.py:95} INFO - [2019-09-15 21:18:27,883] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:28,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:28,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:28,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:28,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:18:28,332] {scheduler_job.py:146} INFO - Started process (PID=23803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:33,345] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:33,346] {logging_mixin.py:95} INFO - [2019-09-15 21:18:33,345] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:33,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:33,710] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:33,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:33,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:18:33,792] {scheduler_job.py:146} INFO - Started process (PID=23806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:38,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:38,802] {logging_mixin.py:95} INFO - [2019-09-15 21:18:38,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:39,146] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:39,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:39,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:39,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:18:39,248] {scheduler_job.py:146} INFO - Started process (PID=23807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:44,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:44,257] {logging_mixin.py:95} INFO - [2019-09-15 21:18:44,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:44,598] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:44,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:44,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:44,636] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:18:44,706] {scheduler_job.py:146} INFO - Started process (PID=23808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:49,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:49,714] {logging_mixin.py:95} INFO - [2019-09-15 21:18:49,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:50,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:50,085] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:50,094] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:50,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:18:50,170] {scheduler_job.py:146} INFO - Started process (PID=23810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:55,182] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:18:55,183] {logging_mixin.py:95} INFO - [2019-09-15 21:18:55,183] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:55,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:18:55,549] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:18:55,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:18:55,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:18:55,631] {scheduler_job.py:146} INFO - Started process (PID=23811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:00,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:00,638] {logging_mixin.py:95} INFO - [2019-09-15 21:19:00,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:00,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:01,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:01,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:01,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 21:19:01,088] {scheduler_job.py:146} INFO - Started process (PID=23812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:06,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:06,098] {logging_mixin.py:95} INFO - [2019-09-15 21:19:06,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:06,457] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:06,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:06,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:06,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:19:06,546] {scheduler_job.py:146} INFO - Started process (PID=23814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:11,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:11,566] {logging_mixin.py:95} INFO - [2019-09-15 21:19:11,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:11,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:11,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:11,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:11,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:19:12,000] {scheduler_job.py:146} INFO - Started process (PID=23815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:17,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:17,013] {logging_mixin.py:95} INFO - [2019-09-15 21:19:17,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:17,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:17,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:17,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:17,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:19:17,459] {scheduler_job.py:146} INFO - Started process (PID=23816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:22,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:22,468] {logging_mixin.py:95} INFO - [2019-09-15 21:19:22,467] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:22,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:22,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:22,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:22,851] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:19:22,921] {scheduler_job.py:146} INFO - Started process (PID=23818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:27,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:27,929] {logging_mixin.py:95} INFO - [2019-09-15 21:19:27,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:28,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:28,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:28,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:28,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:19:28,381] {scheduler_job.py:146} INFO - Started process (PID=23819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:33,392] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:33,393] {logging_mixin.py:95} INFO - [2019-09-15 21:19:33,393] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:33,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:33,770] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:33,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:33,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:19:33,835] {scheduler_job.py:146} INFO - Started process (PID=23821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:38,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:38,848] {logging_mixin.py:95} INFO - [2019-09-15 21:19:38,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:39,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:39,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:39,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:39,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 21:19:39,291] {scheduler_job.py:146} INFO - Started process (PID=23823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:44,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:44,301] {logging_mixin.py:95} INFO - [2019-09-15 21:19:44,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:44,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:44,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:44,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:44,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:19:44,742] {scheduler_job.py:146} INFO - Started process (PID=23824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:49,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:49,751] {logging_mixin.py:95} INFO - [2019-09-15 21:19:49,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:50,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:50,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:50,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:50,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:19:50,200] {scheduler_job.py:146} INFO - Started process (PID=23826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:55,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:19:55,211] {logging_mixin.py:95} INFO - [2019-09-15 21:19:55,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:55,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:19:55,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:19:55,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:19:55,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:19:55,654] {scheduler_job.py:146} INFO - Started process (PID=23827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:00,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:00,664] {logging_mixin.py:95} INFO - [2019-09-15 21:20:00,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:00,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:01,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:01,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:01,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-15 21:20:01,111] {scheduler_job.py:146} INFO - Started process (PID=23828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:06,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:06,120] {logging_mixin.py:95} INFO - [2019-09-15 21:20:06,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:06,423] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:06,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:06,455] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:06,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.349 seconds
[2019-09-15 21:20:06,572] {scheduler_job.py:146} INFO - Started process (PID=23830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:11,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:11,595] {logging_mixin.py:95} INFO - [2019-09-15 21:20:11,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:11,935] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:11,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:11,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:11,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:20:12,027] {scheduler_job.py:146} INFO - Started process (PID=23831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:17,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:17,035] {logging_mixin.py:95} INFO - [2019-09-15 21:20:17,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:17,380] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:17,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:17,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:17,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:20:17,487] {scheduler_job.py:146} INFO - Started process (PID=23832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:22,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:22,496] {logging_mixin.py:95} INFO - [2019-09-15 21:20:22,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:22,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:22,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:22,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:22,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:20:22,942] {scheduler_job.py:146} INFO - Started process (PID=23834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:27,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:27,951] {logging_mixin.py:95} INFO - [2019-09-15 21:20:27,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:28,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:28,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:28,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:28,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:20:28,399] {scheduler_job.py:146} INFO - Started process (PID=23835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:33,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:33,408] {logging_mixin.py:95} INFO - [2019-09-15 21:20:33,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:33,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:33,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:33,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:33,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:20:33,857] {scheduler_job.py:146} INFO - Started process (PID=23837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:38,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:38,866] {logging_mixin.py:95} INFO - [2019-09-15 21:20:38,865] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:39,209] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:39,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:39,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:39,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:20:39,318] {scheduler_job.py:146} INFO - Started process (PID=23839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:44,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:44,327] {logging_mixin.py:95} INFO - [2019-09-15 21:20:44,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:44,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:44,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:44,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:44,702] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-15 21:20:44,778] {scheduler_job.py:146} INFO - Started process (PID=23840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:49,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:49,788] {logging_mixin.py:95} INFO - [2019-09-15 21:20:49,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:50,140] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:50,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:50,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:50,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:20:50,252] {scheduler_job.py:146} INFO - Started process (PID=23842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:55,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:20:55,263] {logging_mixin.py:95} INFO - [2019-09-15 21:20:55,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:55,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:20:55,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:20:55,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:20:55,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 21:20:55,696] {scheduler_job.py:146} INFO - Started process (PID=23843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:00,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:00,702] {logging_mixin.py:95} INFO - [2019-09-15 21:21:00,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:01,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:01,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:01,080] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:01,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:21:01,149] {scheduler_job.py:146} INFO - Started process (PID=23847) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:06,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:06,161] {logging_mixin.py:95} INFO - [2019-09-15 21:21:06,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:06,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:06,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:06,538] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:06,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:21:06,609] {scheduler_job.py:146} INFO - Started process (PID=23849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:11,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:11,630] {logging_mixin.py:95} INFO - [2019-09-15 21:21:11,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:11,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:11,990] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:11,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:12,004] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:21:12,071] {scheduler_job.py:146} INFO - Started process (PID=23850) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:17,083] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:17,084] {logging_mixin.py:95} INFO - [2019-09-15 21:21:17,084] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:17,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:17,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:17,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:17,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:21:17,533] {scheduler_job.py:146} INFO - Started process (PID=23851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:22,544] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:22,545] {logging_mixin.py:95} INFO - [2019-09-15 21:21:22,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:22,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:22,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:22,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:22,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:21:22,994] {scheduler_job.py:146} INFO - Started process (PID=23853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:28,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:28,006] {logging_mixin.py:95} INFO - [2019-09-15 21:21:28,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:28,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:28,370] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:28,379] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:28,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:21:28,460] {scheduler_job.py:146} INFO - Started process (PID=23854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:33,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:33,472] {logging_mixin.py:95} INFO - [2019-09-15 21:21:33,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:33,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:33,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:33,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:33,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:21:33,921] {scheduler_job.py:146} INFO - Started process (PID=23856) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:38,928] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:38,929] {logging_mixin.py:95} INFO - [2019-09-15 21:21:38,929] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:39,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:39,296] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:39,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:39,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:21:39,384] {scheduler_job.py:146} INFO - Started process (PID=23858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:44,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:44,392] {logging_mixin.py:95} INFO - [2019-09-15 21:21:44,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:44,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:44,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:44,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:44,772] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:21:44,845] {scheduler_job.py:146} INFO - Started process (PID=23859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:49,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:49,854] {logging_mixin.py:95} INFO - [2019-09-15 21:21:49,854] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:50,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:50,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:50,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:50,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 21:21:50,308] {scheduler_job.py:146} INFO - Started process (PID=23861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:55,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:21:55,315] {logging_mixin.py:95} INFO - [2019-09-15 21:21:55,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:55,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:21:55,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:21:55,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:21:55,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:21:55,772] {scheduler_job.py:146} INFO - Started process (PID=23862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:00,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:00,782] {logging_mixin.py:95} INFO - [2019-09-15 21:22:00,782] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:01,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:01,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:01,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:01,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 21:22:01,228] {scheduler_job.py:146} INFO - Started process (PID=23863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:06,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:06,237] {logging_mixin.py:95} INFO - [2019-09-15 21:22:06,237] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:06,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:06,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:06,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:06,619] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:22:06,692] {scheduler_job.py:146} INFO - Started process (PID=23865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:11,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:11,710] {logging_mixin.py:95} INFO - [2019-09-15 21:22:11,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:12,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:12,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:12,079] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:12,085] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 21:22:12,153] {scheduler_job.py:146} INFO - Started process (PID=23866) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:17,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:17,161] {logging_mixin.py:95} INFO - [2019-09-15 21:22:17,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:17,507] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:17,530] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:17,539] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:17,544] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:22:17,611] {scheduler_job.py:146} INFO - Started process (PID=23867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:22,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:22,622] {logging_mixin.py:95} INFO - [2019-09-15 21:22:22,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:22,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:22,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:23,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:23,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:22:23,071] {scheduler_job.py:146} INFO - Started process (PID=23869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:28,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:28,082] {logging_mixin.py:95} INFO - [2019-09-15 21:22:28,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:28,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:28,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:28,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:28,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:22:28,530] {scheduler_job.py:146} INFO - Started process (PID=23870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:33,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:33,538] {logging_mixin.py:95} INFO - [2019-09-15 21:22:33,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:33,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:33,906] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:33,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:33,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:22:33,989] {scheduler_job.py:146} INFO - Started process (PID=23872) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:38,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:38,998] {logging_mixin.py:95} INFO - [2019-09-15 21:22:38,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:39,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:39,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:39,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:39,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:22:39,449] {scheduler_job.py:146} INFO - Started process (PID=23874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:44,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:44,458] {logging_mixin.py:95} INFO - [2019-09-15 21:22:44,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:44,797] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:44,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:44,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:44,835] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 21:22:44,902] {scheduler_job.py:146} INFO - Started process (PID=23875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:49,909] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:49,910] {logging_mixin.py:95} INFO - [2019-09-15 21:22:49,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:50,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:50,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:50,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:50,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 21:22:50,365] {scheduler_job.py:146} INFO - Started process (PID=23877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:55,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:22:55,371] {logging_mixin.py:95} INFO - [2019-09-15 21:22:55,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:55,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:22:55,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:22:55,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:22:55,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:22:55,829] {scheduler_job.py:146} INFO - Started process (PID=23878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:00,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:00,836] {logging_mixin.py:95} INFO - [2019-09-15 21:23:00,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:01,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:01,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:01,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:01,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:23:01,284] {scheduler_job.py:146} INFO - Started process (PID=23879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:06,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:06,292] {logging_mixin.py:95} INFO - [2019-09-15 21:23:06,292] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:06,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:06,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:06,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:06,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 21:23:06,844] {scheduler_job.py:146} INFO - Started process (PID=23881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:11,852] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:11,853] {logging_mixin.py:95} INFO - [2019-09-15 21:23:11,853] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:12,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:12,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:12,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:12,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 21:23:12,399] {scheduler_job.py:146} INFO - Started process (PID=23882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:17,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:17,404] {logging_mixin.py:95} INFO - [2019-09-15 21:23:17,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:17,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:17,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:17,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:17,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 21:23:17,846] {scheduler_job.py:146} INFO - Started process (PID=23884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:22,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:22,856] {logging_mixin.py:95} INFO - [2019-09-15 21:23:22,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:23,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:23,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:23,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:23,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 21:23:23,298] {scheduler_job.py:146} INFO - Started process (PID=23885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:28,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:28,304] {logging_mixin.py:95} INFO - [2019-09-15 21:23:28,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:28,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:28,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:28,755] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:28,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-15 21:23:28,855] {scheduler_job.py:146} INFO - Started process (PID=23886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:33,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:33,865] {logging_mixin.py:95} INFO - [2019-09-15 21:23:33,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:34,275] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:34,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:34,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:34,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 21:23:34,400] {scheduler_job.py:146} INFO - Started process (PID=23889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:39,405] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:39,406] {logging_mixin.py:95} INFO - [2019-09-15 21:23:39,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:39,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:39,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:39,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:39,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-15 21:23:39,971] {scheduler_job.py:146} INFO - Started process (PID=23893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:44,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:44,983] {logging_mixin.py:95} INFO - [2019-09-15 21:23:44,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:45,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:45,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:45,440] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:45,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-09-15 21:23:45,497] {scheduler_job.py:146} INFO - Started process (PID=23895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:50,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:50,504] {logging_mixin.py:95} INFO - [2019-09-15 21:23:50,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:50,891] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:50,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:50,925] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:50,931] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:23:51,038] {scheduler_job.py:146} INFO - Started process (PID=23897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:56,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:23:56,048] {logging_mixin.py:95} INFO - [2019-09-15 21:23:56,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:56,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:23:56,516] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:23:56,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:23:56,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-15 21:23:56,585] {scheduler_job.py:146} INFO - Started process (PID=23898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:01,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:01,596] {logging_mixin.py:95} INFO - [2019-09-15 21:24:01,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:02,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:02,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:02,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:02,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-15 21:24:02,216] {scheduler_job.py:146} INFO - Started process (PID=23899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:07,224] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:07,225] {logging_mixin.py:95} INFO - [2019-09-15 21:24:07,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:07,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:07,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:07,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:07,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.587 seconds
[2019-09-15 21:24:07,858] {scheduler_job.py:146} INFO - Started process (PID=23901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:12,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:12,869] {logging_mixin.py:95} INFO - [2019-09-15 21:24:12,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:13,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:13,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:13,336] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:13,343] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-15 21:24:13,384] {scheduler_job.py:146} INFO - Started process (PID=23902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:18,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:18,395] {logging_mixin.py:95} INFO - [2019-09-15 21:24:18,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:18,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:18,917] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:18,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:18,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.554 seconds
[2019-09-15 21:24:19,022] {scheduler_job.py:146} INFO - Started process (PID=23904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:24,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:24,032] {logging_mixin.py:95} INFO - [2019-09-15 21:24:24,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:24,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:24,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:24,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:24,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:24:24,557] {scheduler_job.py:146} INFO - Started process (PID=23905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:29,563] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:29,564] {logging_mixin.py:95} INFO - [2019-09-15 21:24:29,564] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:29,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:30,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:30,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:30,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:24:30,092] {scheduler_job.py:146} INFO - Started process (PID=23906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:35,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:35,100] {logging_mixin.py:95} INFO - [2019-09-15 21:24:35,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:35,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:35,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:35,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:35,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:24:35,624] {scheduler_job.py:146} INFO - Started process (PID=23909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:40,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:40,633] {logging_mixin.py:95} INFO - [2019-09-15 21:24:40,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:41,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:41,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:41,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:41,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.545 seconds
[2019-09-15 21:24:41,256] {scheduler_job.py:146} INFO - Started process (PID=23910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:46,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:46,266] {logging_mixin.py:95} INFO - [2019-09-15 21:24:46,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:46,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:46,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:46,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:46,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:24:46,788] {scheduler_job.py:146} INFO - Started process (PID=23911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:51,796] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:51,798] {logging_mixin.py:95} INFO - [2019-09-15 21:24:51,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:52,229] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:52,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:52,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:52,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:24:52,320] {scheduler_job.py:146} INFO - Started process (PID=23913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:57,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:24:57,326] {logging_mixin.py:95} INFO - [2019-09-15 21:24:57,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:57,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:24:57,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:24:57,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:24:57,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-15 21:24:57,850] {scheduler_job.py:146} INFO - Started process (PID=23914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:02,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:02,857] {logging_mixin.py:95} INFO - [2019-09-15 21:25:02,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:03,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:03,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:03,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:03,330] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-15 21:25:03,383] {scheduler_job.py:146} INFO - Started process (PID=23916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:08,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:08,389] {logging_mixin.py:95} INFO - [2019-09-15 21:25:08,388] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:08,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:08,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:08,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:08,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 21:25:08,917] {scheduler_job.py:146} INFO - Started process (PID=23917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:13,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:13,924] {logging_mixin.py:95} INFO - [2019-09-15 21:25:13,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:14,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:14,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:14,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:14,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 21:25:14,455] {scheduler_job.py:146} INFO - Started process (PID=23918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:19,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:19,460] {logging_mixin.py:95} INFO - [2019-09-15 21:25:19,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:19,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:20,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:20,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:20,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.596 seconds
[2019-09-15 21:25:20,089] {scheduler_job.py:146} INFO - Started process (PID=23920) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:25,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:25,100] {logging_mixin.py:95} INFO - [2019-09-15 21:25:25,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:25,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:25,610] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:25,625] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:25,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.546 seconds
[2019-09-15 21:25:25,732] {scheduler_job.py:146} INFO - Started process (PID=23921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:30,740] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:30,741] {logging_mixin.py:95} INFO - [2019-09-15 21:25:30,741] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:31,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:31,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:31,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:31,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.546 seconds
[2019-09-15 21:25:31,369] {scheduler_job.py:146} INFO - Started process (PID=23922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:36,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:36,380] {logging_mixin.py:95} INFO - [2019-09-15 21:25:36,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:36,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:36,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:36,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:36,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.499 seconds
[2019-09-15 21:25:36,905] {scheduler_job.py:146} INFO - Started process (PID=23925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:41,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:41,911] {logging_mixin.py:95} INFO - [2019-09-15 21:25:41,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:42,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:42,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:42,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:42,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.529 seconds
[2019-09-15 21:25:42,543] {scheduler_job.py:146} INFO - Started process (PID=23926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:47,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:47,550] {logging_mixin.py:95} INFO - [2019-09-15 21:25:47,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:47,993] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:48,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:48,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:48,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-15 21:25:48,082] {scheduler_job.py:146} INFO - Started process (PID=23928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:53,092] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:53,093] {logging_mixin.py:95} INFO - [2019-09-15 21:25:53,093] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:53,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:53,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:53,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:53,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.494 seconds
[2019-09-15 21:25:53,621] {scheduler_job.py:146} INFO - Started process (PID=23929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:58,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:25:58,631] {logging_mixin.py:95} INFO - [2019-09-15 21:25:58,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:59,118] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:25:59,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:25:59,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:25:59,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.539 seconds
[2019-09-15 21:25:59,253] {scheduler_job.py:146} INFO - Started process (PID=23930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:04,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:04,266] {logging_mixin.py:95} INFO - [2019-09-15 21:26:04,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:04,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:04,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:04,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:04,775] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.522 seconds
[2019-09-15 21:26:04,888] {scheduler_job.py:146} INFO - Started process (PID=23932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:09,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:09,898] {logging_mixin.py:95} INFO - [2019-09-15 21:26:09,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:10,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:10,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:10,389] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:10,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-15 21:26:10,435] {scheduler_job.py:146} INFO - Started process (PID=23933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:15,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:15,444] {logging_mixin.py:95} INFO - [2019-09-15 21:26:15,443] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:15,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:15,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:15,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:15,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.529 seconds
[2019-09-15 21:26:16,069] {scheduler_job.py:146} INFO - Started process (PID=23934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:21,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:21,077] {logging_mixin.py:95} INFO - [2019-09-15 21:26:21,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:21,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:21,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:21,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:21,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.490 seconds
[2019-09-15 21:26:21,602] {scheduler_job.py:146} INFO - Started process (PID=23936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:26,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:26,613] {logging_mixin.py:95} INFO - [2019-09-15 21:26:26,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:27,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:27,073] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:27,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:27,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-09-15 21:26:27,132] {scheduler_job.py:146} INFO - Started process (PID=23937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:32,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:32,141] {logging_mixin.py:95} INFO - [2019-09-15 21:26:32,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:32,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:32,599] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:32,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:32,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-15 21:26:32,672] {scheduler_job.py:146} INFO - Started process (PID=23938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:37,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:37,679] {logging_mixin.py:95} INFO - [2019-09-15 21:26:37,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:38,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:38,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:38,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:38,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-09-15 21:26:38,200] {scheduler_job.py:146} INFO - Started process (PID=23941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:43,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:43,210] {logging_mixin.py:95} INFO - [2019-09-15 21:26:43,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:43,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:43,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:43,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:43,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:26:43,744] {scheduler_job.py:146} INFO - Started process (PID=23942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:48,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:48,753] {logging_mixin.py:95} INFO - [2019-09-15 21:26:48,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:49,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:49,164] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:49,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:49,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 21:26:49,292] {scheduler_job.py:146} INFO - Started process (PID=23944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:54,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:54,302] {logging_mixin.py:95} INFO - [2019-09-15 21:26:54,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:54,685] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:54,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:26:54,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:26:54,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:26:54,831] {scheduler_job.py:146} INFO - Started process (PID=23945) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:26:59,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:26:59,839] {logging_mixin.py:95} INFO - [2019-09-15 21:26:59,838] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:00,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:00,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:00,257] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:00,263] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 21:27:00,374] {scheduler_job.py:146} INFO - Started process (PID=23946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:05,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:05,380] {logging_mixin.py:95} INFO - [2019-09-15 21:27:05,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:05,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:05,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:05,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:05,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:27:05,828] {scheduler_job.py:146} INFO - Started process (PID=23948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:10,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:10,849] {logging_mixin.py:95} INFO - [2019-09-15 21:27:10,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:11,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:11,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:11,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:11,299] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 21:27:11,376] {scheduler_job.py:146} INFO - Started process (PID=23949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:16,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:16,385] {logging_mixin.py:95} INFO - [2019-09-15 21:27:16,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:16,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:16,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:16,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:16,836] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-15 21:27:16,914] {scheduler_job.py:146} INFO - Started process (PID=23950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:21,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:21,921] {logging_mixin.py:95} INFO - [2019-09-15 21:27:21,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:22,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:22,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:22,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:22,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:27:22,454] {scheduler_job.py:146} INFO - Started process (PID=23952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:27,462] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:27,463] {logging_mixin.py:95} INFO - [2019-09-15 21:27:27,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:27,993] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:28,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:28,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:28,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.597 seconds
[2019-09-15 21:27:28,102] {scheduler_job.py:146} INFO - Started process (PID=23953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:33,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:33,114] {logging_mixin.py:95} INFO - [2019-09-15 21:27:33,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:33,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:33,603] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:33,619] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:33,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.526 seconds
[2019-09-15 21:27:33,740] {scheduler_job.py:146} INFO - Started process (PID=23955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:38,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:38,749] {logging_mixin.py:95} INFO - [2019-09-15 21:27:38,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:39,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:39,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:39,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:39,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.720 seconds
[2019-09-15 21:27:39,574] {scheduler_job.py:146} INFO - Started process (PID=23957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:44,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:44,581] {logging_mixin.py:95} INFO - [2019-09-15 21:27:44,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:45,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:45,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:45,051] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:45,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:27:45,112] {scheduler_job.py:146} INFO - Started process (PID=23958) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:50,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:50,119] {logging_mixin.py:95} INFO - [2019-09-15 21:27:50,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:50,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:50,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:50,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:50,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-09-15 21:27:50,648] {scheduler_job.py:146} INFO - Started process (PID=23960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:55,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:27:55,657] {logging_mixin.py:95} INFO - [2019-09-15 21:27:55,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:56,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:27:56,122] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:27:56,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:27:56,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.497 seconds
[2019-09-15 21:27:56,184] {scheduler_job.py:146} INFO - Started process (PID=23961) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:01,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:01,190] {logging_mixin.py:95} INFO - [2019-09-15 21:28:01,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:01,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:01,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:01,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:01,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:28:01,625] {scheduler_job.py:146} INFO - Started process (PID=23962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:06,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:06,634] {logging_mixin.py:95} INFO - [2019-09-15 21:28:06,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:07,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:07,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:07,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:07,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 21:28:07,172] {scheduler_job.py:146} INFO - Started process (PID=23964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:12,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:12,180] {logging_mixin.py:95} INFO - [2019-09-15 21:28:12,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:12,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:12,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:12,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:12,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 21:28:12,626] {scheduler_job.py:146} INFO - Started process (PID=23965) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:17,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:17,633] {logging_mixin.py:95} INFO - [2019-09-15 21:28:17,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:18,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:18,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:18,047] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:18,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:28:18,078] {scheduler_job.py:146} INFO - Started process (PID=23967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:23,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:23,087] {logging_mixin.py:95} INFO - [2019-09-15 21:28:23,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:23,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:23,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:23,506] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:23,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:28:23,615] {scheduler_job.py:146} INFO - Started process (PID=23968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:28,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:28,624] {logging_mixin.py:95} INFO - [2019-09-15 21:28:28,623] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:29,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:29,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:29,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:29,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:28:29,157] {scheduler_job.py:146} INFO - Started process (PID=23969) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:34,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:34,169] {logging_mixin.py:95} INFO - [2019-09-15 21:28:34,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:34,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:34,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:34,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:34,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 21:28:34,695] {scheduler_job.py:146} INFO - Started process (PID=23972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:39,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:39,702] {logging_mixin.py:95} INFO - [2019-09-15 21:28:39,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:40,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:40,114] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:40,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:40,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:28:40,240] {scheduler_job.py:146} INFO - Started process (PID=23973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:45,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:45,268] {logging_mixin.py:95} INFO - [2019-09-15 21:28:45,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:45,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:45,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:45,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:45,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.555 seconds
[2019-09-15 21:28:45,887] {scheduler_job.py:146} INFO - Started process (PID=23974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:50,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:50,898] {logging_mixin.py:95} INFO - [2019-09-15 21:28:50,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:51,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:51,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:51,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:51,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.724 seconds
[2019-09-15 21:28:51,717] {scheduler_job.py:146} INFO - Started process (PID=23976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:56,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:28:56,723] {logging_mixin.py:95} INFO - [2019-09-15 21:28:56,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:57,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:28:57,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:28:57,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:28:57,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.537 seconds
[2019-09-15 21:28:57,346] {scheduler_job.py:146} INFO - Started process (PID=23977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:02,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:02,356] {logging_mixin.py:95} INFO - [2019-09-15 21:29:02,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:02,834] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:02,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:02,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:02,875] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.529 seconds
[2019-09-15 21:29:02,978] {scheduler_job.py:146} INFO - Started process (PID=23978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:07,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:07,986] {logging_mixin.py:95} INFO - [2019-09-15 21:29:07,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:08,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:08,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:08,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:08,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.511 seconds
[2019-09-15 21:29:08,515] {scheduler_job.py:146} INFO - Started process (PID=23980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:13,525] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:13,527] {logging_mixin.py:95} INFO - [2019-09-15 21:29:13,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:13,926] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:13,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:13,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:13,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-15 21:29:14,049] {scheduler_job.py:146} INFO - Started process (PID=23981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:19,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:19,058] {logging_mixin.py:95} INFO - [2019-09-15 21:29:19,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:19,496] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:19,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:19,535] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:19,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 21:29:19,585] {scheduler_job.py:146} INFO - Started process (PID=23983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:24,594] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:24,596] {logging_mixin.py:95} INFO - [2019-09-15 21:29:24,595] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:25,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:25,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:25,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:25,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:29:25,120] {scheduler_job.py:146} INFO - Started process (PID=23984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:30,128] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:30,129] {logging_mixin.py:95} INFO - [2019-09-15 21:29:30,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:30,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:30,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:30,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:30,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-15 21:29:30,657] {scheduler_job.py:146} INFO - Started process (PID=23985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:35,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:35,667] {logging_mixin.py:95} INFO - [2019-09-15 21:29:35,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:36,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:36,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:36,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:36,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 21:29:36,195] {scheduler_job.py:146} INFO - Started process (PID=23988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:41,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:41,211] {logging_mixin.py:95} INFO - [2019-09-15 21:29:41,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:41,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:41,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:41,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:41,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 21:29:41,735] {scheduler_job.py:146} INFO - Started process (PID=23989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:46,743] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:46,745] {logging_mixin.py:95} INFO - [2019-09-15 21:29:46,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:47,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:47,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:47,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:47,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 21:29:47,267] {scheduler_job.py:146} INFO - Started process (PID=23990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:52,273] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:52,274] {logging_mixin.py:95} INFO - [2019-09-15 21:29:52,274] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:52,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:52,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:52,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:52,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 21:29:52,807] {scheduler_job.py:146} INFO - Started process (PID=23992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:57,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:29:57,816] {logging_mixin.py:95} INFO - [2019-09-15 21:29:57,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:58,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:29:58,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:29:58,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:29:58,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-09-15 21:29:58,348] {scheduler_job.py:146} INFO - Started process (PID=23993) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:03,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:03,355] {logging_mixin.py:95} INFO - [2019-09-15 21:30:03,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:03,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:03,821] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:03,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:03,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 21:30:03,888] {scheduler_job.py:146} INFO - Started process (PID=23996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:08,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:08,897] {logging_mixin.py:95} INFO - [2019-09-15 21:30:08,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:09,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:09,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:09,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:09,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:30:09,426] {scheduler_job.py:146} INFO - Started process (PID=23997) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:14,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:14,437] {logging_mixin.py:95} INFO - [2019-09-15 21:30:14,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:14,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:14,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:14,972] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:14,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.557 seconds
[2019-09-15 21:30:15,073] {scheduler_job.py:146} INFO - Started process (PID=23998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:20,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:20,081] {logging_mixin.py:95} INFO - [2019-09-15 21:30:20,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:20,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:20,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:20,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:20,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.494 seconds
[2019-09-15 21:30:20,607] {scheduler_job.py:146} INFO - Started process (PID=24000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:25,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:25,615] {logging_mixin.py:95} INFO - [2019-09-15 21:30:25,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:26,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:26,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:26,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:26,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:30:26,148] {scheduler_job.py:146} INFO - Started process (PID=24001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:31,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:31,156] {logging_mixin.py:95} INFO - [2019-09-15 21:30:31,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:31,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:31,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:31,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:31,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 21:30:31,600] {scheduler_job.py:146} INFO - Started process (PID=24002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:36,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:36,611] {logging_mixin.py:95} INFO - [2019-09-15 21:30:36,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:36,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:37,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:37,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:37,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:30:37,143] {scheduler_job.py:146} INFO - Started process (PID=24005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:42,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:42,149] {logging_mixin.py:95} INFO - [2019-09-15 21:30:42,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:42,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:42,571] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:42,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:42,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:30:42,685] {scheduler_job.py:146} INFO - Started process (PID=24006) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:47,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:47,694] {logging_mixin.py:95} INFO - [2019-09-15 21:30:47,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:48,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:48,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:48,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:48,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.546 seconds
[2019-09-15 21:30:48,339] {scheduler_job.py:146} INFO - Started process (PID=24008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:53,347] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:53,348] {logging_mixin.py:95} INFO - [2019-09-15 21:30:53,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:53,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:53,844] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:53,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:53,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.531 seconds
[2019-09-15 21:30:53,968] {scheduler_job.py:146} INFO - Started process (PID=24009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:58,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:30:58,974] {logging_mixin.py:95} INFO - [2019-09-15 21:30:58,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:59,361] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:30:59,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:30:59,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:30:59,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:30:59,509] {scheduler_job.py:146} INFO - Started process (PID=24013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:04,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:04,519] {logging_mixin.py:95} INFO - [2019-09-15 21:31:04,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:04,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:04,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:04,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:04,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-09-15 21:31:05,048] {scheduler_job.py:146} INFO - Started process (PID=24015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:10,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:10,057] {logging_mixin.py:95} INFO - [2019-09-15 21:31:10,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:10,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:10,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:10,512] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:10,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 21:31:10,607] {scheduler_job.py:146} INFO - Started process (PID=24016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:15,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:15,614] {logging_mixin.py:95} INFO - [2019-09-15 21:31:15,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:16,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:16,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:16,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:16,070] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 21:31:16,152] {scheduler_job.py:146} INFO - Started process (PID=24017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:21,159] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:21,160] {logging_mixin.py:95} INFO - [2019-09-15 21:31:21,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:21,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:21,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:21,567] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:21,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 21:31:21,688] {scheduler_job.py:146} INFO - Started process (PID=24019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:26,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:26,695] {logging_mixin.py:95} INFO - [2019-09-15 21:31:26,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:27,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:27,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:27,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:27,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:31:27,140] {scheduler_job.py:146} INFO - Started process (PID=24020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:32,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:32,147] {logging_mixin.py:95} INFO - [2019-09-15 21:31:32,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:32,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:32,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:32,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:32,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.505 seconds
[2019-09-15 21:31:32,687] {scheduler_job.py:146} INFO - Started process (PID=24021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:37,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:37,694] {logging_mixin.py:95} INFO - [2019-09-15 21:31:37,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:38,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:38,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:38,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:38,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.633 seconds
[2019-09-15 21:31:38,431] {scheduler_job.py:146} INFO - Started process (PID=24028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:43,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:43,439] {logging_mixin.py:95} INFO - [2019-09-15 21:31:43,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:43,874] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:43,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:43,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:43,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 21:31:43,972] {scheduler_job.py:146} INFO - Started process (PID=24033) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:48,977] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:48,979] {logging_mixin.py:95} INFO - [2019-09-15 21:31:48,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:50,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:50,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:50,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:50,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.122 seconds
[2019-09-15 21:31:50,128] {scheduler_job.py:146} INFO - Started process (PID=24037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:55,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:31:55,138] {logging_mixin.py:95} INFO - [2019-09-15 21:31:55,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:55,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:31:55,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:31:55,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:31:55,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.545 seconds
[2019-09-15 21:31:55,763] {scheduler_job.py:146} INFO - Started process (PID=24039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:00,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:00,772] {logging_mixin.py:95} INFO - [2019-09-15 21:32:00,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:01,307] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:01,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:01,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:01,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.600 seconds
[2019-09-15 21:32:01,399] {scheduler_job.py:146} INFO - Started process (PID=24040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:06,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:06,409] {logging_mixin.py:95} INFO - [2019-09-15 21:32:06,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:06,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:06,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:06,964] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:06,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.573 seconds
[2019-09-15 21:32:07,042] {scheduler_job.py:146} INFO - Started process (PID=24042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:12,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:12,050] {logging_mixin.py:95} INFO - [2019-09-15 21:32:12,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:12,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:12,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:12,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:12,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-09-15 21:32:12,554] {scheduler_job.py:146} INFO - Started process (PID=24049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:17,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:17,560] {logging_mixin.py:95} INFO - [2019-09-15 21:32:17,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:17,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:17,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:18,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:18,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 21:32:18,089] {scheduler_job.py:146} INFO - Started process (PID=24050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:23,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:23,097] {logging_mixin.py:95} INFO - [2019-09-15 21:32:23,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:23,509] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:23,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:23,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:23,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 21:32:23,613] {scheduler_job.py:146} INFO - Started process (PID=24052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:28,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:28,622] {logging_mixin.py:95} INFO - [2019-09-15 21:32:28,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:29,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:29,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:29,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:29,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-09-15 21:32:29,151] {scheduler_job.py:146} INFO - Started process (PID=24053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:34,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:34,159] {logging_mixin.py:95} INFO - [2019-09-15 21:32:34,158] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:34,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:34,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:34,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:34,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.759 seconds
[2019-09-15 21:32:34,986] {scheduler_job.py:146} INFO - Started process (PID=24056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:39,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:39,992] {logging_mixin.py:95} INFO - [2019-09-15 21:32:39,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:40,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:40,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:40,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:40,448] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 21:32:40,518] {scheduler_job.py:146} INFO - Started process (PID=24057) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:45,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:45,524] {logging_mixin.py:95} INFO - [2019-09-15 21:32:45,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:45,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:45,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:45,962] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:45,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 21:32:46,045] {scheduler_job.py:146} INFO - Started process (PID=24058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:51,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:51,052] {logging_mixin.py:95} INFO - [2019-09-15 21:32:51,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:51,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:51,491] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:51,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:51,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-15 21:32:51,571] {scheduler_job.py:146} INFO - Started process (PID=24060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:56,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:32:56,578] {logging_mixin.py:95} INFO - [2019-09-15 21:32:56,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:56,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:32:57,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:32:57,021] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:32:57,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 21:32:57,095] {scheduler_job.py:146} INFO - Started process (PID=24061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:02,102] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:02,103] {logging_mixin.py:95} INFO - [2019-09-15 21:33:02,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:02,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:02,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:02,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:02,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.507 seconds
[2019-09-15 21:33:02,628] {scheduler_job.py:146} INFO - Started process (PID=24062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:07,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:07,638] {logging_mixin.py:95} INFO - [2019-09-15 21:33:07,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:08,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:08,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:08,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:08,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:33:08,153] {scheduler_job.py:146} INFO - Started process (PID=24064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:13,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:13,165] {logging_mixin.py:95} INFO - [2019-09-15 21:33:13,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:14,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:14,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:14,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:14,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.557 seconds
[2019-09-15 21:33:14,798] {scheduler_job.py:146} INFO - Started process (PID=24075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:19,807] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:19,808] {logging_mixin.py:95} INFO - [2019-09-15 21:33:19,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:20,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:20,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:20,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:20,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 21:33:20,321] {scheduler_job.py:146} INFO - Started process (PID=24079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:25,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:25,328] {logging_mixin.py:95} INFO - [2019-09-15 21:33:25,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:25,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:25,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:25,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:25,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 21:33:25,866] {scheduler_job.py:146} INFO - Started process (PID=24081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:30,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:30,874] {logging_mixin.py:95} INFO - [2019-09-15 21:33:30,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:31,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:31,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:31,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:31,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 21:33:31,319] {scheduler_job.py:146} INFO - Started process (PID=24082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:36,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:36,326] {logging_mixin.py:95} INFO - [2019-09-15 21:33:36,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:36,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:36,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:36,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:36,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:33:36,763] {scheduler_job.py:146} INFO - Started process (PID=24086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:41,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:41,779] {logging_mixin.py:95} INFO - [2019-09-15 21:33:41,779] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:42,150] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:42,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:42,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:42,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 21:33:42,318] {scheduler_job.py:146} INFO - Started process (PID=24087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:47,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:47,328] {logging_mixin.py:95} INFO - [2019-09-15 21:33:47,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:47,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:47,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:47,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:47,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.545 seconds
[2019-09-15 21:33:47,954] {scheduler_job.py:146} INFO - Started process (PID=24089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:52,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:52,964] {logging_mixin.py:95} INFO - [2019-09-15 21:33:52,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:53,327] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:53,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:53,358] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:53,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 21:33:53,410] {scheduler_job.py:146} INFO - Started process (PID=24091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:58,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:33:58,418] {logging_mixin.py:95} INFO - [2019-09-15 21:33:58,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:58,815] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:33:58,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:33:58,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:33:58,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-15 21:33:58,951] {scheduler_job.py:146} INFO - Started process (PID=24092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:03,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:03,963] {logging_mixin.py:95} INFO - [2019-09-15 21:34:03,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:04,325] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:04,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:04,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:04,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 21:34:04,402] {scheduler_job.py:146} INFO - Started process (PID=24094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:09,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:09,409] {logging_mixin.py:95} INFO - [2019-09-15 21:34:09,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:09,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:09,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:09,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:09,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.501 seconds
[2019-09-15 21:34:09,949] {scheduler_job.py:146} INFO - Started process (PID=24095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:14,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:14,958] {logging_mixin.py:95} INFO - [2019-09-15 21:34:14,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:15,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:15,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:15,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:15,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:34:15,396] {scheduler_job.py:146} INFO - Started process (PID=24096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:20,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:20,403] {logging_mixin.py:95} INFO - [2019-09-15 21:34:20,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:20,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:20,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:20,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:20,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 21:34:20,941] {scheduler_job.py:146} INFO - Started process (PID=24102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:25,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:25,951] {logging_mixin.py:95} INFO - [2019-09-15 21:34:25,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:26,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:26,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:26,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:26,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:34:26,486] {scheduler_job.py:146} INFO - Started process (PID=24103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:31,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:31,496] {logging_mixin.py:95} INFO - [2019-09-15 21:34:31,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:31,947] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:31,965] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:31,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:31,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.500 seconds
[2019-09-15 21:34:32,018] {scheduler_job.py:146} INFO - Started process (PID=24104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:37,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:37,027] {logging_mixin.py:95} INFO - [2019-09-15 21:34:37,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:37,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:37,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:37,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:37,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.599 seconds
[2019-09-15 21:34:37,645] {scheduler_job.py:146} INFO - Started process (PID=24107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:42,653] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:42,664] {logging_mixin.py:95} INFO - [2019-09-15 21:34:42,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:43,171] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:43,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:43,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:43,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.571 seconds
[2019-09-15 21:34:43,283] {scheduler_job.py:146} INFO - Started process (PID=24108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:48,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:48,291] {logging_mixin.py:95} INFO - [2019-09-15 21:34:48,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:48,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:48,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:48,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:48,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 21:34:48,806] {scheduler_job.py:146} INFO - Started process (PID=24110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:53,812] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:53,813] {logging_mixin.py:95} INFO - [2019-09-15 21:34:53,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:54,247] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:54,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:54,280] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:54,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-15 21:34:54,348] {scheduler_job.py:146} INFO - Started process (PID=24111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:59,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:34:59,358] {logging_mixin.py:95} INFO - [2019-09-15 21:34:59,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:59,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:34:59,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:34:59,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:34:59,799] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 21:34:59,875] {scheduler_job.py:146} INFO - Started process (PID=24112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:04,883] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:04,884] {logging_mixin.py:95} INFO - [2019-09-15 21:35:04,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:05,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:05,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:05,353] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:05,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:35:05,412] {scheduler_job.py:146} INFO - Started process (PID=24114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:10,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:10,424] {logging_mixin.py:95} INFO - [2019-09-15 21:35:10,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:10,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:10,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:10,903] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:10,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-15 21:35:10,945] {scheduler_job.py:146} INFO - Started process (PID=24115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:15,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:15,950] {logging_mixin.py:95} INFO - [2019-09-15 21:35:15,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:16,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:16,479] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:16,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:16,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.559 seconds
[2019-09-15 21:35:16,577] {scheduler_job.py:146} INFO - Started process (PID=24116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:21,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:21,583] {logging_mixin.py:95} INFO - [2019-09-15 21:35:21,582] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:22,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:22,070] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:22,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:22,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.516 seconds
[2019-09-15 21:35:22,205] {scheduler_job.py:146} INFO - Started process (PID=24118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:27,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:27,211] {logging_mixin.py:95} INFO - [2019-09-15 21:35:27,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:27,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:27,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:27,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:27,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.501 seconds
[2019-09-15 21:35:27,735] {scheduler_job.py:146} INFO - Started process (PID=24120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:32,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:32,747] {logging_mixin.py:95} INFO - [2019-09-15 21:35:32,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:33,093] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:33,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:33,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:33,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:35:33,186] {scheduler_job.py:146} INFO - Started process (PID=24121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:38,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:38,191] {logging_mixin.py:95} INFO - [2019-09-15 21:35:38,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:38,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:38,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:38,679] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:38,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.500 seconds
[2019-09-15 21:35:38,733] {scheduler_job.py:146} INFO - Started process (PID=24124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:43,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:43,743] {logging_mixin.py:95} INFO - [2019-09-15 21:35:43,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:44,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:44,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:44,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:44,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.581 seconds
[2019-09-15 21:35:44,389] {scheduler_job.py:146} INFO - Started process (PID=24127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:49,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:49,396] {logging_mixin.py:95} INFO - [2019-09-15 21:35:49,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:49,745] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:49,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:49,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:49,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:35:49,829] {scheduler_job.py:146} INFO - Started process (PID=24129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:54,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:35:54,834] {logging_mixin.py:95} INFO - [2019-09-15 21:35:54,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:55,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:35:55,262] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:35:55,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:35:55,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 21:35:55,382] {scheduler_job.py:146} INFO - Started process (PID=24130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:00,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:00,389] {logging_mixin.py:95} INFO - [2019-09-15 21:36:00,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:00,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:00,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:00,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:00,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 21:36:00,838] {scheduler_job.py:146} INFO - Started process (PID=24131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:05,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:05,844] {logging_mixin.py:95} INFO - [2019-09-15 21:36:05,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:06,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:06,233] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:06,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:06,248] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-15 21:36:06,283] {scheduler_job.py:146} INFO - Started process (PID=24133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:11,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:11,301] {logging_mixin.py:95} INFO - [2019-09-15 21:36:11,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:11,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:11,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:11,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:11,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 21:36:11,724] {scheduler_job.py:146} INFO - Started process (PID=24134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:16,731] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:16,732] {logging_mixin.py:95} INFO - [2019-09-15 21:36:16,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:17,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:17,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:17,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:17,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:36:17,174] {scheduler_job.py:146} INFO - Started process (PID=24135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:22,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:22,181] {logging_mixin.py:95} INFO - [2019-09-15 21:36:22,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:22,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:22,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:22,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:22,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 21:36:22,631] {scheduler_job.py:146} INFO - Started process (PID=24137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:27,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:27,638] {logging_mixin.py:95} INFO - [2019-09-15 21:36:27,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:27,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:28,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:28,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:28,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:36:28,087] {scheduler_job.py:146} INFO - Started process (PID=24138) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:33,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:33,095] {logging_mixin.py:95} INFO - [2019-09-15 21:36:33,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:33,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:33,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:33,481] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:33,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:36:33,536] {scheduler_job.py:146} INFO - Started process (PID=24140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:38,546] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:38,548] {logging_mixin.py:95} INFO - [2019-09-15 21:36:38,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:38,908] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:38,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:38,939] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:38,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:36:38,994] {scheduler_job.py:146} INFO - Started process (PID=24142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:44,004] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:44,016] {logging_mixin.py:95} INFO - [2019-09-15 21:36:44,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:44,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:44,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:44,393] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:44,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:36:44,454] {scheduler_job.py:146} INFO - Started process (PID=24143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:49,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:49,465] {logging_mixin.py:95} INFO - [2019-09-15 21:36:49,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:49,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:49,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:49,861] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:49,866] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:36:49,916] {scheduler_job.py:146} INFO - Started process (PID=24145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:54,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:36:54,924] {logging_mixin.py:95} INFO - [2019-09-15 21:36:54,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:55,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:36:55,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:36:55,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:36:55,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:36:55,374] {scheduler_job.py:146} INFO - Started process (PID=24146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:00,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:00,382] {logging_mixin.py:95} INFO - [2019-09-15 21:37:00,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:00,728] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:00,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:00,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:00,763] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 21:37:00,825] {scheduler_job.py:146} INFO - Started process (PID=24147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:05,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:05,836] {logging_mixin.py:95} INFO - [2019-09-15 21:37:05,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:06,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:06,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:06,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:06,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:37:06,288] {scheduler_job.py:146} INFO - Started process (PID=24149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:11,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:11,296] {logging_mixin.py:95} INFO - [2019-09-15 21:37:11,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:11,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:11,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:11,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:11,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:37:11,744] {scheduler_job.py:146} INFO - Started process (PID=24150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:16,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:16,754] {logging_mixin.py:95} INFO - [2019-09-15 21:37:16,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:17,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:17,134] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:17,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:17,149] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 21:37:17,199] {scheduler_job.py:146} INFO - Started process (PID=24151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:22,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:22,207] {logging_mixin.py:95} INFO - [2019-09-15 21:37:22,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:22,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:22,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:22,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:22,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:37:22,657] {scheduler_job.py:146} INFO - Started process (PID=24153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:27,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:27,666] {logging_mixin.py:95} INFO - [2019-09-15 21:37:27,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:28,017] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:28,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:28,049] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:28,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:37:28,112] {scheduler_job.py:146} INFO - Started process (PID=24154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:33,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:33,121] {logging_mixin.py:95} INFO - [2019-09-15 21:37:33,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:33,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:33,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:33,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:33,508] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:37:33,565] {scheduler_job.py:146} INFO - Started process (PID=24156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:38,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:38,576] {logging_mixin.py:95} INFO - [2019-09-15 21:37:38,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:38,932] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:38,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:38,965] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:38,971] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 21:37:39,022] {scheduler_job.py:146} INFO - Started process (PID=24158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:44,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:44,028] {logging_mixin.py:95} INFO - [2019-09-15 21:37:44,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:44,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:44,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:44,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:44,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.508 seconds
[2019-09-15 21:37:44,562] {scheduler_job.py:146} INFO - Started process (PID=24161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:49,568] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:49,569] {logging_mixin.py:95} INFO - [2019-09-15 21:37:49,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:49,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:49,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:49,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:49,966] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 21:37:50,005] {scheduler_job.py:146} INFO - Started process (PID=24163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:55,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:37:55,016] {logging_mixin.py:95} INFO - [2019-09-15 21:37:55,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:55,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:37:55,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:37:55,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:37:55,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:37:55,447] {scheduler_job.py:146} INFO - Started process (PID=24164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:00,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:00,454] {logging_mixin.py:95} INFO - [2019-09-15 21:38:00,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:00,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:00,894] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:00,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:00,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 21:38:00,997] {scheduler_job.py:146} INFO - Started process (PID=24165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:06,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:06,004] {logging_mixin.py:95} INFO - [2019-09-15 21:38:06,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:06,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:06,464] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:06,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:06,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:38:06,521] {scheduler_job.py:146} INFO - Started process (PID=24168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:11,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:11,530] {logging_mixin.py:95} INFO - [2019-09-15 21:38:11,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:11,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:11,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:11,979] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:11,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 21:38:12,059] {scheduler_job.py:146} INFO - Started process (PID=24169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:17,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:17,070] {logging_mixin.py:95} INFO - [2019-09-15 21:38:17,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:17,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:17,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:17,497] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:17,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 21:38:17,605] {scheduler_job.py:146} INFO - Started process (PID=24170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:22,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:22,615] {logging_mixin.py:95} INFO - [2019-09-15 21:38:22,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:23,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:23,027] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:23,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:23,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 21:38:23,141] {scheduler_job.py:146} INFO - Started process (PID=24172) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:28,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:28,147] {logging_mixin.py:95} INFO - [2019-09-15 21:38:28,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:28,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:28,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:28,572] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:28,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:38:28,685] {scheduler_job.py:146} INFO - Started process (PID=24173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:33,695] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:33,696] {logging_mixin.py:95} INFO - [2019-09-15 21:38:33,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:34,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:34,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:34,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:34,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 21:38:34,131] {scheduler_job.py:146} INFO - Started process (PID=24175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:39,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:39,139] {logging_mixin.py:95} INFO - [2019-09-15 21:38:39,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:39,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:39,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:39,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:39,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:38:39,577] {scheduler_job.py:146} INFO - Started process (PID=24177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:44,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:44,586] {logging_mixin.py:95} INFO - [2019-09-15 21:38:44,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:44,960] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:44,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:44,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:45,005] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:38:45,030] {scheduler_job.py:146} INFO - Started process (PID=24178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:50,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:50,037] {logging_mixin.py:95} INFO - [2019-09-15 21:38:50,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:50,412] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:50,435] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:50,444] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:50,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 21:38:50,481] {scheduler_job.py:146} INFO - Started process (PID=24180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:55,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:38:55,489] {logging_mixin.py:95} INFO - [2019-09-15 21:38:55,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:55,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:38:55,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:38:55,889] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:38:55,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 21:38:55,934] {scheduler_job.py:146} INFO - Started process (PID=24181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:00,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:00,946] {logging_mixin.py:95} INFO - [2019-09-15 21:39:00,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:01,301] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:01,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:01,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:01,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:39:01,386] {scheduler_job.py:146} INFO - Started process (PID=24182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:06,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:06,397] {logging_mixin.py:95} INFO - [2019-09-15 21:39:06,396] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:06,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:06,827] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:06,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:06,845] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-15 21:39:06,936] {scheduler_job.py:146} INFO - Started process (PID=24184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:11,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:11,957] {logging_mixin.py:95} INFO - [2019-09-15 21:39:11,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:12,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:12,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:12,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:12,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:39:12,392] {scheduler_job.py:146} INFO - Started process (PID=24185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:17,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:17,399] {logging_mixin.py:95} INFO - [2019-09-15 21:39:17,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:17,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:17,780] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:17,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:17,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 21:39:17,850] {scheduler_job.py:146} INFO - Started process (PID=24186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:22,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:22,858] {logging_mixin.py:95} INFO - [2019-09-15 21:39:22,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:23,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:23,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:23,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:23,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 21:39:23,304] {scheduler_job.py:146} INFO - Started process (PID=24188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:28,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:28,312] {logging_mixin.py:95} INFO - [2019-09-15 21:39:28,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:28,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:28,695] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:28,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:28,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:39:28,763] {scheduler_job.py:146} INFO - Started process (PID=24189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:33,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:33,770] {logging_mixin.py:95} INFO - [2019-09-15 21:39:33,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:34,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:34,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:34,148] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:34,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 21:39:34,223] {scheduler_job.py:146} INFO - Started process (PID=24191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:39,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:39,229] {logging_mixin.py:95} INFO - [2019-09-15 21:39:39,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:39,692] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:39,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:39,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:39,727] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.505 seconds
[2019-09-15 21:39:39,768] {scheduler_job.py:146} INFO - Started process (PID=24193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:44,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:44,775] {logging_mixin.py:95} INFO - [2019-09-15 21:39:44,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:45,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:45,155] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:45,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:45,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 21:39:45,219] {scheduler_job.py:146} INFO - Started process (PID=24194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:50,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:50,230] {logging_mixin.py:95} INFO - [2019-09-15 21:39:50,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:50,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:50,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:50,620] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:50,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 21:39:50,677] {scheduler_job.py:146} INFO - Started process (PID=24196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:55,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:39:55,687] {logging_mixin.py:95} INFO - [2019-09-15 21:39:55,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:56,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:39:56,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:39:56,095] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:39:56,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 21:39:56,136] {scheduler_job.py:146} INFO - Started process (PID=24197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:01,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:01,146] {logging_mixin.py:95} INFO - [2019-09-15 21:40:01,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:01,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:01,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:01,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:01,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 21:40:01,583] {scheduler_job.py:146} INFO - Started process (PID=24198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:06,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:06,588] {logging_mixin.py:95} INFO - [2019-09-15 21:40:06,587] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:07,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:07,040] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:07,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:07,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-15 21:40:07,121] {scheduler_job.py:146} INFO - Started process (PID=24200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:12,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:12,136] {logging_mixin.py:95} INFO - [2019-09-15 21:40:12,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:12,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:12,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:12,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:12,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.507 seconds
[2019-09-15 21:40:12,666] {scheduler_job.py:146} INFO - Started process (PID=24201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:17,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:17,674] {logging_mixin.py:95} INFO - [2019-09-15 21:40:17,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:18,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:18,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:18,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:18,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 21:40:18,210] {scheduler_job.py:146} INFO - Started process (PID=24202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:23,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:23,221] {logging_mixin.py:95} INFO - [2019-09-15 21:40:23,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:23,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:23,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:23,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:23,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 21:40:23,754] {scheduler_job.py:146} INFO - Started process (PID=24204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:28,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:28,763] {logging_mixin.py:95} INFO - [2019-09-15 21:40:28,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:29,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:29,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:29,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:29,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:40:29,209] {scheduler_job.py:146} INFO - Started process (PID=24205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:34,216] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:34,218] {logging_mixin.py:95} INFO - [2019-09-15 21:40:34,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:34,624] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:34,643] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:34,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:34,661] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 21:40:34,762] {scheduler_job.py:146} INFO - Started process (PID=24207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:39,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:39,771] {logging_mixin.py:95} INFO - [2019-09-15 21:40:39,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:40,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:40,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:40,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:40,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 21:40:40,310] {scheduler_job.py:146} INFO - Started process (PID=24209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:45,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:45,317] {logging_mixin.py:95} INFO - [2019-09-15 21:40:45,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:45,667] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:45,690] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:45,699] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:45,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 21:40:45,765] {scheduler_job.py:146} INFO - Started process (PID=24210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:50,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:50,772] {logging_mixin.py:95} INFO - [2019-09-15 21:40:50,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:51,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:51,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:51,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:51,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 21:40:51,320] {scheduler_job.py:146} INFO - Started process (PID=24212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:56,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:40:56,333] {logging_mixin.py:95} INFO - [2019-09-15 21:40:56,332] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:56,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:40:56,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:40:56,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:40:56,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 21:40:56,772] {scheduler_job.py:146} INFO - Started process (PID=24213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:01,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:01,783] {logging_mixin.py:95} INFO - [2019-09-15 21:41:01,783] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:02,136] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:02,158] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:02,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:02,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 21:41:02,225] {scheduler_job.py:146} INFO - Started process (PID=24214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:07,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:07,237] {logging_mixin.py:95} INFO - [2019-09-15 21:41:07,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:07,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:07,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:07,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:07,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 21:41:07,676] {scheduler_job.py:146} INFO - Started process (PID=24216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:12,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:12,685] {logging_mixin.py:95} INFO - [2019-09-15 21:41:12,685] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:13,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:13,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:13,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:13,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 21:41:13,127] {scheduler_job.py:146} INFO - Started process (PID=24217) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:18,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:18,137] {logging_mixin.py:95} INFO - [2019-09-15 21:41:18,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:18,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:18,517] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:18,525] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:18,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 21:41:18,577] {scheduler_job.py:146} INFO - Started process (PID=24218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:23,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:23,585] {logging_mixin.py:95} INFO - [2019-09-15 21:41:23,584] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:23,948] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:23,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:23,981] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:23,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 21:41:24,029] {scheduler_job.py:146} INFO - Started process (PID=24220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:29,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:29,038] {logging_mixin.py:95} INFO - [2019-09-15 21:41:29,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:29,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:29,456] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:29,465] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:29,471] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 21:41:29,579] {scheduler_job.py:146} INFO - Started process (PID=24223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:34,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:34,587] {logging_mixin.py:95} INFO - [2019-09-15 21:41:34,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:34,942] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:34,960] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:34,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:34,975] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 21:41:35,010] {scheduler_job.py:146} INFO - Started process (PID=24229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:40,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:40,021] {logging_mixin.py:95} INFO - [2019-09-15 21:41:40,020] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:40,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:40,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:40,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:40,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 21:41:40,554] {scheduler_job.py:146} INFO - Started process (PID=24231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:45,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:45,560] {logging_mixin.py:95} INFO - [2019-09-15 21:41:45,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:46,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:46,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:46,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:46,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.551 seconds
[2019-09-15 21:41:46,194] {scheduler_job.py:146} INFO - Started process (PID=24232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:51,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:51,201] {logging_mixin.py:95} INFO - [2019-09-15 21:41:51,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:51,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:51,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:51,627] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:51,632] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:41:51,730] {scheduler_job.py:146} INFO - Started process (PID=24234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:56,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:41:56,739] {logging_mixin.py:95} INFO - [2019-09-15 21:41:56,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:57,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:41:57,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:41:57,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:41:57,196] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-15 21:41:57,275] {scheduler_job.py:146} INFO - Started process (PID=24235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:02,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:02,282] {logging_mixin.py:95} INFO - [2019-09-15 21:42:02,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:02,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:02,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:02,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:02,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.514 seconds
[2019-09-15 21:42:02,820] {scheduler_job.py:146} INFO - Started process (PID=24239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:07,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:07,828] {logging_mixin.py:95} INFO - [2019-09-15 21:42:07,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:08,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:08,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:08,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:08,307] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 21:42:08,363] {scheduler_job.py:146} INFO - Started process (PID=24241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:13,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:13,370] {logging_mixin.py:95} INFO - [2019-09-15 21:42:13,369] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:13,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:13,835] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:13,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:13,852] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.490 seconds
[2019-09-15 21:42:13,890] {scheduler_job.py:146} INFO - Started process (PID=24244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:18,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:18,901] {logging_mixin.py:95} INFO - [2019-09-15 21:42:18,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:19,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:19,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:19,376] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:19,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 21:42:19,430] {scheduler_job.py:146} INFO - Started process (PID=24246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:24,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:24,437] {logging_mixin.py:95} INFO - [2019-09-15 21:42:24,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:24,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:24,895] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:24,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:24,913] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 21:42:24,965] {scheduler_job.py:146} INFO - Started process (PID=24247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:29,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:29,972] {logging_mixin.py:95} INFO - [2019-09-15 21:42:29,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:30,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:30,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:30,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:30,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.557 seconds
[2019-09-15 21:42:30,596] {scheduler_job.py:146} INFO - Started process (PID=24248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:35,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:35,606] {logging_mixin.py:95} INFO - [2019-09-15 21:42:35,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:36,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:36,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:36,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:36,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 21:42:36,134] {scheduler_job.py:146} INFO - Started process (PID=24251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:41,144] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:41,145] {logging_mixin.py:95} INFO - [2019-09-15 21:42:41,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:41,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:41,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:41,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:41,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 21:42:41,661] {scheduler_job.py:146} INFO - Started process (PID=24252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:46,668] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:46,669] {logging_mixin.py:95} INFO - [2019-09-15 21:42:46,669] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:47,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:47,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:47,109] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:47,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 21:42:47,196] {scheduler_job.py:146} INFO - Started process (PID=24253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:52,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:52,203] {logging_mixin.py:95} INFO - [2019-09-15 21:42:52,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:52,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:52,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:52,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:52,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-15 21:42:52,730] {scheduler_job.py:146} INFO - Started process (PID=24255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:57,739] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:42:57,740] {logging_mixin.py:95} INFO - [2019-09-15 21:42:57,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:58,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:42:58,240] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:42:58,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:42:58,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.528 seconds
[2019-09-15 21:42:58,364] {scheduler_job.py:146} INFO - Started process (PID=24256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:03,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:03,373] {logging_mixin.py:95} INFO - [2019-09-15 21:43:03,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:03,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:03,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:03,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:03,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 21:43:03,895] {scheduler_job.py:146} INFO - Started process (PID=24259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:08,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:08,903] {logging_mixin.py:95} INFO - [2019-09-15 21:43:08,902] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:09,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:09,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:09,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:09,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 21:43:09,346] {scheduler_job.py:146} INFO - Started process (PID=24260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:14,354] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:14,355] {logging_mixin.py:95} INFO - [2019-09-15 21:43:14,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:14,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:14,746] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:14,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:14,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 21:43:14,797] {scheduler_job.py:146} INFO - Started process (PID=24261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:19,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:19,807] {logging_mixin.py:95} INFO - [2019-09-15 21:43:19,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:20,172] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:20,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:20,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:20,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-15 21:43:20,244] {scheduler_job.py:146} INFO - Started process (PID=24263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:25,251] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:25,261] {logging_mixin.py:95} INFO - [2019-09-15 21:43:25,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:25,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:25,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:25,668] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:25,673] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:43:25,696] {scheduler_job.py:146} INFO - Started process (PID=24264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:30,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:30,706] {logging_mixin.py:95} INFO - [2019-09-15 21:43:30,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:31,077] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:31,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:31,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:31,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 21:43:31,142] {scheduler_job.py:146} INFO - Started process (PID=24265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:36,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:36,151] {logging_mixin.py:95} INFO - [2019-09-15 21:43:36,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:36,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:36,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:36,677] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:36,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.545 seconds
[2019-09-15 21:43:36,787] {scheduler_job.py:146} INFO - Started process (PID=24268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:41,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:41,795] {logging_mixin.py:95} INFO - [2019-09-15 21:43:41,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:42,190] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:42,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:42,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:42,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 21:43:42,318] {scheduler_job.py:146} INFO - Started process (PID=24269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:47,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:47,325] {logging_mixin.py:95} INFO - [2019-09-15 21:43:47,325] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:47,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:47,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:47,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:47,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:43:47,861] {scheduler_job.py:146} INFO - Started process (PID=24270) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:52,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:52,870] {logging_mixin.py:95} INFO - [2019-09-15 21:43:52,869] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:53,347] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:53,377] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:53,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:53,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.541 seconds
[2019-09-15 21:43:53,486] {scheduler_job.py:146} INFO - Started process (PID=24272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:58,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:43:58,496] {logging_mixin.py:95} INFO - [2019-09-15 21:43:58,495] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:58,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:43:58,971] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:43:58,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:43:58,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.508 seconds
[2019-09-15 21:43:59,022] {scheduler_job.py:146} INFO - Started process (PID=24273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:04,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:04,031] {logging_mixin.py:95} INFO - [2019-09-15 21:44:04,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:04,449] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:04,473] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:04,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:04,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 21:44:04,546] {scheduler_job.py:146} INFO - Started process (PID=24276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:09,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:09,553] {logging_mixin.py:95} INFO - [2019-09-15 21:44:09,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:09,944] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:09,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:09,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:09,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 21:44:10,093] {scheduler_job.py:146} INFO - Started process (PID=24277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:15,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:15,099] {logging_mixin.py:95} INFO - [2019-09-15 21:44:15,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:15,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:15,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:15,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:15,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 21:44:15,549] {scheduler_job.py:146} INFO - Started process (PID=24278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:20,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:20,555] {logging_mixin.py:95} INFO - [2019-09-15 21:44:20,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:20,982] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:21,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:21,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:21,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 21:44:21,095] {scheduler_job.py:146} INFO - Started process (PID=24280) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:26,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:26,107] {logging_mixin.py:95} INFO - [2019-09-15 21:44:26,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:26,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:26,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:26,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:26,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:44:26,641] {scheduler_job.py:146} INFO - Started process (PID=24281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:31,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:31,652] {logging_mixin.py:95} INFO - [2019-09-15 21:44:31,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:32,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:32,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:32,066] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:32,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:44:32,187] {scheduler_job.py:146} INFO - Started process (PID=24282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:37,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:37,208] {logging_mixin.py:95} INFO - [2019-09-15 21:44:37,207] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:37,581] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:37,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:37,613] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:37,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 21:44:37,731] {scheduler_job.py:146} INFO - Started process (PID=24285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:42,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:42,738] {logging_mixin.py:95} INFO - [2019-09-15 21:44:42,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:43,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:43,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:43,140] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:43,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 21:44:43,179] {scheduler_job.py:146} INFO - Started process (PID=24286) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:48,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:48,187] {logging_mixin.py:95} INFO - [2019-09-15 21:44:48,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:48,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:48,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:48,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:48,601] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-15 21:44:48,630] {scheduler_job.py:146} INFO - Started process (PID=24287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:53,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:53,647] {logging_mixin.py:95} INFO - [2019-09-15 21:44:53,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:54,021] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:54,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:54,054] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:54,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:44:54,084] {scheduler_job.py:146} INFO - Started process (PID=24289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:59,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:44:59,091] {logging_mixin.py:95} INFO - [2019-09-15 21:44:59,091] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:59,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:44:59,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:44:59,530] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:44:59,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 21:44:59,630] {scheduler_job.py:146} INFO - Started process (PID=24290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:04,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:04,639] {logging_mixin.py:95} INFO - [2019-09-15 21:45:04,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:05,012] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:05,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:05,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:05,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 21:45:05,076] {scheduler_job.py:146} INFO - Started process (PID=24292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:10,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:10,090] {logging_mixin.py:95} INFO - [2019-09-15 21:45:10,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:10,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:10,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:10,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:10,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:45:10,527] {scheduler_job.py:146} INFO - Started process (PID=24293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:15,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:15,534] {logging_mixin.py:95} INFO - [2019-09-15 21:45:15,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:15,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:15,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:15,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:15,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:45:15,978] {scheduler_job.py:146} INFO - Started process (PID=24294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:20,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:20,985] {logging_mixin.py:95} INFO - [2019-09-15 21:45:20,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:21,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:21,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:21,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:21,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:45:21,430] {scheduler_job.py:146} INFO - Started process (PID=24296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:26,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:26,437] {logging_mixin.py:95} INFO - [2019-09-15 21:45:26,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:26,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:26,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:26,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:26,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 21:45:26,878] {scheduler_job.py:146} INFO - Started process (PID=24297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:31,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:31,885] {logging_mixin.py:95} INFO - [2019-09-15 21:45:31,885] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:32,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:32,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:32,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:32,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 21:45:32,332] {scheduler_job.py:146} INFO - Started process (PID=24298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:37,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:37,352] {logging_mixin.py:95} INFO - [2019-09-15 21:45:37,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:37,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:37,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:37,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:37,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:45:37,783] {scheduler_job.py:146} INFO - Started process (PID=24301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:42,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:42,789] {logging_mixin.py:95} INFO - [2019-09-15 21:45:42,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:43,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:43,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:43,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:43,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 21:45:43,238] {scheduler_job.py:146} INFO - Started process (PID=24302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:48,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:48,244] {logging_mixin.py:95} INFO - [2019-09-15 21:45:48,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:48,616] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:48,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:48,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:48,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 21:45:48,684] {scheduler_job.py:146} INFO - Started process (PID=24303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:53,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:53,691] {logging_mixin.py:95} INFO - [2019-09-15 21:45:53,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:54,059] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:54,084] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:54,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:54,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 21:45:54,136] {scheduler_job.py:146} INFO - Started process (PID=24305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:59,144] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:45:59,145] {logging_mixin.py:95} INFO - [2019-09-15 21:45:59,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:59,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:45:59,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:45:59,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:45:59,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 21:45:59,582] {scheduler_job.py:146} INFO - Started process (PID=24306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:04,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:04,594] {logging_mixin.py:95} INFO - [2019-09-15 21:46:04,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:04,969] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:04,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:05,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:05,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:46:05,034] {scheduler_job.py:146} INFO - Started process (PID=24308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:10,045] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:10,046] {logging_mixin.py:95} INFO - [2019-09-15 21:46:10,046] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:10,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:10,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:10,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:10,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-15 21:46:10,484] {scheduler_job.py:146} INFO - Started process (PID=24309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:15,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:15,494] {logging_mixin.py:95} INFO - [2019-09-15 21:46:15,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:15,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:15,885] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:15,896] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:15,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-15 21:46:15,930] {scheduler_job.py:146} INFO - Started process (PID=24310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:20,937] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:20,938] {logging_mixin.py:95} INFO - [2019-09-15 21:46:20,938] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:21,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:21,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:21,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:21,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-15 21:46:21,386] {scheduler_job.py:146} INFO - Started process (PID=24312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:26,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:26,405] {logging_mixin.py:95} INFO - [2019-09-15 21:46:26,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:26,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:26,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:26,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:26,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 21:46:26,846] {scheduler_job.py:146} INFO - Started process (PID=24313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:31,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:31,858] {logging_mixin.py:95} INFO - [2019-09-15 21:46:31,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:32,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:32,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:32,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:32,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 21:46:32,298] {scheduler_job.py:146} INFO - Started process (PID=24314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:37,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:37,307] {logging_mixin.py:95} INFO - [2019-09-15 21:46:37,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:37,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:37,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:37,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:37,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:46:37,748] {scheduler_job.py:146} INFO - Started process (PID=24317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:42,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:42,756] {logging_mixin.py:95} INFO - [2019-09-15 21:46:42,756] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:43,132] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:43,163] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:43,173] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:43,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:46:43,203] {scheduler_job.py:146} INFO - Started process (PID=24318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:48,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:48,212] {logging_mixin.py:95} INFO - [2019-09-15 21:46:48,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:48,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:48,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:48,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:48,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:46:48,664] {scheduler_job.py:146} INFO - Started process (PID=24319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:53,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:53,682] {logging_mixin.py:95} INFO - [2019-09-15 21:46:53,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:54,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:54,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:54,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:54,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 21:46:54,112] {scheduler_job.py:146} INFO - Started process (PID=24321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:59,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:46:59,122] {logging_mixin.py:95} INFO - [2019-09-15 21:46:59,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:59,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:46:59,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:46:59,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:46:59,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 21:46:59,665] {scheduler_job.py:146} INFO - Started process (PID=24322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:04,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:04,673] {logging_mixin.py:95} INFO - [2019-09-15 21:47:04,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:05,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:05,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:05,090] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:05,096] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:47:05,210] {scheduler_job.py:146} INFO - Started process (PID=24324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:10,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:10,218] {logging_mixin.py:95} INFO - [2019-09-15 21:47:10,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:10,669] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:10,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:10,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:10,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-09-15 21:47:10,761] {scheduler_job.py:146} INFO - Started process (PID=24325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:15,769] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:15,779] {logging_mixin.py:95} INFO - [2019-09-15 21:47:15,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:16,183] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:16,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:16,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:16,225] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-15 21:47:16,298] {scheduler_job.py:146} INFO - Started process (PID=24326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:21,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:21,304] {logging_mixin.py:95} INFO - [2019-09-15 21:47:21,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:21,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:21,714] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:21,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:21,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:47:21,828] {scheduler_job.py:146} INFO - Started process (PID=24328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:26,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:26,839] {logging_mixin.py:95} INFO - [2019-09-15 21:47:26,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:27,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:27,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:27,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:27,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 21:47:27,280] {scheduler_job.py:146} INFO - Started process (PID=24329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:32,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:32,301] {logging_mixin.py:95} INFO - [2019-09-15 21:47:32,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:32,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:32,701] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:32,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:32,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 21:47:32,832] {scheduler_job.py:146} INFO - Started process (PID=24330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:37,842] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:37,843] {logging_mixin.py:95} INFO - [2019-09-15 21:47:37,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:38,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:38,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:38,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:38,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 21:47:38,375] {scheduler_job.py:146} INFO - Started process (PID=24333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:43,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:43,390] {logging_mixin.py:95} INFO - [2019-09-15 21:47:43,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:43,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:43,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:43,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:43,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 21:47:43,823] {scheduler_job.py:146} INFO - Started process (PID=24334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:48,830] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:48,831] {logging_mixin.py:95} INFO - [2019-09-15 21:47:48,830] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:49,195] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:49,219] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:49,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:49,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 21:47:49,276] {scheduler_job.py:146} INFO - Started process (PID=24336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:54,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:54,283] {logging_mixin.py:95} INFO - [2019-09-15 21:47:54,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:54,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:54,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:47:54,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:47:54,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:47:54,825] {scheduler_job.py:146} INFO - Started process (PID=24337) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:47:59,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:47:59,843] {logging_mixin.py:95} INFO - [2019-09-15 21:47:59,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:00,216] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:00,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:00,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:00,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:48:00,275] {scheduler_job.py:146} INFO - Started process (PID=24338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:05,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:05,283] {logging_mixin.py:95} INFO - [2019-09-15 21:48:05,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:05,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:05,678] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:05,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:05,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 21:48:05,729] {scheduler_job.py:146} INFO - Started process (PID=24340) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:10,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:10,735] {logging_mixin.py:95} INFO - [2019-09-15 21:48:10,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:11,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:11,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:11,198] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:11,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-09-15 21:48:11,277] {scheduler_job.py:146} INFO - Started process (PID=24341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:16,283] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:16,284] {logging_mixin.py:95} INFO - [2019-09-15 21:48:16,284] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:16,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:16,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:16,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:16,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 21:48:16,722] {scheduler_job.py:146} INFO - Started process (PID=24342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:21,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:21,731] {logging_mixin.py:95} INFO - [2019-09-15 21:48:21,730] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:22,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:22,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:22,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:22,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 21:48:22,170] {scheduler_job.py:146} INFO - Started process (PID=24344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:27,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:27,175] {logging_mixin.py:95} INFO - [2019-09-15 21:48:27,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:27,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:27,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:27,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:27,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 21:48:27,712] {scheduler_job.py:146} INFO - Started process (PID=24346) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:32,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:32,720] {logging_mixin.py:95} INFO - [2019-09-15 21:48:32,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:33,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:33,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:33,088] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:33,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-15 21:48:33,160] {scheduler_job.py:146} INFO - Started process (PID=24347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:38,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:38,171] {logging_mixin.py:95} INFO - [2019-09-15 21:48:38,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:38,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:38,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:38,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:38,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:48:38,612] {scheduler_job.py:146} INFO - Started process (PID=24350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:43,622] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:43,632] {logging_mixin.py:95} INFO - [2019-09-15 21:48:43,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:43,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:43,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:44,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:44,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 21:48:44,068] {scheduler_job.py:146} INFO - Started process (PID=24351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:49,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:49,076] {logging_mixin.py:95} INFO - [2019-09-15 21:48:49,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:49,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:49,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:49,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:49,466] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 21:48:49,521] {scheduler_job.py:146} INFO - Started process (PID=24353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:54,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:48:54,529] {logging_mixin.py:95} INFO - [2019-09-15 21:48:54,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:55,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:48:55,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:48:55,195] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:48:55,216] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.695 seconds
[2019-09-15 21:48:55,281] {scheduler_job.py:146} INFO - Started process (PID=24358) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:00,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:00,291] {logging_mixin.py:95} INFO - [2019-09-15 21:49:00,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:00,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:00,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:00,780] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:00,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.506 seconds
[2019-09-15 21:49:00,812] {scheduler_job.py:146} INFO - Started process (PID=24359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:05,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:05,822] {logging_mixin.py:95} INFO - [2019-09-15 21:49:05,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:06,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:06,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:06,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:06,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.562 seconds
[2019-09-15 21:49:06,452] {scheduler_job.py:146} INFO - Started process (PID=24361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:11,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:11,458] {logging_mixin.py:95} INFO - [2019-09-15 21:49:11,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:11,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:11,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:11,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:11,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:49:11,988] {scheduler_job.py:146} INFO - Started process (PID=24362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:16,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:16,998] {logging_mixin.py:95} INFO - [2019-09-15 21:49:16,998] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:17,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:17,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:17,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:17,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:49:17,532] {scheduler_job.py:146} INFO - Started process (PID=24363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:22,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:22,542] {logging_mixin.py:95} INFO - [2019-09-15 21:49:22,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:22,925] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:22,950] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:22,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:22,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:49:23,074] {scheduler_job.py:146} INFO - Started process (PID=24365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:28,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:28,081] {logging_mixin.py:95} INFO - [2019-09-15 21:49:28,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:28,596] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:28,623] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:28,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:28,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.575 seconds
[2019-09-15 21:49:28,723] {scheduler_job.py:146} INFO - Started process (PID=24366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:33,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:33,733] {logging_mixin.py:95} INFO - [2019-09-15 21:49:33,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:34,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:34,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:34,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:34,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-15 21:49:34,251] {scheduler_job.py:146} INFO - Started process (PID=24368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:39,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:39,262] {logging_mixin.py:95} INFO - [2019-09-15 21:49:39,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:39,689] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:39,715] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:39,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:39,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 21:49:39,786] {scheduler_job.py:146} INFO - Started process (PID=24370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:44,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:44,796] {logging_mixin.py:95} INFO - [2019-09-15 21:49:44,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:45,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:45,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:45,267] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:45,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:49:45,329] {scheduler_job.py:146} INFO - Started process (PID=24371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:50,334] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:50,336] {logging_mixin.py:95} INFO - [2019-09-15 21:49:50,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:50,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:50,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:50,799] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:50,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-15 21:49:50,863] {scheduler_job.py:146} INFO - Started process (PID=24373) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:55,868] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:49:55,869] {logging_mixin.py:95} INFO - [2019-09-15 21:49:55,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:56,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:49:56,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:49:56,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:49:56,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.496 seconds
[2019-09-15 21:49:56,399] {scheduler_job.py:146} INFO - Started process (PID=24374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:01,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:01,410] {logging_mixin.py:95} INFO - [2019-09-15 21:50:01,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:01,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:01,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:01,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:01,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-09-15 21:50:01,932] {scheduler_job.py:146} INFO - Started process (PID=24375) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:06,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:06,940] {logging_mixin.py:95} INFO - [2019-09-15 21:50:06,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:07,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:07,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:07,413] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:07,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:50:07,468] {scheduler_job.py:146} INFO - Started process (PID=24377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:12,479] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:12,481] {logging_mixin.py:95} INFO - [2019-09-15 21:50:12,480] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:12,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:12,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:12,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:12,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:50:13,008] {scheduler_job.py:146} INFO - Started process (PID=24378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:18,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:18,016] {logging_mixin.py:95} INFO - [2019-09-15 21:50:18,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:18,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:18,481] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:18,492] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:18,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 21:50:18,548] {scheduler_job.py:146} INFO - Started process (PID=24379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:23,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:23,556] {logging_mixin.py:95} INFO - [2019-09-15 21:50:23,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:23,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:24,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:24,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:24,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-09-15 21:50:24,085] {scheduler_job.py:146} INFO - Started process (PID=24381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:29,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:29,100] {logging_mixin.py:95} INFO - [2019-09-15 21:50:29,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:29,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:29,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:29,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:29,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 21:50:29,621] {scheduler_job.py:146} INFO - Started process (PID=24382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:34,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:34,629] {logging_mixin.py:95} INFO - [2019-09-15 21:50:34,628] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:35,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:35,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:35,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:35,109] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:50:35,154] {scheduler_job.py:146} INFO - Started process (PID=24384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:40,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:40,164] {logging_mixin.py:95} INFO - [2019-09-15 21:50:40,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:40,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:40,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:40,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:40,638] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:50:40,692] {scheduler_job.py:146} INFO - Started process (PID=24386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:45,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:45,701] {logging_mixin.py:95} INFO - [2019-09-15 21:50:45,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:46,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:46,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:46,169] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:46,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-15 21:50:46,225] {scheduler_job.py:146} INFO - Started process (PID=24387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:51,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:51,233] {logging_mixin.py:95} INFO - [2019-09-15 21:50:51,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:51,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:51,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:51,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:51,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-15 21:50:51,769] {scheduler_job.py:146} INFO - Started process (PID=24389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:56,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:50:56,776] {logging_mixin.py:95} INFO - [2019-09-15 21:50:56,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:57,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:50:57,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:50:57,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:50:57,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:50:57,304] {scheduler_job.py:146} INFO - Started process (PID=24390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:02,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:02,313] {logging_mixin.py:95} INFO - [2019-09-15 21:51:02,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:02,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:02,774] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:02,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:02,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 21:51:02,838] {scheduler_job.py:146} INFO - Started process (PID=24391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:07,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:07,847] {logging_mixin.py:95} INFO - [2019-09-15 21:51:07,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:08,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:08,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:08,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:08,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 21:51:08,375] {scheduler_job.py:146} INFO - Started process (PID=24393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:13,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:13,383] {logging_mixin.py:95} INFO - [2019-09-15 21:51:13,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:13,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:13,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:13,855] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:13,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 21:51:13,913] {scheduler_job.py:146} INFO - Started process (PID=24394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:18,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:18,922] {logging_mixin.py:95} INFO - [2019-09-15 21:51:18,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:19,362] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:19,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:19,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:19,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 21:51:19,448] {scheduler_job.py:146} INFO - Started process (PID=24397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:24,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:24,456] {logging_mixin.py:95} INFO - [2019-09-15 21:51:24,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:24,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:24,906] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:24,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:24,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-15 21:51:24,989] {scheduler_job.py:146} INFO - Started process (PID=24398) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:30,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:30,004] {logging_mixin.py:95} INFO - [2019-09-15 21:51:30,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:30,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:30,470] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:30,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:30,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.499 seconds
[2019-09-15 21:51:30,528] {scheduler_job.py:146} INFO - Started process (PID=24401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:35,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:35,548] {logging_mixin.py:95} INFO - [2019-09-15 21:51:35,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:35,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:35,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:36,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:36,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 21:51:36,064] {scheduler_job.py:146} INFO - Started process (PID=24406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:41,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:41,071] {logging_mixin.py:95} INFO - [2019-09-15 21:51:41,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:41,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:41,534] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:41,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:41,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:51:41,597] {scheduler_job.py:146} INFO - Started process (PID=24408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:46,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:46,607] {logging_mixin.py:95} INFO - [2019-09-15 21:51:46,606] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:47,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:47,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:47,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:47,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-09-15 21:51:47,142] {scheduler_job.py:146} INFO - Started process (PID=24409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:52,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:52,149] {logging_mixin.py:95} INFO - [2019-09-15 21:51:52,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:52,636] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:52,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:52,673] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:52,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.539 seconds
[2019-09-15 21:51:52,798] {scheduler_job.py:146} INFO - Started process (PID=24411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:57,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:51:57,810] {logging_mixin.py:95} INFO - [2019-09-15 21:51:57,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:58,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:51:58,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:51:58,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:51:58,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-15 21:51:58,335] {scheduler_job.py:146} INFO - Started process (PID=24412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:03,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:03,345] {logging_mixin.py:95} INFO - [2019-09-15 21:52:03,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:03,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:03,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:03,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:03,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.485 seconds
[2019-09-15 21:52:03,868] {scheduler_job.py:146} INFO - Started process (PID=24413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:08,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:08,877] {logging_mixin.py:95} INFO - [2019-09-15 21:52:08,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:09,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:09,352] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:09,364] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:09,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-15 21:52:09,406] {scheduler_job.py:146} INFO - Started process (PID=24415) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:14,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:14,413] {logging_mixin.py:95} INFO - [2019-09-15 21:52:14,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:14,799] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:14,823] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:14,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:14,841] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:52:14,951] {scheduler_job.py:146} INFO - Started process (PID=24416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:19,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:19,958] {logging_mixin.py:95} INFO - [2019-09-15 21:52:19,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:20,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:20,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:20,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:20,399] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-15 21:52:20,492] {scheduler_job.py:146} INFO - Started process (PID=24418) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:25,500] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:25,501] {logging_mixin.py:95} INFO - [2019-09-15 21:52:25,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:25,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:25,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:25,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:25,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 21:52:26,035] {scheduler_job.py:146} INFO - Started process (PID=24419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:31,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:31,046] {logging_mixin.py:95} INFO - [2019-09-15 21:52:31,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:31,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:31,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:31,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:31,481] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:52:31,580] {scheduler_job.py:146} INFO - Started process (PID=24420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:36,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:36,593] {logging_mixin.py:95} INFO - [2019-09-15 21:52:36,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:36,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:37,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:37,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:37,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:52:37,126] {scheduler_job.py:146} INFO - Started process (PID=24423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:42,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:42,133] {logging_mixin.py:95} INFO - [2019-09-15 21:52:42,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:42,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:42,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:42,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:42,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 21:52:42,659] {scheduler_job.py:146} INFO - Started process (PID=24424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:47,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:47,668] {logging_mixin.py:95} INFO - [2019-09-15 21:52:47,668] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:48,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:48,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:48,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:48,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:52:48,198] {scheduler_job.py:146} INFO - Started process (PID=24425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:53,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:53,207] {logging_mixin.py:95} INFO - [2019-09-15 21:52:53,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:53,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:53,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:53,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:53,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:52:53,739] {scheduler_job.py:146} INFO - Started process (PID=24427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:58,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:52:58,746] {logging_mixin.py:95} INFO - [2019-09-15 21:52:58,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:59,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:52:59,168] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:52:59,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:52:59,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:52:59,289] {scheduler_job.py:146} INFO - Started process (PID=24428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:04,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:04,296] {logging_mixin.py:95} INFO - [2019-09-15 21:53:04,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:04,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:04,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:04,717] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:04,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:53:04,839] {scheduler_job.py:146} INFO - Started process (PID=24430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:09,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:09,851] {logging_mixin.py:95} INFO - [2019-09-15 21:53:09,850] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:10,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:10,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:10,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:10,280] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-15 21:53:10,388] {scheduler_job.py:146} INFO - Started process (PID=24431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:15,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:15,396] {logging_mixin.py:95} INFO - [2019-09-15 21:53:15,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:15,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:15,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:15,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:15,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 21:53:15,841] {scheduler_job.py:146} INFO - Started process (PID=24432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:20,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:20,848] {logging_mixin.py:95} INFO - [2019-09-15 21:53:20,848] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:21,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:21,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:21,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:21,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:53:21,296] {scheduler_job.py:146} INFO - Started process (PID=24434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:26,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:26,312] {logging_mixin.py:95} INFO - [2019-09-15 21:53:26,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:26,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:26,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:26,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:26,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:53:26,840] {scheduler_job.py:146} INFO - Started process (PID=24435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:31,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:31,847] {logging_mixin.py:95} INFO - [2019-09-15 21:53:31,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:32,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:32,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:32,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:32,267] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:53:32,291] {scheduler_job.py:146} INFO - Started process (PID=24436) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:37,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:37,303] {logging_mixin.py:95} INFO - [2019-09-15 21:53:37,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:37,684] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:37,712] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:37,724] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:37,730] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 21:53:37,838] {scheduler_job.py:146} INFO - Started process (PID=24439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:42,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:42,845] {logging_mixin.py:95} INFO - [2019-09-15 21:53:42,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:43,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:43,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:43,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:43,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:53:43,289] {scheduler_job.py:146} INFO - Started process (PID=24440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:48,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:48,297] {logging_mixin.py:95} INFO - [2019-09-15 21:53:48,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:48,683] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:48,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:48,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:48,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:53:48,745] {scheduler_job.py:146} INFO - Started process (PID=24441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:53,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:53,753] {logging_mixin.py:95} INFO - [2019-09-15 21:53:53,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:54,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:54,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:54,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:54,173] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:53:54,196] {scheduler_job.py:146} INFO - Started process (PID=24443) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:59,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:53:59,204] {logging_mixin.py:95} INFO - [2019-09-15 21:53:59,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:59,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:53:59,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:53:59,622] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:53:59,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 21:53:59,738] {scheduler_job.py:146} INFO - Started process (PID=24444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:04,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:04,746] {logging_mixin.py:95} INFO - [2019-09-15 21:54:04,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:05,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:05,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:05,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:05,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 21:54:05,186] {scheduler_job.py:146} INFO - Started process (PID=24446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:10,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:10,194] {logging_mixin.py:95} INFO - [2019-09-15 21:54:10,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:10,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:10,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:10,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:10,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:54:10,640] {scheduler_job.py:146} INFO - Started process (PID=24447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:15,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:15,650] {logging_mixin.py:95} INFO - [2019-09-15 21:54:15,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:16,011] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:16,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:16,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:16,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:54:16,083] {scheduler_job.py:146} INFO - Started process (PID=24448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:21,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:21,094] {logging_mixin.py:95} INFO - [2019-09-15 21:54:21,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:21,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:21,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:21,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:21,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-15 21:54:21,529] {scheduler_job.py:146} INFO - Started process (PID=24450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:26,540] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:26,541] {logging_mixin.py:95} INFO - [2019-09-15 21:54:26,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:26,896] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:26,918] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:26,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:26,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 21:54:26,970] {scheduler_job.py:146} INFO - Started process (PID=24451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:31,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:31,978] {logging_mixin.py:95} INFO - [2019-09-15 21:54:31,977] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:32,335] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:32,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:32,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:32,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 21:54:32,421] {scheduler_job.py:146} INFO - Started process (PID=24452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:37,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:37,427] {logging_mixin.py:95} INFO - [2019-09-15 21:54:37,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:37,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:37,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:37,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:37,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 21:54:37,867] {scheduler_job.py:146} INFO - Started process (PID=24455) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:42,874] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:42,875] {logging_mixin.py:95} INFO - [2019-09-15 21:54:42,875] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:43,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:43,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:43,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:43,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 21:54:43,317] {scheduler_job.py:146} INFO - Started process (PID=24456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:48,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:48,327] {logging_mixin.py:95} INFO - [2019-09-15 21:54:48,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:48,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:48,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:48,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:48,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:54:48,772] {scheduler_job.py:146} INFO - Started process (PID=24457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:53,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:53,784] {logging_mixin.py:95} INFO - [2019-09-15 21:54:53,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:54,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:54,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:54,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:54,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 21:54:54,320] {scheduler_job.py:146} INFO - Started process (PID=24459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:59,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:54:59,327] {logging_mixin.py:95} INFO - [2019-09-15 21:54:59,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:59,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:54:59,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:54:59,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:54:59,747] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 21:54:59,770] {scheduler_job.py:146} INFO - Started process (PID=24460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:04,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:04,781] {logging_mixin.py:95} INFO - [2019-09-15 21:55:04,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:05,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:05,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:05,195] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:05,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:55:05,225] {scheduler_job.py:146} INFO - Started process (PID=24462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:10,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:10,235] {logging_mixin.py:95} INFO - [2019-09-15 21:55:10,234] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:10,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:10,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:10,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:10,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:55:10,770] {scheduler_job.py:146} INFO - Started process (PID=24463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:15,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:15,781] {logging_mixin.py:95} INFO - [2019-09-15 21:55:15,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:16,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:16,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:16,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:16,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:55:16,226] {scheduler_job.py:146} INFO - Started process (PID=24464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:21,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:21,236] {logging_mixin.py:95} INFO - [2019-09-15 21:55:21,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:21,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:21,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:21,655] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:21,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 21:55:21,771] {scheduler_job.py:146} INFO - Started process (PID=24466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:26,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:26,782] {logging_mixin.py:95} INFO - [2019-09-15 21:55:26,782] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:27,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:27,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:27,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:27,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:55:27,318] {scheduler_job.py:146} INFO - Started process (PID=24467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:32,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:32,329] {logging_mixin.py:95} INFO - [2019-09-15 21:55:32,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:32,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:32,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:32,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:32,756] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:55:32,867] {scheduler_job.py:146} INFO - Started process (PID=24468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:37,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:37,876] {logging_mixin.py:95} INFO - [2019-09-15 21:55:37,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:38,266] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:38,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:38,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:38,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 21:55:38,418] {scheduler_job.py:146} INFO - Started process (PID=24471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:43,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:43,427] {logging_mixin.py:95} INFO - [2019-09-15 21:55:43,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:43,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:43,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:43,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:43,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-15 21:55:43,965] {scheduler_job.py:146} INFO - Started process (PID=24472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:49,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:49,045] {logging_mixin.py:95} INFO - [2019-09-15 21:55:49,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:49,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:49,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:49,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:49,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-15 21:55:49,513] {scheduler_job.py:146} INFO - Started process (PID=24474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:54,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:55:54,523] {logging_mixin.py:95} INFO - [2019-09-15 21:55:54,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:54,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:55:54,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:55:54,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:55:54,945] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:55:55,052] {scheduler_job.py:146} INFO - Started process (PID=24475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:00,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:00,060] {logging_mixin.py:95} INFO - [2019-09-15 21:56:00,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:00,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:00,451] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:00,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:00,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 21:56:00,496] {scheduler_job.py:146} INFO - Started process (PID=24476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:05,501] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:05,502] {logging_mixin.py:95} INFO - [2019-09-15 21:56:05,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:05,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:05,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:05,908] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:05,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-15 21:56:05,944] {scheduler_job.py:146} INFO - Started process (PID=24478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:10,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:10,954] {logging_mixin.py:95} INFO - [2019-09-15 21:56:10,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:11,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:11,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:11,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:11,404] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-15 21:56:11,486] {scheduler_job.py:146} INFO - Started process (PID=24479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:16,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:16,494] {logging_mixin.py:95} INFO - [2019-09-15 21:56:16,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:16,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:16,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:16,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:16,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:56:16,943] {scheduler_job.py:146} INFO - Started process (PID=24480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:21,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:21,950] {logging_mixin.py:95} INFO - [2019-09-15 21:56:21,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:22,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:22,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:22,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:22,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:56:22,491] {scheduler_job.py:146} INFO - Started process (PID=24482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:27,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:27,500] {logging_mixin.py:95} INFO - [2019-09-15 21:56:27,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:27,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:27,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:27,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:27,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:56:28,040] {scheduler_job.py:146} INFO - Started process (PID=24483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:33,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:33,048] {logging_mixin.py:95} INFO - [2019-09-15 21:56:33,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:33,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:33,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:33,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:33,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:56:33,583] {scheduler_job.py:146} INFO - Started process (PID=24484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:38,592] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:38,593] {logging_mixin.py:95} INFO - [2019-09-15 21:56:38,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:38,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:38,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:39,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:39,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:56:39,120] {scheduler_job.py:146} INFO - Started process (PID=24487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:44,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:44,128] {logging_mixin.py:95} INFO - [2019-09-15 21:56:44,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:44,513] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:44,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:44,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:44,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:56:44,667] {scheduler_job.py:146} INFO - Started process (PID=24488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:49,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:49,675] {logging_mixin.py:95} INFO - [2019-09-15 21:56:49,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:50,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:50,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:50,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:50,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-15 21:56:50,217] {scheduler_job.py:146} INFO - Started process (PID=24490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:55,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:56:55,224] {logging_mixin.py:95} INFO - [2019-09-15 21:56:55,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:55,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:56:55,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:56:55,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:56:55,670] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 21:56:55,766] {scheduler_job.py:146} INFO - Started process (PID=24491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:00,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:00,774] {logging_mixin.py:95} INFO - [2019-09-15 21:57:00,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:01,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:01,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:01,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:01,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:57:01,314] {scheduler_job.py:146} INFO - Started process (PID=24492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:06,324] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:06,325] {logging_mixin.py:95} INFO - [2019-09-15 21:57:06,324] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:06,711] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:06,733] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:06,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:06,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:57:06,855] {scheduler_job.py:146} INFO - Started process (PID=24494) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:11,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:11,862] {logging_mixin.py:95} INFO - [2019-09-15 21:57:11,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:12,257] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:12,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:12,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:12,290] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:57:12,403] {scheduler_job.py:146} INFO - Started process (PID=24495) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:17,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:17,424] {logging_mixin.py:95} INFO - [2019-09-15 21:57:17,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:17,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:17,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:17,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:17,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-15 21:57:17,951] {scheduler_job.py:146} INFO - Started process (PID=24496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:22,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:22,958] {logging_mixin.py:95} INFO - [2019-09-15 21:57:22,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:23,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:23,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:23,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:23,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 21:57:23,497] {scheduler_job.py:146} INFO - Started process (PID=24498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:28,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:28,508] {logging_mixin.py:95} INFO - [2019-09-15 21:57:28,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:28,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:28,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:28,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:28,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 21:57:29,041] {scheduler_job.py:146} INFO - Started process (PID=24499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:34,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:34,048] {logging_mixin.py:95} INFO - [2019-09-15 21:57:34,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:34,437] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:34,459] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:34,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:34,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 21:57:34,588] {scheduler_job.py:146} INFO - Started process (PID=24501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:39,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:39,598] {logging_mixin.py:95} INFO - [2019-09-15 21:57:39,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:39,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:40,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:40,019] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:40,026] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:57:40,137] {scheduler_job.py:146} INFO - Started process (PID=24503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:45,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:45,148] {logging_mixin.py:95} INFO - [2019-09-15 21:57:45,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:45,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:45,554] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:45,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:45,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-15 21:57:45,680] {scheduler_job.py:146} INFO - Started process (PID=24504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:50,690] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:50,691] {logging_mixin.py:95} INFO - [2019-09-15 21:57:50,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:51,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:51,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:51,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:51,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:57:51,223] {scheduler_job.py:146} INFO - Started process (PID=24506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:56,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:57:56,232] {logging_mixin.py:95} INFO - [2019-09-15 21:57:56,231] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:56,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:57:56,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:57:56,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:57:56,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 21:57:56,674] {scheduler_job.py:146} INFO - Started process (PID=24507) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:01,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:01,680] {logging_mixin.py:95} INFO - [2019-09-15 21:58:01,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:02,065] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:02,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:02,098] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:02,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:58:02,130] {scheduler_job.py:146} INFO - Started process (PID=24508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:07,141] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:07,142] {logging_mixin.py:95} INFO - [2019-09-15 21:58:07,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:07,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:07,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:07,566] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:07,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 21:58:07,596] {scheduler_job.py:146} INFO - Started process (PID=24510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:12,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:12,615] {logging_mixin.py:95} INFO - [2019-09-15 21:58:12,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:13,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:13,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:13,036] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:13,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 21:58:13,067] {scheduler_job.py:146} INFO - Started process (PID=24511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:18,073] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:18,074] {logging_mixin.py:95} INFO - [2019-09-15 21:58:18,074] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:18,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:18,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:18,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:18,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:58:18,535] {scheduler_job.py:146} INFO - Started process (PID=24512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:23,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:23,544] {logging_mixin.py:95} INFO - [2019-09-15 21:58:23,544] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:23,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:23,958] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:23,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:23,974] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-15 21:58:24,003] {scheduler_job.py:146} INFO - Started process (PID=24514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:29,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:29,011] {logging_mixin.py:95} INFO - [2019-09-15 21:58:29,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:29,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:29,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:29,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:29,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:58:29,476] {scheduler_job.py:146} INFO - Started process (PID=24515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:34,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:34,488] {logging_mixin.py:95} INFO - [2019-09-15 21:58:34,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:34,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:34,900] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:34,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:34,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 21:58:34,945] {scheduler_job.py:146} INFO - Started process (PID=24517) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:39,955] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:39,956] {logging_mixin.py:95} INFO - [2019-09-15 21:58:39,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:40,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:40,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:40,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:40,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 21:58:40,403] {scheduler_job.py:146} INFO - Started process (PID=24519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:45,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:45,416] {logging_mixin.py:95} INFO - [2019-09-15 21:58:45,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:45,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:45,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:45,831] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:45,838] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:58:45,877] {scheduler_job.py:146} INFO - Started process (PID=24520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:50,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:50,890] {logging_mixin.py:95} INFO - [2019-09-15 21:58:50,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:51,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:51,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:51,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:51,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 21:58:51,351] {scheduler_job.py:146} INFO - Started process (PID=24522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:56,362] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:58:56,364] {logging_mixin.py:95} INFO - [2019-09-15 21:58:56,363] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:56,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:58:56,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:58:56,783] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:58:56,789] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 21:58:56,814] {scheduler_job.py:146} INFO - Started process (PID=24523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:01,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:01,820] {logging_mixin.py:95} INFO - [2019-09-15 21:59:01,820] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:02,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:02,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:02,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:02,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 21:59:02,276] {scheduler_job.py:146} INFO - Started process (PID=24524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:07,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:07,289] {logging_mixin.py:95} INFO - [2019-09-15 21:59:07,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:07,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:07,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:07,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:07,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 21:59:07,751] {scheduler_job.py:146} INFO - Started process (PID=24526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:12,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:12,763] {logging_mixin.py:95} INFO - [2019-09-15 21:59:12,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:13,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:13,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:13,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:13,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:59:13,216] {scheduler_job.py:146} INFO - Started process (PID=24527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:18,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:18,226] {logging_mixin.py:95} INFO - [2019-09-15 21:59:18,225] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:18,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:18,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:18,641] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:18,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-15 21:59:18,682] {scheduler_job.py:146} INFO - Started process (PID=24528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:23,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:23,690] {logging_mixin.py:95} INFO - [2019-09-15 21:59:23,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:24,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:24,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:24,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:24,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 21:59:24,160] {scheduler_job.py:146} INFO - Started process (PID=24530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:29,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:29,166] {logging_mixin.py:95} INFO - [2019-09-15 21:59:29,166] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:29,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:29,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:29,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:29,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.582 seconds
[2019-09-15 21:59:29,798] {scheduler_job.py:146} INFO - Started process (PID=24532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:34,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:34,807] {logging_mixin.py:95} INFO - [2019-09-15 21:59:34,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:35,222] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:35,246] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:35,258] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:35,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-15 21:59:35,351] {scheduler_job.py:146} INFO - Started process (PID=24534) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:40,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:40,358] {logging_mixin.py:95} INFO - [2019-09-15 21:59:40,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:40,735] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:40,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:40,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:40,785] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 21:59:40,904] {scheduler_job.py:146} INFO - Started process (PID=24536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:45,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:45,917] {logging_mixin.py:95} INFO - [2019-09-15 21:59:45,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:46,265] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:46,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:46,297] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:46,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 21:59:46,348] {scheduler_job.py:146} INFO - Started process (PID=24537) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:51,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:51,372] {logging_mixin.py:95} INFO - [2019-09-15 21:59:51,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:51,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:51,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:51,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:51,886] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.538 seconds
[2019-09-15 21:59:51,995] {scheduler_job.py:146} INFO - Started process (PID=24541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:56,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 21:59:57,000] {logging_mixin.py:95} INFO - [2019-09-15 21:59:57,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:57,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 21:59:57,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 21:59:57,506] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 21:59:57,512] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.517 seconds
[2019-09-15 21:59:57,626] {scheduler_job.py:146} INFO - Started process (PID=24546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:02,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:02,632] {logging_mixin.py:95} INFO - [2019-09-15 22:00:02,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:03,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:03,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:03,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:03,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.568 seconds
[2019-09-15 22:00:03,248] {scheduler_job.py:146} INFO - Started process (PID=24547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:08,256] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:08,257] {logging_mixin.py:95} INFO - [2019-09-15 22:00:08,257] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:08,661] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:08,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:08,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:08,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-15 22:00:08,770] {scheduler_job.py:146} INFO - Started process (PID=24549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:13,776] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:13,777] {logging_mixin.py:95} INFO - [2019-09-15 22:00:13,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:14,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:14,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:14,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:14,315] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.545 seconds
[2019-09-15 22:00:14,396] {scheduler_job.py:146} INFO - Started process (PID=24550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:19,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:19,404] {logging_mixin.py:95} INFO - [2019-09-15 22:00:19,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:19,833] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:19,861] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:19,872] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:19,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 22:00:19,911] {scheduler_job.py:146} INFO - Started process (PID=24552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:24,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:24,922] {logging_mixin.py:95} INFO - [2019-09-15 22:00:24,922] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:25,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:25,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:25,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:25,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.491 seconds
[2019-09-15 22:00:25,432] {scheduler_job.py:146} INFO - Started process (PID=24553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:30,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:30,441] {logging_mixin.py:95} INFO - [2019-09-15 22:00:30,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:30,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:30,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:30,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:30,900] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-15 22:00:30,952] {scheduler_job.py:146} INFO - Started process (PID=24554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:35,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:35,962] {logging_mixin.py:95} INFO - [2019-09-15 22:00:35,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:36,380] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:36,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:36,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:36,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-15 22:00:36,471] {scheduler_job.py:146} INFO - Started process (PID=24556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:41,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:41,477] {logging_mixin.py:95} INFO - [2019-09-15 22:00:41,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:41,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:41,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:41,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:41,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-15 22:00:42,095] {scheduler_job.py:146} INFO - Started process (PID=24558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:47,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:47,104] {logging_mixin.py:95} INFO - [2019-09-15 22:00:47,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:47,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:47,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:47,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:47,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.593 seconds
[2019-09-15 22:00:47,732] {scheduler_job.py:146} INFO - Started process (PID=24565) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:52,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:52,742] {logging_mixin.py:95} INFO - [2019-09-15 22:00:52,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:53,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:53,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:53,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:53,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-15 22:00:53,269] {scheduler_job.py:146} INFO - Started process (PID=24579) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:58,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:00:58,276] {logging_mixin.py:95} INFO - [2019-09-15 22:00:58,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:58,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:00:58,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:00:58,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:00:58,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-15 22:00:58,739] {scheduler_job.py:146} INFO - Started process (PID=24580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:03,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:03,747] {logging_mixin.py:95} INFO - [2019-09-15 22:01:03,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:04,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:04,205] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:04,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:04,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-15 22:01:04,271] {scheduler_job.py:146} INFO - Started process (PID=24581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:09,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:09,282] {logging_mixin.py:95} INFO - [2019-09-15 22:01:09,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:09,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:09,776] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:09,789] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:09,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.525 seconds
[2019-09-15 22:01:09,907] {scheduler_job.py:146} INFO - Started process (PID=24583) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:14,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:14,918] {logging_mixin.py:95} INFO - [2019-09-15 22:01:14,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:15,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:15,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:15,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:15,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 22:01:15,450] {scheduler_job.py:146} INFO - Started process (PID=24584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:20,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:20,461] {logging_mixin.py:95} INFO - [2019-09-15 22:01:20,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:20,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:20,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:20,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:20,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 22:01:20,999] {scheduler_job.py:146} INFO - Started process (PID=24589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:26,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:26,006] {logging_mixin.py:95} INFO - [2019-09-15 22:01:26,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:26,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:26,430] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:26,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:26,450] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 22:01:26,548] {scheduler_job.py:146} INFO - Started process (PID=24590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:31,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:31,557] {logging_mixin.py:95} INFO - [2019-09-15 22:01:31,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:31,934] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:31,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:31,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:31,982] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-15 22:01:32,004] {scheduler_job.py:146} INFO - Started process (PID=24591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:37,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:37,014] {logging_mixin.py:95} INFO - [2019-09-15 22:01:37,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:37,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:37,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:37,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:37,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.482 seconds
[2019-09-15 22:01:37,543] {scheduler_job.py:146} INFO - Started process (PID=24594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:42,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:42,552] {logging_mixin.py:95} INFO - [2019-09-15 22:01:42,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:42,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:42,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:42,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:42,946] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 22:01:42,995] {scheduler_job.py:146} INFO - Started process (PID=24595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:48,005] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:48,006] {logging_mixin.py:95} INFO - [2019-09-15 22:01:48,005] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:48,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:48,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:48,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:48,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-15 22:01:48,445] {scheduler_job.py:146} INFO - Started process (PID=24596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:53,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:53,454] {logging_mixin.py:95} INFO - [2019-09-15 22:01:53,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:53,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:53,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:53,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:53,909] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-15 22:01:53,984] {scheduler_job.py:146} INFO - Started process (PID=24600) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:58,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:01:58,991] {logging_mixin.py:95} INFO - [2019-09-15 22:01:58,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:59,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:01:59,435] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:01:59,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:01:59,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 22:01:59,541] {scheduler_job.py:146} INFO - Started process (PID=24601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:04,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:04,550] {logging_mixin.py:95} INFO - [2019-09-15 22:02:04,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:04,956] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:04,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:04,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:04,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 22:02:05,090] {scheduler_job.py:146} INFO - Started process (PID=24603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:10,099] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:10,101] {logging_mixin.py:95} INFO - [2019-09-15 22:02:10,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:10,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:10,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:10,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:10,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-09-15 22:02:10,638] {scheduler_job.py:146} INFO - Started process (PID=24604) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:15,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:15,650] {logging_mixin.py:95} INFO - [2019-09-15 22:02:15,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:16,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:16,096] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:16,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:16,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-15 22:02:16,185] {scheduler_job.py:146} INFO - Started process (PID=24605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:21,195] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:21,196] {logging_mixin.py:95} INFO - [2019-09-15 22:02:21,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:21,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:21,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:21,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:21,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-15 22:02:21,728] {scheduler_job.py:146} INFO - Started process (PID=24607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:26,735] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:26,738] {logging_mixin.py:95} INFO - [2019-09-15 22:02:26,736] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:27,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:27,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:27,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:27,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 22:02:27,278] {scheduler_job.py:146} INFO - Started process (PID=24608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:32,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:32,288] {logging_mixin.py:95} INFO - [2019-09-15 22:02:32,288] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:32,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:32,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:32,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:32,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-15 22:02:32,825] {scheduler_job.py:146} INFO - Started process (PID=24609) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:37,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:37,834] {logging_mixin.py:95} INFO - [2019-09-15 22:02:37,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:38,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:38,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:38,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:38,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-15 22:02:38,280] {scheduler_job.py:146} INFO - Started process (PID=24613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:43,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:43,289] {logging_mixin.py:95} INFO - [2019-09-15 22:02:43,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:43,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:43,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:43,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:43,725] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 22:02:43,815] {scheduler_job.py:146} INFO - Started process (PID=24614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:48,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:48,823] {logging_mixin.py:95} INFO - [2019-09-15 22:02:48,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:49,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:49,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:49,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:49,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-15 22:02:49,352] {scheduler_job.py:146} INFO - Started process (PID=24615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:54,360] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:54,361] {logging_mixin.py:95} INFO - [2019-09-15 22:02:54,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:54,724] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:54,745] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:02:54,754] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:02:54,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-15 22:02:54,799] {scheduler_job.py:146} INFO - Started process (PID=24617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:02:59,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:02:59,810] {logging_mixin.py:95} INFO - [2019-09-15 22:02:59,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:00,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:00,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:00,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:00,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-15 22:03:00,347] {scheduler_job.py:146} INFO - Started process (PID=24618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:05,357] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:05,358] {logging_mixin.py:95} INFO - [2019-09-15 22:03:05,358] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:05,803] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:05,825] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:05,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:05,842] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.495 seconds
[2019-09-15 22:03:05,891] {scheduler_job.py:146} INFO - Started process (PID=24620) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:10,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:10,904] {logging_mixin.py:95} INFO - [2019-09-15 22:03:10,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:11,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:11,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:11,399] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:11,411] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.521 seconds
[2019-09-15 22:03:11,444] {scheduler_job.py:146} INFO - Started process (PID=24621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:16,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:16,456] {logging_mixin.py:95} INFO - [2019-09-15 22:03:16,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:16,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:16,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:16,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:16,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-09-15 22:03:16,979] {scheduler_job.py:146} INFO - Started process (PID=24622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:21,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:21,990] {logging_mixin.py:95} INFO - [2019-09-15 22:03:21,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:22,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:22,380] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:22,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:22,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-15 22:03:22,431] {scheduler_job.py:146} INFO - Started process (PID=24624) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:27,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:27,439] {logging_mixin.py:95} INFO - [2019-09-15 22:03:27,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:27,849] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:27,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:27,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:27,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-15 22:03:27,978] {scheduler_job.py:146} INFO - Started process (PID=24625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:32,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:32,992] {logging_mixin.py:95} INFO - [2019-09-15 22:03:32,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:33,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:33,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:33,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:33,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 22:03:33,508] {scheduler_job.py:146} INFO - Started process (PID=24626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:38,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:38,517] {logging_mixin.py:95} INFO - [2019-09-15 22:03:38,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:38,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:38,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:38,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:38,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-15 22:03:38,956] {scheduler_job.py:146} INFO - Started process (PID=24629) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:43,966] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:43,967] {logging_mixin.py:95} INFO - [2019-09-15 22:03:43,966] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:44,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:44,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:44,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:44,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 22:03:44,509] {scheduler_job.py:146} INFO - Started process (PID=24630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:49,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:49,518] {logging_mixin.py:95} INFO - [2019-09-15 22:03:49,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:49,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:49,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:49,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:49,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 22:03:50,053] {scheduler_job.py:146} INFO - Started process (PID=24632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:55,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:03:55,065] {logging_mixin.py:95} INFO - [2019-09-15 22:03:55,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:55,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:03:55,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:03:55,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:03:55,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 22:03:55,594] {scheduler_job.py:146} INFO - Started process (PID=24633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:00,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:00,603] {logging_mixin.py:95} INFO - [2019-09-15 22:04:00,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:01,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:01,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:01,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:01,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-09-15 22:04:01,147] {scheduler_job.py:146} INFO - Started process (PID=24634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:06,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:06,161] {logging_mixin.py:95} INFO - [2019-09-15 22:04:06,161] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:06,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:06,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:06,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:06,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 22:04:06,695] {scheduler_job.py:146} INFO - Started process (PID=24636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:11,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:11,702] {logging_mixin.py:95} INFO - [2019-09-15 22:04:11,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:12,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:12,085] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:12,095] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:12,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-15 22:04:12,149] {scheduler_job.py:146} INFO - Started process (PID=24637) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:17,162] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:17,163] {logging_mixin.py:95} INFO - [2019-09-15 22:04:17,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:17,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:17,624] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:17,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:17,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.493 seconds
[2019-09-15 22:04:17,680] {scheduler_job.py:146} INFO - Started process (PID=24638) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:22,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:22,693] {logging_mixin.py:95} INFO - [2019-09-15 22:04:22,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:23,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:23,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:23,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:23,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 22:04:23,229] {scheduler_job.py:146} INFO - Started process (PID=24640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:28,236] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:28,237] {logging_mixin.py:95} INFO - [2019-09-15 22:04:28,236] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:28,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:28,638] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:28,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:28,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 22:04:28,773] {scheduler_job.py:146} INFO - Started process (PID=24649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:33,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:33,781] {logging_mixin.py:95} INFO - [2019-09-15 22:04:33,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:34,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:34,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:34,169] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:34,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 22:04:34,205] {scheduler_job.py:146} INFO - Started process (PID=24650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:39,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:39,212] {logging_mixin.py:95} INFO - [2019-09-15 22:04:39,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:39,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:39,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:39,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:39,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.657 seconds
[2019-09-15 22:04:39,953] {scheduler_job.py:146} INFO - Started process (PID=24660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:44,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:44,963] {logging_mixin.py:95} INFO - [2019-09-15 22:04:44,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:45,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:45,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:45,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:45,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-15 22:04:45,399] {scheduler_job.py:146} INFO - Started process (PID=24662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:50,410] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:50,412] {logging_mixin.py:95} INFO - [2019-09-15 22:04:50,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:50,807] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:50,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:50,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:50,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-15 22:04:50,945] {scheduler_job.py:146} INFO - Started process (PID=24666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:55,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:04:55,953] {logging_mixin.py:95} INFO - [2019-09-15 22:04:55,952] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:56,297] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:04:56,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:04:56,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:04:56,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-15 22:04:56,382] {scheduler_job.py:146} INFO - Started process (PID=24667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:01,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:01,390] {logging_mixin.py:95} INFO - [2019-09-15 22:05:01,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:01,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:01,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:01,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:01,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 22:05:01,837] {scheduler_job.py:146} INFO - Started process (PID=24668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:06,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:06,848] {logging_mixin.py:95} INFO - [2019-09-15 22:05:06,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:07,193] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:07,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:07,224] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:07,230] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 22:05:07,295] {scheduler_job.py:146} INFO - Started process (PID=24670) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:12,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:12,305] {logging_mixin.py:95} INFO - [2019-09-15 22:05:12,304] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:12,652] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:12,676] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:12,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:12,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-15 22:05:12,746] {scheduler_job.py:146} INFO - Started process (PID=24671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:17,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:17,754] {logging_mixin.py:95} INFO - [2019-09-15 22:05:17,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:18,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:18,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:18,189] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:18,195] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 22:05:18,292] {scheduler_job.py:146} INFO - Started process (PID=24672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:23,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:23,301] {logging_mixin.py:95} INFO - [2019-09-15 22:05:23,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:23,672] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:23,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:23,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:23,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-15 22:05:23,732] {scheduler_job.py:146} INFO - Started process (PID=24674) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:28,739] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:28,740] {logging_mixin.py:95} INFO - [2019-09-15 22:05:28,740] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:29,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:29,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:29,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:29,134] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 22:05:29,189] {scheduler_job.py:146} INFO - Started process (PID=24675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:34,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:34,198] {logging_mixin.py:95} INFO - [2019-09-15 22:05:34,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:34,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:34,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:34,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:34,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 22:05:34,643] {scheduler_job.py:146} INFO - Started process (PID=24676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:39,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:39,651] {logging_mixin.py:95} INFO - [2019-09-15 22:05:39,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:40,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:40,025] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:40,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:40,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 22:05:40,094] {scheduler_job.py:146} INFO - Started process (PID=24679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:45,105] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:45,116] {logging_mixin.py:95} INFO - [2019-09-15 22:05:45,115] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:45,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:45,487] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:45,496] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:45,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-15 22:05:45,549] {scheduler_job.py:146} INFO - Started process (PID=24680) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:50,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:50,560] {logging_mixin.py:95} INFO - [2019-09-15 22:05:50,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:50,914] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:50,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:50,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:50,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 22:05:51,005] {scheduler_job.py:146} INFO - Started process (PID=24682) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:56,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:05:56,013] {logging_mixin.py:95} INFO - [2019-09-15 22:05:56,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:56,407] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:05:56,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:05:56,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:05:56,447] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-15 22:05:56,554] {scheduler_job.py:146} INFO - Started process (PID=24683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:01,564] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:01,565] {logging_mixin.py:95} INFO - [2019-09-15 22:06:01,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:01,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:01,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:01,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:01,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 22:06:01,995] {scheduler_job.py:146} INFO - Started process (PID=24684) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:07,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:07,007] {logging_mixin.py:95} INFO - [2019-09-15 22:06:07,006] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:07,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:07,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:07,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:07,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 22:06:07,460] {scheduler_job.py:146} INFO - Started process (PID=24686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:12,467] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:12,477] {logging_mixin.py:95} INFO - [2019-09-15 22:06:12,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:12,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:12,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:12,856] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:12,861] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-15 22:06:12,903] {scheduler_job.py:146} INFO - Started process (PID=24689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:17,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:17,922] {logging_mixin.py:95} INFO - [2019-09-15 22:06:17,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:18,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:18,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:18,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:18,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-15 22:06:18,361] {scheduler_job.py:146} INFO - Started process (PID=24690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:23,374] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:23,375] {logging_mixin.py:95} INFO - [2019-09-15 22:06:23,375] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:23,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:23,741] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:23,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:23,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 22:06:23,825] {scheduler_job.py:146} INFO - Started process (PID=24692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:28,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:28,837] {logging_mixin.py:95} INFO - [2019-09-15 22:06:28,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:29,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:29,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:29,216] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:29,222] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 22:06:29,286] {scheduler_job.py:146} INFO - Started process (PID=24693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:34,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:34,295] {logging_mixin.py:95} INFO - [2019-09-15 22:06:34,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:34,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:34,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:34,689] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:34,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 22:06:34,743] {scheduler_job.py:146} INFO - Started process (PID=24695) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:39,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:39,751] {logging_mixin.py:95} INFO - [2019-09-15 22:06:39,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:40,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:40,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:40,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:40,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 22:06:40,204] {scheduler_job.py:146} INFO - Started process (PID=24698) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:45,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:45,212] {logging_mixin.py:95} INFO - [2019-09-15 22:06:45,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:45,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:45,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:45,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:45,589] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 22:06:45,668] {scheduler_job.py:146} INFO - Started process (PID=24699) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:50,680] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:50,681] {logging_mixin.py:95} INFO - [2019-09-15 22:06:50,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:51,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:51,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:51,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:51,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-15 22:06:51,128] {scheduler_job.py:146} INFO - Started process (PID=24701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:56,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:06:56,141] {logging_mixin.py:95} INFO - [2019-09-15 22:06:56,141] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:56,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:06:56,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:06:56,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:06:56,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-15 22:06:56,588] {scheduler_job.py:146} INFO - Started process (PID=24702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:01,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:01,597] {logging_mixin.py:95} INFO - [2019-09-15 22:07:01,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:01,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:01,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:01,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:01,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 22:07:02,056] {scheduler_job.py:146} INFO - Started process (PID=24703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:07,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:07,067] {logging_mixin.py:95} INFO - [2019-09-15 22:07:07,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:07,421] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:07,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:07,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:07,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 22:07:07,515] {scheduler_job.py:146} INFO - Started process (PID=24705) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:12,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:12,524] {logging_mixin.py:95} INFO - [2019-09-15 22:07:12,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:12,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:12,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:12,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:12,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 22:07:13,066] {scheduler_job.py:146} INFO - Started process (PID=24713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:18,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:18,077] {logging_mixin.py:95} INFO - [2019-09-15 22:07:18,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:18,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:18,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:18,502] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:18,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-15 22:07:18,606] {scheduler_job.py:146} INFO - Started process (PID=24714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:23,615] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:23,616] {logging_mixin.py:95} INFO - [2019-09-15 22:07:23,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:24,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:24,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:24,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:24,041] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 22:07:24,147] {scheduler_job.py:146} INFO - Started process (PID=24716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:29,157] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:29,158] {logging_mixin.py:95} INFO - [2019-09-15 22:07:29,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:29,522] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:29,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:29,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:29,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-15 22:07:29,596] {scheduler_job.py:146} INFO - Started process (PID=24717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:34,604] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:34,605] {logging_mixin.py:95} INFO - [2019-09-15 22:07:34,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:35,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:35,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:35,110] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:35,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.525 seconds
[2019-09-15 22:07:35,155] {scheduler_job.py:146} INFO - Started process (PID=24720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:40,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:40,168] {logging_mixin.py:95} INFO - [2019-09-15 22:07:40,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:40,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:40,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:40,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:40,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 22:07:40,693] {scheduler_job.py:146} INFO - Started process (PID=24726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:45,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:45,703] {logging_mixin.py:95} INFO - [2019-09-15 22:07:45,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:46,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:46,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:46,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:46,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 22:07:46,143] {scheduler_job.py:146} INFO - Started process (PID=24727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:51,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:51,152] {logging_mixin.py:95} INFO - [2019-09-15 22:07:51,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:51,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:51,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:51,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:51,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-15 22:07:51,593] {scheduler_job.py:146} INFO - Started process (PID=24729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:56,599] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:07:56,600] {logging_mixin.py:95} INFO - [2019-09-15 22:07:56,600] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:56,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:07:56,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:07:56,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:07:56,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 22:07:57,052] {scheduler_job.py:146} INFO - Started process (PID=24730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:02,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:02,061] {logging_mixin.py:95} INFO - [2019-09-15 22:08:02,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:02,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:02,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:02,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:02,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-15 22:08:02,601] {scheduler_job.py:146} INFO - Started process (PID=24731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:07,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:07,612] {logging_mixin.py:95} INFO - [2019-09-15 22:08:07,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:08,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:08,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:08,056] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:08,062] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 22:08:08,134] {scheduler_job.py:146} INFO - Started process (PID=24738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:13,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:13,147] {logging_mixin.py:95} INFO - [2019-09-15 22:08:13,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:13,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:13,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:13,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:13,585] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 22:08:13,671] {scheduler_job.py:146} INFO - Started process (PID=24739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:18,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:18,680] {logging_mixin.py:95} INFO - [2019-09-15 22:08:18,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:19,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:19,128] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:19,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:19,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-15 22:08:19,202] {scheduler_job.py:146} INFO - Started process (PID=24740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:24,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:24,213] {logging_mixin.py:95} INFO - [2019-09-15 22:08:24,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:24,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:24,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:24,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:24,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-15 22:08:24,743] {scheduler_job.py:146} INFO - Started process (PID=24742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:29,750] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:29,751] {logging_mixin.py:95} INFO - [2019-09-15 22:08:29,751] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:30,142] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:30,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:30,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:30,187] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-15 22:08:30,291] {scheduler_job.py:146} INFO - Started process (PID=24743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:35,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:35,301] {logging_mixin.py:95} INFO - [2019-09-15 22:08:35,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:35,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:35,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:35,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:35,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-15 22:08:35,836] {scheduler_job.py:146} INFO - Started process (PID=24745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:40,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:40,846] {logging_mixin.py:95} INFO - [2019-09-15 22:08:40,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:41,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:41,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:41,315] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:41,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 22:08:41,374] {scheduler_job.py:146} INFO - Started process (PID=24747) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:46,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:46,384] {logging_mixin.py:95} INFO - [2019-09-15 22:08:46,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:46,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:46,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:46,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:46,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-15 22:08:46,916] {scheduler_job.py:146} INFO - Started process (PID=24749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:51,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:51,924] {logging_mixin.py:95} INFO - [2019-09-15 22:08:51,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:52,313] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:52,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:52,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:52,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 22:08:52,461] {scheduler_job.py:146} INFO - Started process (PID=24751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:57,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:08:57,473] {logging_mixin.py:95} INFO - [2019-09-15 22:08:57,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:57,937] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:08:57,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:08:57,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:08:57,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.522 seconds
[2019-09-15 22:08:58,011] {scheduler_job.py:146} INFO - Started process (PID=24752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:03,019] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:03,020] {logging_mixin.py:95} INFO - [2019-09-15 22:09:03,019] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:03,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:03,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:03,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:03,531] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.520 seconds
[2019-09-15 22:09:03,645] {scheduler_job.py:146} INFO - Started process (PID=24753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:08,654] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:08,655] {logging_mixin.py:95} INFO - [2019-09-15 22:09:08,655] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:09,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:09,081] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:09,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:09,099] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-15 22:09:09,179] {scheduler_job.py:146} INFO - Started process (PID=24755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:14,191] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:14,192] {logging_mixin.py:95} INFO - [2019-09-15 22:09:14,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:14,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:14,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:14,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:14,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-15 22:09:14,722] {scheduler_job.py:146} INFO - Started process (PID=24756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:19,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:19,733] {logging_mixin.py:95} INFO - [2019-09-15 22:09:19,732] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:20,122] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:20,145] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:20,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:20,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-15 22:09:20,263] {scheduler_job.py:146} INFO - Started process (PID=24760) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:25,270] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:25,271] {logging_mixin.py:95} INFO - [2019-09-15 22:09:25,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:25,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:25,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:25,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:25,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-15 22:09:25,810] {scheduler_job.py:146} INFO - Started process (PID=24761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:30,820] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:30,821] {logging_mixin.py:95} INFO - [2019-09-15 22:09:30,821] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:31,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:31,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:31,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:31,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-15 22:09:31,359] {scheduler_job.py:146} INFO - Started process (PID=24762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:36,367] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:36,368] {logging_mixin.py:95} INFO - [2019-09-15 22:09:36,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:36,788] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:36,814] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:36,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:36,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-15 22:09:36,902] {scheduler_job.py:146} INFO - Started process (PID=24764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:41,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:41,920] {logging_mixin.py:95} INFO - [2019-09-15 22:09:41,920] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:42,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:42,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:42,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:42,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.490 seconds
[2019-09-15 22:09:42,444] {scheduler_job.py:146} INFO - Started process (PID=24766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:47,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:47,454] {logging_mixin.py:95} INFO - [2019-09-15 22:09:47,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:47,862] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:47,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:47,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:47,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-15 22:09:47,979] {scheduler_job.py:146} INFO - Started process (PID=24767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:52,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:52,987] {logging_mixin.py:95} INFO - [2019-09-15 22:09:52,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:53,391] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:53,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:53,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:53,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 22:09:53,522] {scheduler_job.py:146} INFO - Started process (PID=24769) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:58,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:09:58,534] {logging_mixin.py:95} INFO - [2019-09-15 22:09:58,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:58,963] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:09:58,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:09:58,998] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:09:59,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 22:09:59,064] {scheduler_job.py:146} INFO - Started process (PID=24770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:04,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:04,073] {logging_mixin.py:95} INFO - [2019-09-15 22:10:04,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:04,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:04,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:04,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:04,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-15 22:10:04,597] {scheduler_job.py:146} INFO - Started process (PID=24774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:09,608] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:09,610] {logging_mixin.py:95} INFO - [2019-09-15 22:10:09,609] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:10,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:10,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:10,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:10,052] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-15 22:10:10,140] {scheduler_job.py:146} INFO - Started process (PID=24776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:15,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:15,149] {logging_mixin.py:95} INFO - [2019-09-15 22:10:15,149] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:15,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:15,618] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:15,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:15,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-15 22:10:15,681] {scheduler_job.py:146} INFO - Started process (PID=24777) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:20,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:20,694] {logging_mixin.py:95} INFO - [2019-09-15 22:10:20,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:21,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:21,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:21,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:21,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.608 seconds
[2019-09-15 22:10:21,317] {scheduler_job.py:146} INFO - Started process (PID=24780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:26,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:26,329] {logging_mixin.py:95} INFO - [2019-09-15 22:10:26,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:26,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:26,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:26,755] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:26,763] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-15 22:10:26,856] {scheduler_job.py:146} INFO - Started process (PID=24781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:31,867] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:31,868] {logging_mixin.py:95} INFO - [2019-09-15 22:10:31,868] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:32,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:32,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:32,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:32,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-15 22:10:32,391] {scheduler_job.py:146} INFO - Started process (PID=24782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:37,402] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:37,403] {logging_mixin.py:95} INFO - [2019-09-15 22:10:37,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:37,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:37,886] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:37,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:37,903] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-15 22:10:37,929] {scheduler_job.py:146} INFO - Started process (PID=24785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:42,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:42,939] {logging_mixin.py:95} INFO - [2019-09-15 22:10:42,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:43,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:43,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:43,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:43,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.496 seconds
[2019-09-15 22:10:43,464] {scheduler_job.py:146} INFO - Started process (PID=24786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:48,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:48,472] {logging_mixin.py:95} INFO - [2019-09-15 22:10:48,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:48,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:48,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:48,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:48,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-15 22:10:48,996] {scheduler_job.py:146} INFO - Started process (PID=24787) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:54,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:54,008] {logging_mixin.py:95} INFO - [2019-09-15 22:10:54,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:54,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:54,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:10:54,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:10:54,460] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-15 22:10:54,538] {scheduler_job.py:146} INFO - Started process (PID=24790) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:10:59,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:10:59,551] {logging_mixin.py:95} INFO - [2019-09-15 22:10:59,551] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:00,004] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:00,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:00,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:00,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-15 22:11:00,080] {scheduler_job.py:146} INFO - Started process (PID=24791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:05,090] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:05,091] {logging_mixin.py:95} INFO - [2019-09-15 22:11:05,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:05,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:05,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:05,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:05,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-15 22:11:05,620] {scheduler_job.py:146} INFO - Started process (PID=24793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:10,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:10,633] {logging_mixin.py:95} INFO - [2019-09-15 22:11:10,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:11,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:11,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:11,168] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:11,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.555 seconds
[2019-09-15 22:11:11,255] {scheduler_job.py:146} INFO - Started process (PID=24794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:16,265] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:16,266] {logging_mixin.py:95} INFO - [2019-09-15 22:11:16,266] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:16,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:16,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:16,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:16,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-15 22:11:16,798] {scheduler_job.py:146} INFO - Started process (PID=24795) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:21,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:21,812] {logging_mixin.py:95} INFO - [2019-09-15 22:11:21,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:22,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:22,239] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:22,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:22,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-15 22:11:22,332] {scheduler_job.py:146} INFO - Started process (PID=24797) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:27,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:27,343] {logging_mixin.py:95} INFO - [2019-09-15 22:11:27,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:27,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:27,874] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:27,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:27,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.561 seconds
[2019-09-15 22:11:27,963] {scheduler_job.py:146} INFO - Started process (PID=24798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:32,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:32,974] {logging_mixin.py:95} INFO - [2019-09-15 22:11:32,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:33,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:33,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:33,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:33,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.520 seconds
[2019-09-15 22:11:33,511] {scheduler_job.py:146} INFO - Started process (PID=24799) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:38,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:38,523] {logging_mixin.py:95} INFO - [2019-09-15 22:11:38,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:38,986] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:39,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:39,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:39,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.521 seconds
[2019-09-15 22:11:39,145] {scheduler_job.py:146} INFO - Started process (PID=24804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:44,155] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:44,156] {logging_mixin.py:95} INFO - [2019-09-15 22:11:44,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:44,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:44,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:44,589] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:44,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-15 22:11:44,683] {scheduler_job.py:146} INFO - Started process (PID=24805) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:49,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:49,692] {logging_mixin.py:95} INFO - [2019-09-15 22:11:49,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:50,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:50,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:50,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:50,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-15 22:11:50,222] {scheduler_job.py:146} INFO - Started process (PID=24807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:55,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:11:55,233] {logging_mixin.py:95} INFO - [2019-09-15 22:11:55,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:55,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:11:55,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:11:55,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:11:55,644] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-15 22:11:55,668] {scheduler_job.py:146} INFO - Started process (PID=24811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:00,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:00,680] {logging_mixin.py:95} INFO - [2019-09-15 22:12:00,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:01,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:01,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:01,061] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:01,067] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-15 22:12:01,117] {scheduler_job.py:146} INFO - Started process (PID=24812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:06,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:06,130] {logging_mixin.py:95} INFO - [2019-09-15 22:12:06,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:06,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:06,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:06,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:06,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 22:12:06,578] {scheduler_job.py:146} INFO - Started process (PID=24814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:11,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:11,594] {logging_mixin.py:95} INFO - [2019-09-15 22:12:11,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:11,962] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:11,986] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:11,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:12,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 22:12:12,029] {scheduler_job.py:146} INFO - Started process (PID=24815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:17,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:17,037] {logging_mixin.py:95} INFO - [2019-09-15 22:12:17,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:17,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:17,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:17,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:17,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 22:12:17,482] {scheduler_job.py:146} INFO - Started process (PID=24816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:22,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:22,489] {logging_mixin.py:95} INFO - [2019-09-15 22:12:22,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:22,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:22,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:22,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:22,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 22:12:22,944] {scheduler_job.py:146} INFO - Started process (PID=24818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:27,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:27,955] {logging_mixin.py:95} INFO - [2019-09-15 22:12:27,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:28,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:28,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:28,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:28,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-15 22:12:28,407] {scheduler_job.py:146} INFO - Started process (PID=24819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:33,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:33,416] {logging_mixin.py:95} INFO - [2019-09-15 22:12:33,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:33,797] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:33,820] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:33,828] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:33,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-15 22:12:33,854] {scheduler_job.py:146} INFO - Started process (PID=24820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:38,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:38,861] {logging_mixin.py:95} INFO - [2019-09-15 22:12:38,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:39,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:39,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:39,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:39,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 22:12:39,308] {scheduler_job.py:146} INFO - Started process (PID=24823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:44,319] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:44,320] {logging_mixin.py:95} INFO - [2019-09-15 22:12:44,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:44,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:44,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:44,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:44,696] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 22:12:44,765] {scheduler_job.py:146} INFO - Started process (PID=24824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:49,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:49,772] {logging_mixin.py:95} INFO - [2019-09-15 22:12:49,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:50,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:50,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:50,150] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:50,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-15 22:12:50,215] {scheduler_job.py:146} INFO - Started process (PID=24826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:55,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:12:55,225] {logging_mixin.py:95} INFO - [2019-09-15 22:12:55,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:55,635] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:12:55,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:12:55,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:12:55,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-15 22:12:55,775] {scheduler_job.py:146} INFO - Started process (PID=24827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:00,781] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:00,782] {logging_mixin.py:95} INFO - [2019-09-15 22:13:00,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:01,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:01,184] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:01,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:01,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-15 22:13:01,236] {scheduler_job.py:146} INFO - Started process (PID=24828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:06,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:06,242] {logging_mixin.py:95} INFO - [2019-09-15 22:13:06,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:06,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:06,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:06,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:06,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-15 22:13:06,769] {scheduler_job.py:146} INFO - Started process (PID=24830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:11,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:11,788] {logging_mixin.py:95} INFO - [2019-09-15 22:13:11,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:12,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:12,179] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:12,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:12,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-15 22:13:12,219] {scheduler_job.py:146} INFO - Started process (PID=24831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:17,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:17,226] {logging_mixin.py:95} INFO - [2019-09-15 22:13:17,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:17,708] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:17,727] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:17,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:17,744] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.525 seconds
[2019-09-15 22:13:17,770] {scheduler_job.py:146} INFO - Started process (PID=24832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:22,785] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:22,786] {logging_mixin.py:95} INFO - [2019-09-15 22:13:22,786] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:23,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:23,158] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:23,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:23,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 22:13:23,245] {scheduler_job.py:146} INFO - Started process (PID=24835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:28,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:28,254] {logging_mixin.py:95} INFO - [2019-09-15 22:13:28,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:28,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:28,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:28,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:28,633] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-15 22:13:28,745] {scheduler_job.py:146} INFO - Started process (PID=24836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:33,756] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:33,757] {logging_mixin.py:95} INFO - [2019-09-15 22:13:33,757] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:34,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:34,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:34,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:34,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-15 22:13:34,216] {scheduler_job.py:146} INFO - Started process (PID=24844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:39,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:39,230] {logging_mixin.py:95} INFO - [2019-09-15 22:13:39,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:39,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:39,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:39,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:39,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 22:13:39,676] {scheduler_job.py:146} INFO - Started process (PID=24849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:44,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:44,688] {logging_mixin.py:95} INFO - [2019-09-15 22:13:44,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:45,022] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:45,036] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:45,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:45,050] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 22:13:45,108] {scheduler_job.py:146} INFO - Started process (PID=24851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:50,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:50,125] {logging_mixin.py:95} INFO - [2019-09-15 22:13:50,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:50,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:50,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:50,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:50,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-15 22:13:50,594] {scheduler_job.py:146} INFO - Started process (PID=24853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:55,609] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 22:13:55,610] {logging_mixin.py:95} INFO - [2019-09-15 22:13:55,610] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:55,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 22:13:55,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 22:13:55,985] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 22:13:55,991] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-15 22:13:56,092] {scheduler_job.py:146} INFO - Started process (PID=24854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:12:57,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:12:57,502] {logging_mixin.py:95} INFO - [2019-09-15 23:12:57,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:12:57,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:12:57,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:12:57,868] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:12:57,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 3541.781 seconds
[2019-09-15 23:12:57,956] {scheduler_job.py:146} INFO - Started process (PID=24863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:02,969] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:02,970] {logging_mixin.py:95} INFO - [2019-09-15 23:13:02,970] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:03,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:03,334] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:03,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:03,348] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 23:13:03,438] {scheduler_job.py:146} INFO - Started process (PID=24865) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:08,448] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:08,451] {logging_mixin.py:95} INFO - [2019-09-15 23:13:08,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:09,736] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:09,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:09,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:09,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.417 seconds
[2019-09-15 23:13:09,963] {scheduler_job.py:146} INFO - Started process (PID=24868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:14,976] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:14,977] {logging_mixin.py:95} INFO - [2019-09-15 23:13:14,976] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:15,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:15,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:15,351] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:15,357] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-15 23:13:15,429] {scheduler_job.py:146} INFO - Started process (PID=24869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:20,439] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:20,440] {logging_mixin.py:95} INFO - [2019-09-15 23:13:20,440] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:20,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:20,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:20,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:20,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-15 23:13:20,924] {scheduler_job.py:146} INFO - Started process (PID=24873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:25,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:25,937] {logging_mixin.py:95} INFO - [2019-09-15 23:13:25,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:26,277] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:26,301] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:26,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:26,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 23:13:26,417] {scheduler_job.py:146} INFO - Started process (PID=24874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:31,428] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:31,429] {logging_mixin.py:95} INFO - [2019-09-15 23:13:31,429] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:31,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:31,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:31,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:31,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-15 23:13:31,907] {scheduler_job.py:146} INFO - Started process (PID=24876) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:36,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:36,913] {logging_mixin.py:95} INFO - [2019-09-15 23:13:36,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:37,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:37,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:37,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:37,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-15 23:13:37,401] {scheduler_job.py:146} INFO - Started process (PID=24878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:42,415] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:13:42,416] {logging_mixin.py:95} INFO - [2019-09-15 23:13:42,416] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:42,755] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:13:42,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:13:42,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:13:42,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-15 23:13:42,892] {scheduler_job.py:146} INFO - Started process (PID=24879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:11,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:11,009] {logging_mixin.py:95} INFO - [2019-09-15 23:50:11,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:11,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:11,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:11,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:11,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2188.490 seconds
[2019-09-15 23:50:11,426] {scheduler_job.py:146} INFO - Started process (PID=24884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:16,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:16,438] {logging_mixin.py:95} INFO - [2019-09-15 23:50:16,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:16,767] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:16,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:16,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:16,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-15 23:50:16,904] {scheduler_job.py:146} INFO - Started process (PID=24891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:21,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:21,926] {logging_mixin.py:95} INFO - [2019-09-15 23:50:21,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:23,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:23,416] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:23,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:23,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.571 seconds
[2019-09-15 23:50:23,536] {scheduler_job.py:146} INFO - Started process (PID=24893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:28,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:28,560] {logging_mixin.py:95} INFO - [2019-09-15 23:50:28,559] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:29,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:29,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:29,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:29,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.428 seconds
[2019-09-15 23:50:30,049] {scheduler_job.py:146} INFO - Started process (PID=24895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:35,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:35,064] {logging_mixin.py:95} INFO - [2019-09-15 23:50:35,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:35,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:35,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:35,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:35,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-15 23:50:35,524] {scheduler_job.py:146} INFO - Started process (PID=24896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:40,536] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:40,537] {logging_mixin.py:95} INFO - [2019-09-15 23:50:40,537] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:40,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:40,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:40,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:40,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-15 23:50:41,020] {scheduler_job.py:146} INFO - Started process (PID=24898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:46,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:46,026] {logging_mixin.py:95} INFO - [2019-09-15 23:50:46,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:46,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:46,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:46,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:46,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-15 23:50:46,512] {scheduler_job.py:146} INFO - Started process (PID=24899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:51,517] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:51,518] {logging_mixin.py:95} INFO - [2019-09-15 23:50:51,518] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:51,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:51,882] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:51,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:51,896] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-15 23:50:52,002] {scheduler_job.py:146} INFO - Started process (PID=24900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:57,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:50:57,013] {logging_mixin.py:95} INFO - [2019-09-15 23:50:57,013] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:57,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:50:57,372] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:50:57,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:50:57,386] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-15 23:50:57,406] {scheduler_job.py:146} INFO - Started process (PID=24903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:02,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:51:02,418] {logging_mixin.py:95} INFO - [2019-09-15 23:51:02,418] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:02,737] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:02,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:51:02,766] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:51:02,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-15 23:51:02,808] {scheduler_job.py:146} INFO - Started process (PID=24904) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:02,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:51:02,813] {logging_mixin.py:95} INFO - [2019-09-15 23:51:02,813] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,148] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:51:03,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:51:03,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.368 seconds
[2019-09-15 23:51:03,219] {scheduler_job.py:146} INFO - Started process (PID=24905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:51:03,224] {logging_mixin.py:95} INFO - [2019-09-15 23:51:03,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-15 23:51:03,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-15 23:51:03,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-15 23:51:03,631] {scheduler_job.py:146} INFO - Started process (PID=24906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-15 23:51:03,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-15 23:51:03,636] {logging_mixin.py:95} INFO - [2019-09-15 23:51:03,636] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:46,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:46,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:04:46,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:04:46,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 4422.722 seconds
[2019-09-16 01:04:46,439] {scheduler_job.py:146} INFO - Started process (PID=24909) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:51,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:04:51,453] {logging_mixin.py:95} INFO - [2019-09-16 01:04:51,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:51,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:51,808] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:04:51,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:04:51,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 01:04:51,908] {scheduler_job.py:146} INFO - Started process (PID=24919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:56,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:04:56,925] {logging_mixin.py:95} INFO - [2019-09-16 01:04:56,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:58,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:04:58,438] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:04:58,473] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:04:58,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.587 seconds
[2019-09-16 01:04:58,556] {scheduler_job.py:146} INFO - Started process (PID=24922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:03,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:03,573] {logging_mixin.py:95} INFO - [2019-09-16 01:05:03,572] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:04,856] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:04,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:04,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:04,977] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.422 seconds
[2019-09-16 01:05:05,061] {scheduler_job.py:146} INFO - Started process (PID=24923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:10,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:10,081] {logging_mixin.py:95} INFO - [2019-09-16 01:05:10,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:10,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:10,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:10,451] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:10,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 01:05:10,543] {scheduler_job.py:146} INFO - Started process (PID=24925) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:15,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:15,553] {logging_mixin.py:95} INFO - [2019-09-16 01:05:15,553] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:15,886] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:15,909] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:15,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:15,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 01:05:16,033] {scheduler_job.py:146} INFO - Started process (PID=24926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:21,041] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:21,042] {logging_mixin.py:95} INFO - [2019-09-16 01:05:21,042] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:21,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:21,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:21,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:21,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 01:05:21,533] {scheduler_job.py:146} INFO - Started process (PID=24928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:26,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:26,550] {logging_mixin.py:95} INFO - [2019-09-16 01:05:26,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:26,889] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:26,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:26,919] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:26,924] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 01:05:27,031] {scheduler_job.py:146} INFO - Started process (PID=24929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:32,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:32,044] {logging_mixin.py:95} INFO - [2019-09-16 01:05:32,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:32,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:32,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:32,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:32,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 01:05:32,514] {scheduler_job.py:146} INFO - Started process (PID=24930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:37,520] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:37,521] {logging_mixin.py:95} INFO - [2019-09-16 01:05:37,521] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:37,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:37,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:37,876] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:37,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 01:05:37,904] {scheduler_job.py:146} INFO - Started process (PID=24932) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:37,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:37,909] {logging_mixin.py:95} INFO - [2019-09-16 01:05:37,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:38,273] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:38,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-16 01:05:38,313] {scheduler_job.py:146} INFO - Started process (PID=24933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,318] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:38,319] {logging_mixin.py:95} INFO - [2019-09-16 01:05:38,319] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:05:38,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:05:38,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.370 seconds
[2019-09-16 01:05:38,722] {scheduler_job.py:146} INFO - Started process (PID=24934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:05:38,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:05:38,727] {logging_mixin.py:95} INFO - [2019-09-16 01:05:38,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:01,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:01,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:01,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:01,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2122.544 seconds
[2019-09-16 01:41:01,322] {scheduler_job.py:146} INFO - Started process (PID=24937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:06,336] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:06,337] {logging_mixin.py:95} INFO - [2019-09-16 01:41:06,337] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:06,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:06,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:06,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:06,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 01:41:06,803] {scheduler_job.py:146} INFO - Started process (PID=24943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:11,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:11,818] {logging_mixin.py:95} INFO - [2019-09-16 01:41:11,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:13,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:13,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:13,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:13,379] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.576 seconds
[2019-09-16 01:41:13,448] {scheduler_job.py:146} INFO - Started process (PID=24946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:18,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:18,466] {logging_mixin.py:95} INFO - [2019-09-16 01:41:18,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:19,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:19,821] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:19,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:19,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.431 seconds
[2019-09-16 01:41:19,964] {scheduler_job.py:146} INFO - Started process (PID=24947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:24,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:24,984] {logging_mixin.py:95} INFO - [2019-09-16 01:41:24,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:25,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:25,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:25,353] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:25,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 01:41:25,436] {scheduler_job.py:146} INFO - Started process (PID=24948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:30,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:30,448] {logging_mixin.py:95} INFO - [2019-09-16 01:41:30,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:30,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:30,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:30,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:30,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 01:41:30,926] {scheduler_job.py:146} INFO - Started process (PID=24950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:35,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:35,934] {logging_mixin.py:95} INFO - [2019-09-16 01:41:35,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:36,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:36,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:36,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:36,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 01:41:36,425] {scheduler_job.py:146} INFO - Started process (PID=24951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:41,430] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:41,431] {logging_mixin.py:95} INFO - [2019-09-16 01:41:41,431] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:41,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:41,786] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:41,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:41,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-16 01:41:41,911] {scheduler_job.py:146} INFO - Started process (PID=24952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:46,917] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:46,919] {logging_mixin.py:95} INFO - [2019-09-16 01:41:46,918] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:47,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:47,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:47,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:47,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 01:41:47,399] {scheduler_job.py:146} INFO - Started process (PID=24954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:52,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 01:41:52,413] {logging_mixin.py:95} INFO - [2019-09-16 01:41:52,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:52,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 01:41:52,777] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 01:41:52,786] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 01:41:52,791] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 01:41:52,900] {scheduler_job.py:146} INFO - Started process (PID=24955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:08,392] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:08,393] {logging_mixin.py:95} INFO - [2019-09-16 02:16:08,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:08,727] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:08,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:08,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:08,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2055.862 seconds
[2019-09-16 02:16:08,845] {scheduler_job.py:146} INFO - Started process (PID=24962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:13,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:13,855] {logging_mixin.py:95} INFO - [2019-09-16 02:16:13,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:14,223] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:14,243] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:14,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:14,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 02:16:14,334] {scheduler_job.py:146} INFO - Started process (PID=24964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:19,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:19,363] {logging_mixin.py:95} INFO - [2019-09-16 02:16:19,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:20,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:20,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:20,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:20,776] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.442 seconds
[2019-09-16 02:16:20,866] {scheduler_job.py:146} INFO - Started process (PID=24967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:25,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:25,887] {logging_mixin.py:95} INFO - [2019-09-16 02:16:25,887] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:26,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:26,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:26,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:26,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 02:16:26,336] {scheduler_job.py:146} INFO - Started process (PID=24970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:31,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:31,350] {logging_mixin.py:95} INFO - [2019-09-16 02:16:31,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:31,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:31,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:31,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:31,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-16 02:16:31,828] {scheduler_job.py:146} INFO - Started process (PID=24971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:36,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:36,844] {logging_mixin.py:95} INFO - [2019-09-16 02:16:36,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:37,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:37,195] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:37,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:37,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 02:16:37,325] {scheduler_job.py:146} INFO - Started process (PID=24972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:42,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:42,336] {logging_mixin.py:95} INFO - [2019-09-16 02:16:42,336] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:42,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:42,689] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:42,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:42,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 02:16:42,822] {scheduler_job.py:146} INFO - Started process (PID=24974) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:47,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:47,836] {logging_mixin.py:95} INFO - [2019-09-16 02:16:47,835] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:48,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:48,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:48,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:48,211] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 02:16:48,314] {scheduler_job.py:146} INFO - Started process (PID=24975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:53,327] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:53,328] {logging_mixin.py:95} INFO - [2019-09-16 02:16:53,327] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:53,663] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:53,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 02:16:53,695] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 02:16:53,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 02:16:53,802] {scheduler_job.py:146} INFO - Started process (PID=24977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 02:16:58,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 02:16:58,815] {logging_mixin.py:95} INFO - [2019-09-16 02:16:58,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:13,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:13,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:13,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:13,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6439.752 seconds
[2019-09-16 04:04:13,628] {scheduler_job.py:146} INFO - Started process (PID=24989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:18,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:18,635] {logging_mixin.py:95} INFO - [2019-09-16 04:04:18,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:18,974] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:18,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:19,002] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:19,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 04:04:19,099] {scheduler_job.py:146} INFO - Started process (PID=25013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:24,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:24,112] {logging_mixin.py:95} INFO - [2019-09-16 04:04:24,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:25,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:25,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:25,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:25,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.451 seconds
[2019-09-16 04:04:25,644] {scheduler_job.py:146} INFO - Started process (PID=25017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:30,666] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:30,678] {logging_mixin.py:95} INFO - [2019-09-16 04:04:30,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:31,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:32,038] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:32,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:32,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.443 seconds
[2019-09-16 04:04:32,161] {scheduler_job.py:146} INFO - Started process (PID=25018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:37,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:37,171] {logging_mixin.py:95} INFO - [2019-09-16 04:04:37,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:37,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:37,535] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:37,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:37,549] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 04:04:37,648] {scheduler_job.py:146} INFO - Started process (PID=25020) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:42,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:42,656] {logging_mixin.py:95} INFO - [2019-09-16 04:04:42,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:42,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:43,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:43,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:43,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 04:04:43,138] {scheduler_job.py:146} INFO - Started process (PID=25021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:48,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:48,150] {logging_mixin.py:95} INFO - [2019-09-16 04:04:48,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:48,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:48,513] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:48,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:48,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 04:04:48,639] {scheduler_job.py:146} INFO - Started process (PID=25023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:53,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:53,651] {logging_mixin.py:95} INFO - [2019-09-16 04:04:53,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:53,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:54,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:54,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:54,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 04:04:54,134] {scheduler_job.py:146} INFO - Started process (PID=25026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:59,148] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:04:59,163] {logging_mixin.py:95} INFO - [2019-09-16 04:04:59,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:59,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:04:59,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:04:59,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:04:59,547] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 04:04:59,632] {scheduler_job.py:146} INFO - Started process (PID=25027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:04,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:05:04,638] {logging_mixin.py:95} INFO - [2019-09-16 04:05:04,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:04,965] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:04,989] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:05:04,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:05:05,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-16 04:05:05,022] {scheduler_job.py:146} INFO - Started process (PID=25028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:05:05,026] {logging_mixin.py:95} INFO - [2019-09-16 04:05:05,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:05:05,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:05:05,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-16 04:05:05,431] {scheduler_job.py:146} INFO - Started process (PID=25029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,435] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:05:05,436] {logging_mixin.py:95} INFO - [2019-09-16 04:05:05,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:05:05,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:05:05,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:05:05,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.367 seconds
[2019-09-16 04:06:06,021] {scheduler_job.py:146} INFO - Started process (PID=25030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,024] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:06,025] {logging_mixin.py:95} INFO - [2019-09-16 04:06:06,025] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:06,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:06,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.396 seconds
[2019-09-16 04:06:06,527] {scheduler_job.py:146} INFO - Started process (PID=25031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:06,532] {logging_mixin.py:95} INFO - [2019-09-16 04:06:06,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,925] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:06,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:06,959] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:06,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.437 seconds
[2019-09-16 04:06:07,037] {scheduler_job.py:146} INFO - Started process (PID=25032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:12,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:12,048] {logging_mixin.py:95} INFO - [2019-09-16 04:06:12,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:12,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:12,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:12,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:12,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 04:06:12,517] {scheduler_job.py:146} INFO - Started process (PID=25043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:17,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:17,523] {logging_mixin.py:95} INFO - [2019-09-16 04:06:17,523] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:17,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:17,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:17,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:17,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 04:06:17,973] {scheduler_job.py:146} INFO - Started process (PID=25046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:22,980] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:22,981] {logging_mixin.py:95} INFO - [2019-09-16 04:06:22,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:23,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:23,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:23,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:23,378] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 04:06:23,425] {scheduler_job.py:146} INFO - Started process (PID=25049) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:28,433] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:28,434] {logging_mixin.py:95} INFO - [2019-09-16 04:06:28,433] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:28,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:28,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:28,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:28,801] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-16 04:06:28,876] {scheduler_job.py:146} INFO - Started process (PID=25051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:33,884] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:33,885] {logging_mixin.py:95} INFO - [2019-09-16 04:06:33,884] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:34,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:34,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:34,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:34,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 04:06:34,338] {scheduler_job.py:146} INFO - Started process (PID=25052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:39,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:39,350] {logging_mixin.py:95} INFO - [2019-09-16 04:06:39,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:39,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:39,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:39,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:39,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 04:06:39,799] {scheduler_job.py:146} INFO - Started process (PID=25056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:44,808] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:44,809] {logging_mixin.py:95} INFO - [2019-09-16 04:06:44,808] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:45,164] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:45,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:45,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:45,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 04:06:45,254] {scheduler_job.py:146} INFO - Started process (PID=25058) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:50,267] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:50,268] {logging_mixin.py:95} INFO - [2019-09-16 04:06:50,268] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:50,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:50,633] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:50,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:50,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 04:06:50,738] {scheduler_job.py:146} INFO - Started process (PID=25061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:55,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:06:55,752] {logging_mixin.py:95} INFO - [2019-09-16 04:06:55,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:56,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:06:56,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:06:56,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:06:56,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 04:06:56,234] {scheduler_job.py:146} INFO - Started process (PID=25063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:07:01,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:07:01,251] {logging_mixin.py:95} INFO - [2019-09-16 04:07:01,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:07:01,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:07:01,614] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:07:01,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:07:01,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 04:07:01,727] {scheduler_job.py:146} INFO - Started process (PID=25064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:44,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:30:44,313] {logging_mixin.py:95} INFO - [2019-09-16 04:30:44,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:44,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:44,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:30:44,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:30:44,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 1422.995 seconds
[2019-09-16 04:30:44,860] {scheduler_job.py:146} INFO - Started process (PID=25068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:49,872] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:30:49,873] {logging_mixin.py:95} INFO - [2019-09-16 04:30:49,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:50,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:50,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:30:50,240] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:30:50,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 04:30:50,340] {scheduler_job.py:146} INFO - Started process (PID=25076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:55,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:30:55,361] {logging_mixin.py:95} INFO - [2019-09-16 04:30:55,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:56,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:30:56,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:30:56,911] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:30:56,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.593 seconds
[2019-09-16 04:30:56,995] {scheduler_job.py:146} INFO - Started process (PID=25079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:02,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:02,020] {logging_mixin.py:95} INFO - [2019-09-16 04:31:02,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,374] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,390] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:03,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:03,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.415 seconds
[2019-09-16 04:31:03,429] {scheduler_job.py:146} INFO - Started process (PID=25085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:03,435] {logging_mixin.py:95} INFO - [2019-09-16 04:31:03,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,823] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:03,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:03,855] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.426 seconds
[2019-09-16 04:31:03,937] {scheduler_job.py:146} INFO - Started process (PID=25086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:03,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:03,941] {logging_mixin.py:95} INFO - [2019-09-16 04:31:03,941] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:04,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:04,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:04,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:04,334] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.397 seconds
[2019-09-16 04:31:04,446] {scheduler_job.py:146} INFO - Started process (PID=25087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:09,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:09,453] {logging_mixin.py:95} INFO - [2019-09-16 04:31:09,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:09,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:09,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:09,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:09,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 04:31:09,893] {scheduler_job.py:146} INFO - Started process (PID=25088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:14,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:14,903] {logging_mixin.py:95} INFO - [2019-09-16 04:31:14,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:15,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:15,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:15,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:15,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 04:31:15,341] {scheduler_job.py:146} INFO - Started process (PID=25090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:20,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:20,350] {logging_mixin.py:95} INFO - [2019-09-16 04:31:20,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:20,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:20,707] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:20,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:20,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 04:31:20,784] {scheduler_job.py:146} INFO - Started process (PID=25091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:25,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:25,791] {logging_mixin.py:95} INFO - [2019-09-16 04:31:25,790] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:26,124] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:26,147] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:26,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:26,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-16 04:31:26,234] {scheduler_job.py:146} INFO - Started process (PID=25092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:31,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:31,245] {logging_mixin.py:95} INFO - [2019-09-16 04:31:31,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:31,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:31,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:31,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:31,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 04:31:31,695] {scheduler_job.py:146} INFO - Started process (PID=25094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:36,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:36,718] {logging_mixin.py:95} INFO - [2019-09-16 04:31:36,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:37,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:37,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:37,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:37,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 04:31:37,177] {scheduler_job.py:146} INFO - Started process (PID=25095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:42,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:42,191] {logging_mixin.py:95} INFO - [2019-09-16 04:31:42,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:42,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:42,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:42,564] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:42,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 04:31:42,675] {scheduler_job.py:146} INFO - Started process (PID=25096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:47,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:47,683] {logging_mixin.py:95} INFO - [2019-09-16 04:31:47,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:48,015] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:48,039] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:48,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:48,053] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 04:31:48,075] {scheduler_job.py:146} INFO - Started process (PID=25098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:53,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:53,082] {logging_mixin.py:95} INFO - [2019-09-16 04:31:53,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:53,429] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:53,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:53,462] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:53,468] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 04:31:53,564] {scheduler_job.py:146} INFO - Started process (PID=25099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:58,576] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:31:58,577] {logging_mixin.py:95} INFO - [2019-09-16 04:31:58,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:58,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:31:58,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:31:58,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:31:58,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 04:31:59,061] {scheduler_job.py:146} INFO - Started process (PID=25100) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:04,068] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:04,069] {logging_mixin.py:95} INFO - [2019-09-16 04:32:04,069] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:04,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:04,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:04,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:04,446] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 04:32:04,529] {scheduler_job.py:146} INFO - Started process (PID=25105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:09,538] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:09,539] {logging_mixin.py:95} INFO - [2019-09-16 04:32:09,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:09,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:09,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:09,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:09,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:32:09,979] {scheduler_job.py:146} INFO - Started process (PID=25106) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:14,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:14,990] {logging_mixin.py:95} INFO - [2019-09-16 04:32:14,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:15,371] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:15,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:15,404] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:15,410] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 04:32:15,432] {scheduler_job.py:146} INFO - Started process (PID=25114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:20,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:20,442] {logging_mixin.py:95} INFO - [2019-09-16 04:32:20,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:20,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:20,812] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:20,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:20,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 04:32:20,886] {scheduler_job.py:146} INFO - Started process (PID=25115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:25,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:25,896] {logging_mixin.py:95} INFO - [2019-09-16 04:32:25,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:26,248] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:26,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:26,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:26,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 04:32:26,343] {scheduler_job.py:146} INFO - Started process (PID=25116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:31,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:31,349] {logging_mixin.py:95} INFO - [2019-09-16 04:32:31,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:31,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:31,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:31,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:31,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 04:32:31,798] {scheduler_job.py:146} INFO - Started process (PID=25118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:36,806] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:36,807] {logging_mixin.py:95} INFO - [2019-09-16 04:32:36,807] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:37,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:37,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:37,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:37,188] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 04:32:37,254] {scheduler_job.py:146} INFO - Started process (PID=25119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:42,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:42,260] {logging_mixin.py:95} INFO - [2019-09-16 04:32:42,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:42,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:42,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:42,731] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:42,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-16 04:32:42,796] {scheduler_job.py:146} INFO - Started process (PID=25127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:47,804] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:47,805] {logging_mixin.py:95} INFO - [2019-09-16 04:32:47,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:48,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:48,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:48,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:48,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 04:32:48,236] {scheduler_job.py:146} INFO - Started process (PID=25133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:53,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:53,242] {logging_mixin.py:95} INFO - [2019-09-16 04:32:53,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:53,664] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:53,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:53,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:53,704] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-16 04:32:53,774] {scheduler_job.py:146} INFO - Started process (PID=25134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:58,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:32:58,785] {logging_mixin.py:95} INFO - [2019-09-16 04:32:58,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:59,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:32:59,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:32:59,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:32:59,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.496 seconds
[2019-09-16 04:32:59,305] {scheduler_job.py:146} INFO - Started process (PID=25137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:04,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:04,311] {logging_mixin.py:95} INFO - [2019-09-16 04:33:04,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:04,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:04,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:04,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:04,767] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-16 04:33:04,833] {scheduler_job.py:146} INFO - Started process (PID=25141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:09,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:09,842] {logging_mixin.py:95} INFO - [2019-09-16 04:33:09,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:10,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:10,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:10,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:10,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.782 seconds
[2019-09-16 04:33:10,673] {scheduler_job.py:146} INFO - Started process (PID=25144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:15,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:15,683] {logging_mixin.py:95} INFO - [2019-09-16 04:33:15,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:16,360] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:16,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:16,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:16,416] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.743 seconds
[2019-09-16 04:33:16,517] {scheduler_job.py:146} INFO - Started process (PID=25147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:21,523] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:21,524] {logging_mixin.py:95} INFO - [2019-09-16 04:33:21,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:22,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:22,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:22,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:22,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.628 seconds
[2019-09-16 04:33:22,235] {scheduler_job.py:146} INFO - Started process (PID=25148) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:27,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:27,244] {logging_mixin.py:95} INFO - [2019-09-16 04:33:27,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:27,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:27,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:27,876] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:27,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.653 seconds
[2019-09-16 04:33:27,980] {scheduler_job.py:146} INFO - Started process (PID=25152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:32,990] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:32,992] {logging_mixin.py:95} INFO - [2019-09-16 04:33:32,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:33,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:33,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:33,535] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:33,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.561 seconds
[2019-09-16 04:33:33,614] {scheduler_job.py:146} INFO - Started process (PID=25155) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:38,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:38,622] {logging_mixin.py:95} INFO - [2019-09-16 04:33:38,622] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:38,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:39,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:39,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:39,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 04:33:39,155] {scheduler_job.py:146} INFO - Started process (PID=25156) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:44,165] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:44,166] {logging_mixin.py:95} INFO - [2019-09-16 04:33:44,165] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:44,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:44,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:44,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:44,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:33:44,695] {scheduler_job.py:146} INFO - Started process (PID=25163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:49,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:49,702] {logging_mixin.py:95} INFO - [2019-09-16 04:33:49,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:50,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:50,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:50,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:50,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 04:33:50,239] {scheduler_job.py:146} INFO - Started process (PID=25166) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:55,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:33:55,245] {logging_mixin.py:95} INFO - [2019-09-16 04:33:55,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:55,689] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:33:55,708] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:33:55,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:33:55,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-16 04:33:55,784] {scheduler_job.py:146} INFO - Started process (PID=25171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:00,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:00,790] {logging_mixin.py:95} INFO - [2019-09-16 04:34:00,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:01,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:01,185] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:01,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:01,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 04:34:01,228] {scheduler_job.py:146} INFO - Started process (PID=25173) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:06,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:06,239] {logging_mixin.py:95} INFO - [2019-09-16 04:34:06,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:06,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:06,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:06,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:06,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 04:34:06,677] {scheduler_job.py:146} INFO - Started process (PID=25175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:11,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:11,696] {logging_mixin.py:95} INFO - [2019-09-16 04:34:11,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:12,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:12,115] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:12,125] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:12,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-16 04:34:12,216] {scheduler_job.py:146} INFO - Started process (PID=25176) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:17,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:17,223] {logging_mixin.py:95} INFO - [2019-09-16 04:34:17,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:17,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:17,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:17,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:17,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:34:17,759] {scheduler_job.py:146} INFO - Started process (PID=25178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:22,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:22,766] {logging_mixin.py:95} INFO - [2019-09-16 04:34:22,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:23,144] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:23,167] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:23,176] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:23,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:34:23,210] {scheduler_job.py:146} INFO - Started process (PID=25179) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:28,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:28,218] {logging_mixin.py:95} INFO - [2019-09-16 04:34:28,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:28,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:28,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:28,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:28,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:34:28,752] {scheduler_job.py:146} INFO - Started process (PID=25180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:33,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:33,762] {logging_mixin.py:95} INFO - [2019-09-16 04:34:33,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:34,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:34,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:34,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:34,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 04:34:34,202] {scheduler_job.py:146} INFO - Started process (PID=25182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:39,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:39,213] {logging_mixin.py:95} INFO - [2019-09-16 04:34:39,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:39,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:39,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:39,649] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:39,655] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 04:34:39,742] {scheduler_job.py:146} INFO - Started process (PID=25183) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:44,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:44,749] {logging_mixin.py:95} INFO - [2019-09-16 04:34:44,748] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:45,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:45,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:45,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:45,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:34:45,284] {scheduler_job.py:146} INFO - Started process (PID=25184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:50,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:50,292] {logging_mixin.py:95} INFO - [2019-09-16 04:34:50,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:50,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:50,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:50,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:50,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 04:34:50,721] {scheduler_job.py:146} INFO - Started process (PID=25186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:55,725] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:34:55,726] {logging_mixin.py:95} INFO - [2019-09-16 04:34:55,726] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:56,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:34:56,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:34:56,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:34:56,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-16 04:34:56,261] {scheduler_job.py:146} INFO - Started process (PID=25187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:01,272] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:01,273] {logging_mixin.py:95} INFO - [2019-09-16 04:35:01,273] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:01,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:01,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:01,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:01,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 04:35:01,807] {scheduler_job.py:146} INFO - Started process (PID=25189) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:06,814] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:06,824] {logging_mixin.py:95} INFO - [2019-09-16 04:35:06,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:07,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:07,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:07,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:07,242] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:35:07,358] {scheduler_job.py:146} INFO - Started process (PID=25191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:12,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:12,365] {logging_mixin.py:95} INFO - [2019-09-16 04:35:12,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:12,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:12,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:12,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:12,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 04:35:12,806] {scheduler_job.py:146} INFO - Started process (PID=25192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:17,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:17,816] {logging_mixin.py:95} INFO - [2019-09-16 04:35:17,815] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:18,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:18,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:18,232] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:18,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:35:18,347] {scheduler_job.py:146} INFO - Started process (PID=25194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:23,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:23,356] {logging_mixin.py:95} INFO - [2019-09-16 04:35:23,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:23,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:23,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:23,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:23,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:35:23,891] {scheduler_job.py:146} INFO - Started process (PID=25195) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:28,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:28,898] {logging_mixin.py:95} INFO - [2019-09-16 04:35:28,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:29,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:29,307] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:29,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:29,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:35:29,434] {scheduler_job.py:146} INFO - Started process (PID=25196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:34,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:34,442] {logging_mixin.py:95} INFO - [2019-09-16 04:35:34,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:34,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:34,847] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:34,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:34,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 04:35:34,887] {scheduler_job.py:146} INFO - Started process (PID=25198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:39,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:39,893] {logging_mixin.py:95} INFO - [2019-09-16 04:35:39,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:40,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:40,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:40,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:40,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:35:40,430] {scheduler_job.py:146} INFO - Started process (PID=25199) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:45,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:45,435] {logging_mixin.py:95} INFO - [2019-09-16 04:35:45,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:45,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:45,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:45,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:45,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 04:35:45,883] {scheduler_job.py:146} INFO - Started process (PID=25201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:50,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:50,889] {logging_mixin.py:95} INFO - [2019-09-16 04:35:50,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:51,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:51,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:51,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:51,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:35:51,427] {scheduler_job.py:146} INFO - Started process (PID=25202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:56,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:35:56,435] {logging_mixin.py:95} INFO - [2019-09-16 04:35:56,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:56,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:35:56,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:35:56,849] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:35:56,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:35:56,971] {scheduler_job.py:146} INFO - Started process (PID=25203) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:01,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:01,983] {logging_mixin.py:95} INFO - [2019-09-16 04:36:01,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:02,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:02,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:02,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:02,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 04:36:02,509] {scheduler_job.py:146} INFO - Started process (PID=25205) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:07,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:07,527] {logging_mixin.py:95} INFO - [2019-09-16 04:36:07,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:07,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:07,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:07,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:07,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 04:36:08,055] {scheduler_job.py:146} INFO - Started process (PID=25207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:13,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:13,065] {logging_mixin.py:95} INFO - [2019-09-16 04:36:13,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:13,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:13,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:13,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:13,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:36:13,600] {scheduler_job.py:146} INFO - Started process (PID=25208) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:18,611] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:18,612] {logging_mixin.py:95} INFO - [2019-09-16 04:36:18,612] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:18,991] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:19,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:19,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:19,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 04:36:19,145] {scheduler_job.py:146} INFO - Started process (PID=25210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:24,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:24,153] {logging_mixin.py:95} INFO - [2019-09-16 04:36:24,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:24,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:24,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:24,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:24,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 04:36:24,689] {scheduler_job.py:146} INFO - Started process (PID=25211) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:29,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:29,701] {logging_mixin.py:95} INFO - [2019-09-16 04:36:29,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:30,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:30,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:30,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:30,117] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:36:30,141] {scheduler_job.py:146} INFO - Started process (PID=25212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:35,149] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:35,150] {logging_mixin.py:95} INFO - [2019-09-16 04:36:35,150] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:35,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:35,612] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:35,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:35,631] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.490 seconds
[2019-09-16 04:36:35,686] {scheduler_job.py:146} INFO - Started process (PID=25215) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:40,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:40,695] {logging_mixin.py:95} INFO - [2019-09-16 04:36:40,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:41,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:41,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:41,095] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:41,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 04:36:41,127] {scheduler_job.py:146} INFO - Started process (PID=25216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:46,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:46,139] {logging_mixin.py:95} INFO - [2019-09-16 04:36:46,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:46,505] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:46,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:46,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:46,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 04:36:46,576] {scheduler_job.py:146} INFO - Started process (PID=25218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:51,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:51,585] {logging_mixin.py:95} INFO - [2019-09-16 04:36:51,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:51,970] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:51,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:52,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:52,010] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:36:52,114] {scheduler_job.py:146} INFO - Started process (PID=25219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:57,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:36:57,126] {logging_mixin.py:95} INFO - [2019-09-16 04:36:57,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:57,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:36:57,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:36:57,547] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:36:57,553] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:36:57,652] {scheduler_job.py:146} INFO - Started process (PID=25220) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:02,664] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:02,665] {logging_mixin.py:95} INFO - [2019-09-16 04:37:02,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:03,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:03,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:03,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:03,088] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:37:03,201] {scheduler_job.py:146} INFO - Started process (PID=25222) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:08,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:08,210] {logging_mixin.py:95} INFO - [2019-09-16 04:37:08,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:08,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:08,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:08,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:08,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:37:08,741] {scheduler_job.py:146} INFO - Started process (PID=25224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:13,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:13,750] {logging_mixin.py:95} INFO - [2019-09-16 04:37:13,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:14,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:14,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:14,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:14,244] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-09-16 04:37:14,284] {scheduler_job.py:146} INFO - Started process (PID=25225) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:19,299] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:19,301] {logging_mixin.py:95} INFO - [2019-09-16 04:37:19,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:19,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:19,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:19,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:19,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-16 04:37:19,819] {scheduler_job.py:146} INFO - Started process (PID=25227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:24,832] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:24,833] {logging_mixin.py:95} INFO - [2019-09-16 04:37:24,833] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:25,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:25,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:25,293] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:25,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-16 04:37:25,357] {scheduler_job.py:146} INFO - Started process (PID=25228) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:30,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:30,369] {logging_mixin.py:95} INFO - [2019-09-16 04:37:30,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:30,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:30,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:30,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:30,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-16 04:37:30,900] {scheduler_job.py:146} INFO - Started process (PID=25230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:35,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:35,918] {logging_mixin.py:95} INFO - [2019-09-16 04:37:35,917] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:36,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:36,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:36,380] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:36,387] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-16 04:37:36,436] {scheduler_job.py:146} INFO - Started process (PID=25231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:41,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:41,447] {logging_mixin.py:95} INFO - [2019-09-16 04:37:41,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:41,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:41,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:41,853] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:41,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 04:37:41,882] {scheduler_job.py:146} INFO - Started process (PID=25232) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:46,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:46,895] {logging_mixin.py:95} INFO - [2019-09-16 04:37:46,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:47,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:47,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:47,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:47,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-16 04:37:47,428] {scheduler_job.py:146} INFO - Started process (PID=25234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:52,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:52,435] {logging_mixin.py:95} INFO - [2019-09-16 04:37:52,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:52,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:52,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:52,850] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:52,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:37:52,882] {scheduler_job.py:146} INFO - Started process (PID=25235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:57,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:37:57,895] {logging_mixin.py:95} INFO - [2019-09-16 04:37:57,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:58,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:37:58,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:37:58,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:37:58,322] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 04:37:58,438] {scheduler_job.py:146} INFO - Started process (PID=25236) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:03,447] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:03,448] {logging_mixin.py:95} INFO - [2019-09-16 04:38:03,448] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:03,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:03,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:03,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:03,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 04:38:03,979] {scheduler_job.py:146} INFO - Started process (PID=25239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:08,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:08,992] {logging_mixin.py:95} INFO - [2019-09-16 04:38:08,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:09,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:09,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:09,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:09,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:38:09,524] {scheduler_job.py:146} INFO - Started process (PID=25240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:14,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:14,532] {logging_mixin.py:95} INFO - [2019-09-16 04:38:14,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:14,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:14,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:14,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:14,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:38:15,063] {scheduler_job.py:146} INFO - Started process (PID=25241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:20,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:20,073] {logging_mixin.py:95} INFO - [2019-09-16 04:38:20,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:20,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:20,489] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:20,500] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:20,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:38:20,609] {scheduler_job.py:146} INFO - Started process (PID=25243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:25,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:25,617] {logging_mixin.py:95} INFO - [2019-09-16 04:38:25,617] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:25,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:25,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:26,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:26,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 04:38:26,054] {scheduler_job.py:146} INFO - Started process (PID=25244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:31,064] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:31,065] {logging_mixin.py:95} INFO - [2019-09-16 04:38:31,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:31,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:31,471] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:31,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:31,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 04:38:31,513] {scheduler_job.py:146} INFO - Started process (PID=25246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:36,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:36,530] {logging_mixin.py:95} INFO - [2019-09-16 04:38:36,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:36,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:36,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:36,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:36,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 04:38:37,057] {scheduler_job.py:146} INFO - Started process (PID=25247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:42,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:42,066] {logging_mixin.py:95} INFO - [2019-09-16 04:38:42,065] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:42,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:42,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:42,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:42,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-16 04:38:42,602] {scheduler_job.py:146} INFO - Started process (PID=25248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:47,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:47,615] {logging_mixin.py:95} INFO - [2019-09-16 04:38:47,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:47,998] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:48,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:48,030] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:48,036] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 04:38:48,153] {scheduler_job.py:146} INFO - Started process (PID=25250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:53,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:53,164] {logging_mixin.py:95} INFO - [2019-09-16 04:38:53,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:53,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:53,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:53,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:53,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 04:38:53,694] {scheduler_job.py:146} INFO - Started process (PID=25251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:58,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:38:58,701] {logging_mixin.py:95} INFO - [2019-09-16 04:38:58,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:59,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:38:59,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:38:59,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:38:59,111] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 04:38:59,136] {scheduler_job.py:146} INFO - Started process (PID=25253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:04,146] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:04,147] {logging_mixin.py:95} INFO - [2019-09-16 04:39:04,147] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:04,545] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:04,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:04,575] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:04,581] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 04:39:04,684] {scheduler_job.py:146} INFO - Started process (PID=25256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:09,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:09,694] {logging_mixin.py:95} INFO - [2019-09-16 04:39:09,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:10,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:10,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:10,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:10,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-16 04:39:10,225] {scheduler_job.py:146} INFO - Started process (PID=25257) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:15,235] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:15,236] {logging_mixin.py:95} INFO - [2019-09-16 04:39:15,235] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:15,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:15,651] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:15,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:15,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:39:15,771] {scheduler_job.py:146} INFO - Started process (PID=25259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:20,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:20,781] {logging_mixin.py:95} INFO - [2019-09-16 04:39:20,781] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:21,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:21,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:21,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:21,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:39:21,223] {scheduler_job.py:146} INFO - Started process (PID=25260) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:26,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:26,233] {logging_mixin.py:95} INFO - [2019-09-16 04:39:26,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:26,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:26,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:26,654] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:26,660] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 04:39:26,771] {scheduler_job.py:146} INFO - Started process (PID=25261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:31,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:31,780] {logging_mixin.py:95} INFO - [2019-09-16 04:39:31,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:32,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:32,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:32,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:32,200] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 04:39:32,315] {scheduler_job.py:146} INFO - Started process (PID=25263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:37,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:37,322] {logging_mixin.py:95} INFO - [2019-09-16 04:39:37,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:37,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:37,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:37,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:37,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 04:39:37,763] {scheduler_job.py:146} INFO - Started process (PID=25264) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:42,773] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:42,775] {logging_mixin.py:95} INFO - [2019-09-16 04:39:42,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:43,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:43,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:43,191] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:43,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:39:43,310] {scheduler_job.py:146} INFO - Started process (PID=25265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:48,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:48,318] {logging_mixin.py:95} INFO - [2019-09-16 04:39:48,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:48,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:48,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:48,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:48,746] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:39:48,848] {scheduler_job.py:146} INFO - Started process (PID=25267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:53,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:53,859] {logging_mixin.py:95} INFO - [2019-09-16 04:39:53,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:54,242] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:54,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:54,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:54,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 04:39:54,392] {scheduler_job.py:146} INFO - Started process (PID=25268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:59,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:39:59,401] {logging_mixin.py:95} INFO - [2019-09-16 04:39:59,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:59,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:39:59,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:39:59,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:39:59,817] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 04:39:59,840] {scheduler_job.py:146} INFO - Started process (PID=25269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:04,849] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:04,850] {logging_mixin.py:95} INFO - [2019-09-16 04:40:04,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:05,232] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:05,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:05,266] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:05,272] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 04:40:05,300] {scheduler_job.py:146} INFO - Started process (PID=25272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:10,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:10,309] {logging_mixin.py:95} INFO - [2019-09-16 04:40:10,308] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:10,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:10,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:10,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:10,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 04:40:10,840] {scheduler_job.py:146} INFO - Started process (PID=25273) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:15,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:15,849] {logging_mixin.py:95} INFO - [2019-09-16 04:40:15,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:16,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:16,252] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:16,263] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:16,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 04:40:16,293] {scheduler_job.py:146} INFO - Started process (PID=25275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:21,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:21,307] {logging_mixin.py:95} INFO - [2019-09-16 04:40:21,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:21,811] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:21,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:21,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:21,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.567 seconds
[2019-09-16 04:40:21,935] {scheduler_job.py:146} INFO - Started process (PID=25276) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:26,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:26,949] {logging_mixin.py:95} INFO - [2019-09-16 04:40:26,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:27,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:27,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:27,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:27,458] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.524 seconds
[2019-09-16 04:40:27,568] {scheduler_job.py:146} INFO - Started process (PID=25277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:32,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:32,582] {logging_mixin.py:95} INFO - [2019-09-16 04:40:32,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:33,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:33,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:33,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:33,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 04:40:33,103] {scheduler_job.py:146} INFO - Started process (PID=25279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:38,112] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:38,114] {logging_mixin.py:95} INFO - [2019-09-16 04:40:38,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:38,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:38,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:38,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:38,530] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:40:38,645] {scheduler_job.py:146} INFO - Started process (PID=25281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:43,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:43,652] {logging_mixin.py:95} INFO - [2019-09-16 04:40:43,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:44,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:44,103] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:44,153] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:44,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.516 seconds
[2019-09-16 04:40:44,190] {scheduler_job.py:146} INFO - Started process (PID=25282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:49,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:49,198] {logging_mixin.py:95} INFO - [2019-09-16 04:40:49,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:49,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:49,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:49,665] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:49,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-16 04:40:49,735] {scheduler_job.py:146} INFO - Started process (PID=25284) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:54,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:40:54,746] {logging_mixin.py:95} INFO - [2019-09-16 04:40:54,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:55,126] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:40:55,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:40:55,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:40:55,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 04:40:55,284] {scheduler_job.py:146} INFO - Started process (PID=25285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:00,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:00,294] {logging_mixin.py:95} INFO - [2019-09-16 04:41:00,294] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:00,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:00,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:00,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:00,716] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 04:41:00,825] {scheduler_job.py:146} INFO - Started process (PID=25287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:05,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:05,845] {logging_mixin.py:95} INFO - [2019-09-16 04:41:05,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:06,220] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:06,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:06,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:06,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:41:06,372] {scheduler_job.py:146} INFO - Started process (PID=25289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:11,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:11,381] {logging_mixin.py:95} INFO - [2019-09-16 04:41:11,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:11,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:11,793] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:11,803] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:11,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 04:41:11,920] {scheduler_job.py:146} INFO - Started process (PID=25290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:16,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:16,930] {logging_mixin.py:95} INFO - [2019-09-16 04:41:16,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:17,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:17,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:17,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:17,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:41:17,465] {scheduler_job.py:146} INFO - Started process (PID=25292) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:22,476] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:22,477] {logging_mixin.py:95} INFO - [2019-09-16 04:41:22,477] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:22,871] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:22,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:22,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:22,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 04:41:23,001] {scheduler_job.py:146} INFO - Started process (PID=25293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:28,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:28,014] {logging_mixin.py:95} INFO - [2019-09-16 04:41:28,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:28,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:28,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:28,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:28,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-16 04:41:28,542] {scheduler_job.py:146} INFO - Started process (PID=25294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:33,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:33,552] {logging_mixin.py:95} INFO - [2019-09-16 04:41:33,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:33,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:33,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:33,970] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:33,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 04:41:34,082] {scheduler_job.py:146} INFO - Started process (PID=25296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:39,093] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:39,094] {logging_mixin.py:95} INFO - [2019-09-16 04:41:39,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:39,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:39,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:39,519] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:39,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:41:39,622] {scheduler_job.py:146} INFO - Started process (PID=25297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:44,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:44,633] {logging_mixin.py:95} INFO - [2019-09-16 04:41:44,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:45,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:45,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:45,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:45,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:41:45,077] {scheduler_job.py:146} INFO - Started process (PID=25298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:50,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:50,087] {logging_mixin.py:95} INFO - [2019-09-16 04:41:50,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:50,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:50,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:50,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:50,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 04:41:50,621] {scheduler_job.py:146} INFO - Started process (PID=25300) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:55,630] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:41:55,631] {logging_mixin.py:95} INFO - [2019-09-16 04:41:55,631] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:56,014] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:41:56,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:41:56,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:41:56,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 04:41:56,165] {scheduler_job.py:146} INFO - Started process (PID=25301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:01,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:01,175] {logging_mixin.py:95} INFO - [2019-09-16 04:42:01,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:01,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:01,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:01,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:01,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-16 04:42:01,712] {scheduler_job.py:146} INFO - Started process (PID=25303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:06,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:06,729] {logging_mixin.py:95} INFO - [2019-09-16 04:42:06,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:07,102] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:07,123] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:07,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:07,137] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 04:42:07,161] {scheduler_job.py:146} INFO - Started process (PID=25305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:12,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:12,184] {logging_mixin.py:95} INFO - [2019-09-16 04:42:12,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:12,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:12,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:12,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:12,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 04:42:12,709] {scheduler_job.py:146} INFO - Started process (PID=25306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:17,719] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:17,720] {logging_mixin.py:95} INFO - [2019-09-16 04:42:17,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:18,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:18,121] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:18,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:18,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 04:42:18,164] {scheduler_job.py:146} INFO - Started process (PID=25308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:23,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:23,179] {logging_mixin.py:95} INFO - [2019-09-16 04:42:23,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:23,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:23,590] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:23,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:23,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:42:23,710] {scheduler_job.py:146} INFO - Started process (PID=25309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:28,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:28,723] {logging_mixin.py:95} INFO - [2019-09-16 04:42:28,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:29,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:29,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:29,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:29,131] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 04:42:29,162] {scheduler_job.py:146} INFO - Started process (PID=25310) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:34,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:34,173] {logging_mixin.py:95} INFO - [2019-09-16 04:42:34,173] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:34,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:34,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:34,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:34,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:42:34,712] {scheduler_job.py:146} INFO - Started process (PID=25312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:39,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:39,719] {logging_mixin.py:95} INFO - [2019-09-16 04:42:39,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:40,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:40,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:40,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:40,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 04:42:40,251] {scheduler_job.py:146} INFO - Started process (PID=25313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:45,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:45,262] {logging_mixin.py:95} INFO - [2019-09-16 04:42:45,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:45,649] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:45,670] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:45,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:45,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 04:42:45,800] {scheduler_job.py:146} INFO - Started process (PID=25315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:50,810] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:50,812] {logging_mixin.py:95} INFO - [2019-09-16 04:42:50,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:51,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:51,216] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:51,226] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:51,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 04:42:51,344] {scheduler_job.py:146} INFO - Started process (PID=25316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:56,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:42:56,353] {logging_mixin.py:95} INFO - [2019-09-16 04:42:56,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:56,739] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:42:56,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:42:56,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:42:56,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:42:56,894] {scheduler_job.py:146} INFO - Started process (PID=25317) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:01,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:01,903] {logging_mixin.py:95} INFO - [2019-09-16 04:43:01,902] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:02,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:02,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:02,327] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:02,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 04:43:02,436] {scheduler_job.py:146} INFO - Started process (PID=25319) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:07,445] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:07,457] {logging_mixin.py:95} INFO - [2019-09-16 04:43:07,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:07,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:07,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:07,869] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:07,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:43:07,988] {scheduler_job.py:146} INFO - Started process (PID=25321) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:12,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:12,997] {logging_mixin.py:95} INFO - [2019-09-16 04:43:12,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:13,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:13,403] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:13,415] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:13,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 04:43:13,535] {scheduler_job.py:146} INFO - Started process (PID=25322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:18,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:18,544] {logging_mixin.py:95} INFO - [2019-09-16 04:43:18,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:18,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:18,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:18,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:19,002] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-16 04:43:19,074] {scheduler_job.py:146} INFO - Started process (PID=25324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:24,084] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:24,085] {logging_mixin.py:95} INFO - [2019-09-16 04:43:24,085] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:24,483] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:24,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:24,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:24,521] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 04:43:24,621] {scheduler_job.py:146} INFO - Started process (PID=25325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:29,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:29,633] {logging_mixin.py:95} INFO - [2019-09-16 04:43:29,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:29,979] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:30,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:30,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:30,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 04:43:30,073] {scheduler_job.py:146} INFO - Started process (PID=25326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:35,081] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:35,082] {logging_mixin.py:95} INFO - [2019-09-16 04:43:35,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:35,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:35,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:35,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:35,513] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 04:43:35,624] {scheduler_job.py:146} INFO - Started process (PID=25328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:40,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:40,633] {logging_mixin.py:95} INFO - [2019-09-16 04:43:40,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:40,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:41,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:41,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:41,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 04:43:41,077] {scheduler_job.py:146} INFO - Started process (PID=25329) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:46,088] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:46,090] {logging_mixin.py:95} INFO - [2019-09-16 04:43:46,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:46,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:46,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:46,475] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:46,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 04:43:46,536] {scheduler_job.py:146} INFO - Started process (PID=25331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:51,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:51,550] {logging_mixin.py:95} INFO - [2019-09-16 04:43:51,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:51,901] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:51,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:51,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:51,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 04:43:51,987] {scheduler_job.py:146} INFO - Started process (PID=25332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:56,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:43:56,995] {logging_mixin.py:95} INFO - [2019-09-16 04:43:56,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:57,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:43:57,382] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:43:57,394] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:43:57,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 04:43:57,437] {scheduler_job.py:146} INFO - Started process (PID=25334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:02,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:02,450] {logging_mixin.py:95} INFO - [2019-09-16 04:44:02,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:02,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:02,925] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:02,934] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:02,940] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-16 04:44:02,980] {scheduler_job.py:146} INFO - Started process (PID=25338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:07,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:07,992] {logging_mixin.py:95} INFO - [2019-09-16 04:44:07,992] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:08,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:08,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:08,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:08,535] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.555 seconds
[2019-09-16 04:44:08,606] {scheduler_job.py:146} INFO - Started process (PID=25344) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:13,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:13,616] {logging_mixin.py:95} INFO - [2019-09-16 04:44:13,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:14,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:14,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:14,045] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:14,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 04:44:14,138] {scheduler_job.py:146} INFO - Started process (PID=25345) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:19,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:19,146] {logging_mixin.py:95} INFO - [2019-09-16 04:44:19,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:19,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:19,616] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:19,628] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:19,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.497 seconds
[2019-09-16 04:44:19,668] {scheduler_job.py:146} INFO - Started process (PID=25347) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:24,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:24,678] {logging_mixin.py:95} INFO - [2019-09-16 04:44:24,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:25,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:25,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:25,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:25,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.488 seconds
[2019-09-16 04:44:25,193] {scheduler_job.py:146} INFO - Started process (PID=25348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:30,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:30,205] {logging_mixin.py:95} INFO - [2019-09-16 04:44:30,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:30,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:30,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:30,698] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:30,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-16 04:44:30,810] {scheduler_job.py:146} INFO - Started process (PID=25350) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:35,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:35,818] {logging_mixin.py:95} INFO - [2019-09-16 04:44:35,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:36,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:36,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:36,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:36,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 04:44:36,251] {scheduler_job.py:146} INFO - Started process (PID=25353) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:41,259] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:41,260] {logging_mixin.py:95} INFO - [2019-09-16 04:44:41,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:41,633] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:41,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:41,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:41,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 04:44:41,689] {scheduler_job.py:146} INFO - Started process (PID=25363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:46,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:46,699] {logging_mixin.py:95} INFO - [2019-09-16 04:44:46,698] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:47,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:47,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:47,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:47,103] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 04:44:47,132] {scheduler_job.py:146} INFO - Started process (PID=25365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:52,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:52,143] {logging_mixin.py:95} INFO - [2019-09-16 04:44:52,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:52,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:52,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:52,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:52,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 04:44:52,679] {scheduler_job.py:146} INFO - Started process (PID=25366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:57,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:44:57,690] {logging_mixin.py:95} INFO - [2019-09-16 04:44:57,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:58,064] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:44:58,086] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:44:58,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:44:58,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 04:44:58,127] {scheduler_job.py:146} INFO - Started process (PID=25367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:03,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:03,138] {logging_mixin.py:95} INFO - [2019-09-16 04:45:03,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:03,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:03,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:03,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:03,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 04:45:03,675] {scheduler_job.py:146} INFO - Started process (PID=25369) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:08,685] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:08,686] {logging_mixin.py:95} INFO - [2019-09-16 04:45:08,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:09,187] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:09,207] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:09,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:09,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.567 seconds
[2019-09-16 04:45:09,342] {scheduler_job.py:146} INFO - Started process (PID=25378) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:14,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:14,353] {logging_mixin.py:95} INFO - [2019-09-16 04:45:14,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:14,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:14,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:14,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:14,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-16 04:45:14,871] {scheduler_job.py:146} INFO - Started process (PID=25382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:19,880] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:19,881] {logging_mixin.py:95} INFO - [2019-09-16 04:45:19,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:20,278] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:20,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:20,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:20,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-16 04:45:20,411] {scheduler_job.py:146} INFO - Started process (PID=25384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:25,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:25,423] {logging_mixin.py:95} INFO - [2019-09-16 04:45:25,423] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:25,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:25,837] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:25,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:25,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:45:25,952] {scheduler_job.py:146} INFO - Started process (PID=25385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:30,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:30,963] {logging_mixin.py:95} INFO - [2019-09-16 04:45:30,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:31,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:31,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:31,434] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:31,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-16 04:45:31,494] {scheduler_job.py:146} INFO - Started process (PID=25387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:36,500] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:36,501] {logging_mixin.py:95} INFO - [2019-09-16 04:45:36,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:37,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:37,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:37,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:37,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.078 seconds
[2019-09-16 04:45:37,638] {scheduler_job.py:146} INFO - Started process (PID=25388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:42,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:42,647] {logging_mixin.py:95} INFO - [2019-09-16 04:45:42,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:43,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:43,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:43,111] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:43,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-16 04:45:43,168] {scheduler_job.py:146} INFO - Started process (PID=25389) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:48,176] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:48,176] {logging_mixin.py:95} INFO - [2019-09-16 04:45:48,176] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:48,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:48,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:48,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:48,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 04:45:48,712] {scheduler_job.py:146} INFO - Started process (PID=25391) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:53,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:53,722] {logging_mixin.py:95} INFO - [2019-09-16 04:45:53,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:54,110] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:54,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:54,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:54,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 04:45:54,256] {scheduler_job.py:146} INFO - Started process (PID=25392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:59,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:45:59,261] {logging_mixin.py:95} INFO - [2019-09-16 04:45:59,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:59,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:45:59,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:45:59,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:45:59,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.525 seconds
[2019-09-16 04:45:59,900] {scheduler_job.py:146} INFO - Started process (PID=25393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:04,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:04,909] {logging_mixin.py:95} INFO - [2019-09-16 04:46:04,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:05,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:05,395] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:05,406] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:05,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-16 04:46:05,445] {scheduler_job.py:146} INFO - Started process (PID=25396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:10,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:10,451] {logging_mixin.py:95} INFO - [2019-09-16 04:46:10,451] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:10,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:10,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:10,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:10,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-16 04:46:10,987] {scheduler_job.py:146} INFO - Started process (PID=25399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:15,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:15,997] {logging_mixin.py:95} INFO - [2019-09-16 04:46:15,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:16,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:16,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:16,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:16,463] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.476 seconds
[2019-09-16 04:46:16,518] {scheduler_job.py:146} INFO - Started process (PID=25401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:21,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:21,525] {logging_mixin.py:95} INFO - [2019-09-16 04:46:21,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:21,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:21,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:21,977] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:21,984] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-16 04:46:22,054] {scheduler_job.py:146} INFO - Started process (PID=25402) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:27,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:27,060] {logging_mixin.py:95} INFO - [2019-09-16 04:46:27,060] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:27,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:27,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:27,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:27,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.486 seconds
[2019-09-16 04:46:27,594] {scheduler_job.py:146} INFO - Started process (PID=25403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:32,602] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:32,603] {logging_mixin.py:95} INFO - [2019-09-16 04:46:32,603] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:32,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:32,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:33,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:33,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 04:46:33,131] {scheduler_job.py:146} INFO - Started process (PID=25405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:38,140] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:38,141] {logging_mixin.py:95} INFO - [2019-09-16 04:46:38,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:38,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:38,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:38,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:38,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-16 04:46:38,665] {scheduler_job.py:146} INFO - Started process (PID=25408) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:43,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:43,676] {logging_mixin.py:95} INFO - [2019-09-16 04:46:43,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:44,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:44,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:44,377] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:44,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.723 seconds
[2019-09-16 04:46:44,509] {scheduler_job.py:146} INFO - Started process (PID=25411) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:49,518] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:49,520] {logging_mixin.py:95} INFO - [2019-09-16 04:46:49,519] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:49,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:49,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:49,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:49,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 04:46:49,948] {scheduler_job.py:146} INFO - Started process (PID=25416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:54,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:46:54,958] {logging_mixin.py:95} INFO - [2019-09-16 04:46:54,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:55,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:46:55,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:46:55,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:46:55,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.494 seconds
[2019-09-16 04:46:55,493] {scheduler_job.py:146} INFO - Started process (PID=25417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:00,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:00,517] {logging_mixin.py:95} INFO - [2019-09-16 04:47:00,516] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:00,882] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:00,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:00,914] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:00,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:47:01,035] {scheduler_job.py:146} INFO - Started process (PID=25424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:06,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:06,055] {logging_mixin.py:95} INFO - [2019-09-16 04:47:06,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:06,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:06,449] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:06,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:06,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 04:47:06,578] {scheduler_job.py:146} INFO - Started process (PID=25426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:11,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:11,586] {logging_mixin.py:95} INFO - [2019-09-16 04:47:11,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:11,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:11,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:11,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:11,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 04:47:12,022] {scheduler_job.py:146} INFO - Started process (PID=25427) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:17,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:17,029] {logging_mixin.py:95} INFO - [2019-09-16 04:47:17,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:17,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:17,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:17,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:17,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-16 04:47:17,478] {scheduler_job.py:146} INFO - Started process (PID=25429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:22,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:22,491] {logging_mixin.py:95} INFO - [2019-09-16 04:47:22,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:22,845] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:22,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:22,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:22,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 04:47:22,940] {scheduler_job.py:146} INFO - Started process (PID=25430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:27,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:27,949] {logging_mixin.py:95} INFO - [2019-09-16 04:47:27,949] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:28,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:28,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:28,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:28,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.540 seconds
[2019-09-16 04:47:28,595] {scheduler_job.py:146} INFO - Started process (PID=25433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:33,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:33,611] {logging_mixin.py:95} INFO - [2019-09-16 04:47:33,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:34,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:34,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:34,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:34,108] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.513 seconds
[2019-09-16 04:47:34,219] {scheduler_job.py:146} INFO - Started process (PID=25435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:39,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:39,229] {logging_mixin.py:95} INFO - [2019-09-16 04:47:39,229] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:39,640] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:39,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:39,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:39,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-16 04:47:39,758] {scheduler_job.py:146} INFO - Started process (PID=25436) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:44,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:44,766] {logging_mixin.py:95} INFO - [2019-09-16 04:47:44,765] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:45,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:45,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:45,204] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:45,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-16 04:47:45,300] {scheduler_job.py:146} INFO - Started process (PID=25437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:50,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:50,310] {logging_mixin.py:95} INFO - [2019-09-16 04:47:50,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:50,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:50,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:50,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:50,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.499 seconds
[2019-09-16 04:47:50,830] {scheduler_job.py:146} INFO - Started process (PID=25439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:55,837] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:47:55,838] {logging_mixin.py:95} INFO - [2019-09-16 04:47:55,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:56,260] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:47:56,283] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:47:56,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:47:56,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 04:47:56,374] {scheduler_job.py:146} INFO - Started process (PID=25440) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:01,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:01,384] {logging_mixin.py:95} INFO - [2019-09-16 04:48:01,384] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:01,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:01,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:01,825] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:01,831] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-16 04:48:01,911] {scheduler_job.py:146} INFO - Started process (PID=25445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:06,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:06,922] {logging_mixin.py:95} INFO - [2019-09-16 04:48:06,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:07,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:07,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:07,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:07,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 04:48:07,449] {scheduler_job.py:146} INFO - Started process (PID=25447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:12,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:12,460] {logging_mixin.py:95} INFO - [2019-09-16 04:48:12,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:12,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:12,869] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:12,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:12,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:48:12,979] {scheduler_job.py:146} INFO - Started process (PID=25448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:17,989] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:17,990] {logging_mixin.py:95} INFO - [2019-09-16 04:48:17,989] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:18,384] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:18,408] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:18,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:18,425] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-16 04:48:18,513] {scheduler_job.py:146} INFO - Started process (PID=25450) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:23,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:23,522] {logging_mixin.py:95} INFO - [2019-09-16 04:48:23,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:23,887] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:23,911] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:23,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:23,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 04:48:23,952] {scheduler_job.py:146} INFO - Started process (PID=25451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:28,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:28,963] {logging_mixin.py:95} INFO - [2019-09-16 04:48:28,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:29,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:29,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:29,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:29,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 04:48:29,495] {scheduler_job.py:146} INFO - Started process (PID=25457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:34,504] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:34,506] {logging_mixin.py:95} INFO - [2019-09-16 04:48:34,505] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:34,907] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:34,930] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:34,941] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:34,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-16 04:48:35,040] {scheduler_job.py:146} INFO - Started process (PID=25459) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:40,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:40,049] {logging_mixin.py:95} INFO - [2019-09-16 04:48:40,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:40,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:40,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:40,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:40,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.500 seconds
[2019-09-16 04:48:40,584] {scheduler_job.py:146} INFO - Started process (PID=25462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:45,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:45,595] {logging_mixin.py:95} INFO - [2019-09-16 04:48:45,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:45,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:46,022] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:46,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:46,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-16 04:48:46,118] {scheduler_job.py:146} INFO - Started process (PID=25471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:51,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:51,127] {logging_mixin.py:95} INFO - [2019-09-16 04:48:51,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:51,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:51,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:51,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:51,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-16 04:48:51,663] {scheduler_job.py:146} INFO - Started process (PID=25472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:56,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:48:56,673] {logging_mixin.py:95} INFO - [2019-09-16 04:48:56,673] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:57,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:48:57,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:48:57,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:48:57,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 04:48:57,109] {scheduler_job.py:146} INFO - Started process (PID=25473) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:02,115] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:02,117] {logging_mixin.py:95} INFO - [2019-09-16 04:49:02,116] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:02,525] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:02,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:02,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:02,569] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 04:49:02,654] {scheduler_job.py:146} INFO - Started process (PID=25475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:07,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:07,662] {logging_mixin.py:95} INFO - [2019-09-16 04:49:07,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:08,047] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:08,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:08,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:08,095] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-16 04:49:08,202] {scheduler_job.py:146} INFO - Started process (PID=25477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:13,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:13,213] {logging_mixin.py:95} INFO - [2019-09-16 04:49:13,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:13,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:13,614] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:13,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:13,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 04:49:13,652] {scheduler_job.py:146} INFO - Started process (PID=25478) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:18,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:18,661] {logging_mixin.py:95} INFO - [2019-09-16 04:49:18,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:19,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:19,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:19,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:19,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 04:49:19,099] {scheduler_job.py:146} INFO - Started process (PID=25480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:24,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:24,108] {logging_mixin.py:95} INFO - [2019-09-16 04:49:24,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:24,479] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:24,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:24,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:24,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 04:49:24,546] {scheduler_job.py:146} INFO - Started process (PID=25481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:29,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:29,555] {logging_mixin.py:95} INFO - [2019-09-16 04:49:29,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:29,921] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:29,945] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:29,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:29,960] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 04:49:29,992] {scheduler_job.py:146} INFO - Started process (PID=25482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:34,999] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:35,000] {logging_mixin.py:95} INFO - [2019-09-16 04:49:35,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:35,747] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:35,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:35,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:35,784] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.792 seconds
[2019-09-16 04:49:35,833] {scheduler_job.py:146} INFO - Started process (PID=25489) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:40,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:40,841] {logging_mixin.py:95} INFO - [2019-09-16 04:49:40,841] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:41,250] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:41,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:41,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:41,294] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.461 seconds
[2019-09-16 04:49:41,369] {scheduler_job.py:146} INFO - Started process (PID=25491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:46,379] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:46,380] {logging_mixin.py:95} INFO - [2019-09-16 04:49:46,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:46,771] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:46,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:46,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:46,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 04:49:46,904] {scheduler_job.py:146} INFO - Started process (PID=25497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:51,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:51,911] {logging_mixin.py:95} INFO - [2019-09-16 04:49:51,910] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:52,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:52,358] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:52,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:52,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 04:49:52,449] {scheduler_job.py:146} INFO - Started process (PID=25498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:57,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:49:57,461] {logging_mixin.py:95} INFO - [2019-09-16 04:49:57,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:57,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:49:57,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:49:57,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:49:57,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 04:49:57,987] {scheduler_job.py:146} INFO - Started process (PID=25499) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:02,994] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:02,995] {logging_mixin.py:95} INFO - [2019-09-16 04:50:02,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:03,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:03,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:03,529] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:03,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.556 seconds
[2019-09-16 04:50:03,639] {scheduler_job.py:146} INFO - Started process (PID=25503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:08,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:08,654] {logging_mixin.py:95} INFO - [2019-09-16 04:50:08,653] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:09,071] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:09,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:09,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:09,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 04:50:09,166] {scheduler_job.py:146} INFO - Started process (PID=25506) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:14,172] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:14,173] {logging_mixin.py:95} INFO - [2019-09-16 04:50:14,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:14,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:14,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:14,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:14,647] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-16 04:50:14,698] {scheduler_job.py:146} INFO - Started process (PID=25509) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:19,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:19,708] {logging_mixin.py:95} INFO - [2019-09-16 04:50:19,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:20,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:20,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:20,777] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:20,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.100 seconds
[2019-09-16 04:50:20,848] {scheduler_job.py:146} INFO - Started process (PID=25511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:25,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:25,859] {logging_mixin.py:95} INFO - [2019-09-16 04:50:25,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:26,280] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:26,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:26,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:26,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 04:50:26,385] {scheduler_job.py:146} INFO - Started process (PID=25515) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:31,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:31,394] {logging_mixin.py:95} INFO - [2019-09-16 04:50:31,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:31,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:31,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:31,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:31,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 04:50:31,828] {scheduler_job.py:146} INFO - Started process (PID=25519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:36,836] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:36,838] {logging_mixin.py:95} INFO - [2019-09-16 04:50:36,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:37,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:37,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:37,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:37,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 04:50:37,371] {scheduler_job.py:146} INFO - Started process (PID=25520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:42,378] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:42,380] {logging_mixin.py:95} INFO - [2019-09-16 04:50:42,379] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:43,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:43,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:43,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:43,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.723 seconds
[2019-09-16 04:50:43,124] {scheduler_job.py:146} INFO - Started process (PID=25523) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:48,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:48,134] {logging_mixin.py:95} INFO - [2019-09-16 04:50:48,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:48,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:48,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:48,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:48,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 04:50:48,660] {scheduler_job.py:146} INFO - Started process (PID=25527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:53,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:53,670] {logging_mixin.py:95} INFO - [2019-09-16 04:50:53,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:54,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:54,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:54,104] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:54,110] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 04:50:54,206] {scheduler_job.py:146} INFO - Started process (PID=25528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:59,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:50:59,281] {logging_mixin.py:95} INFO - [2019-09-16 04:50:59,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:59,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:50:59,704] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:50:59,715] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:50:59,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.516 seconds
[2019-09-16 04:50:59,753] {scheduler_job.py:146} INFO - Started process (PID=25532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:04,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:04,760] {logging_mixin.py:95} INFO - [2019-09-16 04:51:04,759] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:05,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:05,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:05,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:05,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 04:51:05,201] {scheduler_job.py:146} INFO - Started process (PID=25535) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:10,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:10,214] {logging_mixin.py:95} INFO - [2019-09-16 04:51:10,214] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:10,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:10,611] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:10,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:10,627] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 04:51:10,743] {scheduler_job.py:146} INFO - Started process (PID=25536) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:15,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:15,753] {logging_mixin.py:95} INFO - [2019-09-16 04:51:15,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:16,372] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:16,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:16,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:16,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.672 seconds
[2019-09-16 04:51:16,494] {scheduler_job.py:146} INFO - Started process (PID=25538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:21,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:21,504] {logging_mixin.py:95} INFO - [2019-09-16 04:51:21,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:21,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:21,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:21,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:21,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 04:51:21,940] {scheduler_job.py:146} INFO - Started process (PID=25539) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:26,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:26,948] {logging_mixin.py:95} INFO - [2019-09-16 04:51:26,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:27,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:27,336] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:27,348] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:27,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 04:51:27,383] {scheduler_job.py:146} INFO - Started process (PID=25540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:32,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:32,392] {logging_mixin.py:95} INFO - [2019-09-16 04:51:32,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:32,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:32,831] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:32,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:32,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-16 04:51:32,925] {scheduler_job.py:146} INFO - Started process (PID=25546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:37,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:37,933] {logging_mixin.py:95} INFO - [2019-09-16 04:51:37,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:38,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:38,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:38,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:38,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 04:51:38,466] {scheduler_job.py:146} INFO - Started process (PID=25549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:43,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:43,476] {logging_mixin.py:95} INFO - [2019-09-16 04:51:43,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:43,929] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:43,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:43,962] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:43,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.503 seconds
[2019-09-16 04:51:44,005] {scheduler_job.py:146} INFO - Started process (PID=25550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:49,014] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:49,016] {logging_mixin.py:95} INFO - [2019-09-16 04:51:49,015] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:49,465] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:49,485] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:49,495] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:49,503] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.499 seconds
[2019-09-16 04:51:49,542] {scheduler_job.py:146} INFO - Started process (PID=25552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:54,548] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:51:54,549] {logging_mixin.py:95} INFO - [2019-09-16 04:51:54,549] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:54,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:51:54,996] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:51:55,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:51:55,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 04:51:55,075] {scheduler_job.py:146} INFO - Started process (PID=25553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:00,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:00,086] {logging_mixin.py:95} INFO - [2019-09-16 04:52:00,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:00,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:00,593] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:00,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:00,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.536 seconds
[2019-09-16 04:52:00,704] {scheduler_job.py:146} INFO - Started process (PID=25558) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:05,713] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:05,715] {logging_mixin.py:95} INFO - [2019-09-16 04:52:05,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:06,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:06,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:06,133] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:06,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-16 04:52:06,243] {scheduler_job.py:146} INFO - Started process (PID=25562) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:11,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:11,253] {logging_mixin.py:95} INFO - [2019-09-16 04:52:11,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:11,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:11,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:11,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:11,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.477 seconds
[2019-09-16 04:52:11,783] {scheduler_job.py:146} INFO - Started process (PID=25568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:16,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:16,794] {logging_mixin.py:95} INFO - [2019-09-16 04:52:16,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:17,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:17,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:17,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:17,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-16 04:52:17,323] {scheduler_job.py:146} INFO - Started process (PID=25570) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:22,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:22,331] {logging_mixin.py:95} INFO - [2019-09-16 04:52:22,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:22,762] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:22,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:22,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:22,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-16 04:52:22,863] {scheduler_job.py:146} INFO - Started process (PID=25571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:27,871] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:27,872] {logging_mixin.py:95} INFO - [2019-09-16 04:52:27,872] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:28,286] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:28,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:28,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:28,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 04:52:28,399] {scheduler_job.py:146} INFO - Started process (PID=25574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:33,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:33,409] {logging_mixin.py:95} INFO - [2019-09-16 04:52:33,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:33,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:33,841] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:33,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:33,859] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 04:52:33,935] {scheduler_job.py:146} INFO - Started process (PID=25576) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:38,944] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:38,945] {logging_mixin.py:95} INFO - [2019-09-16 04:52:38,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:39,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:39,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:39,397] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:39,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-09-16 04:52:39,469] {scheduler_job.py:146} INFO - Started process (PID=25577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:44,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:44,478] {logging_mixin.py:95} INFO - [2019-09-16 04:52:44,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:44,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:44,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:44,910] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:44,916] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 04:52:45,006] {scheduler_job.py:146} INFO - Started process (PID=25578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:50,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:50,017] {logging_mixin.py:95} INFO - [2019-09-16 04:52:50,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:50,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:50,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:50,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:50,564] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.558 seconds
[2019-09-16 04:52:50,643] {scheduler_job.py:146} INFO - Started process (PID=25581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:55,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:52:55,652] {logging_mixin.py:95} INFO - [2019-09-16 04:52:55,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:56,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:52:56,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:52:56,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:52:56,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-16 04:52:56,179] {scheduler_job.py:146} INFO - Started process (PID=25582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:01,186] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:01,187] {logging_mixin.py:95} INFO - [2019-09-16 04:53:01,187] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:01,575] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:01,598] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:01,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:01,614] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 04:53:01,715] {scheduler_job.py:146} INFO - Started process (PID=25586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:06,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:06,724] {logging_mixin.py:95} INFO - [2019-09-16 04:53:06,723] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:07,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:07,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:07,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:07,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.005 seconds
[2019-09-16 04:53:07,757] {scheduler_job.py:146} INFO - Started process (PID=25591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:12,767] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:12,778] {logging_mixin.py:95} INFO - [2019-09-16 04:53:12,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:13,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:13,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:13,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:13,237] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-16 04:53:13,291] {scheduler_job.py:146} INFO - Started process (PID=25593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:18,302] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:18,303] {logging_mixin.py:95} INFO - [2019-09-16 04:53:18,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:18,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:18,761] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:18,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:18,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-16 04:53:18,833] {scheduler_job.py:146} INFO - Started process (PID=25595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:23,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:23,845] {logging_mixin.py:95} INFO - [2019-09-16 04:53:23,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:24,240] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:24,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:24,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:24,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:53:24,374] {scheduler_job.py:146} INFO - Started process (PID=25596) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:29,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:29,384] {logging_mixin.py:95} INFO - [2019-09-16 04:53:29,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:29,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:29,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:29,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:29,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 04:53:29,916] {scheduler_job.py:146} INFO - Started process (PID=25601) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:34,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:34,924] {logging_mixin.py:95} INFO - [2019-09-16 04:53:34,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:35,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:35,584] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:35,595] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:35,604] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.688 seconds
[2019-09-16 04:53:35,658] {scheduler_job.py:146} INFO - Started process (PID=25603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:40,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:40,672] {logging_mixin.py:95} INFO - [2019-09-16 04:53:40,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:41,332] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:41,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:41,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:41,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.743 seconds
[2019-09-16 04:53:41,491] {scheduler_job.py:146} INFO - Started process (PID=25610) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:46,498] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:46,500] {logging_mixin.py:95} INFO - [2019-09-16 04:53:46,499] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:47,103] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:47,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:47,151] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:47,164] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.673 seconds
[2019-09-16 04:53:47,237] {scheduler_job.py:146} INFO - Started process (PID=25614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:52,246] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:52,247] {logging_mixin.py:95} INFO - [2019-09-16 04:53:52,247] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:52,646] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:52,664] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:52,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:52,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 04:53:52,777] {scheduler_job.py:146} INFO - Started process (PID=25618) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:57,783] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:53:57,784] {logging_mixin.py:95} INFO - [2019-09-16 04:53:57,784] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:58,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:53:58,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:53:58,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:53:58,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 04:53:58,214] {scheduler_job.py:146} INFO - Started process (PID=25619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:03,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:03,225] {logging_mixin.py:95} INFO - [2019-09-16 04:54:03,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:03,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:03,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:03,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:03,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 04:54:03,653] {scheduler_job.py:146} INFO - Started process (PID=25621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:08,659] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:08,660] {logging_mixin.py:95} INFO - [2019-09-16 04:54:08,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:09,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:09,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:09,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:09,091] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 04:54:09,193] {scheduler_job.py:146} INFO - Started process (PID=25623) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:14,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:14,202] {logging_mixin.py:95} INFO - [2019-09-16 04:54:14,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:15,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:15,044] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:15,058] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:15,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.879 seconds
[2019-09-16 04:54:15,136] {scheduler_job.py:146} INFO - Started process (PID=25626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:20,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:20,145] {logging_mixin.py:95} INFO - [2019-09-16 04:54:20,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:20,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:20,578] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:20,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:20,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 04:54:20,672] {scheduler_job.py:146} INFO - Started process (PID=25632) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:25,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:25,682] {logging_mixin.py:95} INFO - [2019-09-16 04:54:25,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:26,796] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:26,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:26,847] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:26,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.190 seconds
[2019-09-16 04:54:26,903] {scheduler_job.py:146} INFO - Started process (PID=25641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:31,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:31,913] {logging_mixin.py:95} INFO - [2019-09-16 04:54:31,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:32,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:32,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:32,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:32,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 04:54:32,441] {scheduler_job.py:146} INFO - Started process (PID=25644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:37,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:37,452] {logging_mixin.py:95} INFO - [2019-09-16 04:54:37,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:37,852] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:37,878] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:37,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:37,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 04:54:37,978] {scheduler_job.py:146} INFO - Started process (PID=25645) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:42,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:42,989] {logging_mixin.py:95} INFO - [2019-09-16 04:54:42,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:43,406] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:43,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:43,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:43,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 04:54:43,514] {scheduler_job.py:146} INFO - Started process (PID=25646) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:48,524] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:48,525] {logging_mixin.py:95} INFO - [2019-09-16 04:54:48,525] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:48,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:48,956] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:48,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:48,973] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 04:54:49,050] {scheduler_job.py:146} INFO - Started process (PID=25648) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:54,059] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:54,060] {logging_mixin.py:95} INFO - [2019-09-16 04:54:54,059] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:54,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:54,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:54:54,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:54:54,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-16 04:54:54,589] {scheduler_job.py:146} INFO - Started process (PID=25649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:54:59,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:54:59,600] {logging_mixin.py:95} INFO - [2019-09-16 04:54:59,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:00,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:00,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:00,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:00,045] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-16 04:55:00,128] {scheduler_job.py:146} INFO - Started process (PID=25650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:05,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:05,138] {logging_mixin.py:95} INFO - [2019-09-16 04:55:05,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:05,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:05,622] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:05,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:05,641] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-16 04:55:05,667] {scheduler_job.py:146} INFO - Started process (PID=25653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:10,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:10,675] {logging_mixin.py:95} INFO - [2019-09-16 04:55:10,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:11,113] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:11,137] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:11,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:11,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.494 seconds
[2019-09-16 04:55:11,200] {scheduler_job.py:146} INFO - Started process (PID=25654) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:16,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:16,210] {logging_mixin.py:95} INFO - [2019-09-16 04:55:16,210] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:16,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:16,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:16,685] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:16,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-16 04:55:16,734] {scheduler_job.py:146} INFO - Started process (PID=25656) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:21,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:21,746] {logging_mixin.py:95} INFO - [2019-09-16 04:55:21,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:22,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:22,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:22,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:22,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.468 seconds
[2019-09-16 04:55:22,268] {scheduler_job.py:146} INFO - Started process (PID=25657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:27,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:27,278] {logging_mixin.py:95} INFO - [2019-09-16 04:55:27,277] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:27,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:27,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:27,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:27,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-16 04:55:27,792] {scheduler_job.py:146} INFO - Started process (PID=25658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:32,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:32,803] {logging_mixin.py:95} INFO - [2019-09-16 04:55:32,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:33,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:33,240] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:33,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:33,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 04:55:33,330] {scheduler_job.py:146} INFO - Started process (PID=25660) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:38,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:38,351] {logging_mixin.py:95} INFO - [2019-09-16 04:55:38,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:38,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:38,740] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:38,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:38,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 04:55:38,869] {scheduler_job.py:146} INFO - Started process (PID=25661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:43,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:43,878] {logging_mixin.py:95} INFO - [2019-09-16 04:55:43,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:44,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:44,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:44,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:44,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 04:55:44,310] {scheduler_job.py:146} INFO - Started process (PID=25662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:49,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:49,317] {logging_mixin.py:95} INFO - [2019-09-16 04:55:49,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:49,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:49,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:49,720] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:49,726] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 04:55:49,750] {scheduler_job.py:146} INFO - Started process (PID=25665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:54,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:55:54,760] {logging_mixin.py:95} INFO - [2019-09-16 04:55:54,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:55,107] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:55:55,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:55:55,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:55:55,144] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 04:55:55,204] {scheduler_job.py:146} INFO - Started process (PID=25667) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:00,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:00,217] {logging_mixin.py:95} INFO - [2019-09-16 04:56:00,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:00,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:00,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:00,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:00,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 04:56:00,686] {scheduler_job.py:146} INFO - Started process (PID=25668) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:05,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:05,700] {logging_mixin.py:95} INFO - [2019-09-16 04:56:05,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:06,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:06,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:06,073] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:06,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 04:56:06,178] {scheduler_job.py:146} INFO - Started process (PID=25671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:11,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:11,196] {logging_mixin.py:95} INFO - [2019-09-16 04:56:11,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:11,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:11,567] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:11,576] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:11,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 04:56:11,643] {scheduler_job.py:146} INFO - Started process (PID=25677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:16,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:16,658] {logging_mixin.py:95} INFO - [2019-09-16 04:56:16,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:16,993] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:17,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:17,025] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:17,030] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 04:56:17,127] {scheduler_job.py:146} INFO - Started process (PID=25685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:22,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:22,144] {logging_mixin.py:95} INFO - [2019-09-16 04:56:22,144] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:22,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:22,518] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:22,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:22,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 04:56:22,617] {scheduler_job.py:146} INFO - Started process (PID=25686) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:27,632] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:27,633] {logging_mixin.py:95} INFO - [2019-09-16 04:56:27,633] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:27,967] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:27,991] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:27,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:28,005] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 04:56:28,115] {scheduler_job.py:146} INFO - Started process (PID=25687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:33,127] {logging_mixin.py:95} INFO - [2019-09-16 04:56:33,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:33,516] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:33,522] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 04:56:33,601] {scheduler_job.py:146} INFO - Started process (PID=25689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,605] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:33,606] {logging_mixin.py:95} INFO - [2019-09-16 04:56:33,605] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:33,953] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:33,961] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:33,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.366 seconds
[2019-09-16 04:56:34,012] {scheduler_job.py:146} INFO - Started process (PID=25690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:34,018] {logging_mixin.py:95} INFO - [2019-09-16 04:56:34,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:34,390] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:34,396] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.383 seconds
[2019-09-16 04:56:34,423] {scheduler_job.py:146} INFO - Started process (PID=25691) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:34,428] {logging_mixin.py:95} INFO - [2019-09-16 04:56:34,427] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 04:56:34,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 04:56:34,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.374 seconds
[2019-09-16 04:56:34,830] {scheduler_job.py:146} INFO - Started process (PID=25692) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 04:56:34,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 04:56:34,838] {logging_mixin.py:95} INFO - [2019-09-16 04:56:34,837] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:26,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:26,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:26,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:26,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2091.553 seconds
[2019-09-16 05:31:26,440] {scheduler_job.py:146} INFO - Started process (PID=25694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:31,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:31:31,452] {logging_mixin.py:95} INFO - [2019-09-16 05:31:31,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:31,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:31,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:31,837] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:31,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 05:31:31,895] {scheduler_job.py:146} INFO - Started process (PID=25702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:36,904] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:31:36,907] {logging_mixin.py:95} INFO - [2019-09-16 05:31:36,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:38,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:38,299] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:38,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:38,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.464 seconds
[2019-09-16 05:31:38,423] {scheduler_job.py:146} INFO - Started process (PID=25704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:43,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:31:43,443] {logging_mixin.py:95} INFO - [2019-09-16 05:31:43,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:44,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:44,792] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:44,829] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:44,853] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.430 seconds
[2019-09-16 05:31:44,935] {scheduler_job.py:146} INFO - Started process (PID=25707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:49,948] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:31:49,950] {logging_mixin.py:95} INFO - [2019-09-16 05:31:49,949] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:50,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:50,311] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:50,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:50,325] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 05:31:50,415] {scheduler_job.py:146} INFO - Started process (PID=25708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:55,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:31:55,422] {logging_mixin.py:95} INFO - [2019-09-16 05:31:55,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:55,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:31:55,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:31:55,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:31:55,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 05:31:55,906] {scheduler_job.py:146} INFO - Started process (PID=25711) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:00,921] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:00,922] {logging_mixin.py:95} INFO - [2019-09-16 05:32:00,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:01,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:01,286] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:01,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:01,301] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 05:32:01,400] {scheduler_job.py:146} INFO - Started process (PID=25712) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:06,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:06,410] {logging_mixin.py:95} INFO - [2019-09-16 05:32:06,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:06,744] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:06,767] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:06,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:06,782] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 05:32:06,894] {scheduler_job.py:146} INFO - Started process (PID=25713) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:11,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:11,904] {logging_mixin.py:95} INFO - [2019-09-16 05:32:11,904] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:12,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:12,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:12,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:12,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 05:32:12,383] {scheduler_job.py:146} INFO - Started process (PID=25715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:17,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:17,392] {logging_mixin.py:95} INFO - [2019-09-16 05:32:17,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:17,709] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:17,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:17,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:17,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 05:32:17,773] {scheduler_job.py:146} INFO - Started process (PID=25716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:17,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:17,777] {logging_mixin.py:95} INFO - [2019-09-16 05:32:17,777] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:18,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:18,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-16 05:32:18,186] {scheduler_job.py:146} INFO - Started process (PID=25717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:18,191] {logging_mixin.py:95} INFO - [2019-09-16 05:32:18,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,529] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,552] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 05:32:18,561] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 05:32:18,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.380 seconds
[2019-09-16 05:32:18,597] {scheduler_job.py:146} INFO - Started process (PID=25718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 05:32:18,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 05:32:18,602] {logging_mixin.py:95} INFO - [2019-09-16 05:32:18,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:14,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:14,178] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:14,194] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:14,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2755.605 seconds
[2019-09-16 06:18:14,229] {scheduler_job.py:146} INFO - Started process (PID=25719) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:19,243] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:19,244] {logging_mixin.py:95} INFO - [2019-09-16 06:18:19,244] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:19,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:19,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:19,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:19,611] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 06:18:19,693] {scheduler_job.py:146} INFO - Started process (PID=25726) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:24,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:24,713] {logging_mixin.py:95} INFO - [2019-09-16 06:18:24,711] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:26,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:26,225] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:26,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:26,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.592 seconds
[2019-09-16 06:18:26,421] {scheduler_job.py:146} INFO - Started process (PID=25729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:31,444] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:31,447] {logging_mixin.py:95} INFO - [2019-09-16 06:18:31,446] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:32,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:32,809] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:32,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:32,868] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.447 seconds
[2019-09-16 06:18:32,946] {scheduler_job.py:146} INFO - Started process (PID=25731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:37,957] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:37,958] {logging_mixin.py:95} INFO - [2019-09-16 06:18:37,958] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:38,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:38,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:38,320] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:38,326] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 06:18:38,415] {scheduler_job.py:146} INFO - Started process (PID=25732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:43,427] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:43,428] {logging_mixin.py:95} INFO - [2019-09-16 06:18:43,428] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:43,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:43,779] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:43,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:43,794] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 06:18:43,811] {scheduler_job.py:146} INFO - Started process (PID=25733) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:48,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:48,824] {logging_mixin.py:95} INFO - [2019-09-16 06:18:48,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:49,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:49,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:49,185] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:49,191] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 06:18:49,211] {scheduler_job.py:146} INFO - Started process (PID=25735) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:54,225] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:54,239] {logging_mixin.py:95} INFO - [2019-09-16 06:18:54,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:54,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:54,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:18:54,605] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:18:54,610] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 06:18:54,694] {scheduler_job.py:146} INFO - Started process (PID=25737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:18:59,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:18:59,714] {logging_mixin.py:95} INFO - [2019-09-16 06:18:59,714] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:00,055] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:00,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:19:00,088] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:19:00,093] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 06:19:00,190] {scheduler_job.py:146} INFO - Started process (PID=25738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:05,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:19:05,201] {logging_mixin.py:95} INFO - [2019-09-16 06:19:05,201] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:05,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:05,566] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:19:05,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:19:05,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 06:19:05,686] {scheduler_job.py:146} INFO - Started process (PID=25740) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:05,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:19:05,694] {logging_mixin.py:95} INFO - [2019-09-16 06:19:05,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,041] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:19:06,050] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:19:06,055] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.369 seconds
[2019-09-16 06:19:06,098] {scheduler_job.py:146} INFO - Started process (PID=25741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:19:06,104] {logging_mixin.py:95} INFO - [2019-09-16 06:19:06,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,438] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 06:19:06,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 06:19:06,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.376 seconds
[2019-09-16 06:19:06,510] {scheduler_job.py:146} INFO - Started process (PID=25742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 06:19:06,515] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 06:19:06,515] {logging_mixin.py:95} INFO - [2019-09-16 06:19:06,515] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:14,061] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:14,094] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:14,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:14,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 3907.621 seconds
[2019-09-16 07:24:14,236] {scheduler_job.py:146} INFO - Started process (PID=25744) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:19,248] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:19,249] {logging_mixin.py:95} INFO - [2019-09-16 07:24:19,249] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:19,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:19,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:19,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:19,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 07:24:19,705] {scheduler_job.py:146} INFO - Started process (PID=25750) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:24,721] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:24,726] {logging_mixin.py:95} INFO - [2019-09-16 07:24:24,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:26,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:26,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:26,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:26,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.553 seconds
[2019-09-16 07:24:26,331] {scheduler_job.py:146} INFO - Started process (PID=25754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:31,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:31,349] {logging_mixin.py:95} INFO - [2019-09-16 07:24:31,348] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:32,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:32,691] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:32,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:32,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.420 seconds
[2019-09-16 07:24:32,836] {scheduler_job.py:146} INFO - Started process (PID=25755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:37,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:37,855] {logging_mixin.py:95} INFO - [2019-09-16 07:24:37,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:38,188] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:38,211] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:38,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:38,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 07:24:38,306] {scheduler_job.py:146} INFO - Started process (PID=25756) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:43,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:43,313] {logging_mixin.py:95} INFO - [2019-09-16 07:24:43,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:43,645] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:43,669] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:43,678] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:43,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 07:24:43,701] {scheduler_job.py:146} INFO - Started process (PID=25758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:48,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:48,716] {logging_mixin.py:95} INFO - [2019-09-16 07:24:48,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:49,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:49,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:49,069] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:49,075] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-16 07:24:49,103] {scheduler_job.py:146} INFO - Started process (PID=25759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:54,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:54,114] {logging_mixin.py:95} INFO - [2019-09-16 07:24:54,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:54,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:54,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:54,479] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:54,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 07:24:54,594] {scheduler_job.py:146} INFO - Started process (PID=25761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:59,601] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:24:59,602] {logging_mixin.py:95} INFO - [2019-09-16 07:24:59,602] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:59,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:24:59,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:24:59,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:24:59,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-16 07:24:59,984] {scheduler_job.py:146} INFO - Started process (PID=25763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:04,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:25:04,997] {logging_mixin.py:95} INFO - [2019-09-16 07:25:04,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:25:05,365] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:25:05,371] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 07:25:05,480] {scheduler_job.py:146} INFO - Started process (PID=25764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,485] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:25:05,485] {logging_mixin.py:95} INFO - [2019-09-16 07:25:05,485] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,810] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:25:05,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:25:05,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.366 seconds
[2019-09-16 07:25:05,891] {scheduler_job.py:146} INFO - Started process (PID=25765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:05,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:25:05,896] {logging_mixin.py:95} INFO - [2019-09-16 07:25:05,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,248] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:25:06,256] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:25:06,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.371 seconds
[2019-09-16 07:25:06,301] {scheduler_job.py:146} INFO - Started process (PID=25766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:25:06,306] {logging_mixin.py:95} INFO - [2019-09-16 07:25:06,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,663] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 07:25:06,672] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 07:25:06,678] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.378 seconds
[2019-09-16 07:25:06,709] {scheduler_job.py:146} INFO - Started process (PID=25767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 07:25:06,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 07:25:06,713] {logging_mixin.py:95} INFO - [2019-09-16 07:25:06,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:41,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:41,270] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 08:43:41,280] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 08:43:41,287] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 4714.578 seconds
[2019-09-16 08:43:41,323] {scheduler_job.py:146} INFO - Started process (PID=25770) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:46,331] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 08:43:46,332] {logging_mixin.py:95} INFO - [2019-09-16 08:43:46,331] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:46,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:46,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 08:43:46,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 08:43:46,707] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 08:43:46,804] {scheduler_job.py:146} INFO - Started process (PID=25778) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:51,815] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 08:43:51,817] {logging_mixin.py:95} INFO - [2019-09-16 08:43:51,816] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:53,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 08:43:53,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:05:36,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:05:36,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 1309.250 seconds
[2019-09-16 09:05:36,176] {scheduler_job.py:146} INFO - Started process (PID=25782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:41,184] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:05:41,185] {logging_mixin.py:95} INFO - [2019-09-16 09:05:41,185] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:41,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:41,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:05:41,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:05:41,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:05:41,640] {scheduler_job.py:146} INFO - Started process (PID=25793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:46,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:05:46,647] {logging_mixin.py:95} INFO - [2019-09-16 09:05:46,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:47,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:47,028] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:05:47,039] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:05:47,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 09:05:47,081] {scheduler_job.py:146} INFO - Started process (PID=25794) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:52,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:05:52,087] {logging_mixin.py:95} INFO - [2019-09-16 09:05:52,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:52,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:52,462] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:05:52,472] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:05:52,478] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:05:52,527] {scheduler_job.py:146} INFO - Started process (PID=25798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:57,535] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:05:57,536] {logging_mixin.py:95} INFO - [2019-09-16 09:05:57,536] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:57,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:05:57,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:05:57,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:05:57,934] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 09:05:57,978] {scheduler_job.py:146} INFO - Started process (PID=25803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:02,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:02,985] {logging_mixin.py:95} INFO - [2019-09-16 09:06:02,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:03,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:03,342] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:03,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:03,356] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 09:06:03,425] {scheduler_job.py:146} INFO - Started process (PID=25804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:08,431] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:08,432] {logging_mixin.py:95} INFO - [2019-09-16 09:06:08,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:08,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:08,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:08,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:08,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:06:08,877] {scheduler_job.py:146} INFO - Started process (PID=25806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:13,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:13,883] {logging_mixin.py:95} INFO - [2019-09-16 09:06:13,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:14,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:14,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:14,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:14,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:06:14,322] {scheduler_job.py:146} INFO - Started process (PID=25810) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:19,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:19,329] {logging_mixin.py:95} INFO - [2019-09-16 09:06:19,328] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:19,680] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:19,703] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:19,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:19,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:06:19,779] {scheduler_job.py:146} INFO - Started process (PID=25811) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:24,784] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:24,785] {logging_mixin.py:95} INFO - [2019-09-16 09:06:24,785] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:25,130] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:25,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:25,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:25,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:06:25,237] {scheduler_job.py:146} INFO - Started process (PID=25815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:30,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:30,248] {logging_mixin.py:95} INFO - [2019-09-16 09:06:30,248] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:30,589] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:30,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:30,621] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:30,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:06:30,702] {scheduler_job.py:146} INFO - Started process (PID=25816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:35,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:35,713] {logging_mixin.py:95} INFO - [2019-09-16 09:06:35,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:36,069] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:36,091] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:36,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:36,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 09:06:36,178] {scheduler_job.py:146} INFO - Started process (PID=25818) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:41,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:41,189] {logging_mixin.py:95} INFO - [2019-09-16 09:06:41,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:41,543] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:41,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:41,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:41,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:06:41,636] {scheduler_job.py:146} INFO - Started process (PID=25820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:46,644] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:46,645] {logging_mixin.py:95} INFO - [2019-09-16 09:06:46,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:46,971] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:46,984] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:46,992] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:46,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.362 seconds
[2019-09-16 09:06:47,081] {scheduler_job.py:146} INFO - Started process (PID=25821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:52,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:52,087] {logging_mixin.py:95} INFO - [2019-09-16 09:06:52,087] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:52,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:52,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:52,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:52,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-16 09:06:52,534] {scheduler_job.py:146} INFO - Started process (PID=25822) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:57,541] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:06:57,542] {logging_mixin.py:95} INFO - [2019-09-16 09:06:57,542] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:57,888] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:06:57,912] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:06:57,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:06:57,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:06:57,987] {scheduler_job.py:146} INFO - Started process (PID=25824) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:02,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:02,994] {logging_mixin.py:95} INFO - [2019-09-16 09:07:02,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:03,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:03,375] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:03,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:03,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 09:07:03,446] {scheduler_job.py:146} INFO - Started process (PID=25825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:08,453] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:08,454] {logging_mixin.py:95} INFO - [2019-09-16 09:07:08,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:08,798] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:08,819] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:08,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:08,833] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:07:08,903] {scheduler_job.py:146} INFO - Started process (PID=25826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:13,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:13,913] {logging_mixin.py:95} INFO - [2019-09-16 09:07:13,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:14,256] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:14,279] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:14,288] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:14,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:07:14,365] {scheduler_job.py:146} INFO - Started process (PID=25829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:19,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:19,372] {logging_mixin.py:95} INFO - [2019-09-16 09:07:19,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:19,721] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:19,744] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:19,753] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:19,760] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:07:19,820] {scheduler_job.py:146} INFO - Started process (PID=25830) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:24,827] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:24,828] {logging_mixin.py:95} INFO - [2019-09-16 09:07:24,828] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:25,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:25,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:25,203] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:25,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:07:25,275] {scheduler_job.py:146} INFO - Started process (PID=25832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:30,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:30,283] {logging_mixin.py:95} INFO - [2019-09-16 09:07:30,283] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:30,629] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:30,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:30,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:30,666] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:07:30,736] {scheduler_job.py:146} INFO - Started process (PID=25833) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:35,741] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:35,742] {logging_mixin.py:95} INFO - [2019-09-16 09:07:35,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:36,087] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:36,111] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:36,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:36,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:07:36,199] {scheduler_job.py:146} INFO - Started process (PID=25834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:41,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:41,208] {logging_mixin.py:95} INFO - [2019-09-16 09:07:41,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:41,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:41,576] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:41,585] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:41,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:07:41,659] {scheduler_job.py:146} INFO - Started process (PID=25836) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:46,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:46,670] {logging_mixin.py:95} INFO - [2019-09-16 09:07:46,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:47,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:47,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:47,040] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:47,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:07:47,123] {scheduler_job.py:146} INFO - Started process (PID=25837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:52,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:52,134] {logging_mixin.py:95} INFO - [2019-09-16 09:07:52,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:52,478] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:52,501] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:52,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:52,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:07:52,582] {scheduler_job.py:146} INFO - Started process (PID=25838) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:57,591] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:07:57,592] {logging_mixin.py:95} INFO - [2019-09-16 09:07:57,592] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:57,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:07:57,955] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:07:57,964] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:07:57,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:07:58,047] {scheduler_job.py:146} INFO - Started process (PID=25840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:03,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:03,056] {logging_mixin.py:95} INFO - [2019-09-16 09:08:03,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:03,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:03,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:03,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:03,436] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:08:03,502] {scheduler_job.py:146} INFO - Started process (PID=25841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:08,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:08,512] {logging_mixin.py:95} INFO - [2019-09-16 09:08:08,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:08,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:08,873] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:08,882] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:08,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:08:08,965] {scheduler_job.py:146} INFO - Started process (PID=25842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:13,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:13,973] {logging_mixin.py:95} INFO - [2019-09-16 09:08:13,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:14,342] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:14,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:14,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:14,375] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 09:08:14,419] {scheduler_job.py:146} INFO - Started process (PID=25845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:19,425] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:19,426] {logging_mixin.py:95} INFO - [2019-09-16 09:08:19,426] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:19,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:19,790] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:19,799] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:19,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:08:19,877] {scheduler_job.py:146} INFO - Started process (PID=25846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:24,882] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:24,883] {logging_mixin.py:95} INFO - [2019-09-16 09:08:24,882] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:25,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:25,255] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:25,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:25,270] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:08:25,329] {scheduler_job.py:146} INFO - Started process (PID=25848) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:30,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:30,343] {logging_mixin.py:95} INFO - [2019-09-16 09:08:30,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:30,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:30,717] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:30,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:30,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 09:08:30,777] {scheduler_job.py:146} INFO - Started process (PID=25864) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:35,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:35,788] {logging_mixin.py:95} INFO - [2019-09-16 09:08:35,787] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:36,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:36,154] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:36,163] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:36,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:08:36,231] {scheduler_job.py:146} INFO - Started process (PID=25867) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:41,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:41,240] {logging_mixin.py:95} INFO - [2019-09-16 09:08:41,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:41,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:41,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:41,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:41,621] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:08:41,693] {scheduler_job.py:146} INFO - Started process (PID=25869) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:46,700] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:46,701] {logging_mixin.py:95} INFO - [2019-09-16 09:08:46,701] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:47,045] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:47,069] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:47,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:47,084] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:08:47,155] {scheduler_job.py:146} INFO - Started process (PID=25870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:52,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:52,164] {logging_mixin.py:95} INFO - [2019-09-16 09:08:52,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:52,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:52,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:52,553] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:52,559] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 09:08:52,614] {scheduler_job.py:146} INFO - Started process (PID=25871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:57,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:08:57,621] {logging_mixin.py:95} INFO - [2019-09-16 09:08:57,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:57,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:08:57,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:08:58,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:08:58,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:08:58,069] {scheduler_job.py:146} INFO - Started process (PID=25873) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:03,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:03,076] {logging_mixin.py:95} INFO - [2019-09-16 09:09:03,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:03,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:03,452] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:03,461] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:03,467] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:09:03,530] {scheduler_job.py:146} INFO - Started process (PID=25874) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:08,537] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:08,538] {logging_mixin.py:95} INFO - [2019-09-16 09:09:08,538] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:08,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:08,907] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:08,916] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:08,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:09:08,986] {scheduler_job.py:146} INFO - Started process (PID=25875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:13,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:13,997] {logging_mixin.py:95} INFO - [2019-09-16 09:09:13,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:14,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:14,362] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:14,371] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:14,384] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:09:14,444] {scheduler_job.py:146} INFO - Started process (PID=25878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:19,450] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:19,451] {logging_mixin.py:95} INFO - [2019-09-16 09:09:19,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:19,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:19,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:19,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:19,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-16 09:09:19,902] {scheduler_job.py:146} INFO - Started process (PID=25879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:24,908] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:24,909] {logging_mixin.py:95} INFO - [2019-09-16 09:09:24,909] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:25,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:25,300] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:25,309] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:25,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 09:09:25,363] {scheduler_job.py:146} INFO - Started process (PID=25881) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:30,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:30,371] {logging_mixin.py:95} INFO - [2019-09-16 09:09:30,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:30,715] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:30,738] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:30,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:30,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:09:30,818] {scheduler_job.py:146} INFO - Started process (PID=25882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:35,828] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:35,829] {logging_mixin.py:95} INFO - [2019-09-16 09:09:35,829] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:36,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:36,230] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:36,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:36,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 09:09:36,275] {scheduler_job.py:146} INFO - Started process (PID=25883) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:41,280] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:41,282] {logging_mixin.py:95} INFO - [2019-09-16 09:09:41,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:41,651] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:41,674] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:41,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:41,689] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 09:09:41,730] {scheduler_job.py:146} INFO - Started process (PID=25885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:46,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:46,735] {logging_mixin.py:95} INFO - [2019-09-16 09:09:46,735] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:47,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:47,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:47,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:47,123] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:09:47,187] {scheduler_job.py:146} INFO - Started process (PID=25886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:52,196] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:52,197] {logging_mixin.py:95} INFO - [2019-09-16 09:09:52,197] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:52,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:52,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:52,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:52,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:09:52,651] {scheduler_job.py:146} INFO - Started process (PID=25887) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:57,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:09:57,663] {logging_mixin.py:95} INFO - [2019-09-16 09:09:57,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:58,027] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:09:58,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:09:58,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:09:58,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 09:09:58,112] {scheduler_job.py:146} INFO - Started process (PID=25889) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:03,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:03,122] {logging_mixin.py:95} INFO - [2019-09-16 09:10:03,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:03,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:03,500] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:03,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:03,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 09:10:03,572] {scheduler_job.py:146} INFO - Started process (PID=25890) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:08,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:08,581] {logging_mixin.py:95} INFO - [2019-09-16 09:10:08,581] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:08,917] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:08,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:08,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:08,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:10:09,025] {scheduler_job.py:146} INFO - Started process (PID=25891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:14,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:14,035] {logging_mixin.py:95} INFO - [2019-09-16 09:10:14,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:14,387] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:14,402] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:14,411] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:14,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:10:14,483] {scheduler_job.py:146} INFO - Started process (PID=25894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:19,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:19,490] {logging_mixin.py:95} INFO - [2019-09-16 09:10:19,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:19,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:19,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:19,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:19,871] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:10:19,948] {scheduler_job.py:146} INFO - Started process (PID=25895) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:24,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:24,957] {logging_mixin.py:95} INFO - [2019-09-16 09:10:24,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:25,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:25,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:25,337] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:25,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:10:25,406] {scheduler_job.py:146} INFO - Started process (PID=25897) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:30,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:30,417] {logging_mixin.py:95} INFO - [2019-09-16 09:10:30,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:30,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:30,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:30,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:30,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:10:30,869] {scheduler_job.py:146} INFO - Started process (PID=25898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:35,877] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:35,878] {logging_mixin.py:95} INFO - [2019-09-16 09:10:35,877] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:36,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:36,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:36,250] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:36,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:10:36,335] {scheduler_job.py:146} INFO - Started process (PID=25899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:41,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:41,344] {logging_mixin.py:95} INFO - [2019-09-16 09:10:41,343] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:41,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:41,705] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:41,714] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:41,719] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:10:41,795] {scheduler_job.py:146} INFO - Started process (PID=25901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:46,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:46,802] {logging_mixin.py:95} INFO - [2019-09-16 09:10:46,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:47,109] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:47,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:47,142] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:47,147] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.353 seconds
[2019-09-16 09:10:47,256] {scheduler_job.py:146} INFO - Started process (PID=25902) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:52,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:52,262] {logging_mixin.py:95} INFO - [2019-09-16 09:10:52,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:52,582] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:52,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:52,615] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:52,620] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-16 09:10:52,718] {scheduler_job.py:146} INFO - Started process (PID=25903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:57,729] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:10:57,730] {logging_mixin.py:95} INFO - [2019-09-16 09:10:57,729] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:58,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:10:58,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:10:58,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:10:58,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:10:58,184] {scheduler_job.py:146} INFO - Started process (PID=25905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:03,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:03,195] {logging_mixin.py:95} INFO - [2019-09-16 09:11:03,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:03,537] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:03,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:03,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:03,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:11:03,652] {scheduler_job.py:146} INFO - Started process (PID=25906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:08,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:08,661] {logging_mixin.py:95} INFO - [2019-09-16 09:11:08,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:08,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:09,020] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:09,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:09,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:11:09,116] {scheduler_job.py:146} INFO - Started process (PID=25907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:14,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:14,125] {logging_mixin.py:95} INFO - [2019-09-16 09:11:14,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:14,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:14,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:14,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:14,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:11:14,576] {scheduler_job.py:146} INFO - Started process (PID=25910) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:19,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:19,589] {logging_mixin.py:95} INFO - [2019-09-16 09:11:19,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:19,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:19,934] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:19,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:19,948] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-16 09:11:20,038] {scheduler_job.py:146} INFO - Started process (PID=25911) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:25,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:25,048] {logging_mixin.py:95} INFO - [2019-09-16 09:11:25,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:25,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:25,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:25,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:25,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:11:25,496] {scheduler_job.py:146} INFO - Started process (PID=25913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:30,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:30,504] {logging_mixin.py:95} INFO - [2019-09-16 09:11:30,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:30,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:30,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:30,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:30,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:11:30,962] {scheduler_job.py:146} INFO - Started process (PID=25914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:35,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:35,972] {logging_mixin.py:95} INFO - [2019-09-16 09:11:35,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:36,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:36,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:36,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:36,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:11:36,426] {scheduler_job.py:146} INFO - Started process (PID=25915) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:41,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:41,435] {logging_mixin.py:95} INFO - [2019-09-16 09:11:41,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:41,770] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:41,794] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:41,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:41,808] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:11:41,884] {scheduler_job.py:146} INFO - Started process (PID=25917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:46,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:46,893] {logging_mixin.py:95} INFO - [2019-09-16 09:11:46,892] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:47,233] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:47,256] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:47,265] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:47,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:11:47,350] {scheduler_job.py:146} INFO - Started process (PID=25918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:52,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:52,357] {logging_mixin.py:95} INFO - [2019-09-16 09:11:52,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:52,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:52,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:52,727] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:52,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:11:52,813] {scheduler_job.py:146} INFO - Started process (PID=25919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:57,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:11:57,824] {logging_mixin.py:95} INFO - [2019-09-16 09:11:57,824] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:58,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:11:58,180] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:11:58,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:11:58,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:11:58,274] {scheduler_job.py:146} INFO - Started process (PID=25921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:03,287] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:03,288] {logging_mixin.py:95} INFO - [2019-09-16 09:12:03,287] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:03,631] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:03,654] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:03,663] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:03,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:12:03,737] {scheduler_job.py:146} INFO - Started process (PID=25922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:08,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:08,747] {logging_mixin.py:95} INFO - [2019-09-16 09:12:08,747] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:09,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:09,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:09,117] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:09,123] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:12:09,201] {scheduler_job.py:146} INFO - Started process (PID=25923) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:14,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:14,213] {logging_mixin.py:95} INFO - [2019-09-16 09:12:14,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:14,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:14,581] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:14,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:14,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:12:14,661] {scheduler_job.py:146} INFO - Started process (PID=25926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:19,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:19,670] {logging_mixin.py:95} INFO - [2019-09-16 09:12:19,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:20,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:20,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:20,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:20,042] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:12:20,116] {scheduler_job.py:146} INFO - Started process (PID=25927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:25,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:25,124] {logging_mixin.py:95} INFO - [2019-09-16 09:12:25,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:25,461] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:25,482] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:25,490] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:25,496] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:12:25,573] {scheduler_job.py:146} INFO - Started process (PID=25929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:30,584] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:30,585] {logging_mixin.py:95} INFO - [2019-09-16 09:12:30,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:30,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:30,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:30,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:30,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:12:31,036] {scheduler_job.py:146} INFO - Started process (PID=25930) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:36,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:36,044] {logging_mixin.py:95} INFO - [2019-09-16 09:12:36,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:36,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:36,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:36,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:36,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:12:36,499] {scheduler_job.py:146} INFO - Started process (PID=25931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:41,508] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:41,509] {logging_mixin.py:95} INFO - [2019-09-16 09:12:41,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:41,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:41,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:41,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:41,877] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:12:41,963] {scheduler_job.py:146} INFO - Started process (PID=25933) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:46,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:46,973] {logging_mixin.py:95} INFO - [2019-09-16 09:12:46,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:47,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:47,335] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:47,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:47,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:12:47,425] {scheduler_job.py:146} INFO - Started process (PID=25934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:52,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:52,439] {logging_mixin.py:95} INFO - [2019-09-16 09:12:52,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:52,779] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:52,803] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:52,812] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:52,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:12:52,885] {scheduler_job.py:146} INFO - Started process (PID=25935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:57,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:12:57,898] {logging_mixin.py:95} INFO - [2019-09-16 09:12:57,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:58,237] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:12:58,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:12:58,270] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:12:58,276] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:12:58,347] {scheduler_job.py:146} INFO - Started process (PID=25937) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:03,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:03,357] {logging_mixin.py:95} INFO - [2019-09-16 09:13:03,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:03,693] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:03,716] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:03,725] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:03,731] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:13:03,814] {scheduler_job.py:146} INFO - Started process (PID=25938) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:08,823] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:08,824] {logging_mixin.py:95} INFO - [2019-09-16 09:13:08,823] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:09,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:09,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:09,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:09,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:13:09,277] {scheduler_job.py:146} INFO - Started process (PID=25939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:14,288] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:14,289] {logging_mixin.py:95} INFO - [2019-09-16 09:13:14,289] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:14,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:14,653] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:14,662] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:14,668] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:13:14,741] {scheduler_job.py:146} INFO - Started process (PID=25942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:19,751] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:19,752] {logging_mixin.py:95} INFO - [2019-09-16 09:13:19,752] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:20,090] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:20,108] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:20,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:20,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 09:13:20,209] {scheduler_job.py:146} INFO - Started process (PID=25943) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:25,215] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:25,216] {logging_mixin.py:95} INFO - [2019-09-16 09:13:25,216] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:25,560] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:25,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:25,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:25,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:13:25,698] {scheduler_job.py:146} INFO - Started process (PID=25946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:30,705] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:30,706] {logging_mixin.py:95} INFO - [2019-09-16 09:13:30,705] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:31,040] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:31,063] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:31,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:31,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:13:31,189] {scheduler_job.py:146} INFO - Started process (PID=25947) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:36,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:36,204] {logging_mixin.py:95} INFO - [2019-09-16 09:13:36,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:36,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:36,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:36,579] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:36,584] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:13:36,683] {scheduler_job.py:146} INFO - Started process (PID=25948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:41,698] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:41,699] {logging_mixin.py:95} INFO - [2019-09-16 09:13:41,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:42,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:42,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:42,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:42,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:13:42,182] {scheduler_job.py:146} INFO - Started process (PID=25950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:47,192] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:47,193] {logging_mixin.py:95} INFO - [2019-09-16 09:13:47,193] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:47,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:47,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:47,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:47,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:13:47,668] {scheduler_job.py:146} INFO - Started process (PID=25951) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:52,677] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:52,678] {logging_mixin.py:95} INFO - [2019-09-16 09:13:52,678] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:53,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:53,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:53,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:53,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.376 seconds
[2019-09-16 09:13:53,063] {scheduler_job.py:146} INFO - Started process (PID=25952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:58,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:13:58,077] {logging_mixin.py:95} INFO - [2019-09-16 09:13:58,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:58,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:13:58,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:13:58,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:13:58,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:13:58,566] {scheduler_job.py:146} INFO - Started process (PID=25954) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:03,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:03,573] {logging_mixin.py:95} INFO - [2019-09-16 09:14:03,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:03,905] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:03,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:03,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:03,943] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:14:03,963] {scheduler_job.py:146} INFO - Started process (PID=25955) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:08,972] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:08,973] {logging_mixin.py:95} INFO - [2019-09-16 09:14:08,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:09,314] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:09,338] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:09,346] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:09,352] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:14:09,463] {scheduler_job.py:146} INFO - Started process (PID=25956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:14,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:14,473] {logging_mixin.py:95} INFO - [2019-09-16 09:14:14,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:14,806] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:14,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:14,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:14,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:14:14,949] {scheduler_job.py:146} INFO - Started process (PID=25959) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:19,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:19,957] {logging_mixin.py:95} INFO - [2019-09-16 09:14:19,957] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:20,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:20,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:20,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:20,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:14:20,360] {scheduler_job.py:146} INFO - Started process (PID=25960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:25,371] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:25,372] {logging_mixin.py:95} INFO - [2019-09-16 09:14:25,371] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:25,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:25,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:25,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:25,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:14:25,860] {scheduler_job.py:146} INFO - Started process (PID=25962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:30,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:30,866] {logging_mixin.py:95} INFO - [2019-09-16 09:14:30,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:31,202] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:31,225] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:31,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:31,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:14:31,348] {scheduler_job.py:146} INFO - Started process (PID=25963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:36,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:36,365] {logging_mixin.py:95} INFO - [2019-09-16 09:14:36,364] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:36,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:36,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:36,737] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:36,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:14:36,842] {scheduler_job.py:146} INFO - Started process (PID=25964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:41,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:41,856] {logging_mixin.py:95} INFO - [2019-09-16 09:14:41,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:42,196] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:42,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:42,228] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:42,234] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:14:42,340] {scheduler_job.py:146} INFO - Started process (PID=25966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:47,355] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:47,356] {logging_mixin.py:95} INFO - [2019-09-16 09:14:47,356] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:47,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:47,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:47,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:47,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:14:47,830] {scheduler_job.py:146} INFO - Started process (PID=25967) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:52,838] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:52,839] {logging_mixin.py:95} INFO - [2019-09-16 09:14:52,839] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:53,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:53,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:53,209] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:53,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:14:53,322] {scheduler_job.py:146} INFO - Started process (PID=25968) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:58,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:14:58,335] {logging_mixin.py:95} INFO - [2019-09-16 09:14:58,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:58,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:14:58,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:14:58,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:14:58,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:14:58,814] {scheduler_job.py:146} INFO - Started process (PID=25970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:03,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:03,823] {logging_mixin.py:95} INFO - [2019-09-16 09:15:03,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:04,160] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:04,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:04,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:04,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:15:04,298] {scheduler_job.py:146} INFO - Started process (PID=25971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:09,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:09,313] {logging_mixin.py:95} INFO - [2019-09-16 09:15:09,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:09,653] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:09,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:09,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:09,691] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:15:09,792] {scheduler_job.py:146} INFO - Started process (PID=25972) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:14,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:14,806] {logging_mixin.py:95} INFO - [2019-09-16 09:15:14,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:15,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:15,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:15,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:15,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:15:15,291] {scheduler_job.py:146} INFO - Started process (PID=25975) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:20,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:20,306] {logging_mixin.py:95} INFO - [2019-09-16 09:15:20,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:20,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:20,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:20,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:20,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:15:20,788] {scheduler_job.py:146} INFO - Started process (PID=25976) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:25,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:25,800] {logging_mixin.py:95} INFO - [2019-09-16 09:15:25,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:26,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:26,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:26,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:26,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:15:26,290] {scheduler_job.py:146} INFO - Started process (PID=25978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:31,301] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:31,302] {logging_mixin.py:95} INFO - [2019-09-16 09:15:31,302] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:31,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:31,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:31,674] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:31,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:15:31,780] {scheduler_job.py:146} INFO - Started process (PID=25979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:36,788] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:36,789] {logging_mixin.py:95} INFO - [2019-09-16 09:15:36,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:37,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:37,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:37,159] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:37,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:15:37,279] {scheduler_job.py:146} INFO - Started process (PID=25980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:42,296] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:42,297] {logging_mixin.py:95} INFO - [2019-09-16 09:15:42,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:42,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:42,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:42,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:42,675] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:15:42,782] {scheduler_job.py:146} INFO - Started process (PID=25982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:47,788] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:47,789] {logging_mixin.py:95} INFO - [2019-09-16 09:15:47,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:48,125] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:48,149] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:48,158] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:48,163] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 09:15:48,184] {scheduler_job.py:146} INFO - Started process (PID=25983) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:53,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:53,203] {logging_mixin.py:95} INFO - [2019-09-16 09:15:53,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:53,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:53,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:53,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:53,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 09:15:53,682] {scheduler_job.py:146} INFO - Started process (PID=25984) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:58,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:15:58,692] {logging_mixin.py:95} INFO - [2019-09-16 09:15:58,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:59,022] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:15:59,047] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:15:59,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:15:59,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 09:15:59,176] {scheduler_job.py:146} INFO - Started process (PID=25986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:04,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:04,189] {logging_mixin.py:95} INFO - [2019-09-16 09:16:04,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:04,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:04,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:04,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:04,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:16:04,671] {scheduler_job.py:146} INFO - Started process (PID=25987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:09,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:09,689] {logging_mixin.py:95} INFO - [2019-09-16 09:16:09,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:10,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:10,046] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:10,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:10,061] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:16:10,165] {scheduler_job.py:146} INFO - Started process (PID=25988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:15,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:15,174] {logging_mixin.py:95} INFO - [2019-09-16 09:16:15,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:15,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:15,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:15,554] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:15,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:16:15,655] {scheduler_job.py:146} INFO - Started process (PID=25991) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:20,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:20,671] {logging_mixin.py:95} INFO - [2019-09-16 09:16:20,671] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:21,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:21,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:21,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:21,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:16:21,148] {scheduler_job.py:146} INFO - Started process (PID=25992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:26,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:26,157] {logging_mixin.py:95} INFO - [2019-09-16 09:16:26,157] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:26,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:26,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:26,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:26,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:16:26,641] {scheduler_job.py:146} INFO - Started process (PID=25994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:31,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:31,648] {logging_mixin.py:95} INFO - [2019-09-16 09:16:31,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:31,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:32,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:32,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:32,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 09:16:32,127] {scheduler_job.py:146} INFO - Started process (PID=25995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:37,137] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:37,139] {logging_mixin.py:95} INFO - [2019-09-16 09:16:37,138] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:37,486] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:37,509] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:37,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:37,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:16:37,619] {scheduler_job.py:146} INFO - Started process (PID=25996) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:42,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:42,634] {logging_mixin.py:95} INFO - [2019-09-16 09:16:42,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:42,974] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:42,997] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:43,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:43,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:16:43,111] {scheduler_job.py:146} INFO - Started process (PID=25998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:48,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:48,122] {logging_mixin.py:95} INFO - [2019-09-16 09:16:48,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:48,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:48,487] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:48,495] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:48,501] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:16:48,609] {scheduler_job.py:146} INFO - Started process (PID=25999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:53,621] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:53,622] {logging_mixin.py:95} INFO - [2019-09-16 09:16:53,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:53,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:53,982] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:53,991] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:53,997] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:16:54,107] {scheduler_job.py:146} INFO - Started process (PID=26000) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:59,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:16:59,122] {logging_mixin.py:95} INFO - [2019-09-16 09:16:59,122] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:59,468] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:16:59,490] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:16:59,499] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:16:59,505] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:16:59,605] {scheduler_job.py:146} INFO - Started process (PID=26002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:04,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:04,621] {logging_mixin.py:95} INFO - [2019-09-16 09:17:04,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:04,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:04,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:04,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:04,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:17:05,091] {scheduler_job.py:146} INFO - Started process (PID=26003) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:10,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:10,105] {logging_mixin.py:95} INFO - [2019-09-16 09:17:10,105] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:10,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:10,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:10,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:10,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 09:17:10,587] {scheduler_job.py:146} INFO - Started process (PID=26005) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:15,595] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:15,596] {logging_mixin.py:95} INFO - [2019-09-16 09:17:15,596] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:15,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:15,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:15,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:15,969] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:17:16,082] {scheduler_job.py:146} INFO - Started process (PID=26007) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:21,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:21,098] {logging_mixin.py:95} INFO - [2019-09-16 09:17:21,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:21,441] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:21,465] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:21,474] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:21,480] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:17:21,574] {scheduler_job.py:146} INFO - Started process (PID=26008) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:26,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:26,586] {logging_mixin.py:95} INFO - [2019-09-16 09:17:26,585] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:26,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:26,943] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:26,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:26,958] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:17:27,066] {scheduler_job.py:146} INFO - Started process (PID=26010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:32,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:32,083] {logging_mixin.py:95} INFO - [2019-09-16 09:17:32,083] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:32,427] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:32,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:32,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:32,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:17:32,556] {scheduler_job.py:146} INFO - Started process (PID=26011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:37,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:37,571] {logging_mixin.py:95} INFO - [2019-09-16 09:17:37,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:37,900] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:37,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:37,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:37,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:17:38,048] {scheduler_job.py:146} INFO - Started process (PID=26012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:43,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:43,057] {logging_mixin.py:95} INFO - [2019-09-16 09:17:43,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:43,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:43,429] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:43,438] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:43,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:17:43,542] {scheduler_job.py:146} INFO - Started process (PID=26014) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:48,553] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:48,554] {logging_mixin.py:95} INFO - [2019-09-16 09:17:48,554] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:48,885] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:48,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:48,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:48,923] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:17:48,943] {scheduler_job.py:146} INFO - Started process (PID=26015) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:53,954] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:53,955] {logging_mixin.py:95} INFO - [2019-09-16 09:17:53,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:54,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:54,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:54,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:54,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:17:54,443] {scheduler_job.py:146} INFO - Started process (PID=26016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:59,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:17:59,457] {logging_mixin.py:95} INFO - [2019-09-16 09:17:59,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:59,792] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:17:59,816] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:17:59,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:17:59,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:17:59,931] {scheduler_job.py:146} INFO - Started process (PID=26018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:04,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:04,949] {logging_mixin.py:95} INFO - [2019-09-16 09:18:04,948] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:05,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:05,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:05,322] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:05,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:18:05,429] {scheduler_job.py:146} INFO - Started process (PID=26019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:10,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:10,441] {logging_mixin.py:95} INFO - [2019-09-16 09:18:10,441] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:10,778] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:10,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:10,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:10,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:18:10,931] {scheduler_job.py:146} INFO - Started process (PID=26021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:15,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:15,943] {logging_mixin.py:95} INFO - [2019-09-16 09:18:15,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:16,281] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:16,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:16,315] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:16,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:18:16,423] {scheduler_job.py:146} INFO - Started process (PID=26023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:21,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:21,435] {logging_mixin.py:95} INFO - [2019-09-16 09:18:21,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:21,768] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:21,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:21,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:21,806] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:18:21,914] {scheduler_job.py:146} INFO - Started process (PID=26024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:26,927] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:26,928] {logging_mixin.py:95} INFO - [2019-09-16 09:18:26,928] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:27,264] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:27,289] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:27,298] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:27,305] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:18:27,406] {scheduler_job.py:146} INFO - Started process (PID=26026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:32,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:32,421] {logging_mixin.py:95} INFO - [2019-09-16 09:18:32,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:32,758] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:32,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:32,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:32,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:18:32,897] {scheduler_job.py:146} INFO - Started process (PID=26027) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:37,912] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:37,913] {logging_mixin.py:95} INFO - [2019-09-16 09:18:37,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:38,253] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:38,276] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:38,285] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:38,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:18:38,391] {scheduler_job.py:146} INFO - Started process (PID=26028) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:43,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:43,409] {logging_mixin.py:95} INFO - [2019-09-16 09:18:43,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:43,786] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:43,807] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:43,817] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:43,824] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 09:18:43,882] {scheduler_job.py:146} INFO - Started process (PID=26030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:48,890] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:48,891] {logging_mixin.py:95} INFO - [2019-09-16 09:18:48,890] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:49,230] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:49,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:49,262] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:49,268] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:18:49,369] {scheduler_job.py:146} INFO - Started process (PID=26031) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:54,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:54,381] {logging_mixin.py:95} INFO - [2019-09-16 09:18:54,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:54,726] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:54,749] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:18:54,758] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:18:54,764] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:18:54,862] {scheduler_job.py:146} INFO - Started process (PID=26032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:18:59,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:18:59,876] {logging_mixin.py:95} INFO - [2019-09-16 09:18:59,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:00,218] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:00,242] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:00,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:00,257] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:19:00,361] {scheduler_job.py:146} INFO - Started process (PID=26034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:05,375] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:05,376] {logging_mixin.py:95} INFO - [2019-09-16 09:19:05,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:05,713] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:05,737] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:05,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:05,752] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:19:05,846] {scheduler_job.py:146} INFO - Started process (PID=26035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:10,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:10,858] {logging_mixin.py:95} INFO - [2019-09-16 09:19:10,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:11,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:11,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:11,229] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:11,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:19:11,342] {scheduler_job.py:146} INFO - Started process (PID=26037) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:16,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:16,358] {logging_mixin.py:95} INFO - [2019-09-16 09:19:16,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:16,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:16,720] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:16,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:16,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:19:16,838] {scheduler_job.py:146} INFO - Started process (PID=26039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:21,853] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:21,854] {logging_mixin.py:95} INFO - [2019-09-16 09:19:21,853] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:22,195] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:22,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:22,227] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:22,233] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:19:22,337] {scheduler_job.py:146} INFO - Started process (PID=26040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:27,343] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:27,344] {logging_mixin.py:95} INFO - [2019-09-16 09:19:27,344] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:27,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:27,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:27,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:27,724] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:19:27,830] {scheduler_job.py:146} INFO - Started process (PID=26042) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:32,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:32,848] {logging_mixin.py:95} INFO - [2019-09-16 09:19:32,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:33,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:33,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:33,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:33,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:19:33,322] {scheduler_job.py:146} INFO - Started process (PID=26043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:38,330] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:38,331] {logging_mixin.py:95} INFO - [2019-09-16 09:19:38,330] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:38,668] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:38,692] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:38,700] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:38,706] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:19:38,815] {scheduler_job.py:146} INFO - Started process (PID=26044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:43,831] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:43,843] {logging_mixin.py:95} INFO - [2019-09-16 09:19:43,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:44,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:44,204] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:44,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:44,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 09:19:44,311] {scheduler_job.py:146} INFO - Started process (PID=26046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:49,320] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:49,321] {logging_mixin.py:95} INFO - [2019-09-16 09:19:49,320] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:49,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:49,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:49,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:49,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:19:49,815] {scheduler_job.py:146} INFO - Started process (PID=26047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:54,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:19:54,827] {logging_mixin.py:95} INFO - [2019-09-16 09:19:54,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:55,165] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:19:55,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:19:55,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:19:55,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:19:55,306] {scheduler_job.py:146} INFO - Started process (PID=26048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:00,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:00,318] {logging_mixin.py:95} INFO - [2019-09-16 09:20:00,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:00,655] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:00,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:00,686] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:00,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:20:00,796] {scheduler_job.py:146} INFO - Started process (PID=26050) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:05,813] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:05,814] {logging_mixin.py:95} INFO - [2019-09-16 09:20:05,814] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:06,151] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:06,174] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:06,183] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:06,189] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:20:06,286] {scheduler_job.py:146} INFO - Started process (PID=26051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:11,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:11,299] {logging_mixin.py:95} INFO - [2019-09-16 09:20:11,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:11,638] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:11,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:11,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:11,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:20:11,779] {scheduler_job.py:146} INFO - Started process (PID=26053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:16,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:16,788] {logging_mixin.py:95} INFO - [2019-09-16 09:20:16,788] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:17,112] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:17,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:17,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:17,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-16 09:20:17,170] {scheduler_job.py:146} INFO - Started process (PID=26055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:22,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:22,180] {logging_mixin.py:95} INFO - [2019-09-16 09:20:22,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:22,539] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:22,556] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:22,565] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:22,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:20:22,664] {scheduler_job.py:146} INFO - Started process (PID=26056) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:27,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:27,675] {logging_mixin.py:95} INFO - [2019-09-16 09:20:27,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:28,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:28,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:28,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:28,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:20:28,158] {scheduler_job.py:146} INFO - Started process (PID=26059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:33,173] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:33,175] {logging_mixin.py:95} INFO - [2019-09-16 09:20:33,174] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:33,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:33,542] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:33,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:33,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:20:33,646] {scheduler_job.py:146} INFO - Started process (PID=26060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:38,655] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:38,656] {logging_mixin.py:95} INFO - [2019-09-16 09:20:38,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:38,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:39,011] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:39,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:39,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:20:39,052] {scheduler_job.py:146} INFO - Started process (PID=26061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:44,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:44,078] {logging_mixin.py:95} INFO - [2019-09-16 09:20:44,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:44,418] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:44,441] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:44,450] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:44,456] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 09:20:44,543] {scheduler_job.py:146} INFO - Started process (PID=26063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:49,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:49,551] {logging_mixin.py:95} INFO - [2019-09-16 09:20:49,551] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:49,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:49,906] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:49,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:49,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:20:50,036] {scheduler_job.py:146} INFO - Started process (PID=26064) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:55,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:20:55,050] {logging_mixin.py:95} INFO - [2019-09-16 09:20:55,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:55,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:20:55,419] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:20:55,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:20:55,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:20:55,533] {scheduler_job.py:146} INFO - Started process (PID=26065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:00,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:00,546] {logging_mixin.py:95} INFO - [2019-09-16 09:21:00,546] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:00,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:00,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:00,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:00,919] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:21:01,031] {scheduler_job.py:146} INFO - Started process (PID=26067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:06,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:06,040] {logging_mixin.py:95} INFO - [2019-09-16 09:21:06,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:06,386] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:06,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:06,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:06,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:21:06,521] {scheduler_job.py:146} INFO - Started process (PID=26068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:11,533] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:11,534] {logging_mixin.py:95} INFO - [2019-09-16 09:21:11,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:11,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:11,891] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:11,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:11,906] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:21:12,020] {scheduler_job.py:146} INFO - Started process (PID=26070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:17,031] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:17,033] {logging_mixin.py:95} INFO - [2019-09-16 09:21:17,032] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:17,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:17,405] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:17,414] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:17,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:21:17,516] {scheduler_job.py:146} INFO - Started process (PID=26073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:22,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:22,527] {logging_mixin.py:95} INFO - [2019-09-16 09:21:22,526] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:22,860] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:22,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:22,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:22,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 09:21:23,014] {scheduler_job.py:146} INFO - Started process (PID=26074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:28,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:28,026] {logging_mixin.py:95} INFO - [2019-09-16 09:21:28,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:28,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:28,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:28,417] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:28,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 09:21:28,514] {scheduler_job.py:146} INFO - Started process (PID=26078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:33,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:33,527] {logging_mixin.py:95} INFO - [2019-09-16 09:21:33,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:33,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:33,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:33,899] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:33,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:21:34,013] {scheduler_job.py:146} INFO - Started process (PID=26079) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:39,025] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:39,026] {logging_mixin.py:95} INFO - [2019-09-16 09:21:39,026] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:39,370] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:39,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:39,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:39,408] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:21:39,500] {scheduler_job.py:146} INFO - Started process (PID=26080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:44,513] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:44,525] {logging_mixin.py:95} INFO - [2019-09-16 09:21:44,524] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:44,861] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:44,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:44,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:44,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:21:44,980] {scheduler_job.py:146} INFO - Started process (PID=26082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:49,988] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:49,989] {logging_mixin.py:95} INFO - [2019-09-16 09:21:49,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:50,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:50,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:50,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:50,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:21:50,481] {scheduler_job.py:146} INFO - Started process (PID=26083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:55,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:21:55,490] {logging_mixin.py:95} INFO - [2019-09-16 09:21:55,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:55,826] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:21:55,851] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:21:55,860] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:21:55,865] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:21:55,980] {scheduler_job.py:146} INFO - Started process (PID=26085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:00,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:00,996] {logging_mixin.py:95} INFO - [2019-09-16 09:22:00,996] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:01,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:01,360] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:01,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:01,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:22:01,472] {scheduler_job.py:146} INFO - Started process (PID=26086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:06,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:06,484] {logging_mixin.py:95} INFO - [2019-09-16 09:22:06,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:06,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:06,845] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:06,854] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:06,860] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:22:06,972] {scheduler_job.py:146} INFO - Started process (PID=26087) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:11,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:11,984] {logging_mixin.py:95} INFO - [2019-09-16 09:22:11,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:12,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:12,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:12,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:12,361] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:22:12,463] {scheduler_job.py:146} INFO - Started process (PID=26089) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:17,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:17,478] {logging_mixin.py:95} INFO - [2019-09-16 09:22:17,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:17,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:17,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:17,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:17,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:22:17,958] {scheduler_job.py:146} INFO - Started process (PID=26091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:22,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:22,974] {logging_mixin.py:95} INFO - [2019-09-16 09:22:22,973] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:23,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:23,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:23,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:23,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:22:23,451] {scheduler_job.py:146} INFO - Started process (PID=26092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:28,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:28,466] {logging_mixin.py:95} INFO - [2019-09-16 09:22:28,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:28,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:28,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:28,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:28,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:22:28,945] {scheduler_job.py:146} INFO - Started process (PID=26094) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:33,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:33,953] {logging_mixin.py:95} INFO - [2019-09-16 09:22:33,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:34,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:34,317] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:34,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:34,333] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:22:34,446] {scheduler_job.py:146} INFO - Started process (PID=26095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:39,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:39,453] {logging_mixin.py:95} INFO - [2019-09-16 09:22:39,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:39,783] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:39,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:39,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:39,821] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 09:22:39,844] {scheduler_job.py:146} INFO - Started process (PID=26096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:44,848] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:44,849] {logging_mixin.py:95} INFO - [2019-09-16 09:22:44,849] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:45,180] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:45,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:45,212] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:45,217] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-16 09:22:45,324] {scheduler_job.py:146} INFO - Started process (PID=26098) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:50,332] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:50,333] {logging_mixin.py:95} INFO - [2019-09-16 09:22:50,333] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:50,675] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:50,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:50,707] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:50,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:22:50,813] {scheduler_job.py:146} INFO - Started process (PID=26099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:55,826] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:22:55,827] {logging_mixin.py:95} INFO - [2019-09-16 09:22:55,827] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:56,171] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:22:56,194] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:22:56,203] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:22:56,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:22:56,309] {scheduler_job.py:146} INFO - Started process (PID=26101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:01,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:01,317] {logging_mixin.py:95} INFO - [2019-09-16 09:23:01,316] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:01,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:01,685] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:01,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:01,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:23:01,812] {scheduler_job.py:146} INFO - Started process (PID=26102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:06,821] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:06,822] {logging_mixin.py:95} INFO - [2019-09-16 09:23:06,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:07,162] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:07,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:07,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:07,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:23:07,316] {scheduler_job.py:146} INFO - Started process (PID=26103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:12,326] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:12,339] {logging_mixin.py:95} INFO - [2019-09-16 09:23:12,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:12,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:12,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:12,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:12,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:23:12,807] {scheduler_job.py:146} INFO - Started process (PID=26105) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:17,816] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:17,817] {logging_mixin.py:95} INFO - [2019-09-16 09:23:17,816] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:18,156] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:18,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:18,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:18,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:23:18,296] {scheduler_job.py:146} INFO - Started process (PID=26107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:23,307] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:23,319] {logging_mixin.py:95} INFO - [2019-09-16 09:23:23,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:23,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:23,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:23,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:23,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 09:23:23,794] {scheduler_job.py:146} INFO - Started process (PID=26108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:28,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:28,800] {logging_mixin.py:95} INFO - [2019-09-16 09:23:28,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:29,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:29,157] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:29,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:29,171] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:23:29,280] {scheduler_job.py:146} INFO - Started process (PID=26110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:34,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:34,296] {logging_mixin.py:95} INFO - [2019-09-16 09:23:34,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:34,643] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:34,667] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:34,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:34,681] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 09:23:34,773] {scheduler_job.py:146} INFO - Started process (PID=26111) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:39,778] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:39,779] {logging_mixin.py:95} INFO - [2019-09-16 09:23:39,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:40,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:40,138] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:40,147] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:40,153] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:23:40,271] {scheduler_job.py:146} INFO - Started process (PID=26112) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:45,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:45,276] {logging_mixin.py:95} INFO - [2019-09-16 09:23:45,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:45,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:45,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:45,643] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:45,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 09:23:45,752] {scheduler_job.py:146} INFO - Started process (PID=26114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:50,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:50,766] {logging_mixin.py:95} INFO - [2019-09-16 09:23:50,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:51,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:51,125] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:51,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:51,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:23:51,229] {scheduler_job.py:146} INFO - Started process (PID=26115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:56,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:23:56,241] {logging_mixin.py:95} INFO - [2019-09-16 09:23:56,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:56,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:23:56,609] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:23:56,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:23:56,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:23:56,717] {scheduler_job.py:146} INFO - Started process (PID=26117) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:01,732] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:01,733] {logging_mixin.py:95} INFO - [2019-09-16 09:24:01,733] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:02,066] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:02,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:02,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:02,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:24:02,215] {scheduler_job.py:146} INFO - Started process (PID=26118) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:07,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:07,224] {logging_mixin.py:95} INFO - [2019-09-16 09:24:07,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:07,569] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:07,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:07,599] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:07,605] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:24:07,705] {scheduler_job.py:146} INFO - Started process (PID=26119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:12,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:12,716] {logging_mixin.py:95} INFO - [2019-09-16 09:24:12,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:13,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:13,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:13,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:13,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:24:13,198] {scheduler_job.py:146} INFO - Started process (PID=26121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:18,210] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:18,211] {logging_mixin.py:95} INFO - [2019-09-16 09:24:18,211] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:18,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:18,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:18,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:18,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:24:18,695] {scheduler_job.py:146} INFO - Started process (PID=26123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:23,704] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:23,717] {logging_mixin.py:95} INFO - [2019-09-16 09:24:23,716] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:24,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:24,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:24,083] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:24,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:24:24,192] {scheduler_job.py:146} INFO - Started process (PID=26124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:29,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:29,199] {logging_mixin.py:95} INFO - [2019-09-16 09:24:29,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:29,546] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:29,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:29,577] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:29,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:24:29,681] {scheduler_job.py:146} INFO - Started process (PID=26126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:34,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:34,694] {logging_mixin.py:95} INFO - [2019-09-16 09:24:34,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:35,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:35,055] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:35,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:35,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:24:35,186] {scheduler_job.py:146} INFO - Started process (PID=26127) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:40,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:40,194] {logging_mixin.py:95} INFO - [2019-09-16 09:24:40,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:40,542] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:40,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:40,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:40,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:24:40,679] {scheduler_job.py:146} INFO - Started process (PID=26128) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:45,693] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:45,694] {logging_mixin.py:95} INFO - [2019-09-16 09:24:45,694] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:46,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:46,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:46,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:46,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:24:46,177] {scheduler_job.py:146} INFO - Started process (PID=26130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:51,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:51,192] {logging_mixin.py:95} INFO - [2019-09-16 09:24:51,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:51,540] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:51,562] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:51,571] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:51,577] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:24:51,663] {scheduler_job.py:146} INFO - Started process (PID=26131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:56,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:24:56,674] {logging_mixin.py:95} INFO - [2019-09-16 09:24:56,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:57,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:24:57,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:24:57,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:24:57,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:24:57,153] {scheduler_job.py:146} INFO - Started process (PID=26133) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:02,168] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:02,169] {logging_mixin.py:95} INFO - [2019-09-16 09:25:02,169] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:02,512] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:02,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:02,545] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:02,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:25:02,651] {scheduler_job.py:146} INFO - Started process (PID=26134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:07,667] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:07,668] {logging_mixin.py:95} INFO - [2019-09-16 09:25:07,667] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:07,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:08,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:08,030] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:08,035] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:25:08,146] {scheduler_job.py:146} INFO - Started process (PID=26135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:13,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:13,162] {logging_mixin.py:95} INFO - [2019-09-16 09:25:13,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:13,514] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:13,537] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:13,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:13,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 09:25:13,642] {scheduler_job.py:146} INFO - Started process (PID=26137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:18,648] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:18,649] {logging_mixin.py:95} INFO - [2019-09-16 09:25:18,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:19,025] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:19,048] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:19,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:19,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 09:25:19,130] {scheduler_job.py:146} INFO - Started process (PID=26139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:24,142] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:24,143] {logging_mixin.py:95} INFO - [2019-09-16 09:25:24,142] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:24,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:24,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:24,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:24,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:25:24,628] {scheduler_job.py:146} INFO - Started process (PID=26140) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:29,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:29,639] {logging_mixin.py:95} INFO - [2019-09-16 09:25:29,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:29,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:29,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:30,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:30,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:25:30,128] {scheduler_job.py:146} INFO - Started process (PID=26142) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:35,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:35,136] {logging_mixin.py:95} INFO - [2019-09-16 09:25:35,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:35,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:35,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:35,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:35,516] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:25:35,627] {scheduler_job.py:146} INFO - Started process (PID=26143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:40,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:40,635] {logging_mixin.py:95} INFO - [2019-09-16 09:25:40,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:40,975] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:40,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:41,007] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:41,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:25:41,128] {scheduler_job.py:146} INFO - Started process (PID=26145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:46,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:46,152] {logging_mixin.py:95} INFO - [2019-09-16 09:25:46,151] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:46,495] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:46,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:46,528] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:46,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 09:25:46,624] {scheduler_job.py:146} INFO - Started process (PID=26146) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:51,634] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:51,635] {logging_mixin.py:95} INFO - [2019-09-16 09:25:51,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:51,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:51,980] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:51,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:51,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-16 09:25:52,013] {scheduler_job.py:146} INFO - Started process (PID=26147) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:57,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:25:57,027] {logging_mixin.py:95} INFO - [2019-09-16 09:25:57,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:57,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:25:57,397] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:25:57,406] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:25:57,412] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:25:57,503] {scheduler_job.py:146} INFO - Started process (PID=26149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:02,511] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:02,512] {logging_mixin.py:95} INFO - [2019-09-16 09:26:02,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:02,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:02,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:02,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:02,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:26:02,999] {scheduler_job.py:146} INFO - Started process (PID=26150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:08,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:08,011] {logging_mixin.py:95} INFO - [2019-09-16 09:26:08,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:08,352] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:08,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:08,385] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:08,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:26:08,494] {scheduler_job.py:146} INFO - Started process (PID=26151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:13,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:13,503] {logging_mixin.py:95} INFO - [2019-09-16 09:26:13,503] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:13,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:13,873] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:13,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:13,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:26:13,976] {scheduler_job.py:146} INFO - Started process (PID=26153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:18,983] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:18,984] {logging_mixin.py:95} INFO - [2019-09-16 09:26:18,984] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:19,350] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:19,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:19,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:19,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 09:26:19,433] {scheduler_job.py:146} INFO - Started process (PID=26157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:24,443] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:24,455] {logging_mixin.py:95} INFO - [2019-09-16 09:26:24,454] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:24,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:24,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:24,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:24,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 09:26:24,981] {scheduler_job.py:146} INFO - Started process (PID=26158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:29,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:29,990] {logging_mixin.py:95} INFO - [2019-09-16 09:26:29,990] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:30,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:30,364] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:30,374] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:30,380] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:26:30,428] {scheduler_job.py:146} INFO - Started process (PID=26160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:35,438] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:35,439] {logging_mixin.py:95} INFO - [2019-09-16 09:26:35,439] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:35,777] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:35,800] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:35,808] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:35,814] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:26:35,879] {scheduler_job.py:146} INFO - Started process (PID=26161) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:40,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:40,886] {logging_mixin.py:95} INFO - [2019-09-16 09:26:40,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:41,236] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:41,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:41,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:41,274] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:26:41,332] {scheduler_job.py:146} INFO - Started process (PID=26163) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:46,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:46,340] {logging_mixin.py:95} INFO - [2019-09-16 09:26:46,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:46,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:46,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:46,726] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:46,732] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:26:46,786] {scheduler_job.py:146} INFO - Started process (PID=26164) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:51,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:51,795] {logging_mixin.py:95} INFO - [2019-09-16 09:26:51,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:52,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:52,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:52,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:52,165] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:26:52,243] {scheduler_job.py:146} INFO - Started process (PID=26165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:57,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:26:57,253] {logging_mixin.py:95} INFO - [2019-09-16 09:26:57,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:57,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:26:57,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:26:57,633] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:26:57,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:26:57,706] {scheduler_job.py:146} INFO - Started process (PID=26167) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:02,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:02,714] {logging_mixin.py:95} INFO - [2019-09-16 09:27:02,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:03,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:03,076] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:03,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:03,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:27:03,170] {scheduler_job.py:146} INFO - Started process (PID=26168) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:08,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:08,179] {logging_mixin.py:95} INFO - [2019-09-16 09:27:08,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:08,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:08,551] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:08,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:08,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:27:08,630] {scheduler_job.py:146} INFO - Started process (PID=26169) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:13,640] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:13,646] {logging_mixin.py:95} INFO - [2019-09-16 09:27:13,645] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:13,989] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:14,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:14,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:14,028] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:27:14,092] {scheduler_job.py:146} INFO - Started process (PID=26171) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:19,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:19,099] {logging_mixin.py:95} INFO - [2019-09-16 09:27:19,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:19,454] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:19,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:19,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:19,492] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:27:19,549] {scheduler_job.py:146} INFO - Started process (PID=26174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:24,558] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:24,559] {logging_mixin.py:95} INFO - [2019-09-16 09:27:24,559] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:24,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:24,928] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:24,937] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:24,942] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:27:25,009] {scheduler_job.py:146} INFO - Started process (PID=26175) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:30,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:30,016] {logging_mixin.py:95} INFO - [2019-09-16 09:27:30,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:30,356] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:30,379] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:30,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:30,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:27:30,466] {scheduler_job.py:146} INFO - Started process (PID=26177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:35,472] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:35,473] {logging_mixin.py:95} INFO - [2019-09-16 09:27:35,473] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:35,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:35,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:35,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:35,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:27:35,924] {scheduler_job.py:146} INFO - Started process (PID=26178) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:40,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:40,931] {logging_mixin.py:95} INFO - [2019-09-16 09:27:40,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:41,273] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:41,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:41,306] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:41,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:27:41,384] {scheduler_job.py:146} INFO - Started process (PID=26180) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:46,390] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:46,392] {logging_mixin.py:95} INFO - [2019-09-16 09:27:46,391] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:46,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:46,755] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:46,763] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:46,769] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:27:46,842] {scheduler_job.py:146} INFO - Started process (PID=26181) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:51,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:51,852] {logging_mixin.py:95} INFO - [2019-09-16 09:27:51,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:52,194] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:52,218] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:52,226] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:52,232] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:27:52,306] {scheduler_job.py:146} INFO - Started process (PID=26182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:57,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:27:57,314] {logging_mixin.py:95} INFO - [2019-09-16 09:27:57,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:57,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:27:57,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:27:57,691] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:27:57,697] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:27:57,762] {scheduler_job.py:146} INFO - Started process (PID=26184) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:02,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:02,771] {logging_mixin.py:95} INFO - [2019-09-16 09:28:02,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:03,117] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:03,141] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:03,150] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:03,155] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:28:03,215] {scheduler_job.py:146} INFO - Started process (PID=26185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:08,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:08,222] {logging_mixin.py:95} INFO - [2019-09-16 09:28:08,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:08,608] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:08,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:08,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:08,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 09:28:08,679] {scheduler_job.py:146} INFO - Started process (PID=26186) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:13,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:13,689] {logging_mixin.py:95} INFO - [2019-09-16 09:28:13,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:14,034] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:14,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:14,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:14,063] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:28:14,125] {scheduler_job.py:146} INFO - Started process (PID=26188) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:19,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:19,133] {logging_mixin.py:95} INFO - [2019-09-16 09:28:19,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:19,494] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:19,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:19,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:19,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 09:28:19,578] {scheduler_job.py:146} INFO - Started process (PID=26190) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:24,587] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:24,598] {logging_mixin.py:95} INFO - [2019-09-16 09:28:24,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:24,938] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:24,961] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:24,969] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:24,976] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:28:25,041] {scheduler_job.py:146} INFO - Started process (PID=26191) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:30,047] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:30,048] {logging_mixin.py:95} INFO - [2019-09-16 09:28:30,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:30,395] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:30,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:30,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:30,434] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:28:30,502] {scheduler_job.py:146} INFO - Started process (PID=26193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:35,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:35,513] {logging_mixin.py:95} INFO - [2019-09-16 09:28:35,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:35,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:35,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:35,883] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:35,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:28:35,964] {scheduler_job.py:146} INFO - Started process (PID=26194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:40,973] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:40,974] {logging_mixin.py:95} INFO - [2019-09-16 09:28:40,974] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:41,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:41,341] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:41,350] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:41,355] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:28:41,427] {scheduler_job.py:146} INFO - Started process (PID=26196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:46,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:46,445] {logging_mixin.py:95} INFO - [2019-09-16 09:28:46,445] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:46,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:46,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:46,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:46,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:28:46,886] {scheduler_job.py:146} INFO - Started process (PID=26197) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:51,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:51,897] {logging_mixin.py:95} INFO - [2019-09-16 09:28:51,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:52,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:52,264] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:52,273] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:52,279] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:28:52,346] {scheduler_job.py:146} INFO - Started process (PID=26198) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:57,356] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:28:57,357] {logging_mixin.py:95} INFO - [2019-09-16 09:28:57,357] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:57,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:28:57,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:28:57,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:28:57,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:28:57,794] {scheduler_job.py:146} INFO - Started process (PID=26200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:02,804] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:02,805] {logging_mixin.py:95} INFO - [2019-09-16 09:29:02,805] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:03,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:03,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:03,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:03,186] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:29:03,254] {scheduler_job.py:146} INFO - Started process (PID=26201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:08,262] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:08,263] {logging_mixin.py:95} INFO - [2019-09-16 09:29:08,263] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:08,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:08,631] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:08,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:08,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:29:08,718] {scheduler_job.py:146} INFO - Started process (PID=26202) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:13,728] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:13,740] {logging_mixin.py:95} INFO - [2019-09-16 09:29:13,739] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:14,076] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:14,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:14,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:14,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:29:14,178] {scheduler_job.py:146} INFO - Started process (PID=26204) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:19,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:19,186] {logging_mixin.py:95} INFO - [2019-09-16 09:29:19,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:19,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:19,565] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:19,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:19,579] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 09:29:19,641] {scheduler_job.py:146} INFO - Started process (PID=26206) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:24,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:24,662] {logging_mixin.py:95} INFO - [2019-09-16 09:29:24,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:25,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:25,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:25,031] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:25,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:29:25,103] {scheduler_job.py:146} INFO - Started process (PID=26207) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:30,109] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:30,110] {logging_mixin.py:95} INFO - [2019-09-16 09:29:30,110] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:30,456] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:30,480] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:30,489] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:30,495] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:29:30,565] {scheduler_job.py:146} INFO - Started process (PID=26209) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:35,570] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:35,571] {logging_mixin.py:95} INFO - [2019-09-16 09:29:35,570] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:35,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:35,938] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:35,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:35,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:29:36,026] {scheduler_job.py:146} INFO - Started process (PID=26210) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:41,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:41,037] {logging_mixin.py:95} INFO - [2019-09-16 09:29:41,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:41,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:41,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:41,418] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:41,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:29:41,489] {scheduler_job.py:146} INFO - Started process (PID=26212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:46,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:46,507] {logging_mixin.py:95} INFO - [2019-09-16 09:29:46,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:46,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:46,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:46,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:46,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:29:46,955] {scheduler_job.py:146} INFO - Started process (PID=26213) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:51,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:51,963] {logging_mixin.py:95} INFO - [2019-09-16 09:29:51,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:52,304] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:52,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:52,338] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:52,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:29:52,413] {scheduler_job.py:146} INFO - Started process (PID=26214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:57,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:29:57,422] {logging_mixin.py:95} INFO - [2019-09-16 09:29:57,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:57,764] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:29:57,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:29:57,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:29:57,796] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:29:57,869] {scheduler_job.py:146} INFO - Started process (PID=26216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:02,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:02,876] {logging_mixin.py:95} INFO - [2019-09-16 09:30:02,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:03,228] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:03,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:03,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:03,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:30:03,326] {scheduler_job.py:146} INFO - Started process (PID=26218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:08,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:08,338] {logging_mixin.py:95} INFO - [2019-09-16 09:30:08,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:08,682] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:08,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:08,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:08,711] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:30:08,787] {scheduler_job.py:146} INFO - Started process (PID=26219) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:13,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:13,805] {logging_mixin.py:95} INFO - [2019-09-16 09:30:13,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:14,147] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:14,171] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:14,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:14,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 09:30:14,251] {scheduler_job.py:146} INFO - Started process (PID=26221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:19,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:19,262] {logging_mixin.py:95} INFO - [2019-09-16 09:30:19,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:19,612] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:19,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:19,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:19,650] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:30:19,711] {scheduler_job.py:146} INFO - Started process (PID=26223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:24,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:24,728] {logging_mixin.py:95} INFO - [2019-09-16 09:30:24,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:25,069] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:25,092] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:25,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:25,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:30:25,173] {scheduler_job.py:146} INFO - Started process (PID=26224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:30,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:30,181] {logging_mixin.py:95} INFO - [2019-09-16 09:30:30,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:30,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:30,551] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:30,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:30,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:30:30,631] {scheduler_job.py:146} INFO - Started process (PID=26226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:35,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:35,643] {logging_mixin.py:95} INFO - [2019-09-16 09:30:35,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:35,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:36,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:36,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:36,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:30:36,087] {scheduler_job.py:146} INFO - Started process (PID=26227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:41,095] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:41,096] {logging_mixin.py:95} INFO - [2019-09-16 09:30:41,096] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:41,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:41,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:41,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:41,484] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:30:41,557] {scheduler_job.py:146} INFO - Started process (PID=26229) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:46,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:46,577] {logging_mixin.py:95} INFO - [2019-09-16 09:30:46,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:46,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:46,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:46,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:46,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:30:47,020] {scheduler_job.py:146} INFO - Started process (PID=26230) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:52,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:52,027] {logging_mixin.py:95} INFO - [2019-09-16 09:30:52,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:52,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:52,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:52,400] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:52,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:30:52,485] {scheduler_job.py:146} INFO - Started process (PID=26231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:57,495] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:30:57,496] {logging_mixin.py:95} INFO - [2019-09-16 09:30:57,496] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:57,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:30:57,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:30:57,864] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:30:57,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:30:57,946] {scheduler_job.py:146} INFO - Started process (PID=26233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:02,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:02,953] {logging_mixin.py:95} INFO - [2019-09-16 09:31:02,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:03,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:03,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:03,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:03,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:31:03,398] {scheduler_job.py:146} INFO - Started process (PID=26234) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:08,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:08,406] {logging_mixin.py:95} INFO - [2019-09-16 09:31:08,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:08,749] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:08,771] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:08,781] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:08,786] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:31:08,861] {scheduler_job.py:146} INFO - Started process (PID=26235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:13,869] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:13,871] {logging_mixin.py:95} INFO - [2019-09-16 09:31:13,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:14,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:14,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:14,251] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:14,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 09:31:14,323] {scheduler_job.py:146} INFO - Started process (PID=26237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:19,328] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:19,329] {logging_mixin.py:95} INFO - [2019-09-16 09:31:19,329] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:19,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:19,702] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:19,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:19,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:31:19,787] {scheduler_job.py:146} INFO - Started process (PID=26239) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:24,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:24,804] {logging_mixin.py:95} INFO - [2019-09-16 09:31:24,804] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:25,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:25,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:25,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:25,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:31:25,250] {scheduler_job.py:146} INFO - Started process (PID=26240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:30,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:30,261] {logging_mixin.py:95} INFO - [2019-09-16 09:31:30,261] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:30,611] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:30,635] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:30,644] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:30,649] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:31:30,735] {scheduler_job.py:146} INFO - Started process (PID=26242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:35,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:35,745] {logging_mixin.py:95} INFO - [2019-09-16 09:31:35,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:36,094] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:36,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:36,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:36,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:31:36,218] {scheduler_job.py:146} INFO - Started process (PID=26243) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:41,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:41,229] {logging_mixin.py:95} INFO - [2019-09-16 09:31:41,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:41,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:41,597] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:41,607] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:41,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:31:41,717] {scheduler_job.py:146} INFO - Started process (PID=26245) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:46,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:46,743] {logging_mixin.py:95} INFO - [2019-09-16 09:31:46,742] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:47,080] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:47,104] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:47,113] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:47,119] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:31:47,207] {scheduler_job.py:146} INFO - Started process (PID=26246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:52,219] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:52,220] {logging_mixin.py:95} INFO - [2019-09-16 09:31:52,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:52,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:52,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:52,601] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:52,606] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:31:52,703] {scheduler_job.py:146} INFO - Started process (PID=26247) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:57,711] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:31:57,712] {logging_mixin.py:95} INFO - [2019-09-16 09:31:57,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:58,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:31:58,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:31:58,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:31:58,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:31:58,190] {scheduler_job.py:146} INFO - Started process (PID=26249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:03,201] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:03,203] {logging_mixin.py:95} INFO - [2019-09-16 09:32:03,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:03,551] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:03,575] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:03,584] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:03,590] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 09:32:03,681] {scheduler_job.py:146} INFO - Started process (PID=26250) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:08,694] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:08,695] {logging_mixin.py:95} INFO - [2019-09-16 09:32:08,695] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:09,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:09,053] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:09,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:09,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:32:09,173] {scheduler_job.py:146} INFO - Started process (PID=26251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:14,180] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:14,192] {logging_mixin.py:95} INFO - [2019-09-16 09:32:14,192] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:14,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:14,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:14,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:14,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 09:32:14,669] {scheduler_job.py:146} INFO - Started process (PID=26253) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:19,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:19,676] {logging_mixin.py:95} INFO - [2019-09-16 09:32:19,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:20,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:20,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:20,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:20,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 09:32:20,067] {scheduler_job.py:146} INFO - Started process (PID=26255) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:25,077] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:25,090] {logging_mixin.py:95} INFO - [2019-09-16 09:32:25,089] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:25,434] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:25,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:25,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:25,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 09:32:25,560] {scheduler_job.py:146} INFO - Started process (PID=26256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:30,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:30,576] {logging_mixin.py:95} INFO - [2019-09-16 09:32:30,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:30,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:30,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:30,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:30,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:32:31,056] {scheduler_job.py:146} INFO - Started process (PID=26258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:36,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:36,068] {logging_mixin.py:95} INFO - [2019-09-16 09:32:36,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:36,411] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:36,433] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:36,442] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:36,447] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:32:36,554] {scheduler_job.py:146} INFO - Started process (PID=26259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:41,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:41,562] {logging_mixin.py:95} INFO - [2019-09-16 09:32:41,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:41,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:41,922] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:41,931] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:41,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 09:32:42,041] {scheduler_job.py:146} INFO - Started process (PID=26261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:47,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:47,067] {logging_mixin.py:95} INFO - [2019-09-16 09:32:47,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:47,413] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:47,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:47,446] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:47,451] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 09:32:47,539] {scheduler_job.py:146} INFO - Started process (PID=26262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:52,545] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:52,546] {logging_mixin.py:95} INFO - [2019-09-16 09:32:52,545] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:52,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:52,905] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:52,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:52,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:32:53,036] {scheduler_job.py:146} INFO - Started process (PID=26263) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:58,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:32:58,049] {logging_mixin.py:95} INFO - [2019-09-16 09:32:58,049] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:58,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:32:58,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:32:58,428] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:32:58,433] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:32:58,533] {scheduler_job.py:146} INFO - Started process (PID=26265) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:03,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:03,540] {logging_mixin.py:95} INFO - [2019-09-16 09:33:03,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:03,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:03,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:03,910] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:03,915] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 09:33:04,026] {scheduler_job.py:146} INFO - Started process (PID=26266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:09,042] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:09,043] {logging_mixin.py:95} INFO - [2019-09-16 09:33:09,043] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:09,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:09,413] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:09,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:09,428] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:33:09,521] {scheduler_job.py:146} INFO - Started process (PID=26267) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:14,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:14,540] {logging_mixin.py:95} INFO - [2019-09-16 09:33:14,539] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:14,880] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:14,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:14,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:14,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:33:15,014] {scheduler_job.py:146} INFO - Started process (PID=26269) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:20,027] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:20,028] {logging_mixin.py:95} INFO - [2019-09-16 09:33:20,028] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:20,369] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:20,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:20,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:20,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:33:20,507] {scheduler_job.py:146} INFO - Started process (PID=26271) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:25,522] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:25,531] {logging_mixin.py:95} INFO - [2019-09-16 09:33:25,531] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:25,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:25,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:25,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:25,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:33:26,008] {scheduler_job.py:146} INFO - Started process (PID=26272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:31,023] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:31,025] {logging_mixin.py:95} INFO - [2019-09-16 09:33:31,024] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:31,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:31,384] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:31,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:31,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 09:33:31,500] {scheduler_job.py:146} INFO - Started process (PID=26274) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:36,513] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:36,514] {logging_mixin.py:95} INFO - [2019-09-16 09:33:36,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:36,847] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:36,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:36,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:36,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:33:36,993] {scheduler_job.py:146} INFO - Started process (PID=26275) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:42,003] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:42,004] {logging_mixin.py:95} INFO - [2019-09-16 09:33:42,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:42,341] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:42,365] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:42,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:42,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:33:42,495] {scheduler_job.py:146} INFO - Started process (PID=26277) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:47,505] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:47,506] {logging_mixin.py:95} INFO - [2019-09-16 09:33:47,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:47,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:47,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:47,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:47,884] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:33:47,993] {scheduler_job.py:146} INFO - Started process (PID=26278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:53,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:53,010] {logging_mixin.py:95} INFO - [2019-09-16 09:33:53,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:53,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:53,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:53,384] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:53,390] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:33:53,484] {scheduler_job.py:146} INFO - Started process (PID=26279) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:58,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:33:58,494] {logging_mixin.py:95} INFO - [2019-09-16 09:33:58,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:58,832] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:33:58,856] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:33:58,865] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:33:58,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:33:58,978] {scheduler_job.py:146} INFO - Started process (PID=26281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:03,986] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:03,987] {logging_mixin.py:95} INFO - [2019-09-16 09:34:03,987] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:04,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:04,353] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:04,363] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:04,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:34:04,474] {scheduler_job.py:146} INFO - Started process (PID=26282) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:09,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:09,487] {logging_mixin.py:95} INFO - [2019-09-16 09:34:09,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:09,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:09,848] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:09,857] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:09,862] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:34:09,955] {scheduler_job.py:146} INFO - Started process (PID=26283) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:14,961] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:14,963] {logging_mixin.py:95} INFO - [2019-09-16 09:34:14,962] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:15,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:15,326] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:15,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:15,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:34:15,453] {scheduler_job.py:146} INFO - Started process (PID=26285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:20,459] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:20,461] {logging_mixin.py:95} INFO - [2019-09-16 09:34:20,460] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:20,794] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:20,817] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:20,827] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:20,832] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 09:34:20,947] {scheduler_job.py:146} INFO - Started process (PID=26287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:25,960] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:25,961] {logging_mixin.py:95} INFO - [2019-09-16 09:34:25,960] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:26,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:26,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:26,333] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:26,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 09:34:26,445] {scheduler_job.py:146} INFO - Started process (PID=26289) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:31,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:31,455] {logging_mixin.py:95} INFO - [2019-09-16 09:34:31,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:31,791] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:31,815] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:31,824] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:31,830] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:34:31,933] {scheduler_job.py:146} INFO - Started process (PID=26290) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:36,943] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:36,944] {logging_mixin.py:95} INFO - [2019-09-16 09:34:36,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:37,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:37,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:37,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:37,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:34:37,430] {scheduler_job.py:146} INFO - Started process (PID=26291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:42,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:42,442] {logging_mixin.py:95} INFO - [2019-09-16 09:34:42,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:42,781] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:42,804] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:42,813] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:42,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 09:34:42,921] {scheduler_job.py:146} INFO - Started process (PID=26293) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:47,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:47,931] {logging_mixin.py:95} INFO - [2019-09-16 09:34:47,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:48,268] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:48,291] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:48,300] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:48,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:34:48,416] {scheduler_job.py:146} INFO - Started process (PID=26294) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:53,429] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:53,430] {logging_mixin.py:95} INFO - [2019-09-16 09:34:53,430] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:53,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:53,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:53,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:53,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:34:53,912] {scheduler_job.py:146} INFO - Started process (PID=26295) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:58,920] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:34:58,922] {logging_mixin.py:95} INFO - [2019-09-16 09:34:58,921] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:59,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:34:59,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:34:59,291] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:34:59,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:34:59,405] {scheduler_job.py:146} INFO - Started process (PID=26297) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:04,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:04,422] {logging_mixin.py:95} INFO - [2019-09-16 09:35:04,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:04,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:04,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:04,792] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:04,797] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:35:04,904] {scheduler_job.py:146} INFO - Started process (PID=26298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:09,916] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:09,917] {logging_mixin.py:95} INFO - [2019-09-16 09:35:09,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:10,258] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:10,281] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:10,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:10,298] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 09:35:10,386] {scheduler_job.py:146} INFO - Started process (PID=26299) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:15,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:15,398] {logging_mixin.py:95} INFO - [2019-09-16 09:35:15,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:15,740] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:15,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:15,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:15,778] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:35:15,881] {scheduler_job.py:146} INFO - Started process (PID=26301) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:20,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:20,893] {logging_mixin.py:95} INFO - [2019-09-16 09:35:20,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:21,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:21,258] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:21,268] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:21,273] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:35:21,377] {scheduler_job.py:146} INFO - Started process (PID=26303) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:26,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:26,383] {logging_mixin.py:95} INFO - [2019-09-16 09:35:26,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:26,719] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:26,743] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:26,752] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:26,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 09:35:26,870] {scheduler_job.py:146} INFO - Started process (PID=26305) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:31,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:31,879] {logging_mixin.py:95} INFO - [2019-09-16 09:35:31,878] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:32,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:32,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:32,254] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:32,259] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 09:35:32,359] {scheduler_job.py:146} INFO - Started process (PID=26306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:37,364] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:37,365] {logging_mixin.py:95} INFO - [2019-09-16 09:35:37,365] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:37,706] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:37,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:37,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:37,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 09:35:37,844] {scheduler_job.py:146} INFO - Started process (PID=26307) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:42,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:42,861] {logging_mixin.py:95} INFO - [2019-09-16 09:35:42,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:43,203] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:43,226] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:43,235] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:43,241] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 09:35:43,341] {scheduler_job.py:146} INFO - Started process (PID=26309) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:48,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:48,353] {logging_mixin.py:95} INFO - [2019-09-16 09:35:48,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:48,688] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:48,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:48,722] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:48,728] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 09:35:48,837] {scheduler_job.py:146} INFO - Started process (PID=26311) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:53,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:53,846] {logging_mixin.py:95} INFO - [2019-09-16 09:35:53,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:54,184] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:54,208] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:54,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:54,223] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:35:54,243] {scheduler_job.py:146} INFO - Started process (PID=26312) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:59,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:35:59,256] {logging_mixin.py:95} INFO - [2019-09-16 09:35:59,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:59,597] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:35:59,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:35:59,630] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:35:59,635] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:35:59,736] {scheduler_job.py:146} INFO - Started process (PID=26314) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:04,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:04,743] {logging_mixin.py:95} INFO - [2019-09-16 09:36:04,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:05,081] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:05,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:05,114] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:05,120] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 09:36:05,233] {scheduler_job.py:146} INFO - Started process (PID=26315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:10,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:10,240] {logging_mixin.py:95} INFO - [2019-09-16 09:36:10,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:10,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:10,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:10,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:10,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 09:36:10,708] {scheduler_job.py:146} INFO - Started process (PID=26316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:15,720] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:15,721] {logging_mixin.py:95} INFO - [2019-09-16 09:36:15,721] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:16,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:16,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:16,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:16,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:36:16,201] {scheduler_job.py:146} INFO - Started process (PID=26318) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:21,207] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:21,209] {logging_mixin.py:95} INFO - [2019-09-16 09:36:21,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:21,555] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:21,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:21,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:21,594] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 09:36:21,694] {scheduler_job.py:146} INFO - Started process (PID=26320) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:26,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:26,702] {logging_mixin.py:95} INFO - [2019-09-16 09:36:26,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:27,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:27,066] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:27,075] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:27,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 09:36:27,190] {scheduler_job.py:146} INFO - Started process (PID=26322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:32,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:32,205] {logging_mixin.py:95} INFO - [2019-09-16 09:36:32,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:32,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:32,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:32,586] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:32,591] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 09:36:32,686] {scheduler_job.py:146} INFO - Started process (PID=26323) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:37,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:37,697] {logging_mixin.py:95} INFO - [2019-09-16 09:36:37,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:38,028] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:38,051] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:38,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:38,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 09:36:38,173] {scheduler_job.py:146} INFO - Started process (PID=26324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:43,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:43,183] {logging_mixin.py:95} INFO - [2019-09-16 09:36:43,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:43,532] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:43,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:43,563] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:43,570] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 09:36:43,665] {scheduler_job.py:146} INFO - Started process (PID=26326) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:48,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:48,677] {logging_mixin.py:95} INFO - [2019-09-16 09:36:48,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:49,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:49,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:49,042] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:49,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 09:36:49,157] {scheduler_job.py:146} INFO - Started process (PID=26327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:54,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:54,173] {logging_mixin.py:95} INFO - [2019-09-16 09:36:54,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:54,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:54,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:36:54,550] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:36:54,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 09:36:54,646] {scheduler_job.py:146} INFO - Started process (PID=26328) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:59,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:36:59,660] {logging_mixin.py:95} INFO - [2019-09-16 09:36:59,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:36:59,992] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:00,013] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:37:00,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:37:00,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 09:37:00,144] {scheduler_job.py:146} INFO - Started process (PID=26330) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,158] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:37:05,159] {logging_mixin.py:95} INFO - [2019-09-16 09:37:05,159] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:37:05,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:37:05,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 09:37:05,632] {scheduler_job.py:146} INFO - Started process (PID=26331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:37:05,637] {logging_mixin.py:95} INFO - [2019-09-16 09:37:05,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:05,983] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:37:05,993] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:37:05,998] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.366 seconds
[2019-09-16 09:37:06,045] {scheduler_job.py:146} INFO - Started process (PID=26332) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,049] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:37:06,050] {logging_mixin.py:95} INFO - [2019-09-16 09:37:06,050] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:37:06,421] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:37:06,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.382 seconds
[2019-09-16 09:37:06,453] {scheduler_job.py:146} INFO - Started process (PID=26333) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:37:06,458] {logging_mixin.py:95} INFO - [2019-09-16 09:37:06,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,813] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 09:37:06,822] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 09:37:06,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.375 seconds
[2019-09-16 09:37:06,862] {scheduler_job.py:146} INFO - Started process (PID=26334) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 09:37:06,866] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 09:37:06,867] {logging_mixin.py:95} INFO - [2019-09-16 09:37:06,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:23,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:23,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:23,476] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:23,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 4816.620 seconds
[2019-09-16 10:57:23,530] {scheduler_job.py:146} INFO - Started process (PID=26338) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:23,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:23,534] {logging_mixin.py:95} INFO - [2019-09-16 10:57:23,534] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:24,086] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:24,107] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:24,123] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:24,129] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.599 seconds
[2019-09-16 10:57:24,241] {scheduler_job.py:146} INFO - Started process (PID=26342) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:29,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:29,251] {logging_mixin.py:95} INFO - [2019-09-16 10:57:29,250] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:29,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:29,626] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:29,636] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:29,641] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 10:57:29,681] {scheduler_job.py:146} INFO - Started process (PID=26352) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:34,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:34,689] {logging_mixin.py:95} INFO - [2019-09-16 10:57:34,688] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:35,079] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:35,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:35,130] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:35,139] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-16 10:57:35,231] {scheduler_job.py:146} INFO - Started process (PID=26355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:40,247] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:40,249] {logging_mixin.py:95} INFO - [2019-09-16 10:57:40,248] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:40,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:40,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:40,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:40,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 10:57:40,681] {scheduler_job.py:146} INFO - Started process (PID=26359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:45,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:45,687] {logging_mixin.py:95} INFO - [2019-09-16 10:57:45,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:46,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:46,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:46,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:46,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 10:57:46,120] {scheduler_job.py:146} INFO - Started process (PID=26361) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:51,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:51,131] {logging_mixin.py:95} INFO - [2019-09-16 10:57:51,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:51,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:51,502] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:51,511] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:51,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 10:57:51,573] {scheduler_job.py:146} INFO - Started process (PID=26362) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:56,580] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:57:56,581] {logging_mixin.py:95} INFO - [2019-09-16 10:57:56,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:56,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:57:56,966] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:57:56,975] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:57:56,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 10:57:57,024] {scheduler_job.py:146} INFO - Started process (PID=26364) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:02,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:02,035] {logging_mixin.py:95} INFO - [2019-09-16 10:58:02,034] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:02,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:02,407] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:02,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:02,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 10:58:02,478] {scheduler_job.py:146} INFO - Started process (PID=26366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:07,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:07,484] {logging_mixin.py:95} INFO - [2019-09-16 10:58:07,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:07,820] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:07,843] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:07,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:07,857] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 10:58:07,929] {scheduler_job.py:146} INFO - Started process (PID=26368) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:12,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:12,934] {logging_mixin.py:95} INFO - [2019-09-16 10:58:12,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:13,286] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:13,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:13,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:13,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 10:58:13,386] {scheduler_job.py:146} INFO - Started process (PID=26370) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:18,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:18,398] {logging_mixin.py:95} INFO - [2019-09-16 10:58:18,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:18,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:18,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:18,775] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:18,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 10:58:18,839] {scheduler_job.py:146} INFO - Started process (PID=26371) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:23,845] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:23,846] {logging_mixin.py:95} INFO - [2019-09-16 10:58:23,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:24,192] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:24,215] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:24,225] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:24,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 10:58:24,288] {scheduler_job.py:146} INFO - Started process (PID=26372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:29,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:29,305] {logging_mixin.py:95} INFO - [2019-09-16 10:58:29,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:29,665] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:29,688] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:29,697] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:29,703] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 10:58:29,739] {scheduler_job.py:146} INFO - Started process (PID=26374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:34,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:34,750] {logging_mixin.py:95} INFO - [2019-09-16 10:58:34,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:35,106] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:35,127] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:35,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:35,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 10:58:35,195] {scheduler_job.py:146} INFO - Started process (PID=26376) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:40,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:40,203] {logging_mixin.py:95} INFO - [2019-09-16 10:58:40,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:40,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:40,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:40,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:40,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 10:58:40,644] {scheduler_job.py:146} INFO - Started process (PID=26377) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:45,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:45,658] {logging_mixin.py:95} INFO - [2019-09-16 10:58:45,657] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:46,000] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:46,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:46,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:46,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 10:58:46,096] {scheduler_job.py:146} INFO - Started process (PID=26379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:51,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:51,102] {logging_mixin.py:95} INFO - [2019-09-16 10:58:51,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:51,448] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:51,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:51,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:51,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 10:58:51,550] {scheduler_job.py:146} INFO - Started process (PID=26380) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:56,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:58:56,562] {logging_mixin.py:95} INFO - [2019-09-16 10:58:56,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:56,919] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:58:56,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:58:56,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:58:56,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 10:58:57,003] {scheduler_job.py:146} INFO - Started process (PID=26381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:02,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:02,010] {logging_mixin.py:95} INFO - [2019-09-16 10:59:02,010] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:02,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:02,397] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:02,407] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:02,413] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 10:59:02,462] {scheduler_job.py:146} INFO - Started process (PID=26383) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:07,471] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:07,472] {logging_mixin.py:95} INFO - [2019-09-16 10:59:07,472] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:07,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:07,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:07,851] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:07,856] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 10:59:07,912] {scheduler_job.py:146} INFO - Started process (PID=26384) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:12,919] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:12,920] {logging_mixin.py:95} INFO - [2019-09-16 10:59:12,919] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:13,295] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:13,320] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:13,329] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:13,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 10:59:13,360] {scheduler_job.py:146} INFO - Started process (PID=26386) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:18,368] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:18,369] {logging_mixin.py:95} INFO - [2019-09-16 10:59:18,368] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:18,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:18,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:18,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:18,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 10:59:18,811] {scheduler_job.py:146} INFO - Started process (PID=26387) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:23,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:23,818] {logging_mixin.py:95} INFO - [2019-09-16 10:59:23,817] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:24,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:24,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:24,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:24,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 10:59:24,262] {scheduler_job.py:146} INFO - Started process (PID=26388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:29,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:29,282] {logging_mixin.py:95} INFO - [2019-09-16 10:59:29,281] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:29,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:29,642] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:29,652] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:29,657] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 10:59:29,714] {scheduler_job.py:146} INFO - Started process (PID=26390) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:34,722] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:34,723] {logging_mixin.py:95} INFO - [2019-09-16 10:59:34,722] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:35,074] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:35,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:35,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:35,114] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 10:59:35,170] {scheduler_job.py:146} INFO - Started process (PID=26392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:40,179] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:40,180] {logging_mixin.py:95} INFO - [2019-09-16 10:59:40,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:40,535] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:40,558] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:40,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:40,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 10:59:40,617] {scheduler_job.py:146} INFO - Started process (PID=26393) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:45,631] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:45,632] {logging_mixin.py:95} INFO - [2019-09-16 10:59:45,632] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:45,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:45,995] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:46,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:46,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 10:59:46,061] {scheduler_job.py:146} INFO - Started process (PID=26395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:51,066] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:51,067] {logging_mixin.py:95} INFO - [2019-09-16 10:59:51,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:51,424] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:51,447] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:51,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:51,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 10:59:51,521] {scheduler_job.py:146} INFO - Started process (PID=26396) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:56,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 10:59:56,530] {logging_mixin.py:95} INFO - [2019-09-16 10:59:56,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:56,875] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 10:59:56,896] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 10:59:56,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 10:59:56,910] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 10:59:56,975] {scheduler_job.py:146} INFO - Started process (PID=26397) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:01,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:01,983] {logging_mixin.py:95} INFO - [2019-09-16 11:00:01,982] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:02,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:02,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:02,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:02,444] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-16 11:00:02,526] {scheduler_job.py:146} INFO - Started process (PID=26400) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:07,532] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:07,533] {logging_mixin.py:95} INFO - [2019-09-16 11:00:07,533] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:07,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:07,895] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:07,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:07,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 11:00:07,981] {scheduler_job.py:146} INFO - Started process (PID=26401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:12,992] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:12,994] {logging_mixin.py:95} INFO - [2019-09-16 11:00:12,993] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:13,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:13,361] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:13,370] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:13,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 11:00:13,431] {scheduler_job.py:146} INFO - Started process (PID=26403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:18,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:18,438] {logging_mixin.py:95} INFO - [2019-09-16 11:00:18,438] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:18,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:18,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:18,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:18,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:00:18,885] {scheduler_job.py:146} INFO - Started process (PID=26404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:23,895] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:23,896] {logging_mixin.py:95} INFO - [2019-09-16 11:00:23,896] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:24,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:24,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:24,279] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:24,285] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 11:00:24,338] {scheduler_job.py:146} INFO - Started process (PID=26405) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:29,344] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:29,355] {logging_mixin.py:95} INFO - [2019-09-16 11:00:29,355] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:29,705] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:29,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:29,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:29,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:00:29,791] {scheduler_job.py:146} INFO - Started process (PID=26407) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:34,800] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:34,801] {logging_mixin.py:95} INFO - [2019-09-16 11:00:34,801] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:35,178] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:35,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:35,210] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:35,215] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 11:00:35,243] {scheduler_job.py:146} INFO - Started process (PID=26409) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:40,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:40,253] {logging_mixin.py:95} INFO - [2019-09-16 11:00:40,253] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:40,613] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:40,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:40,645] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:40,651] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 11:00:40,706] {scheduler_job.py:146} INFO - Started process (PID=26410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:45,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:45,713] {logging_mixin.py:95} INFO - [2019-09-16 11:00:45,712] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:46,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:46,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:46,106] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:46,112] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:00:46,161] {scheduler_job.py:146} INFO - Started process (PID=26412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:51,166] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:51,167] {logging_mixin.py:95} INFO - [2019-09-16 11:00:51,167] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:51,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:51,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:51,551] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:51,556] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 11:00:51,615] {scheduler_job.py:146} INFO - Started process (PID=26413) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:56,619] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:00:56,620] {logging_mixin.py:95} INFO - [2019-09-16 11:00:56,620] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:57,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:00:57,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:00:57,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:00:57,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 11:00:57,067] {scheduler_job.py:146} INFO - Started process (PID=26414) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:02,076] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:02,078] {logging_mixin.py:95} INFO - [2019-09-16 11:01:02,077] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:02,417] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:02,440] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:02,449] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:02,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 11:01:02,522] {scheduler_job.py:146} INFO - Started process (PID=26416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:07,529] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:07,530] {logging_mixin.py:95} INFO - [2019-09-16 11:01:07,530] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:07,864] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:07,886] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:07,895] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:07,901] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 11:01:07,980] {scheduler_job.py:146} INFO - Started process (PID=26417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:12,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:12,988] {logging_mixin.py:95} INFO - [2019-09-16 11:01:12,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:13,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:13,351] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:13,360] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:13,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 11:01:13,446] {scheduler_job.py:146} INFO - Started process (PID=26419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:18,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:18,453] {logging_mixin.py:95} INFO - [2019-09-16 11:01:18,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:18,800] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:18,824] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:18,834] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:18,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:01:18,902] {scheduler_job.py:146} INFO - Started process (PID=26420) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:23,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:23,911] {logging_mixin.py:95} INFO - [2019-09-16 11:01:23,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:24,270] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:24,292] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:24,301] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:24,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:01:24,360] {scheduler_job.py:146} INFO - Started process (PID=26421) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:29,366] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:29,376] {logging_mixin.py:95} INFO - [2019-09-16 11:01:29,376] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:29,716] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:29,736] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:29,745] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:29,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:01:29,803] {scheduler_job.py:146} INFO - Started process (PID=26423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:34,809] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:34,810] {logging_mixin.py:95} INFO - [2019-09-16 11:01:34,810] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:35,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:35,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:35,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:35,205] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:01:35,263] {scheduler_job.py:146} INFO - Started process (PID=26425) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:40,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:40,270] {logging_mixin.py:95} INFO - [2019-09-16 11:01:40,270] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:40,619] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:40,641] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:40,651] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:40,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:01:40,720] {scheduler_job.py:146} INFO - Started process (PID=26426) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:45,726] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:45,727] {logging_mixin.py:95} INFO - [2019-09-16 11:01:45,727] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:46,078] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:46,102] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:46,112] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:46,118] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:01:46,173] {scheduler_job.py:146} INFO - Started process (PID=26428) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:51,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:51,182] {logging_mixin.py:95} INFO - [2019-09-16 11:01:51,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:51,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:51,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:51,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:51,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:01:51,626] {scheduler_job.py:146} INFO - Started process (PID=26429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:56,635] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:01:56,636] {logging_mixin.py:95} INFO - [2019-09-16 11:01:56,635] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:56,999] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:01:57,021] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:01:57,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:01:57,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:01:57,086] {scheduler_job.py:146} INFO - Started process (PID=26430) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:02,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:02,096] {logging_mixin.py:95} INFO - [2019-09-16 11:02:02,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:02,445] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:02,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:02,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:02,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 11:02:02,537] {scheduler_job.py:146} INFO - Started process (PID=26432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:07,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:07,548] {logging_mixin.py:95} INFO - [2019-09-16 11:02:07,547] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:07,879] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:07,903] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:07,913] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:07,918] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 11:02:07,993] {scheduler_job.py:146} INFO - Started process (PID=26433) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:12,998] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:12,999] {logging_mixin.py:95} INFO - [2019-09-16 11:02:12,999] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:13,345] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:13,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:13,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:13,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:02:13,460] {scheduler_job.py:146} INFO - Started process (PID=26435) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:18,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:18,470] {logging_mixin.py:95} INFO - [2019-09-16 11:02:18,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:18,802] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:18,826] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:18,835] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:18,840] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 11:02:18,919] {scheduler_job.py:146} INFO - Started process (PID=26436) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:23,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:23,925] {logging_mixin.py:95} INFO - [2019-09-16 11:02:23,925] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:24,274] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:24,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:24,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:24,312] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:02:24,377] {scheduler_job.py:146} INFO - Started process (PID=26437) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:29,384] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:29,395] {logging_mixin.py:95} INFO - [2019-09-16 11:02:29,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:29,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:29,775] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:29,784] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:29,790] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:02:29,831] {scheduler_job.py:146} INFO - Started process (PID=26439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:34,835] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:34,836] {logging_mixin.py:95} INFO - [2019-09-16 11:02:34,836] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:35,176] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:35,197] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:35,206] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:35,212] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:02:35,282] {scheduler_job.py:146} INFO - Started process (PID=26441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:40,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:40,293] {logging_mixin.py:95} INFO - [2019-09-16 11:02:40,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:40,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:40,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:40,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:40,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:02:40,742] {scheduler_job.py:146} INFO - Started process (PID=26442) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:45,749] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:45,750] {logging_mixin.py:95} INFO - [2019-09-16 11:02:45,750] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:46,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:46,113] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:46,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:46,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 11:02:46,204] {scheduler_job.py:146} INFO - Started process (PID=26444) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:51,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:51,213] {logging_mixin.py:95} INFO - [2019-09-16 11:02:51,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:51,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:51,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:51,592] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:51,597] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:02:51,668] {scheduler_job.py:146} INFO - Started process (PID=26445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:56,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:02:56,679] {logging_mixin.py:95} INFO - [2019-09-16 11:02:56,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:57,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:02:57,050] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:02:57,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:02:57,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 11:02:57,124] {scheduler_job.py:146} INFO - Started process (PID=26446) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:02,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:02,132] {logging_mixin.py:95} INFO - [2019-09-16 11:03:02,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:02,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:02,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:02,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:02,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:03:02,588] {scheduler_job.py:146} INFO - Started process (PID=26448) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:07,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:07,599] {logging_mixin.py:95} INFO - [2019-09-16 11:03:07,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:07,955] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:07,976] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:07,986] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:07,992] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:03:08,046] {scheduler_job.py:146} INFO - Started process (PID=26449) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:13,056] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:13,057] {logging_mixin.py:95} INFO - [2019-09-16 11:03:13,057] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:13,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:13,439] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:13,448] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:13,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:03:13,505] {scheduler_job.py:146} INFO - Started process (PID=26451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:18,513] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:18,514] {logging_mixin.py:95} INFO - [2019-09-16 11:03:18,514] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:18,875] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:18,901] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:18,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:18,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 11:03:18,953] {scheduler_job.py:146} INFO - Started process (PID=26454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:23,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:23,960] {logging_mixin.py:95} INFO - [2019-09-16 11:03:23,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:24,316] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:24,339] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:24,349] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:24,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:03:24,415] {scheduler_job.py:146} INFO - Started process (PID=26456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:29,426] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:29,437] {logging_mixin.py:95} INFO - [2019-09-16 11:03:29,436] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:29,775] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:29,798] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:29,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:29,813] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:03:29,876] {scheduler_job.py:146} INFO - Started process (PID=26458) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:34,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:34,895] {logging_mixin.py:95} INFO - [2019-09-16 11:03:34,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:35,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:35,261] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:35,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:35,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:03:35,335] {scheduler_job.py:146} INFO - Started process (PID=26460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:40,342] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:40,343] {logging_mixin.py:95} INFO - [2019-09-16 11:03:40,342] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:40,678] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:40,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:40,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:40,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:03:40,793] {scheduler_job.py:146} INFO - Started process (PID=26461) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:45,798] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:45,799] {logging_mixin.py:95} INFO - [2019-09-16 11:03:45,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:46,161] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:46,186] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:46,196] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:46,201] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:03:46,250] {scheduler_job.py:146} INFO - Started process (PID=26463) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:51,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:51,259] {logging_mixin.py:95} INFO - [2019-09-16 11:03:51,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:51,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:51,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:51,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:51,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 11:03:51,692] {scheduler_job.py:146} INFO - Started process (PID=26464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:56,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:03:56,699] {logging_mixin.py:95} INFO - [2019-09-16 11:03:56,699] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:57,053] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:03:57,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:03:57,086] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:03:57,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 11:03:57,139] {scheduler_job.py:146} INFO - Started process (PID=26465) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:02,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:02,146] {logging_mixin.py:95} INFO - [2019-09-16 11:04:02,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:02,527] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:02,550] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:02,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:02,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 11:04:02,589] {scheduler_job.py:146} INFO - Started process (PID=26467) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:07,597] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:07,598] {logging_mixin.py:95} INFO - [2019-09-16 11:04:07,597] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:07,933] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:07,952] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:07,963] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:07,968] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:04:08,045] {scheduler_job.py:146} INFO - Started process (PID=26468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:13,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:13,053] {logging_mixin.py:95} INFO - [2019-09-16 11:04:13,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:13,397] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:13,421] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:13,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:13,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:04:13,504] {scheduler_job.py:146} INFO - Started process (PID=26470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:18,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:18,512] {logging_mixin.py:95} INFO - [2019-09-16 11:04:18,512] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:18,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:18,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:18,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:18,889] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 11:04:18,969] {scheduler_job.py:146} INFO - Started process (PID=26471) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:23,975] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:23,976] {logging_mixin.py:95} INFO - [2019-09-16 11:04:23,975] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:24,321] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:24,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:24,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:24,360] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:04:24,429] {scheduler_job.py:146} INFO - Started process (PID=26472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:29,440] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:29,450] {logging_mixin.py:95} INFO - [2019-09-16 11:04:29,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:29,797] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:29,821] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:29,832] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:29,837] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:04:29,889] {scheduler_job.py:146} INFO - Started process (PID=26474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:34,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:34,895] {logging_mixin.py:95} INFO - [2019-09-16 11:04:34,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:35,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:35,267] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:35,277] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:35,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:04:35,350] {scheduler_job.py:146} INFO - Started process (PID=26476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:40,361] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:40,362] {logging_mixin.py:95} INFO - [2019-09-16 11:04:40,361] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:40,695] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:40,718] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:40,728] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:40,733] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:04:40,808] {scheduler_job.py:146} INFO - Started process (PID=26477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:45,817] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:45,818] {logging_mixin.py:95} INFO - [2019-09-16 11:04:45,818] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:46,159] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:46,183] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:46,193] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:46,198] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:04:46,275] {scheduler_job.py:146} INFO - Started process (PID=26479) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:51,282] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:51,283] {logging_mixin.py:95} INFO - [2019-09-16 11:04:51,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:51,620] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:51,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:51,653] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:51,659] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 11:04:51,738] {scheduler_job.py:146} INFO - Started process (PID=26480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:56,745] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:04:56,746] {logging_mixin.py:95} INFO - [2019-09-16 11:04:56,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:57,088] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:04:57,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:04:57,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:04:57,126] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 11:04:57,200] {scheduler_job.py:146} INFO - Started process (PID=26481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:02,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:05:02,212] {logging_mixin.py:95} INFO - [2019-09-16 11:05:02,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:02,557] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:02,580] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:05:02,590] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:05:02,595] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:05:02,657] {scheduler_job.py:146} INFO - Started process (PID=26483) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:07,663] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:05:07,664] {logging_mixin.py:95} INFO - [2019-09-16 11:05:07,664] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:07,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:08,000] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:05:08,009] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:05:08,014] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.357 seconds
[2019-09-16 11:05:08,119] {scheduler_job.py:146} INFO - Started process (PID=26484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:13,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:05:13,130] {logging_mixin.py:95} INFO - [2019-09-16 11:05:13,129] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:13,435] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:13,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:05:13,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:05:13,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.354 seconds
[2019-09-16 11:05:13,520] {scheduler_job.py:146} INFO - Started process (PID=26486) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:18,526] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:05:18,527] {logging_mixin.py:95} INFO - [2019-09-16 11:05:18,527] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:18,827] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:18,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:05:18,860] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:05:18,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.344 seconds
[2019-09-16 11:05:18,920] {scheduler_job.py:146} INFO - Started process (PID=26487) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:23,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:05:23,931] {logging_mixin.py:95} INFO - [2019-09-16 11:05:23,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:24,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:05:24,295] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:05:24,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:05:24,310] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:05:24,415] {scheduler_job.py:146} INFO - Started process (PID=26488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:39:57,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:39:57,589] {logging_mixin.py:95} INFO - [2019-09-16 11:39:57,588] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:39:58,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:39:58,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:39:58,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:39:58,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2074.015 seconds
[2019-09-16 11:39:58,543] {scheduler_job.py:146} INFO - Started process (PID=26498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:03,547] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:03,548] {logging_mixin.py:95} INFO - [2019-09-16 11:40:03,548] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:03,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:03,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:03,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:03,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:40:03,989] {scheduler_job.py:146} INFO - Started process (PID=26505) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:08,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:09,002] {logging_mixin.py:95} INFO - [2019-09-16 11:40:09,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:09,399] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:09,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:09,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:09,443] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 11:40:09,535] {scheduler_job.py:146} INFO - Started process (PID=26508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:14,543] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:14,544] {logging_mixin.py:95} INFO - [2019-09-16 11:40:14,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:14,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:14,923] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:14,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:14,938] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:40:14,985] {scheduler_job.py:146} INFO - Started process (PID=26510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:19,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:19,996] {logging_mixin.py:95} INFO - [2019-09-16 11:40:19,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:20,329] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:20,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:20,363] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:20,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:40:20,431] {scheduler_job.py:146} INFO - Started process (PID=26511) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:25,437] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:25,438] {logging_mixin.py:95} INFO - [2019-09-16 11:40:25,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:25,804] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:25,822] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:25,833] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:25,839] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:40:25,887] {scheduler_job.py:146} INFO - Started process (PID=26513) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:30,892] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:30,893] {logging_mixin.py:95} INFO - [2019-09-16 11:40:30,893] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:31,212] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:31,236] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:31,246] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:31,251] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-16 11:40:31,340] {scheduler_job.py:146} INFO - Started process (PID=26514) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:36,346] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:36,348] {logging_mixin.py:95} INFO - [2019-09-16 11:40:36,347] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:36,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:36,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:36,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:36,741] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 11:40:36,792] {scheduler_job.py:146} INFO - Started process (PID=26516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:41,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:41,800] {logging_mixin.py:95} INFO - [2019-09-16 11:40:41,799] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:42,153] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:42,173] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:42,184] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:42,189] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 11:40:42,245] {scheduler_job.py:146} INFO - Started process (PID=26518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:47,250] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:47,251] {logging_mixin.py:95} INFO - [2019-09-16 11:40:47,251] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:47,610] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:47,632] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:47,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:47,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:40:47,683] {scheduler_job.py:146} INFO - Started process (PID=26519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:52,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:52,693] {logging_mixin.py:95} INFO - [2019-09-16 11:40:52,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:53,052] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:53,075] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:53,085] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:53,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:40:53,133] {scheduler_job.py:146} INFO - Started process (PID=26520) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:58,143] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:40:58,144] {logging_mixin.py:95} INFO - [2019-09-16 11:40:58,143] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:58,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:40:58,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:40:58,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:40:58,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 11:40:58,581] {scheduler_job.py:146} INFO - Started process (PID=26522) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:03,590] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:03,591] {logging_mixin.py:95} INFO - [2019-09-16 11:41:03,591] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:03,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:03,967] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:03,976] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:03,981] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:41:04,033] {scheduler_job.py:146} INFO - Started process (PID=26524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:09,043] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:09,044] {logging_mixin.py:95} INFO - [2019-09-16 11:41:09,044] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:09,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:09,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:09,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:09,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:41:09,493] {scheduler_job.py:146} INFO - Started process (PID=26525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:14,503] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:14,504] {logging_mixin.py:95} INFO - [2019-09-16 11:41:14,504] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:14,839] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:14,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:14,874] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:14,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 11:41:14,947] {scheduler_job.py:146} INFO - Started process (PID=26527) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:19,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:19,954] {logging_mixin.py:95} INFO - [2019-09-16 11:41:19,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:20,310] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:20,337] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:20,347] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:20,354] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:41:20,407] {scheduler_job.py:146} INFO - Started process (PID=26528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:25,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:25,414] {logging_mixin.py:95} INFO - [2019-09-16 11:41:25,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:25,763] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:25,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:25,795] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:25,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:41:25,856] {scheduler_job.py:146} INFO - Started process (PID=26530) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:30,863] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:30,864] {logging_mixin.py:95} INFO - [2019-09-16 11:41:30,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:31,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:31,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:31,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:31,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:41:31,295] {scheduler_job.py:146} INFO - Started process (PID=26531) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:36,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:36,301] {logging_mixin.py:95} INFO - [2019-09-16 11:41:36,300] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:36,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:36,675] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:36,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:36,693] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:41:36,740] {scheduler_job.py:146} INFO - Started process (PID=27082) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:41,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:41,745] {logging_mixin.py:95} INFO - [2019-09-16 11:41:41,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:42,114] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:42,132] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:42,143] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:42,148] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:41:42,183] {scheduler_job.py:146} INFO - Started process (PID=27109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:47,190] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:47,191] {logging_mixin.py:95} INFO - [2019-09-16 11:41:47,191] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:47,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:47,589] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:47,598] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:47,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 11:41:47,637] {scheduler_job.py:146} INFO - Started process (PID=27131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:52,642] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:52,643] {logging_mixin.py:95} INFO - [2019-09-16 11:41:52,642] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:52,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:53,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:53,014] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:53,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:41:53,085] {scheduler_job.py:146} INFO - Started process (PID=27132) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:58,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:41:58,095] {logging_mixin.py:95} INFO - [2019-09-16 11:41:58,094] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:58,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:41:58,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:41:58,478] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:41:58,483] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:41:58,537] {scheduler_job.py:146} INFO - Started process (PID=27134) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:03,542] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:03,543] {logging_mixin.py:95} INFO - [2019-09-16 11:42:03,543] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:03,911] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:03,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:03,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:03,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 11:42:03,979] {scheduler_job.py:146} INFO - Started process (PID=27928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:08,985] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:08,986] {logging_mixin.py:95} INFO - [2019-09-16 11:42:08,986] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:09,470] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:09,495] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:09,509] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:09,515] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.536 seconds
[2019-09-16 11:42:09,619] {scheduler_job.py:146} INFO - Started process (PID=28543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:14,628] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:14,629] {logging_mixin.py:95} INFO - [2019-09-16 11:42:14,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:14,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:14,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:14,994] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:14,999] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:42:15,074] {scheduler_job.py:146} INFO - Started process (PID=28546) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:20,080] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:20,081] {logging_mixin.py:95} INFO - [2019-09-16 11:42:20,081] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:20,428] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:20,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:20,459] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:20,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:42:20,532] {scheduler_job.py:146} INFO - Started process (PID=28550) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:25,536] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:25,537] {logging_mixin.py:95} INFO - [2019-09-16 11:42:25,537] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:25,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:25,899] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:25,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:25,914] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:42:25,988] {scheduler_job.py:146} INFO - Started process (PID=28552) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:30,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:30,998] {logging_mixin.py:95} INFO - [2019-09-16 11:42:30,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:31,381] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:31,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:31,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:31,423] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 11:42:31,445] {scheduler_job.py:146} INFO - Started process (PID=28553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:36,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:36,456] {logging_mixin.py:95} INFO - [2019-09-16 11:42:36,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:36,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:36,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:36,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:36,871] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 11:42:36,897] {scheduler_job.py:146} INFO - Started process (PID=28557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:41,906] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:41,907] {logging_mixin.py:95} INFO - [2019-09-16 11:42:41,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:42,293] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:42,314] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:42,325] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:42,332] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 11:42:42,447] {scheduler_job.py:146} INFO - Started process (PID=28559) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:47,456] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:47,457] {logging_mixin.py:95} INFO - [2019-09-16 11:42:47,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:47,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:47,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:47,870] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:47,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 11:42:47,897] {scheduler_job.py:146} INFO - Started process (PID=28560) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:52,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:52,906] {logging_mixin.py:95} INFO - [2019-09-16 11:42:52,905] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:53,328] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:53,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:53,358] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:53,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.466 seconds
[2019-09-16 11:42:53,441] {scheduler_job.py:146} INFO - Started process (PID=28571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:58,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:42:58,447] {logging_mixin.py:95} INFO - [2019-09-16 11:42:58,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:58,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:42:58,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:42:58,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:42:58,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 11:42:58,887] {scheduler_job.py:146} INFO - Started process (PID=28574) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:03,897] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:03,898] {logging_mixin.py:95} INFO - [2019-09-16 11:43:03,898] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:04,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:04,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:04,289] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:04,296] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:43:04,327] {scheduler_job.py:146} INFO - Started process (PID=28577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:09,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:09,334] {logging_mixin.py:95} INFO - [2019-09-16 11:43:09,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:09,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:09,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:09,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:09,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.372 seconds
[2019-09-16 11:43:09,775] {scheduler_job.py:146} INFO - Started process (PID=28578) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:14,782] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:14,782] {logging_mixin.py:95} INFO - [2019-09-16 11:43:14,782] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:15,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:15,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:15,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:15,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.363 seconds
[2019-09-16 11:43:15,225] {scheduler_job.py:146} INFO - Started process (PID=28580) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:20,234] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:20,235] {logging_mixin.py:95} INFO - [2019-09-16 11:43:20,235] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:20,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:20,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:20,588] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:20,593] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 11:43:20,678] {scheduler_job.py:146} INFO - Started process (PID=28584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:25,684] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:25,685] {logging_mixin.py:95} INFO - [2019-09-16 11:43:25,685] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:26,024] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:26,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:26,055] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:26,060] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.382 seconds
[2019-09-16 11:43:26,125] {scheduler_job.py:146} INFO - Started process (PID=28586) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:31,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:31,133] {logging_mixin.py:95} INFO - [2019-09-16 11:43:31,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:31,492] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:31,516] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:31,527] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:31,534] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:43:31,576] {scheduler_job.py:146} INFO - Started process (PID=28590) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:36,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:36,586] {logging_mixin.py:95} INFO - [2019-09-16 11:43:36,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:36,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:36,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:37,006] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:37,012] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 11:43:37,125] {scheduler_job.py:146} INFO - Started process (PID=28591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:42,132] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:42,134] {logging_mixin.py:95} INFO - [2019-09-16 11:43:42,133] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:42,578] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:42,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:42,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:42,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.498 seconds
[2019-09-16 11:43:42,667] {scheduler_job.py:146} INFO - Started process (PID=28593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:47,675] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:47,676] {logging_mixin.py:95} INFO - [2019-09-16 11:43:47,676] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:48,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:48,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:48,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:48,087] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-16 11:43:48,117] {scheduler_job.py:146} INFO - Started process (PID=28595) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:53,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:53,127] {logging_mixin.py:95} INFO - [2019-09-16 11:43:53,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:53,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:53,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:53,523] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:53,528] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 11:43:53,572] {scheduler_job.py:146} INFO - Started process (PID=28598) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:58,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:43:58,578] {logging_mixin.py:95} INFO - [2019-09-16 11:43:58,577] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:58,922] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:43:58,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:43:58,952] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:43:58,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 11:43:59,024] {scheduler_job.py:146} INFO - Started process (PID=28603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:04,029] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:04,030] {logging_mixin.py:95} INFO - [2019-09-16 11:44:04,030] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:04,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:04,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:04,420] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:04,426] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:44:04,474] {scheduler_job.py:146} INFO - Started process (PID=28605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:09,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:09,489] {logging_mixin.py:95} INFO - [2019-09-16 11:44:09,488] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:09,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:09,836] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:09,845] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:09,850] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-16 11:44:09,921] {scheduler_job.py:146} INFO - Started process (PID=28606) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:14,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:14,930] {logging_mixin.py:95} INFO - [2019-09-16 11:44:14,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:15,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:15,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:15,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:15,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 11:44:15,378] {scheduler_job.py:146} INFO - Started process (PID=28608) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:20,382] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:20,383] {logging_mixin.py:95} INFO - [2019-09-16 11:44:20,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:20,702] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:20,722] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:20,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:20,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.359 seconds
[2019-09-16 11:44:20,833] {scheduler_job.py:146} INFO - Started process (PID=28612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:25,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:25,840] {logging_mixin.py:95} INFO - [2019-09-16 11:44:25,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:26,169] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:26,189] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:26,199] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:26,204] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-16 11:44:26,286] {scheduler_job.py:146} INFO - Started process (PID=28614) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:31,290] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:31,291] {logging_mixin.py:95} INFO - [2019-09-16 11:44:31,290] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:31,617] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:31,637] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:31,646] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:31,652] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-16 11:44:31,740] {scheduler_job.py:146} INFO - Started process (PID=28615) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:36,746] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:36,747] {logging_mixin.py:95} INFO - [2019-09-16 11:44:36,746] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:37,085] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:37,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:37,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:37,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 11:44:37,193] {scheduler_job.py:146} INFO - Started process (PID=28619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:42,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:42,198] {logging_mixin.py:95} INFO - [2019-09-16 11:44:42,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:42,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:42,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:42,552] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:42,557] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-16 11:44:42,644] {scheduler_job.py:146} INFO - Started process (PID=28621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:47,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:47,650] {logging_mixin.py:95} INFO - [2019-09-16 11:44:47,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:47,972] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:47,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:48,003] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:48,008] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-16 11:44:48,092] {scheduler_job.py:146} INFO - Started process (PID=28625) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:53,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:53,100] {logging_mixin.py:95} INFO - [2019-09-16 11:44:53,100] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:53,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:53,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:53,470] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:53,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 11:44:53,545] {scheduler_job.py:146} INFO - Started process (PID=28626) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:58,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:44:58,563] {logging_mixin.py:95} INFO - [2019-09-16 11:44:58,563] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:58,894] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:44:58,910] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:44:58,920] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:44:58,925] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:44:58,997] {scheduler_job.py:146} INFO - Started process (PID=28628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:04,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:04,003] {logging_mixin.py:95} INFO - [2019-09-16 11:45:04,003] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:04,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:04,496] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:04,510] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:04,517] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.520 seconds
[2019-09-16 11:45:04,546] {scheduler_job.py:146} INFO - Started process (PID=28630) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:09,551] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:09,557] {logging_mixin.py:95} INFO - [2019-09-16 11:45:09,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:09,951] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:09,973] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:09,983] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:09,990] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.444 seconds
[2019-09-16 11:45:10,093] {scheduler_job.py:146} INFO - Started process (PID=28634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:15,097] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:15,098] {logging_mixin.py:95} INFO - [2019-09-16 11:45:15,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:15,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:15,467] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:15,477] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:15,482] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 11:45:15,542] {scheduler_job.py:146} INFO - Started process (PID=28636) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:20,552] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:20,553] {logging_mixin.py:95} INFO - [2019-09-16 11:45:20,552] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:20,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:20,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:20,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:20,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:45:20,994] {scheduler_job.py:146} INFO - Started process (PID=28640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:26,000] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:26,000] {logging_mixin.py:95} INFO - [2019-09-16 11:45:26,000] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:26,336] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:26,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:26,367] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:26,373] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 11:45:26,449] {scheduler_job.py:146} INFO - Started process (PID=28642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:31,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:31,459] {logging_mixin.py:95} INFO - [2019-09-16 11:45:31,458] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:31,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:31,802] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:31,811] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:31,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 11:45:31,894] {scheduler_job.py:146} INFO - Started process (PID=28643) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:36,899] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:36,900] {logging_mixin.py:95} INFO - [2019-09-16 11:45:36,899] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:37,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:37,247] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:37,257] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:37,262] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-16 11:45:37,346] {scheduler_job.py:146} INFO - Started process (PID=28647) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:42,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:42,352] {logging_mixin.py:95} INFO - [2019-09-16 11:45:42,352] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:42,687] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:42,706] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:42,716] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:42,721] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 11:45:42,798] {scheduler_job.py:146} INFO - Started process (PID=28649) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:47,803] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:47,803] {logging_mixin.py:95} INFO - [2019-09-16 11:45:47,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:48,131] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:48,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:48,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:48,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-16 11:45:48,249] {scheduler_job.py:146} INFO - Started process (PID=28650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:53,257] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:53,258] {logging_mixin.py:95} INFO - [2019-09-16 11:45:53,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:53,614] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:53,636] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:53,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:53,653] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:45:53,693] {scheduler_job.py:146} INFO - Started process (PID=28655) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:58,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:45:58,708] {logging_mixin.py:95} INFO - [2019-09-16 11:45:58,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:59,051] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:45:59,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:45:59,078] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:45:59,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:45:59,150] {scheduler_job.py:146} INFO - Started process (PID=28657) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:04,156] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:04,157] {logging_mixin.py:95} INFO - [2019-09-16 11:46:04,156] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:04,607] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:04,634] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:04,647] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:04,656] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.506 seconds
[2019-09-16 11:46:04,698] {scheduler_job.py:146} INFO - Started process (PID=28659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:09,703] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:09,706] {logging_mixin.py:95} INFO - [2019-09-16 11:46:09,706] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:10,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:10,068] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:10,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:10,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 11:46:10,140] {scheduler_job.py:146} INFO - Started process (PID=28663) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:15,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:15,148] {logging_mixin.py:95} INFO - [2019-09-16 11:46:15,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:15,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:15,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:15,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:15,519] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 11:46:15,592] {scheduler_job.py:146} INFO - Started process (PID=28665) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:20,598] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:20,599] {logging_mixin.py:95} INFO - [2019-09-16 11:46:20,599] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:20,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:20,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:20,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:20,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.359 seconds
[2019-09-16 11:46:21,047] {scheduler_job.py:146} INFO - Started process (PID=28666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:26,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:26,054] {logging_mixin.py:95} INFO - [2019-09-16 11:46:26,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:26,396] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:26,417] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:26,427] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:26,432] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 11:46:26,498] {scheduler_job.py:146} INFO - Started process (PID=28671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:31,506] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:31,507] {logging_mixin.py:95} INFO - [2019-09-16 11:46:31,506] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:31,893] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:31,927] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:31,955] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:31,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.469 seconds
[2019-09-16 11:46:32,047] {scheduler_job.py:146} INFO - Started process (PID=28672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:37,054] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:37,055] {logging_mixin.py:95} INFO - [2019-09-16 11:46:37,054] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:37,415] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:37,437] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:37,447] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:37,455] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:46:37,493] {scheduler_job.py:146} INFO - Started process (PID=28676) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:42,500] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:42,501] {logging_mixin.py:95} INFO - [2019-09-16 11:46:42,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:42,844] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:42,868] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:42,879] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:42,887] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:46:42,941] {scheduler_job.py:146} INFO - Started process (PID=28678) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:47,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:47,948] {logging_mixin.py:95} INFO - [2019-09-16 11:46:47,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:48,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:48,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:48,340] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:48,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:46:48,395] {scheduler_job.py:146} INFO - Started process (PID=28679) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:53,400] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:53,400] {logging_mixin.py:95} INFO - [2019-09-16 11:46:53,400] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:53,731] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:53,751] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:53,761] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:53,766] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-16 11:46:53,845] {scheduler_job.py:146} INFO - Started process (PID=28683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:58,854] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:46:58,855] {logging_mixin.py:95} INFO - [2019-09-16 11:46:58,855] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:59,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:46:59,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:46:59,226] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:46:59,231] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 11:46:59,296] {scheduler_job.py:146} INFO - Started process (PID=28685) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:04,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:04,306] {logging_mixin.py:95} INFO - [2019-09-16 11:47:04,306] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:04,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:04,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:04,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:04,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:47:04,755] {scheduler_job.py:146} INFO - Started process (PID=28687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:09,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:09,771] {logging_mixin.py:95} INFO - [2019-09-16 11:47:09,770] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:10,098] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:10,118] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:10,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:10,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 11:47:10,208] {scheduler_job.py:146} INFO - Started process (PID=28688) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:15,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:15,213] {logging_mixin.py:95} INFO - [2019-09-16 11:47:15,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:15,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:15,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:15,578] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:15,583] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 11:47:15,660] {scheduler_job.py:146} INFO - Started process (PID=28693) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:20,665] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:20,667] {logging_mixin.py:95} INFO - [2019-09-16 11:47:20,666] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:21,003] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:21,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:21,035] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:21,040] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:47:21,120] {scheduler_job.py:146} INFO - Started process (PID=28694) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:26,129] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:26,130] {logging_mixin.py:95} INFO - [2019-09-16 11:47:26,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:26,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:26,551] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:26,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:26,565] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-16 11:47:26,673] {scheduler_job.py:146} INFO - Started process (PID=28700) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:31,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:31,682] {logging_mixin.py:95} INFO - [2019-09-16 11:47:31,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:32,033] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:32,054] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:32,063] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:32,068] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 11:47:32,120] {scheduler_job.py:146} INFO - Started process (PID=28701) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:37,125] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:37,126] {logging_mixin.py:95} INFO - [2019-09-16 11:47:37,126] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:37,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:37,533] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:37,542] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:37,548] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 11:47:37,572] {scheduler_job.py:146} INFO - Started process (PID=28702) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:42,582] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:42,583] {logging_mixin.py:95} INFO - [2019-09-16 11:47:42,583] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:42,987] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:43,010] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:43,024] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:43,031] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 11:47:43,129] {scheduler_job.py:146} INFO - Started process (PID=28707) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:48,135] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:48,136] {logging_mixin.py:95} INFO - [2019-09-16 11:47:48,136] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:48,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:48,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:48,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:48,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-16 11:47:48,676] {scheduler_job.py:146} INFO - Started process (PID=28708) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:53,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:53,683] {logging_mixin.py:95} INFO - [2019-09-16 11:47:53,682] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:54,063] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:54,085] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:54,095] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:54,101] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 11:47:54,125] {scheduler_job.py:146} INFO - Started process (PID=28709) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:59,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:47:59,132] {logging_mixin.py:95} INFO - [2019-09-16 11:47:59,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:59,547] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:47:59,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:47:59,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:47:59,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-16 11:47:59,668] {scheduler_job.py:146} INFO - Started process (PID=28714) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:04,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:04,673] {logging_mixin.py:95} INFO - [2019-09-16 11:48:04,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:05,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:05,056] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:05,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:05,074] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:48:05,115] {scheduler_job.py:146} INFO - Started process (PID=28716) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:10,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:10,132] {logging_mixin.py:95} INFO - [2019-09-16 11:48:10,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:10,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:10,528] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:10,537] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:10,543] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 11:48:10,570] {scheduler_job.py:146} INFO - Started process (PID=28717) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:15,577] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:15,579] {logging_mixin.py:95} INFO - [2019-09-16 11:48:15,578] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:15,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:15,941] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:15,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:15,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 11:48:16,017] {scheduler_job.py:146} INFO - Started process (PID=28722) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:21,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:21,023] {logging_mixin.py:95} INFO - [2019-09-16 11:48:21,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:21,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:21,431] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:21,441] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:21,447] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 11:48:21,471] {scheduler_job.py:146} INFO - Started process (PID=28723) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:26,480] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:26,481] {logging_mixin.py:95} INFO - [2019-09-16 11:48:26,481] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:26,836] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:26,855] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:26,864] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:26,870] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:48:26,922] {scheduler_job.py:146} INFO - Started process (PID=28725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:31,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:31,931] {logging_mixin.py:95} INFO - [2019-09-16 11:48:31,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:32,285] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:32,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:32,319] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:32,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:48:32,375] {scheduler_job.py:146} INFO - Started process (PID=28729) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:37,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:37,382] {logging_mixin.py:95} INFO - [2019-09-16 11:48:37,381] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:37,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:37,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:37,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:37,820] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 11:48:37,926] {scheduler_job.py:146} INFO - Started process (PID=28730) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:42,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:42,934] {logging_mixin.py:95} INFO - [2019-09-16 11:48:42,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:43,334] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:43,357] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:43,368] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:43,374] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-16 11:48:43,477] {scheduler_job.py:146} INFO - Started process (PID=28732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:48,482] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:48,483] {logging_mixin.py:95} INFO - [2019-09-16 11:48:48,483] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:48,848] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:48,871] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:48,881] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:48,888] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 11:48:48,932] {scheduler_job.py:146} INFO - Started process (PID=28737) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:53,939] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:53,940] {logging_mixin.py:95} INFO - [2019-09-16 11:48:53,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:54,339] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:54,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:54,375] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:54,382] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 11:48:54,479] {scheduler_job.py:146} INFO - Started process (PID=28738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:59,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:48:59,485] {logging_mixin.py:95} INFO - [2019-09-16 11:48:59,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:59,841] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:48:59,865] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:48:59,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:48:59,881] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:48:59,928] {scheduler_job.py:146} INFO - Started process (PID=28743) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:04,935] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:04,936] {logging_mixin.py:95} INFO - [2019-09-16 11:49:04,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:05,300] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:05,324] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:05,337] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:05,344] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 11:49:05,381] {scheduler_job.py:146} INFO - Started process (PID=28745) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:10,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:10,390] {logging_mixin.py:95} INFO - [2019-09-16 11:49:10,390] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:10,752] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:10,772] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:10,782] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:10,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:49:10,831] {scheduler_job.py:146} INFO - Started process (PID=28746) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:15,841] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:15,842] {logging_mixin.py:95} INFO - [2019-09-16 11:49:15,842] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:16,206] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:16,229] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:16,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:16,245] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 11:49:16,287] {scheduler_job.py:146} INFO - Started process (PID=28748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:21,293] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:21,294] {logging_mixin.py:95} INFO - [2019-09-16 11:49:21,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:21,710] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:21,732] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:21,743] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:21,750] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-16 11:49:21,841] {scheduler_job.py:146} INFO - Started process (PID=28752) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:26,847] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:26,848] {logging_mixin.py:95} INFO - [2019-09-16 11:49:26,847] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:27,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:27,223] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:27,236] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:27,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:49:27,291] {scheduler_job.py:146} INFO - Started process (PID=28754) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:32,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:32,305] {logging_mixin.py:95} INFO - [2019-09-16 11:49:32,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:32,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:32,694] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:32,704] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:32,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 11:49:32,739] {scheduler_job.py:146} INFO - Started process (PID=28755) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:37,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:37,745] {logging_mixin.py:95} INFO - [2019-09-16 11:49:37,745] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:38,095] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:38,119] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:38,128] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:38,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 11:49:38,195] {scheduler_job.py:146} INFO - Started process (PID=28759) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:43,202] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:43,203] {logging_mixin.py:95} INFO - [2019-09-16 11:49:43,202] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:43,561] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:43,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:43,594] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:43,599] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:49:43,648] {scheduler_job.py:146} INFO - Started process (PID=28761) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:48,656] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:48,657] {logging_mixin.py:95} INFO - [2019-09-16 11:49:48,656] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:49,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:49,023] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:49,033] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:49,038] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:49:49,110] {scheduler_job.py:146} INFO - Started process (PID=28762) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:54,116] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:54,117] {logging_mixin.py:95} INFO - [2019-09-16 11:49:54,117] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:54,498] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:54,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:54,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:54,536] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 11:49:54,570] {scheduler_job.py:146} INFO - Started process (PID=28766) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:59,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:49:59,580] {logging_mixin.py:95} INFO - [2019-09-16 11:49:59,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:59,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:49:59,948] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:49:59,957] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:49:59,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:50:00,032] {scheduler_job.py:146} INFO - Started process (PID=28768) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:05,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:05,040] {logging_mixin.py:95} INFO - [2019-09-16 11:50:05,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:05,444] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:05,469] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:05,482] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:05,489] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-16 11:50:05,583] {scheduler_job.py:146} INFO - Started process (PID=28773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:10,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:10,598] {logging_mixin.py:95} INFO - [2019-09-16 11:50:10,598] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:10,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:10,969] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:10,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:10,986] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:50:11,027] {scheduler_job.py:146} INFO - Started process (PID=28774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:16,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:16,037] {logging_mixin.py:95} INFO - [2019-09-16 11:50:16,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:16,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:16,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:16,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:16,417] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 11:50:16,472] {scheduler_job.py:146} INFO - Started process (PID=28776) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:21,477] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:21,478] {logging_mixin.py:95} INFO - [2019-09-16 11:50:21,478] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:21,814] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:21,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:21,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:21,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-16 11:50:21,927] {scheduler_job.py:146} INFO - Started process (PID=28780) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:26,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:26,938] {logging_mixin.py:95} INFO - [2019-09-16 11:50:26,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:27,306] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:27,325] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:27,335] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:27,341] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:50:27,385] {scheduler_job.py:146} INFO - Started process (PID=28782) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:32,393] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:32,394] {logging_mixin.py:95} INFO - [2019-09-16 11:50:32,394] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:32,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:32,806] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:32,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:32,828] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 11:50:32,942] {scheduler_job.py:146} INFO - Started process (PID=28783) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:37,953] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:37,954] {logging_mixin.py:95} INFO - [2019-09-16 11:50:37,954] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:38,315] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:38,340] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:38,352] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:38,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 11:50:38,392] {scheduler_job.py:146} INFO - Started process (PID=28784) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:43,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:43,404] {logging_mixin.py:95} INFO - [2019-09-16 11:50:43,404] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:43,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:43,823] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:43,836] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:43,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 11:50:43,939] {scheduler_job.py:146} INFO - Started process (PID=28796) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:48,947] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:48,948] {logging_mixin.py:95} INFO - [2019-09-16 11:50:48,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:49,309] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:49,331] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:49,341] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:49,347] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:50:49,390] {scheduler_job.py:146} INFO - Started process (PID=28798) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:54,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:54,397] {logging_mixin.py:95} INFO - [2019-09-16 11:50:54,397] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:54,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:54,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:50:54,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:50:54,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 11:50:54,845] {scheduler_job.py:146} INFO - Started process (PID=28802) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:50:59,856] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:50:59,857] {logging_mixin.py:95} INFO - [2019-09-16 11:50:59,857] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:00,210] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:00,234] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:00,244] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:00,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:51:00,299] {scheduler_job.py:146} INFO - Started process (PID=28804) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:05,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:05,312] {logging_mixin.py:95} INFO - [2019-09-16 11:51:05,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:05,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:05,677] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:05,687] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:05,692] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:51:05,747] {scheduler_job.py:146} INFO - Started process (PID=28806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:10,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:10,767] {logging_mixin.py:95} INFO - [2019-09-16 11:51:10,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:11,119] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:11,143] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:11,154] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:11,159] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 11:51:11,198] {scheduler_job.py:146} INFO - Started process (PID=28808) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:16,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:16,206] {logging_mixin.py:95} INFO - [2019-09-16 11:51:16,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:16,530] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:16,553] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:16,562] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:16,567] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-16 11:51:16,651] {scheduler_job.py:146} INFO - Started process (PID=28812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:21,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:21,660] {logging_mixin.py:95} INFO - [2019-09-16 11:51:21,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:22,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:22,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:22,132] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:22,138] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.487 seconds
[2019-09-16 11:51:22,203] {scheduler_job.py:146} INFO - Started process (PID=28814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:27,214] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:27,215] {logging_mixin.py:95} INFO - [2019-09-16 11:51:27,215] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:27,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:27,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:27,659] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:27,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-16 11:51:27,751] {scheduler_job.py:146} INFO - Started process (PID=28816) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:32,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:32,763] {logging_mixin.py:95} INFO - [2019-09-16 11:51:32,762] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:33,185] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:33,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:33,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:33,229] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-16 11:51:33,299] {scheduler_job.py:146} INFO - Started process (PID=28820) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:38,306] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:38,307] {logging_mixin.py:95} INFO - [2019-09-16 11:51:38,307] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:38,686] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:38,709] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:38,718] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:38,723] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 11:51:38,838] {scheduler_job.py:146} INFO - Started process (PID=28823) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:43,846] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:43,847] {logging_mixin.py:95} INFO - [2019-09-16 11:51:43,846] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:44,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:44,221] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:44,233] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:44,239] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:51:44,287] {scheduler_job.py:146} INFO - Started process (PID=28827) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:49,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:49,296] {logging_mixin.py:95} INFO - [2019-09-16 11:51:49,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:49,639] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:49,662] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:49,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:49,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 11:51:49,745] {scheduler_job.py:146} INFO - Started process (PID=28831) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:54,752] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:51:54,753] {logging_mixin.py:95} INFO - [2019-09-16 11:51:54,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:55,096] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:51:55,120] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:51:55,131] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:51:55,136] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:51:55,203] {scheduler_job.py:146} INFO - Started process (PID=28832) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:00,212] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:00,225] {logging_mixin.py:95} INFO - [2019-09-16 11:52:00,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:00,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:00,601] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:00,610] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:00,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 11:52:00,662] {scheduler_job.py:146} INFO - Started process (PID=28837) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:05,674] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:05,675] {logging_mixin.py:95} INFO - [2019-09-16 11:52:05,675] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:06,010] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:06,033] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:06,043] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:06,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 11:52:06,127] {scheduler_job.py:146} INFO - Started process (PID=28839) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:11,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:11,148] {logging_mixin.py:95} INFO - [2019-09-16 11:52:11,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:11,544] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:11,569] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:11,580] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:11,586] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 11:52:11,682] {scheduler_job.py:146} INFO - Started process (PID=28841) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:16,688] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:16,689] {logging_mixin.py:95} INFO - [2019-09-16 11:52:16,689] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:17,035] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:17,057] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:17,067] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:17,072] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:52:17,129] {scheduler_job.py:146} INFO - Started process (PID=28845) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:22,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:22,140] {logging_mixin.py:95} INFO - [2019-09-16 11:52:22,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:22,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:22,579] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:22,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:22,600] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 11:52:22,680] {scheduler_job.py:146} INFO - Started process (PID=28846) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:27,687] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:27,688] {logging_mixin.py:95} INFO - [2019-09-16 11:52:27,687] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:28,072] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:28,097] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:28,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:28,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 11:52:28,221] {scheduler_job.py:146} INFO - Started process (PID=28851) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:33,229] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:33,231] {logging_mixin.py:95} INFO - [2019-09-16 11:52:33,230] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:33,583] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:33,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:33,616] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:33,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:52:33,670] {scheduler_job.py:146} INFO - Started process (PID=28852) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:38,678] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:38,679] {logging_mixin.py:95} INFO - [2019-09-16 11:52:38,679] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:39,061] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:39,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:39,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:39,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 11:52:39,119] {scheduler_job.py:146} INFO - Started process (PID=28853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:44,127] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:44,128] {logging_mixin.py:95} INFO - [2019-09-16 11:52:44,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:44,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:44,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:44,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:44,552] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 11:52:44,573] {scheduler_job.py:146} INFO - Started process (PID=28858) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:49,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:49,580] {logging_mixin.py:95} INFO - [2019-09-16 11:52:49,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:49,899] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:49,921] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:49,930] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:49,935] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.363 seconds
[2019-09-16 11:52:50,031] {scheduler_job.py:146} INFO - Started process (PID=28859) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:55,039] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:52:55,040] {logging_mixin.py:95} INFO - [2019-09-16 11:52:55,040] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:55,405] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:52:55,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:52:55,429] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:52:55,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:52:55,483] {scheduler_job.py:146} INFO - Started process (PID=28861) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:00,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:00,502] {logging_mixin.py:95} INFO - [2019-09-16 11:53:00,501] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:00,846] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:00,870] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:00,880] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:00,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:53:00,937] {scheduler_job.py:146} INFO - Started process (PID=28863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:05,946] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:05,947] {logging_mixin.py:95} INFO - [2019-09-16 11:53:05,947] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:06,358] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:06,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:06,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:06,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 11:53:06,491] {scheduler_job.py:146} INFO - Started process (PID=28868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:11,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:11,498] {logging_mixin.py:95} INFO - [2019-09-16 11:53:11,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:11,851] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:11,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:11,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:11,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 11:53:11,938] {scheduler_job.py:146} INFO - Started process (PID=28870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:16,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:16,946] {logging_mixin.py:95} INFO - [2019-09-16 11:53:16,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:17,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:17,316] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:17,326] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:17,331] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:53:17,393] {scheduler_job.py:146} INFO - Started process (PID=28871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:22,404] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:22,405] {logging_mixin.py:95} INFO - [2019-09-16 11:53:22,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:22,750] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:22,773] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:22,782] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:22,787] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 11:53:22,848] {scheduler_job.py:146} INFO - Started process (PID=28875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:27,855] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:27,856] {logging_mixin.py:95} INFO - [2019-09-16 11:53:27,856] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:28,245] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:28,269] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:28,281] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:28,286] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.438 seconds
[2019-09-16 11:53:28,402] {scheduler_job.py:146} INFO - Started process (PID=28877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:33,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:33,413] {logging_mixin.py:95} INFO - [2019-09-16 11:53:33,412] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:33,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:33,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:33,802] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:33,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:53:33,850] {scheduler_job.py:146} INFO - Started process (PID=28879) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:38,857] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:38,858] {logging_mixin.py:95} INFO - [2019-09-16 11:53:38,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:39,272] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:39,297] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:39,307] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:39,314] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-16 11:53:39,407] {scheduler_job.py:146} INFO - Started process (PID=28882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:44,416] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:44,417] {logging_mixin.py:95} INFO - [2019-09-16 11:53:44,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:44,760] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:44,788] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:44,803] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:44,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:53:44,853] {scheduler_job.py:146} INFO - Started process (PID=28884) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:49,859] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:49,860] {logging_mixin.py:95} INFO - [2019-09-16 11:53:49,860] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:50,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:50,210] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:50,220] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:50,226] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.374 seconds
[2019-09-16 11:53:50,302] {scheduler_job.py:146} INFO - Started process (PID=28885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:55,310] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:53:55,311] {logging_mixin.py:95} INFO - [2019-09-16 11:53:55,311] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:55,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:53:55,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:53:55,730] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:53:55,735] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 11:53:55,756] {scheduler_job.py:146} INFO - Started process (PID=28886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:00,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:00,762] {logging_mixin.py:95} INFO - [2019-09-16 11:54:00,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:01,111] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:01,133] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:01,144] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:01,150] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 11:54:01,198] {scheduler_job.py:146} INFO - Started process (PID=28891) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:06,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:06,206] {logging_mixin.py:95} INFO - [2019-09-16 11:54:06,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:06,588] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:06,605] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:06,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:06,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.425 seconds
[2019-09-16 11:54:06,649] {scheduler_job.py:146} INFO - Started process (PID=28896) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:11,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:11,661] {logging_mixin.py:95} INFO - [2019-09-16 11:54:11,661] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:12,061] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:12,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:12,096] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:12,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 11:54:12,196] {scheduler_job.py:146} INFO - Started process (PID=28898) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:17,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:17,204] {logging_mixin.py:95} INFO - [2019-09-16 11:54:17,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:17,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:17,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:17,596] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:17,602] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:54:17,638] {scheduler_job.py:146} INFO - Started process (PID=28899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:22,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:22,650] {logging_mixin.py:95} INFO - [2019-09-16 11:54:22,649] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:22,994] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:23,017] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:23,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:23,032] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:54:23,084] {scheduler_job.py:146} INFO - Started process (PID=28903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:28,094] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:28,095] {logging_mixin.py:95} INFO - [2019-09-16 11:54:28,095] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:28,499] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:28,520] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:28,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:28,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 11:54:28,640] {scheduler_job.py:146} INFO - Started process (PID=28905) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:33,651] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:33,652] {logging_mixin.py:95} INFO - [2019-09-16 11:54:33,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:34,016] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:34,037] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:34,048] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:34,054] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 11:54:34,088] {scheduler_job.py:146} INFO - Started process (PID=28906) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:39,096] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:39,097] {logging_mixin.py:95} INFO - [2019-09-16 11:54:39,097] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:39,455] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:39,478] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:39,487] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:39,493] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:54:39,548] {scheduler_job.py:146} INFO - Started process (PID=28907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:44,560] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:44,561] {logging_mixin.py:95} INFO - [2019-09-16 11:54:44,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:44,915] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:44,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:44,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:44,954] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:54:45,007] {scheduler_job.py:146} INFO - Started process (PID=28912) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:50,016] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:50,017] {logging_mixin.py:95} INFO - [2019-09-16 11:54:50,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:50,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:50,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:50,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:50,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 11:54:50,474] {scheduler_job.py:146} INFO - Started process (PID=28913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:55,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:54:55,482] {logging_mixin.py:95} INFO - [2019-09-16 11:54:55,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:55,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:54:55,866] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:54:55,875] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:54:55,880] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:54:55,921] {scheduler_job.py:146} INFO - Started process (PID=28917) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:00,933] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:00,934] {logging_mixin.py:95} INFO - [2019-09-16 11:55:00,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:01,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:01,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:01,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:01,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:55:01,384] {scheduler_job.py:146} INFO - Started process (PID=28919) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:06,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:06,396] {logging_mixin.py:95} INFO - [2019-09-16 11:55:06,395] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:06,790] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:06,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:06,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:06,827] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 11:55:06,932] {scheduler_job.py:146} INFO - Started process (PID=28921) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:11,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:11,942] {logging_mixin.py:95} INFO - [2019-09-16 11:55:11,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:12,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:12,374] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:12,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:12,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-16 11:55:12,485] {scheduler_job.py:146} INFO - Started process (PID=28926) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:17,494] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:17,495] {logging_mixin.py:95} INFO - [2019-09-16 11:55:17,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:17,838] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:17,862] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:17,871] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:17,876] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:55:17,947] {scheduler_job.py:146} INFO - Started process (PID=28927) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:22,956] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:22,957] {logging_mixin.py:95} INFO - [2019-09-16 11:55:22,956] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:23,333] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:23,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:23,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:23,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 11:55:23,400] {scheduler_job.py:146} INFO - Started process (PID=28929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:28,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:28,409] {logging_mixin.py:95} INFO - [2019-09-16 11:55:28,408] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:28,780] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:28,801] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:28,810] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:28,816] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 11:55:28,851] {scheduler_job.py:146} INFO - Started process (PID=28934) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:33,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:33,861] {logging_mixin.py:95} INFO - [2019-09-16 11:55:33,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:34,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:34,266] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:34,276] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:34,282] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 11:55:34,308] {scheduler_job.py:146} INFO - Started process (PID=28935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:39,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:39,317] {logging_mixin.py:95} INFO - [2019-09-16 11:55:39,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:39,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:39,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:39,703] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:39,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 11:55:39,762] {scheduler_job.py:146} INFO - Started process (PID=28939) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:44,774] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:44,774] {logging_mixin.py:95} INFO - [2019-09-16 11:55:44,774] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:45,108] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:45,130] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:45,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:45,145] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.383 seconds
[2019-09-16 11:55:45,219] {scheduler_job.py:146} INFO - Started process (PID=28941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:50,227] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:50,228] {logging_mixin.py:95} INFO - [2019-09-16 11:55:50,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:50,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:50,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:50,611] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:50,617] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:55:50,672] {scheduler_job.py:146} INFO - Started process (PID=28942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:55,679] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:55:55,680] {logging_mixin.py:95} INFO - [2019-09-16 11:55:55,680] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:56,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:55:56,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:55:56,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:55:56,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 11:55:56,128] {scheduler_job.py:146} INFO - Started process (PID=28946) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:01,139] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:01,140] {logging_mixin.py:95} INFO - [2019-09-16 11:56:01,140] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:01,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:01,545] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:01,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:01,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 11:56:01,586] {scheduler_job.py:146} INFO - Started process (PID=28948) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:06,593] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:06,594] {logging_mixin.py:95} INFO - [2019-09-16 11:56:06,594] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:06,946] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:06,968] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:06,978] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:06,983] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 11:56:07,037] {scheduler_job.py:146} INFO - Started process (PID=28950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:12,048] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:12,049] {logging_mixin.py:95} INFO - [2019-09-16 11:56:12,048] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:12,402] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:12,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:12,435] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:12,441] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:56:12,499] {scheduler_job.py:146} INFO - Started process (PID=28952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:17,510] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:17,511] {logging_mixin.py:95} INFO - [2019-09-16 11:56:17,511] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:17,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:17,916] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:17,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:17,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 11:56:17,955] {scheduler_job.py:146} INFO - Started process (PID=28956) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:22,962] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:22,963] {logging_mixin.py:95} INFO - [2019-09-16 11:56:22,963] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:23,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:23,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:23,359] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:23,364] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 11:56:23,407] {scheduler_job.py:146} INFO - Started process (PID=28957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:28,413] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:28,414] {logging_mixin.py:95} INFO - [2019-09-16 11:56:28,414] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:28,776] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:28,799] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:28,809] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:28,815] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 11:56:28,853] {scheduler_job.py:146} INFO - Started process (PID=28962) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:33,861] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:33,862] {logging_mixin.py:95} INFO - [2019-09-16 11:56:33,862] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:34,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:34,235] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:34,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:34,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 11:56:34,305] {scheduler_job.py:146} INFO - Started process (PID=28963) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:39,311] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:39,312] {logging_mixin.py:95} INFO - [2019-09-16 11:56:39,312] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:39,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:39,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:39,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:39,714] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 11:56:39,763] {scheduler_job.py:146} INFO - Started process (PID=28964) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:44,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:44,776] {logging_mixin.py:95} INFO - [2019-09-16 11:56:44,775] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:45,133] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:45,156] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:45,167] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:45,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 11:56:45,209] {scheduler_job.py:146} INFO - Started process (PID=28966) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:50,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:50,221] {logging_mixin.py:95} INFO - [2019-09-16 11:56:50,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:50,576] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:50,600] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:50,609] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:50,615] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:56:50,666] {scheduler_job.py:146} INFO - Started process (PID=28970) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:55,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:56:55,674] {logging_mixin.py:95} INFO - [2019-09-16 11:56:55,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:56,019] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:56:56,042] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:56:56,052] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:56:56,057] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 11:56:56,115] {scheduler_job.py:146} INFO - Started process (PID=28971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:01,121] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:01,133] {logging_mixin.py:95} INFO - [2019-09-16 11:57:01,132] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:01,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:01,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:01,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:01,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 11:57:01,574] {scheduler_job.py:146} INFO - Started process (PID=28973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:06,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:06,586] {logging_mixin.py:95} INFO - [2019-09-16 11:57:06,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:06,939] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:06,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:06,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:06,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:57:07,021] {scheduler_job.py:146} INFO - Started process (PID=28978) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:12,028] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:12,029] {logging_mixin.py:95} INFO - [2019-09-16 11:57:12,029] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:12,431] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:12,455] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:12,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:12,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-16 11:57:12,576] {scheduler_job.py:146} INFO - Started process (PID=28980) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:17,585] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:17,586] {logging_mixin.py:95} INFO - [2019-09-16 11:57:17,586] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:17,928] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:17,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:17,960] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:17,965] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 11:57:18,019] {scheduler_job.py:146} INFO - Started process (PID=28985) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:23,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:23,027] {logging_mixin.py:95} INFO - [2019-09-16 11:57:23,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:23,383] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:23,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:23,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:23,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 11:57:23,476] {scheduler_job.py:146} INFO - Started process (PID=28986) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:28,483] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:28,484] {logging_mixin.py:95} INFO - [2019-09-16 11:57:28,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:28,842] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:28,864] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:28,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:28,879] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 11:57:28,926] {scheduler_job.py:146} INFO - Started process (PID=28990) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:33,932] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:33,933] {logging_mixin.py:95} INFO - [2019-09-16 11:57:33,933] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:34,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:34,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:34,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:34,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-16 11:57:34,374] {scheduler_job.py:146} INFO - Started process (PID=28994) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:39,383] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:39,384] {logging_mixin.py:95} INFO - [2019-09-16 11:57:39,383] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:39,699] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:39,723] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:39,732] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:39,737] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.364 seconds
[2019-09-16 11:57:39,830] {scheduler_job.py:146} INFO - Started process (PID=28995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:44,839] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:44,840] {logging_mixin.py:95} INFO - [2019-09-16 11:57:44,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:45,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:45,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:45,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:45,235] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 11:57:45,283] {scheduler_job.py:146} INFO - Started process (PID=28997) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:50,292] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:50,293] {logging_mixin.py:95} INFO - [2019-09-16 11:57:50,293] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:50,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:50,672] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:50,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:50,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 11:57:50,735] {scheduler_job.py:146} INFO - Started process (PID=28998) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:55,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:57:55,743] {logging_mixin.py:95} INFO - [2019-09-16 11:57:55,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:56,092] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:57:56,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:57:56,121] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:57:56,127] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 11:57:56,192] {scheduler_job.py:146} INFO - Started process (PID=29002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:01,200] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:01,201] {logging_mixin.py:95} INFO - [2019-09-16 11:58:01,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:01,553] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:01,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:01,582] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:01,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 11:58:01,640] {scheduler_job.py:146} INFO - Started process (PID=29004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:06,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:06,651] {logging_mixin.py:95} INFO - [2019-09-16 11:58:06,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:06,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:06,993] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:07,001] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:07,007] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-16 11:58:07,094] {scheduler_job.py:146} INFO - Started process (PID=29009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:12,101] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:12,102] {logging_mixin.py:95} INFO - [2019-09-16 11:58:12,102] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:12,439] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:12,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:12,468] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:12,474] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 11:58:12,544] {scheduler_job.py:146} INFO - Started process (PID=29011) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:17,554] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:17,555] {logging_mixin.py:95} INFO - [2019-09-16 11:58:17,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:17,877] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:17,897] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:17,906] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:17,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 11:58:17,995] {scheduler_job.py:146} INFO - Started process (PID=29012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:23,006] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:23,007] {logging_mixin.py:95} INFO - [2019-09-16 11:58:23,007] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:23,349] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:23,373] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:23,383] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:23,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:58:23,445] {scheduler_job.py:146} INFO - Started process (PID=29013) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:28,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:28,463] {logging_mixin.py:95} INFO - [2019-09-16 11:58:28,462] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:28,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:28,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:28,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:28,873] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 11:58:28,895] {scheduler_job.py:146} INFO - Started process (PID=29018) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:33,903] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:33,904] {logging_mixin.py:95} INFO - [2019-09-16 11:58:33,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:34,299] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:34,321] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:34,331] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:34,337] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 11:58:34,360] {scheduler_job.py:146} INFO - Started process (PID=29019) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:39,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:39,373] {logging_mixin.py:95} INFO - [2019-09-16 11:58:39,373] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:39,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:39,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:39,796] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:39,803] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 11:58:39,914] {scheduler_job.py:146} INFO - Started process (PID=29023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:44,922] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:44,923] {logging_mixin.py:95} INFO - [2019-09-16 11:58:44,923] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:45,311] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:45,333] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:45,345] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:45,351] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 11:58:45,461] {scheduler_job.py:146} INFO - Started process (PID=29025) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:50,470] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:50,471] {logging_mixin.py:95} INFO - [2019-09-16 11:58:50,471] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:50,816] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:50,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:50,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:50,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 11:58:50,913] {scheduler_job.py:146} INFO - Started process (PID=29026) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:55,923] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:58:55,925] {logging_mixin.py:95} INFO - [2019-09-16 11:58:55,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:56,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:58:56,369] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:58:56,381] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:58:56,388] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-16 11:58:56,462] {scheduler_job.py:146} INFO - Started process (PID=29030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:01,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:01,470] {logging_mixin.py:95} INFO - [2019-09-16 11:59:01,470] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:01,850] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:01,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:01,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:01,894] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 11:59:01,919] {scheduler_job.py:146} INFO - Started process (PID=29032) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:06,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:06,931] {logging_mixin.py:95} INFO - [2019-09-16 11:59:06,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:07,320] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:07,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:07,355] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:07,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 11:59:07,476] {scheduler_job.py:146} INFO - Started process (PID=29034) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:12,484] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:12,485] {logging_mixin.py:95} INFO - [2019-09-16 11:59:12,484] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:12,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:12,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:12,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:12,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 11:59:12,924] {scheduler_job.py:146} INFO - Started process (PID=29039) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:17,935] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:17,936] {logging_mixin.py:95} INFO - [2019-09-16 11:59:17,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:18,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:18,305] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:18,314] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:18,320] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 11:59:18,376] {scheduler_job.py:146} INFO - Started process (PID=29040) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:23,386] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:23,387] {logging_mixin.py:95} INFO - [2019-09-16 11:59:23,386] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:23,809] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:23,830] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:23,840] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:23,846] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-09-16 11:59:23,932] {scheduler_job.py:146} INFO - Started process (PID=29044) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:28,941] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:28,943] {logging_mixin.py:95} INFO - [2019-09-16 11:59:28,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:29,340] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:29,363] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:29,372] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:29,377] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 11:59:29,482] {scheduler_job.py:146} INFO - Started process (PID=29046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:34,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:34,494] {logging_mixin.py:95} INFO - [2019-09-16 11:59:34,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:34,866] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:34,887] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:34,897] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:34,902] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 11:59:34,926] {scheduler_job.py:146} INFO - Started process (PID=29047) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:39,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:39,935] {logging_mixin.py:95} INFO - [2019-09-16 11:59:39,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:40,283] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:40,308] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:40,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:40,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 11:59:40,378] {scheduler_job.py:146} INFO - Started process (PID=29051) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:45,388] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:45,389] {logging_mixin.py:95} INFO - [2019-09-16 11:59:45,388] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:45,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:45,763] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:45,773] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:45,779] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 11:59:45,838] {scheduler_job.py:146} INFO - Started process (PID=29053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:50,850] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:50,851] {logging_mixin.py:95} INFO - [2019-09-16 11:59:50,851] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:51,197] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:51,220] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:51,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:51,236] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 11:59:51,294] {scheduler_job.py:146} INFO - Started process (PID=29054) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:56,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 11:59:56,305] {logging_mixin.py:95} INFO - [2019-09-16 11:59:56,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:56,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 11:59:56,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 11:59:56,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 11:59:56,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 11:59:56,750] {scheduler_job.py:146} INFO - Started process (PID=29059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:01,757] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:01,758] {logging_mixin.py:95} INFO - [2019-09-16 12:00:01,758] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:02,139] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:02,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:02,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:02,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 12:00:02,211] {scheduler_job.py:146} INFO - Started process (PID=29061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:07,217] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:07,218] {logging_mixin.py:95} INFO - [2019-09-16 12:00:07,217] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:07,568] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:07,592] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:07,602] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:07,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:00:07,663] {scheduler_job.py:146} INFO - Started process (PID=29063) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:12,669] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:12,670] {logging_mixin.py:95} INFO - [2019-09-16 12:00:12,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:13,056] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:13,080] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:13,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:13,100] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 12:00:13,128] {scheduler_job.py:146} INFO - Started process (PID=29065) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:18,133] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:18,134] {logging_mixin.py:95} INFO - [2019-09-16 12:00:18,134] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:18,502] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:18,525] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:18,534] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:18,540] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 12:00:18,579] {scheduler_job.py:146} INFO - Started process (PID=29069) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:23,589] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:23,590] {logging_mixin.py:95} INFO - [2019-09-16 12:00:23,590] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:23,949] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:23,972] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:23,982] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:23,987] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 12:00:24,026] {scheduler_job.py:146} INFO - Started process (PID=29070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:29,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:29,038] {logging_mixin.py:95} INFO - [2019-09-16 12:00:29,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:29,389] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:29,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:29,422] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:29,427] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:00:29,481] {scheduler_job.py:146} INFO - Started process (PID=29076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:34,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:34,490] {logging_mixin.py:95} INFO - [2019-09-16 12:00:34,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:34,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:34,888] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:34,901] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:34,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 12:00:34,934] {scheduler_job.py:146} INFO - Started process (PID=29077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:39,940] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:39,941] {logging_mixin.py:95} INFO - [2019-09-16 12:00:39,940] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:40,325] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:40,349] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:40,361] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:40,368] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 12:00:40,478] {scheduler_job.py:146} INFO - Started process (PID=29078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:45,488] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:45,489] {logging_mixin.py:95} INFO - [2019-09-16 12:00:45,489] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:45,855] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:45,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:45,888] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:45,893] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 12:00:45,930] {scheduler_job.py:146} INFO - Started process (PID=29083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:50,938] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:50,939] {logging_mixin.py:95} INFO - [2019-09-16 12:00:50,939] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:51,296] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:51,319] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:51,330] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:51,336] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 12:00:51,383] {scheduler_job.py:146} INFO - Started process (PID=29084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:56,389] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:00:56,390] {logging_mixin.py:95} INFO - [2019-09-16 12:00:56,389] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:56,733] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:00:56,756] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:00:56,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:00:56,771] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:00:56,835] {scheduler_job.py:146} INFO - Started process (PID=29086) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:01,843] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:01,844] {logging_mixin.py:95} INFO - [2019-09-16 12:01:01,844] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:02,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:02,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:02,241] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:02,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 12:01:02,287] {scheduler_job.py:146} INFO - Started process (PID=29088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:07,294] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:07,295] {logging_mixin.py:95} INFO - [2019-09-16 12:01:07,295] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:07,648] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:07,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:07,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:07,687] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:01:07,739] {scheduler_job.py:146} INFO - Started process (PID=29093) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:12,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:12,749] {logging_mixin.py:95} INFO - [2019-09-16 12:01:12,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:13,089] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:13,112] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:13,122] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:13,128] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:01:13,200] {scheduler_job.py:146} INFO - Started process (PID=29095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:18,211] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:18,212] {logging_mixin.py:95} INFO - [2019-09-16 12:01:18,212] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:18,559] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:18,583] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:18,593] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:18,598] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:01:18,667] {scheduler_job.py:146} INFO - Started process (PID=29096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:23,673] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:23,674] {logging_mixin.py:95} INFO - [2019-09-16 12:01:23,674] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:24,029] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:24,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:24,059] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:24,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:01:24,129] {scheduler_job.py:146} INFO - Started process (PID=29097) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:29,136] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:29,137] {logging_mixin.py:95} INFO - [2019-09-16 12:01:29,137] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:29,488] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:29,512] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:29,522] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:29,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:01:29,583] {scheduler_job.py:146} INFO - Started process (PID=29102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:34,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:34,589] {logging_mixin.py:95} INFO - [2019-09-16 12:01:34,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:34,941] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:34,962] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:34,973] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:34,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:01:35,038] {scheduler_job.py:146} INFO - Started process (PID=29104) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:40,046] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:40,047] {logging_mixin.py:95} INFO - [2019-09-16 12:01:40,047] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:40,404] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:40,426] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:40,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:40,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:01:40,484] {scheduler_job.py:146} INFO - Started process (PID=29107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:45,489] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:45,490] {logging_mixin.py:95} INFO - [2019-09-16 12:01:45,490] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:45,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:45,876] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:45,886] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:45,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 12:01:45,937] {scheduler_job.py:146} INFO - Started process (PID=29109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:50,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:50,946] {logging_mixin.py:95} INFO - [2019-09-16 12:01:50,945] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:51,294] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:51,318] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:51,328] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:51,335] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 12:01:51,397] {scheduler_job.py:146} INFO - Started process (PID=29110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:56,403] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:01:56,404] {logging_mixin.py:95} INFO - [2019-09-16 12:01:56,403] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:56,756] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:01:56,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:01:56,788] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:01:56,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:01:56,855] {scheduler_job.py:146} INFO - Started process (PID=29115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:01,860] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:01,861] {logging_mixin.py:95} INFO - [2019-09-16 12:02:01,861] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:02,208] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:02,231] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:02,242] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:02,247] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:02:02,305] {scheduler_job.py:146} INFO - Started process (PID=29116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:07,315] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:07,316] {logging_mixin.py:95} INFO - [2019-09-16 12:02:07,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:07,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:07,683] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:07,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:07,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 12:02:07,763] {scheduler_job.py:146} INFO - Started process (PID=29121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:12,771] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:12,773] {logging_mixin.py:95} INFO - [2019-09-16 12:02:12,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:13,121] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:13,146] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:13,156] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:13,161] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:02:13,223] {scheduler_job.py:146} INFO - Started process (PID=29123) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:18,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:18,232] {logging_mixin.py:95} INFO - [2019-09-16 12:02:18,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:18,593] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:18,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:18,624] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:18,629] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:02:18,685] {scheduler_job.py:146} INFO - Started process (PID=29124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:23,691] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:23,692] {logging_mixin.py:95} INFO - [2019-09-16 12:02:23,691] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:24,048] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:24,071] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:24,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:24,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:02:24,147] {scheduler_job.py:146} INFO - Started process (PID=29125) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:29,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:29,154] {logging_mixin.py:95} INFO - [2019-09-16 12:02:29,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:29,518] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:29,544] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:29,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:29,561] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 12:02:29,607] {scheduler_job.py:146} INFO - Started process (PID=29130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:34,616] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:34,617] {logging_mixin.py:95} INFO - [2019-09-16 12:02:34,616] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:34,953] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:34,977] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:34,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:34,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 12:02:35,061] {scheduler_job.py:146} INFO - Started process (PID=29131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:40,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:40,068] {logging_mixin.py:95} INFO - [2019-09-16 12:02:40,067] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:40,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:40,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:40,454] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:40,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:02:40,518] {scheduler_job.py:146} INFO - Started process (PID=29135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:45,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:45,529] {logging_mixin.py:95} INFO - [2019-09-16 12:02:45,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:45,869] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:45,893] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:45,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:45,908] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:02:45,979] {scheduler_job.py:146} INFO - Started process (PID=29137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:50,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:50,988] {logging_mixin.py:95} INFO - [2019-09-16 12:02:50,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:51,378] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:51,399] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:51,410] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:51,415] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.436 seconds
[2019-09-16 12:02:51,531] {scheduler_job.py:146} INFO - Started process (PID=29141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:56,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:02:56,540] {logging_mixin.py:95} INFO - [2019-09-16 12:02:56,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:56,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:02:56,904] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:02:56,915] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:02:56,921] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 12:02:56,986] {scheduler_job.py:146} INFO - Started process (PID=29144) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:01,993] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:01,994] {logging_mixin.py:95} INFO - [2019-09-16 12:03:01,994] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:02,344] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:02,368] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:02,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:02,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 12:03:02,443] {scheduler_job.py:146} INFO - Started process (PID=29145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:07,451] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:07,453] {logging_mixin.py:95} INFO - [2019-09-16 12:03:07,452] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:07,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:07,880] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:07,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:07,899] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.457 seconds
[2019-09-16 12:03:07,989] {scheduler_job.py:146} INFO - Started process (PID=29150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:12,996] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:12,997] {logging_mixin.py:95} INFO - [2019-09-16 12:03:12,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:13,351] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:13,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:13,376] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:13,383] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:03:13,447] {scheduler_job.py:146} INFO - Started process (PID=29152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:18,454] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:18,455] {logging_mixin.py:95} INFO - [2019-09-16 12:03:18,455] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:18,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:18,829] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:18,839] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:18,844] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 12:03:18,897] {scheduler_job.py:146} INFO - Started process (PID=29153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:23,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:23,906] {logging_mixin.py:95} INFO - [2019-09-16 12:03:23,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:24,308] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:24,330] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:24,343] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:24,349] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-16 12:03:24,453] {scheduler_job.py:146} INFO - Started process (PID=29154) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:29,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:29,461] {logging_mixin.py:95} INFO - [2019-09-16 12:03:29,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:29,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:29,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:29,892] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:29,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.445 seconds
[2019-09-16 12:03:30,006] {scheduler_job.py:146} INFO - Started process (PID=29159) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:35,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:35,014] {logging_mixin.py:95} INFO - [2019-09-16 12:03:35,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:35,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:35,391] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:35,402] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:35,407] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:03:35,454] {scheduler_job.py:146} INFO - Started process (PID=29160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:40,464] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:40,465] {logging_mixin.py:95} INFO - [2019-09-16 12:03:40,465] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:40,813] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:40,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:40,844] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:40,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:03:40,905] {scheduler_job.py:146} INFO - Started process (PID=29165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:45,910] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:45,911] {logging_mixin.py:95} INFO - [2019-09-16 12:03:45,911] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:46,261] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:46,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:46,296] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:46,302] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 12:03:46,362] {scheduler_job.py:146} INFO - Started process (PID=29170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:51,372] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:51,373] {logging_mixin.py:95} INFO - [2019-09-16 12:03:51,372] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:51,751] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:51,768] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:51,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:51,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-16 12:03:51,807] {scheduler_job.py:146} INFO - Started process (PID=29177) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:56,816] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:03:56,817] {logging_mixin.py:95} INFO - [2019-09-16 12:03:56,816] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:57,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:03:57,200] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:03:57,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:03:57,220] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 12:03:57,270] {scheduler_job.py:146} INFO - Started process (PID=29182) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:02,277] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:02,278] {logging_mixin.py:95} INFO - [2019-09-16 12:04:02,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:02,765] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:02,782] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:02,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:02,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.530 seconds
[2019-09-16 12:04:02,828] {scheduler_job.py:146} INFO - Started process (PID=29185) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:07,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:07,835] {logging_mixin.py:95} INFO - [2019-09-16 12:04:07,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:08,219] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:08,241] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:08,252] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:08,258] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 12:04:08,373] {scheduler_job.py:146} INFO - Started process (PID=29187) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:13,380] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:13,381] {logging_mixin.py:95} INFO - [2019-09-16 12:04:13,380] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:13,732] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:13,757] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:13,768] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:13,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:04:13,831] {scheduler_job.py:146} INFO - Started process (PID=29192) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:18,840] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:18,841] {logging_mixin.py:95} INFO - [2019-09-16 12:04:18,840] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:19,186] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:19,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:19,219] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:19,224] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 12:04:19,295] {scheduler_job.py:146} INFO - Started process (PID=29193) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:24,303] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:24,304] {logging_mixin.py:95} INFO - [2019-09-16 12:04:24,303] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:24,650] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:24,673] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:24,683] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:24,688] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 12:04:24,754] {scheduler_job.py:146} INFO - Started process (PID=29194) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:29,761] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:29,772] {logging_mixin.py:95} INFO - [2019-09-16 12:04:29,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:30,128] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:30,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:30,161] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:30,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 12:04:30,216] {scheduler_job.py:146} INFO - Started process (PID=29196) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:35,222] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:35,223] {logging_mixin.py:95} INFO - [2019-09-16 12:04:35,223] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:35,605] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:35,629] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:35,642] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:35,648] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 12:04:35,759] {scheduler_job.py:146} INFO - Started process (PID=29200) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:40,764] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:40,765] {logging_mixin.py:95} INFO - [2019-09-16 12:04:40,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:41,166] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:41,188] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:41,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:41,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 12:04:41,316] {scheduler_job.py:146} INFO - Started process (PID=29201) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:46,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:46,326] {logging_mixin.py:95} INFO - [2019-09-16 12:04:46,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:46,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:46,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:46,948] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:46,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.639 seconds
[2019-09-16 12:04:47,061] {scheduler_job.py:146} INFO - Started process (PID=29212) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:52,069] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:52,071] {logging_mixin.py:95} INFO - [2019-09-16 12:04:52,070] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:52,526] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:52,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:52,560] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:52,566] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.505 seconds
[2019-09-16 12:04:52,607] {scheduler_job.py:146} INFO - Started process (PID=29214) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:57,614] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:04:57,616] {logging_mixin.py:95} INFO - [2019-09-16 12:04:57,615] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:57,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:04:58,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:04:58,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:04:58,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 12:04:58,043] {scheduler_job.py:146} INFO - Started process (PID=29218) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:03,052] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:03,054] {logging_mixin.py:95} INFO - [2019-09-16 12:05:03,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:03,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:03,444] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:03,456] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:03,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-16 12:05:03,502] {scheduler_job.py:146} INFO - Started process (PID=29223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:08,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:08,508] {logging_mixin.py:95} INFO - [2019-09-16 12:05:08,508] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:08,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:08,890] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:08,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:08,905] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:05:08,953] {scheduler_job.py:146} INFO - Started process (PID=29224) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:13,958] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:13,959] {logging_mixin.py:95} INFO - [2019-09-16 12:05:13,959] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:14,324] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:14,348] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:14,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:14,363] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 12:05:14,406] {scheduler_job.py:146} INFO - Started process (PID=29226) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:19,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:19,418] {logging_mixin.py:95} INFO - [2019-09-16 12:05:19,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:19,774] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:19,797] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:19,807] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:19,812] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 12:05:19,859] {scheduler_job.py:146} INFO - Started process (PID=29227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:24,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:24,866] {logging_mixin.py:95} INFO - [2019-09-16 12:05:24,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:25,231] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:25,254] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:25,264] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:25,269] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 12:05:25,308] {scheduler_job.py:146} INFO - Started process (PID=29231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:30,314] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:30,316] {logging_mixin.py:95} INFO - [2019-09-16 12:05:30,315] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:30,670] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:30,693] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:30,702] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:30,708] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 12:05:30,763] {scheduler_job.py:146} INFO - Started process (PID=29233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:35,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:35,773] {logging_mixin.py:95} INFO - [2019-09-16 12:05:35,773] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:36,123] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:36,144] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:36,155] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:36,160] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:05:36,218] {scheduler_job.py:146} INFO - Started process (PID=29237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:41,228] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:41,229] {logging_mixin.py:95} INFO - [2019-09-16 12:05:41,228] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:41,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:41,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:41,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:41,643] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 12:05:41,666] {scheduler_job.py:146} INFO - Started process (PID=29238) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:46,671] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:46,672] {logging_mixin.py:95} INFO - [2019-09-16 12:05:46,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:47,049] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:47,072] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:47,082] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:47,090] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 12:05:47,114] {scheduler_job.py:146} INFO - Started process (PID=29240) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:52,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:52,121] {logging_mixin.py:95} INFO - [2019-09-16 12:05:52,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:52,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:52,511] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:52,521] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:52,527] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 12:05:52,563] {scheduler_job.py:146} INFO - Started process (PID=29241) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:57,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:05:57,581] {logging_mixin.py:95} INFO - [2019-09-16 12:05:57,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:57,943] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:05:57,964] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:05:57,974] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:05:57,979] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 12:05:58,005] {scheduler_job.py:146} INFO - Started process (PID=29246) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:03,013] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:03,014] {logging_mixin.py:95} INFO - [2019-09-16 12:06:03,014] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:03,394] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:03,412] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:03,423] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:03,429] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 12:06:03,452] {scheduler_job.py:146} INFO - Started process (PID=29248) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:08,458] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:08,460] {logging_mixin.py:95} INFO - [2019-09-16 12:06:08,459] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:08,853] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:08,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:08,887] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:08,892] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 12:06:08,991] {scheduler_job.py:146} INFO - Started process (PID=29252) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:14,000] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:14,001] {logging_mixin.py:95} INFO - [2019-09-16 12:06:14,001] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:14,377] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:14,401] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:14,413] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:14,418] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 12:06:14,443] {scheduler_job.py:146} INFO - Started process (PID=29254) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:19,449] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:19,450] {logging_mixin.py:95} INFO - [2019-09-16 12:06:19,450] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:19,819] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:19,839] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:19,848] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:19,854] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 12:06:19,887] {scheduler_job.py:146} INFO - Started process (PID=29258) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:24,893] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:24,894] {logging_mixin.py:95} INFO - [2019-09-16 12:06:24,894] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:25,263] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:25,288] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:25,299] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:25,306] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-16 12:06:25,331] {scheduler_job.py:146} INFO - Started process (PID=29259) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:30,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:30,340] {logging_mixin.py:95} INFO - [2019-09-16 12:06:30,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:30,741] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:30,764] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:30,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:30,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.449 seconds
[2019-09-16 12:06:30,878] {scheduler_job.py:146} INFO - Started process (PID=29261) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:35,885] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:35,886] {logging_mixin.py:95} INFO - [2019-09-16 12:06:35,886] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:36,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:36,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:36,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:36,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:06:36,331] {scheduler_job.py:146} INFO - Started process (PID=29262) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:41,338] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:41,339] {logging_mixin.py:95} INFO - [2019-09-16 12:06:41,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:41,690] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:41,713] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:41,723] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:41,729] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:06:41,781] {scheduler_job.py:146} INFO - Started process (PID=29266) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:46,790] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:46,791] {logging_mixin.py:95} INFO - [2019-09-16 12:06:46,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:47,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:47,161] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:47,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:47,176] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:06:47,236] {scheduler_job.py:146} INFO - Started process (PID=29268) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:52,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:52,243] {logging_mixin.py:95} INFO - [2019-09-16 12:06:52,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:52,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:52,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:52,711] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:52,720] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.484 seconds
[2019-09-16 12:06:52,781] {scheduler_job.py:146} INFO - Started process (PID=29272) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:57,787] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:06:57,799] {logging_mixin.py:95} INFO - [2019-09-16 12:06:57,798] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:58,189] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:06:58,206] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:06:58,215] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:06:58,221] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.441 seconds
[2019-09-16 12:06:58,329] {scheduler_job.py:146} INFO - Started process (PID=29278) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:03,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:03,338] {logging_mixin.py:95} INFO - [2019-09-16 12:07:03,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:03,772] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:03,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:03,803] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:03,809] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.481 seconds
[2019-09-16 12:07:03,866] {scheduler_job.py:146} INFO - Started process (PID=29281) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:08,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:08,874] {logging_mixin.py:95} INFO - [2019-09-16 12:07:08,874] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:09,217] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:09,238] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:09,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:09,253] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 12:07:09,312] {scheduler_job.py:146} INFO - Started process (PID=29285) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:14,321] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:14,322] {logging_mixin.py:95} INFO - [2019-09-16 12:07:14,322] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:14,671] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:14,696] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:14,705] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:14,710] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:07:14,770] {scheduler_job.py:146} INFO - Started process (PID=29287) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:19,780] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:19,781] {logging_mixin.py:95} INFO - [2019-09-16 12:07:19,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:20,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:20,148] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:20,157] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:20,162] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 12:07:20,230] {scheduler_job.py:146} INFO - Started process (PID=29288) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:25,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:25,241] {logging_mixin.py:95} INFO - [2019-09-16 12:07:25,241] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:25,590] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:25,614] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:25,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:25,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:07:25,689] {scheduler_job.py:146} INFO - Started process (PID=29291) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:30,699] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:30,700] {logging_mixin.py:95} INFO - [2019-09-16 12:07:30,700] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:31,043] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:31,067] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:31,077] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:31,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:07:31,146] {scheduler_job.py:146} INFO - Started process (PID=29296) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:36,152] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:36,153] {logging_mixin.py:95} INFO - [2019-09-16 12:07:36,153] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:36,511] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:36,535] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:36,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:36,550] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:07:36,605] {scheduler_job.py:146} INFO - Started process (PID=29298) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:41,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:41,613] {logging_mixin.py:95} INFO - [2019-09-16 12:07:41,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:41,958] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:41,981] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:41,990] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:41,995] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:07:42,061] {scheduler_job.py:146} INFO - Started process (PID=29302) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:47,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:47,068] {logging_mixin.py:95} INFO - [2019-09-16 12:07:47,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:47,474] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:47,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:47,504] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:47,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-16 12:07:47,602] {scheduler_job.py:146} INFO - Started process (PID=29306) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:52,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:52,607] {logging_mixin.py:95} INFO - [2019-09-16 12:07:52,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:53,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:53,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:53,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:53,048] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-16 12:07:53,154] {scheduler_job.py:146} INFO - Started process (PID=29308) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:58,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:07:58,164] {logging_mixin.py:95} INFO - [2019-09-16 12:07:58,163] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:58,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:07:58,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:07:58,639] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:07:58,646] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.492 seconds
[2019-09-16 12:07:58,701] {scheduler_job.py:146} INFO - Started process (PID=29313) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:03,709] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:03,710] {logging_mixin.py:95} INFO - [2019-09-16 12:08:03,709] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:04,116] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:04,135] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:04,146] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:04,151] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 12:08:04,253] {scheduler_job.py:146} INFO - Started process (PID=29315) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:09,261] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:09,262] {logging_mixin.py:95} INFO - [2019-09-16 12:08:09,262] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:09,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:09,666] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:09,677] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:09,684] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 12:08:09,709] {scheduler_job.py:146} INFO - Started process (PID=29316) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:14,718] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:14,719] {logging_mixin.py:95} INFO - [2019-09-16 12:08:14,719] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:15,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:15,153] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:15,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:15,168] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 12:08:15,264] {scheduler_job.py:146} INFO - Started process (PID=29322) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:20,286] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:20,287] {logging_mixin.py:95} INFO - [2019-09-16 12:08:20,286] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:20,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:20,686] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:20,696] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:20,701] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.437 seconds
[2019-09-16 12:08:20,811] {scheduler_job.py:146} INFO - Started process (PID=29324) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:25,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:25,823] {logging_mixin.py:95} INFO - [2019-09-16 12:08:25,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:26,199] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:26,222] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:26,234] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:26,240] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 12:08:26,268] {scheduler_job.py:146} INFO - Started process (PID=29325) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:31,274] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:31,275] {logging_mixin.py:95} INFO - [2019-09-16 12:08:31,275] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:31,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:31,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:31,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:31,680] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 12:08:31,717] {scheduler_job.py:146} INFO - Started process (PID=29327) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:36,723] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:36,724] {logging_mixin.py:95} INFO - [2019-09-16 12:08:36,724] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:37,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:37,093] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:37,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:37,107] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:08:37,171] {scheduler_job.py:146} INFO - Started process (PID=29331) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:42,178] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:42,179] {logging_mixin.py:95} INFO - [2019-09-16 12:08:42,179] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:42,534] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:42,559] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:42,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:42,573] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 12:08:42,626] {scheduler_job.py:146} INFO - Started process (PID=29335) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:47,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:47,634] {logging_mixin.py:95} INFO - [2019-09-16 12:08:47,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:47,977] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:47,999] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:48,008] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:48,013] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 12:08:48,080] {scheduler_job.py:146} INFO - Started process (PID=29336) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:53,086] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:53,087] {logging_mixin.py:95} INFO - [2019-09-16 12:08:53,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:53,446] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:53,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:53,484] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:53,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 12:08:53,525] {scheduler_job.py:146} INFO - Started process (PID=29341) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:58,534] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:08:58,536] {logging_mixin.py:95} INFO - [2019-09-16 12:08:58,535] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:58,930] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:08:58,951] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:08:58,961] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:08:58,967] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.442 seconds
[2019-09-16 12:08:59,079] {scheduler_job.py:146} INFO - Started process (PID=29343) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:04,085] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:04,086] {logging_mixin.py:95} INFO - [2019-09-16 12:09:04,086] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:04,519] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:04,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:04,556] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:04,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.483 seconds
[2019-09-16 12:09:04,628] {scheduler_job.py:146} INFO - Started process (PID=29348) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:09,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:09,639] {logging_mixin.py:95} INFO - [2019-09-16 12:09:09,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:10,030] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:10,052] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:10,062] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:10,069] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 12:09:10,179] {scheduler_job.py:146} INFO - Started process (PID=29349) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:15,187] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:15,188] {logging_mixin.py:95} INFO - [2019-09-16 12:09:15,188] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:15,566] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:15,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:15,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:15,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 12:09:15,635] {scheduler_job.py:146} INFO - Started process (PID=29351) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:20,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:20,644] {logging_mixin.py:95} INFO - [2019-09-16 12:09:20,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:21,001] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:21,024] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:21,034] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:21,039] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:09:21,080] {scheduler_job.py:146} INFO - Started process (PID=29355) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:26,089] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:26,090] {logging_mixin.py:95} INFO - [2019-09-16 12:09:26,090] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:26,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:26,529] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:26,544] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:26,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 12:09:26,628] {scheduler_job.py:146} INFO - Started process (PID=29357) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:31,633] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:31,634] {logging_mixin.py:95} INFO - [2019-09-16 12:09:31,634] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:32,071] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:32,088] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:32,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:32,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.475 seconds
[2019-09-16 12:09:32,165] {scheduler_job.py:146} INFO - Started process (PID=29359) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:37,171] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:37,172] {logging_mixin.py:95} INFO - [2019-09-16 12:09:37,172] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:37,591] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:37,613] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:37,623] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:37,628] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.463 seconds
[2019-09-16 12:09:37,711] {scheduler_job.py:146} INFO - Started process (PID=29363) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:42,716] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:42,717] {logging_mixin.py:95} INFO - [2019-09-16 12:09:42,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:43,099] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:43,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:43,139] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:43,146] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.435 seconds
[2019-09-16 12:09:43,254] {scheduler_job.py:146} INFO - Started process (PID=29365) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:48,264] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:48,265] {logging_mixin.py:95} INFO - [2019-09-16 12:09:48,264] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:48,627] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:48,652] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:48,661] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:48,667] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 12:09:48,698] {scheduler_job.py:146} INFO - Started process (PID=29366) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:53,702] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:53,704] {logging_mixin.py:95} INFO - [2019-09-16 12:09:53,703] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:54,075] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:54,098] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:54,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:54,115] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 12:09:54,145] {scheduler_job.py:146} INFO - Started process (PID=29367) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:59,151] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:09:59,152] {logging_mixin.py:95} INFO - [2019-09-16 12:09:59,152] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:59,577] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:09:59,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:09:59,614] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:09:59,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.478 seconds
[2019-09-16 12:09:59,691] {scheduler_job.py:146} INFO - Started process (PID=29372) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:04,701] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:04,703] {logging_mixin.py:95} INFO - [2019-09-16 12:10:04,702] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:05,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:05,140] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:05,152] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:05,158] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-16 12:10:05,247] {scheduler_job.py:146} INFO - Started process (PID=29374) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:10,254] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:10,255] {logging_mixin.py:95} INFO - [2019-09-16 12:10:10,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:10,634] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:10,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:10,671] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:10,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 12:10:10,704] {scheduler_job.py:146} INFO - Started process (PID=29379) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:15,712] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:15,713] {logging_mixin.py:95} INFO - [2019-09-16 12:10:15,713] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:16,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:16,059] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:16,068] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:16,073] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-16 12:10:16,149] {scheduler_job.py:146} INFO - Started process (PID=29381) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:21,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:21,155] {logging_mixin.py:95} INFO - [2019-09-16 12:10:21,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:21,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:21,506] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:21,515] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:21,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.371 seconds
[2019-09-16 12:10:21,604] {scheduler_job.py:146} INFO - Started process (PID=29382) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:26,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:26,613] {logging_mixin.py:95} INFO - [2019-09-16 12:10:26,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:26,936] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:26,957] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:26,967] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:26,972] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 12:10:27,054] {scheduler_job.py:146} INFO - Started process (PID=29385) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:32,060] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:32,061] {logging_mixin.py:95} INFO - [2019-09-16 12:10:32,061] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:32,393] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:32,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:32,425] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:32,431] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.377 seconds
[2019-09-16 12:10:32,502] {scheduler_job.py:146} INFO - Started process (PID=29388) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:37,512] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:37,513] {logging_mixin.py:95} INFO - [2019-09-16 12:10:37,513] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:37,837] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:37,857] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:37,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:37,871] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-16 12:10:37,957] {scheduler_job.py:146} INFO - Started process (PID=29392) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:42,964] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:42,965] {logging_mixin.py:95} INFO - [2019-09-16 12:10:42,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:43,288] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:43,309] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:43,318] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:43,324] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 12:10:43,408] {scheduler_job.py:146} INFO - Started process (PID=29394) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:48,414] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:48,415] {logging_mixin.py:95} INFO - [2019-09-16 12:10:48,415] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:48,769] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:48,789] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:48,799] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:48,804] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:10:48,860] {scheduler_job.py:146} INFO - Started process (PID=29395) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:53,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:53,866] {logging_mixin.py:95} INFO - [2019-09-16 12:10:53,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:54,276] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:54,298] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:54,310] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:54,316] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.456 seconds
[2019-09-16 12:10:54,412] {scheduler_job.py:146} INFO - Started process (PID=29399) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:59,420] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:10:59,433] {logging_mixin.py:95} INFO - [2019-09-16 12:10:59,432] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:59,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:10:59,787] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:10:59,797] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:10:59,802] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:10:59,859] {scheduler_job.py:146} INFO - Started process (PID=29401) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:04,864] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:04,864] {logging_mixin.py:95} INFO - [2019-09-16 12:11:04,864] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:05,191] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:05,213] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:05,222] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:05,227] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 12:11:05,309] {scheduler_job.py:146} INFO - Started process (PID=29403) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:10,316] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:10,317] {logging_mixin.py:95} INFO - [2019-09-16 12:11:10,317] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:10,659] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:10,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:10,688] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:10,694] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 12:11:10,765] {scheduler_job.py:146} INFO - Started process (PID=29404) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:15,770] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:15,771] {logging_mixin.py:95} INFO - [2019-09-16 12:11:15,771] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:16,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:16,117] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:16,126] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:16,132] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 12:11:16,214] {scheduler_job.py:146} INFO - Started process (PID=29406) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:21,223] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:21,224] {logging_mixin.py:95} INFO - [2019-09-16 12:11:21,224] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:21,585] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:21,606] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:21,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:21,625] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 12:11:21,673] {scheduler_job.py:146} INFO - Started process (PID=29410) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:26,681] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:26,681] {logging_mixin.py:95} INFO - [2019-09-16 12:11:26,681] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:27,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:27,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:27,076] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:27,081] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 12:11:27,130] {scheduler_job.py:146} INFO - Started process (PID=29412) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:32,138] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:32,139] {logging_mixin.py:95} INFO - [2019-09-16 12:11:32,139] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:32,473] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:32,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:32,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:32,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.379 seconds
[2019-09-16 12:11:32,581] {scheduler_job.py:146} INFO - Started process (PID=29416) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:37,588] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:37,589] {logging_mixin.py:95} INFO - [2019-09-16 12:11:37,589] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:37,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:37,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:37,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:37,951] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-16 12:11:38,031] {scheduler_job.py:146} INFO - Started process (PID=29417) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:43,037] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:43,038] {logging_mixin.py:95} INFO - [2019-09-16 12:11:43,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:43,367] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:43,383] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:43,392] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:43,398] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.367 seconds
[2019-09-16 12:11:43,487] {scheduler_job.py:146} INFO - Started process (PID=29419) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:48,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:48,493] {logging_mixin.py:95} INFO - [2019-09-16 12:11:48,492] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:48,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:48,863] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:48,873] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:48,878] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:11:48,937] {scheduler_job.py:146} INFO - Started process (PID=29423) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:53,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:53,943] {logging_mixin.py:95} INFO - [2019-09-16 12:11:53,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:54,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:54,302] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:54,311] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:54,317] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.380 seconds
[2019-09-16 12:11:54,390] {scheduler_job.py:146} INFO - Started process (PID=29424) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:59,396] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:11:59,405] {logging_mixin.py:95} INFO - [2019-09-16 12:11:59,405] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:59,730] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:11:59,750] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:11:59,760] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:11:59,765] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 12:11:59,844] {scheduler_job.py:146} INFO - Started process (PID=29429) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:04,851] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:04,852] {logging_mixin.py:95} INFO - [2019-09-16 12:12:04,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:05,221] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:05,244] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:05,255] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:05,261] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 12:12:05,304] {scheduler_job.py:146} INFO - Started process (PID=29431) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:10,308] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:10,309] {logging_mixin.py:95} INFO - [2019-09-16 12:12:10,309] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:10,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:10,658] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:10,667] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:10,672] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 12:12:10,754] {scheduler_job.py:146} INFO - Started process (PID=29432) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:15,760] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:15,761] {logging_mixin.py:95} INFO - [2019-09-16 12:12:15,761] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:16,105] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:16,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:16,136] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:16,142] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:12:16,208] {scheduler_job.py:146} INFO - Started process (PID=29434) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:21,213] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:21,214] {logging_mixin.py:95} INFO - [2019-09-16 12:12:21,213] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:21,541] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:21,561] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:21,570] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:21,576] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.368 seconds
[2019-09-16 12:12:21,655] {scheduler_job.py:146} INFO - Started process (PID=29438) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:26,660] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:26,661] {logging_mixin.py:95} INFO - [2019-09-16 12:12:26,660] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:27,037] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:27,060] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:27,071] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:27,077] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-16 12:12:27,107] {scheduler_job.py:146} INFO - Started process (PID=29439) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:32,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:32,113] {logging_mixin.py:95} INFO - [2019-09-16 12:12:32,113] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:32,503] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:32,524] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:32,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:32,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 12:12:32,639] {scheduler_job.py:146} INFO - Started process (PID=29441) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:37,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:37,648] {logging_mixin.py:95} INFO - [2019-09-16 12:12:37,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:38,026] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:38,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:38,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:38,066] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 12:12:38,179] {scheduler_job.py:146} INFO - Started process (PID=29445) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:43,185] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:43,186] {logging_mixin.py:95} INFO - [2019-09-16 12:12:43,186] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:43,642] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:43,665] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:43,675] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:43,683] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.504 seconds
[2019-09-16 12:12:43,728] {scheduler_job.py:146} INFO - Started process (PID=29447) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:48,734] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:48,735] {logging_mixin.py:95} INFO - [2019-09-16 12:12:48,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:49,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:49,079] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:49,089] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:49,094] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.366 seconds
[2019-09-16 12:12:49,173] {scheduler_job.py:146} INFO - Started process (PID=29451) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:54,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:54,182] {logging_mixin.py:95} INFO - [2019-09-16 12:12:54,181] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:54,515] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:54,536] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:12:54,546] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:12:54,551] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.378 seconds
[2019-09-16 12:12:54,621] {scheduler_job.py:146} INFO - Started process (PID=29452) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:59,627] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:12:59,629] {logging_mixin.py:95} INFO - [2019-09-16 12:12:59,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:59,973] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:12:59,994] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:00,004] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:00,009] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 12:13:00,066] {scheduler_job.py:146} INFO - Started process (PID=29454) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:05,070] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:05,071] {logging_mixin.py:95} INFO - [2019-09-16 12:13:05,071] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:05,398] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:05,420] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:05,430] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:05,435] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.369 seconds
[2019-09-16 12:13:05,517] {scheduler_job.py:146} INFO - Started process (PID=29456) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:10,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:10,522] {logging_mixin.py:95} INFO - [2019-09-16 12:13:10,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:10,854] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:10,875] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:10,884] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:10,890] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.373 seconds
[2019-09-16 12:13:10,962] {scheduler_job.py:146} INFO - Started process (PID=29460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:15,970] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:15,971] {logging_mixin.py:95} INFO - [2019-09-16 12:13:15,971] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:16,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:16,323] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:16,332] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:16,338] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.375 seconds
[2019-09-16 12:13:16,412] {scheduler_job.py:146} INFO - Started process (PID=29462) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:21,417] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:21,417] {logging_mixin.py:95} INFO - [2019-09-16 12:13:21,417] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:21,789] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:21,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:21,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:21,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 12:13:21,857] {scheduler_job.py:146} INFO - Started process (PID=29466) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:26,862] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:26,863] {logging_mixin.py:95} INFO - [2019-09-16 12:13:26,863] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:27,207] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:27,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:27,239] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:27,246] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:13:27,309] {scheduler_job.py:146} INFO - Started process (PID=29468) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:32,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:32,318] {logging_mixin.py:95} INFO - [2019-09-16 12:13:32,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:32,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:32,684] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:32,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:32,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 12:13:32,749] {scheduler_job.py:146} INFO - Started process (PID=29469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:37,755] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:37,755] {logging_mixin.py:95} INFO - [2019-09-16 12:13:37,755] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:38,137] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:38,159] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:38,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:38,175] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.426 seconds
[2019-09-16 12:13:38,197] {scheduler_job.py:146} INFO - Started process (PID=29470) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:43,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:43,204] {logging_mixin.py:95} INFO - [2019-09-16 12:13:43,204] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:43,556] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:43,577] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:43,587] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:43,592] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:13:43,640] {scheduler_job.py:146} INFO - Started process (PID=29475) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:48,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:48,646] {logging_mixin.py:95} INFO - [2019-09-16 12:13:48,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:49,069] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:49,095] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:49,107] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:49,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-09-16 12:13:49,193] {scheduler_job.py:146} INFO - Started process (PID=29476) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:54,199] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:54,200] {logging_mixin.py:95} INFO - [2019-09-16 12:13:54,200] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:54,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:54,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:13:54,604] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:13:54,609] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 12:13:54,639] {scheduler_job.py:146} INFO - Started process (PID=29480) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:13:59,646] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:13:59,647] {logging_mixin.py:95} INFO - [2019-09-16 12:13:59,647] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:00,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:00,087] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:00,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:00,109] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.470 seconds
[2019-09-16 12:14:00,188] {scheduler_job.py:146} INFO - Started process (PID=29482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:05,194] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:05,196] {logging_mixin.py:95} INFO - [2019-09-16 12:14:05,195] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:05,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:05,656] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:05,669] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:05,677] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.489 seconds
[2019-09-16 12:14:05,730] {scheduler_job.py:146} INFO - Started process (PID=29484) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:10,737] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:10,738] {logging_mixin.py:95} INFO - [2019-09-16 12:14:10,737] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:11,087] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:11,109] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:11,118] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:11,124] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 12:14:11,179] {scheduler_job.py:146} INFO - Started process (PID=29488) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:16,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:16,189] {logging_mixin.py:95} INFO - [2019-09-16 12:14:16,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:16,549] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:16,573] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:16,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:16,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.409 seconds
[2019-09-16 12:14:16,635] {scheduler_job.py:146} INFO - Started process (PID=29490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:21,645] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:21,646] {logging_mixin.py:95} INFO - [2019-09-16 12:14:21,646] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:22,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:22,034] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:22,044] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:22,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 12:14:22,091] {scheduler_job.py:146} INFO - Started process (PID=29491) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:27,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:27,099] {logging_mixin.py:95} INFO - [2019-09-16 12:14:27,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:27,489] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:27,522] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:27,533] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:27,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 12:14:27,651] {scheduler_job.py:146} INFO - Started process (PID=29496) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:32,657] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:32,658] {logging_mixin.py:95} INFO - [2019-09-16 12:14:32,658] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:33,009] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:33,031] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:33,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:33,046] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:14:33,106] {scheduler_job.py:146} INFO - Started process (PID=29497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:38,113] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:38,114] {logging_mixin.py:95} INFO - [2019-09-16 12:14:38,114] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:38,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:38,492] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:38,501] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:38,506] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:14:38,564] {scheduler_job.py:146} INFO - Started process (PID=29501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:43,575] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:43,576] {logging_mixin.py:95} INFO - [2019-09-16 12:14:43,576] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:43,918] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:43,942] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:43,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:43,956] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:14:44,026] {scheduler_job.py:146} INFO - Started process (PID=29503) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:49,034] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:49,035] {logging_mixin.py:95} INFO - [2019-09-16 12:14:49,035] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:49,388] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:49,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:49,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:49,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:14:49,491] {scheduler_job.py:146} INFO - Started process (PID=29504) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:54,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:14:54,498] {logging_mixin.py:95} INFO - [2019-09-16 12:14:54,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:54,904] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:14:54,932] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:14:54,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:14:54,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 12:14:55,038] {scheduler_job.py:146} INFO - Started process (PID=29508) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:00,044] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:00,046] {logging_mixin.py:95} INFO - [2019-09-16 12:15:00,045] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:00,408] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:00,427] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:00,437] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:00,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:15:00,484] {scheduler_job.py:146} INFO - Started process (PID=29510) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:05,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:05,494] {logging_mixin.py:95} INFO - [2019-09-16 12:15:05,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:05,881] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:05,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:05,918] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:05,923] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 12:15:06,043] {scheduler_job.py:146} INFO - Started process (PID=29512) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:11,051] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:11,052] {logging_mixin.py:95} INFO - [2019-09-16 12:15:11,052] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:11,426] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:11,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:11,460] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:11,465] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.422 seconds
[2019-09-16 12:15:11,491] {scheduler_job.py:146} INFO - Started process (PID=29516) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:16,497] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:16,499] {logging_mixin.py:95} INFO - [2019-09-16 12:15:16,498] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:16,876] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:16,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:16,914] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:16,920] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.429 seconds
[2019-09-16 12:15:16,945] {scheduler_job.py:146} INFO - Started process (PID=29518) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:21,950] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:21,951] {logging_mixin.py:95} INFO - [2019-09-16 12:15:21,951] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:22,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:22,345] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:22,357] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:22,365] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 12:15:22,399] {scheduler_job.py:146} INFO - Started process (PID=29519) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:27,406] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:27,407] {logging_mixin.py:95} INFO - [2019-09-16 12:15:27,406] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:27,884] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:27,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:27,929] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:27,937] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.539 seconds
[2019-09-16 12:15:28,047] {scheduler_job.py:146} INFO - Started process (PID=29524) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:33,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:33,058] {logging_mixin.py:95} INFO - [2019-09-16 12:15:33,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:33,472] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:33,498] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:33,508] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:33,514] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.467 seconds
[2019-09-16 12:15:33,598] {scheduler_job.py:146} INFO - Started process (PID=29525) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:38,604] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:38,605] {logging_mixin.py:95} INFO - [2019-09-16 12:15:38,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:38,962] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:38,987] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:38,997] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:39,003] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:15:39,045] {scheduler_job.py:146} INFO - Started process (PID=29526) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:44,053] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:44,054] {logging_mixin.py:95} INFO - [2019-09-16 12:15:44,053] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:44,419] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:44,442] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:44,452] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:44,457] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 12:15:44,499] {scheduler_job.py:146} INFO - Started process (PID=29528) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:49,507] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:49,508] {logging_mixin.py:95} INFO - [2019-09-16 12:15:49,507] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:49,867] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:49,889] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:49,898] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:49,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:15:49,956] {scheduler_job.py:146} INFO - Started process (PID=29532) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:54,963] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:15:54,964] {logging_mixin.py:95} INFO - [2019-09-16 12:15:54,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:55,318] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:15:55,343] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:15:55,353] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:15:55,358] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 12:15:55,415] {scheduler_job.py:146} INFO - Started process (PID=29533) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:00,421] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:00,422] {logging_mixin.py:95} INFO - [2019-09-16 12:16:00,421] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:00,773] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:00,795] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:00,804] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:00,810] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:16:00,870] {scheduler_job.py:146} INFO - Started process (PID=29538) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:05,878] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:05,879] {logging_mixin.py:95} INFO - [2019-09-16 12:16:05,879] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:06,234] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:06,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:06,271] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:06,277] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 12:16:06,330] {scheduler_job.py:146} INFO - Started process (PID=29540) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:11,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:11,340] {logging_mixin.py:95} INFO - [2019-09-16 12:16:11,339] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:11,694] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:11,719] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:11,729] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:11,734] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 12:16:11,786] {scheduler_job.py:146} INFO - Started process (PID=29541) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:16,793] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:16,794] {logging_mixin.py:95} INFO - [2019-09-16 12:16:16,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:17,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:17,170] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:17,180] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:17,185] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 12:16:17,239] {scheduler_job.py:146} INFO - Started process (PID=29543) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:22,244] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:22,245] {logging_mixin.py:95} INFO - [2019-09-16 12:16:22,245] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:22,595] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:22,620] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:22,629] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:22,634] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:16:22,691] {scheduler_job.py:146} INFO - Started process (PID=29547) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:27,697] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:27,710] {logging_mixin.py:95} INFO - [2019-09-16 12:16:27,710] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:28,060] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:28,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:28,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:28,098] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 12:16:28,149] {scheduler_job.py:146} INFO - Started process (PID=29549) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:33,154] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:33,155] {logging_mixin.py:95} INFO - [2019-09-16 12:16:33,155] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:33,528] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:33,555] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:33,568] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:33,575] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.427 seconds
[2019-09-16 12:16:33,601] {scheduler_job.py:146} INFO - Started process (PID=29553) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:38,606] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:38,607] {logging_mixin.py:95} INFO - [2019-09-16 12:16:38,607] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:39,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:39,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:39,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:39,049] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.448 seconds
[2019-09-16 12:16:39,159] {scheduler_job.py:146} INFO - Started process (PID=29554) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:44,167] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:44,168] {logging_mixin.py:95} INFO - [2019-09-16 12:16:44,168] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:44,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:44,547] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:44,557] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:44,562] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 12:16:44,604] {scheduler_job.py:146} INFO - Started process (PID=29556) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:49,610] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:49,611] {logging_mixin.py:95} INFO - [2019-09-16 12:16:49,611] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:49,950] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:49,974] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:49,984] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:49,989] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 12:16:50,058] {scheduler_job.py:146} INFO - Started process (PID=29557) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:55,065] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:16:55,066] {logging_mixin.py:95} INFO - [2019-09-16 12:16:55,066] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:55,452] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:16:55,477] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:16:55,486] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:16:55,491] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 12:16:55,606] {scheduler_job.py:146} INFO - Started process (PID=29561) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:00,612] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:00,613] {logging_mixin.py:95} INFO - [2019-09-16 12:17:00,613] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:00,957] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:00,979] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:00,989] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:00,994] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:17:01,056] {scheduler_job.py:146} INFO - Started process (PID=29566) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:06,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:06,064] {logging_mixin.py:95} INFO - [2019-09-16 12:17:06,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:06,436] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:06,460] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:06,469] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:06,475] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 12:17:06,506] {scheduler_job.py:146} INFO - Started process (PID=29568) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:11,516] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:11,517] {logging_mixin.py:95} INFO - [2019-09-16 12:17:11,517] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:11,859] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:11,883] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:11,893] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:11,898] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:17:11,970] {scheduler_job.py:146} INFO - Started process (PID=29569) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:16,978] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:16,979] {logging_mixin.py:95} INFO - [2019-09-16 12:17:16,978] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:17,331] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:17,354] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:17,363] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:17,369] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:17:17,429] {scheduler_job.py:146} INFO - Started process (PID=29571) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:22,436] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:22,437] {logging_mixin.py:95} INFO - [2019-09-16 12:17:22,437] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:22,787] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:22,811] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:22,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:22,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 12:17:22,889] {scheduler_job.py:146} INFO - Started process (PID=29575) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:27,896] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:27,897] {logging_mixin.py:95} INFO - [2019-09-16 12:17:27,897] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:28,243] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:28,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:28,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:28,283] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:17:28,345] {scheduler_job.py:146} INFO - Started process (PID=29577) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:33,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:33,351] {logging_mixin.py:95} INFO - [2019-09-16 12:17:33,351] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:33,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:33,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:33,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:33,738] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:17:33,808] {scheduler_job.py:146} INFO - Started process (PID=29581) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:38,818] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:38,819] {logging_mixin.py:95} INFO - [2019-09-16 12:17:38,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:39,170] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:39,196] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:39,207] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:39,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:17:39,271] {scheduler_job.py:146} INFO - Started process (PID=29582) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:44,281] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:44,282] {logging_mixin.py:95} INFO - [2019-09-16 12:17:44,282] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:44,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:44,648] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:44,658] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:44,663] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:17:44,736] {scheduler_job.py:146} INFO - Started process (PID=29584) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:49,744] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:49,745] {logging_mixin.py:95} INFO - [2019-09-16 12:17:49,744] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:50,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:50,106] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:50,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:50,121] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 12:17:50,197] {scheduler_job.py:146} INFO - Started process (PID=29585) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:55,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:17:55,206] {logging_mixin.py:95} INFO - [2019-09-16 12:17:55,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:55,558] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:17:55,582] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:17:55,591] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:17:55,596] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:17:55,655] {scheduler_job.py:146} INFO - Started process (PID=29589) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:00,661] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:00,662] {logging_mixin.py:95} INFO - [2019-09-16 12:18:00,662] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:01,005] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:01,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:01,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:01,043] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:18:01,112] {scheduler_job.py:146} INFO - Started process (PID=29591) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:06,118] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:06,128] {logging_mixin.py:95} INFO - [2019-09-16 12:18:06,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:06,480] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:06,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:06,513] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:06,518] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 12:18:06,563] {scheduler_job.py:146} INFO - Started process (PID=29593) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:11,574] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:11,575] {logging_mixin.py:95} INFO - [2019-09-16 12:18:11,575] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:11,912] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:11,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:11,945] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:11,950] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 12:18:12,025] {scheduler_job.py:146} INFO - Started process (PID=29594) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:17,038] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:17,039] {logging_mixin.py:95} INFO - [2019-09-16 12:18:17,038] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:17,390] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:17,415] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:17,424] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:17,430] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:18:17,486] {scheduler_job.py:146} INFO - Started process (PID=29599) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:22,492] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:22,493] {logging_mixin.py:95} INFO - [2019-09-16 12:18:22,493] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:22,843] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:22,867] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:22,877] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:22,882] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:18:22,946] {scheduler_job.py:146} INFO - Started process (PID=29603) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:27,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:27,965] {logging_mixin.py:95} INFO - [2019-09-16 12:18:27,964] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:28,319] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:28,344] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:28,354] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:28,359] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 12:18:28,407] {scheduler_job.py:146} INFO - Started process (PID=29605) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:33,418] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:33,419] {logging_mixin.py:95} INFO - [2019-09-16 12:18:33,419] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:33,766] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:33,791] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:33,800] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:33,805] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 12:18:33,865] {scheduler_job.py:146} INFO - Started process (PID=29606) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:38,876] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:38,877] {logging_mixin.py:95} INFO - [2019-09-16 12:18:38,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:39,226] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:39,251] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:39,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:39,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:18:39,327] {scheduler_job.py:146} INFO - Started process (PID=29607) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:44,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:44,334] {logging_mixin.py:95} INFO - [2019-09-16 12:18:44,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:44,675] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:44,700] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:44,710] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:44,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:18:44,787] {scheduler_job.py:146} INFO - Started process (PID=29612) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:49,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:49,795] {logging_mixin.py:95} INFO - [2019-09-16 12:18:49,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:50,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:50,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:50,174] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:50,179] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:18:50,252] {scheduler_job.py:146} INFO - Started process (PID=29613) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:55,260] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:18:55,261] {logging_mixin.py:95} INFO - [2019-09-16 12:18:55,260] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:55,603] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:18:55,627] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:18:55,637] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:18:55,642] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 12:18:55,714] {scheduler_job.py:146} INFO - Started process (PID=29617) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:00,724] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:00,725] {logging_mixin.py:95} INFO - [2019-09-16 12:19:00,725] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:01,067] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:01,089] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:01,099] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:01,104] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 12:19:01,175] {scheduler_job.py:146} INFO - Started process (PID=29619) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:06,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:06,182] {logging_mixin.py:95} INFO - [2019-09-16 12:19:06,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:06,524] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:06,548] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:06,558] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:06,563] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:19:06,638] {scheduler_job.py:146} INFO - Started process (PID=29621) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:11,647] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:11,648] {logging_mixin.py:95} INFO - [2019-09-16 12:19:11,648] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:11,988] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:12,012] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:12,022] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:12,027] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 12:19:12,101] {scheduler_job.py:146} INFO - Started process (PID=29622) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:17,117] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:17,118] {logging_mixin.py:95} INFO - [2019-09-16 12:19:17,118] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:17,469] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:17,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:17,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:17,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 12:19:17,563] {scheduler_job.py:146} INFO - Started process (PID=29627) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:22,571] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:22,572] {logging_mixin.py:95} INFO - [2019-09-16 12:19:22,571] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:22,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:22,940] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:22,950] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:22,955] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:19:23,025] {scheduler_job.py:146} INFO - Started process (PID=29628) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:28,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:28,037] {logging_mixin.py:95} INFO - [2019-09-16 12:19:28,037] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:28,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:28,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:28,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:28,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 12:19:28,480] {scheduler_job.py:146} INFO - Started process (PID=29633) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:33,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:33,491] {logging_mixin.py:95} INFO - [2019-09-16 12:19:33,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:33,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:33,858] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:33,867] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:33,872] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 12:19:33,942] {scheduler_job.py:146} INFO - Started process (PID=29634) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:38,949] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:38,950] {logging_mixin.py:95} INFO - [2019-09-16 12:19:38,950] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:39,303] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:39,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:39,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:39,345] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 12:19:39,402] {scheduler_job.py:146} INFO - Started process (PID=29635) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:44,409] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:44,410] {logging_mixin.py:95} INFO - [2019-09-16 12:19:44,410] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:44,759] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:44,784] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:44,793] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:44,798] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 12:19:44,869] {scheduler_job.py:146} INFO - Started process (PID=29640) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:49,875] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:49,877] {logging_mixin.py:95} INFO - [2019-09-16 12:19:49,876] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:50,224] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:50,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:50,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:50,264] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 12:19:50,330] {scheduler_job.py:146} INFO - Started process (PID=29641) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:55,339] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:19:55,340] {logging_mixin.py:95} INFO - [2019-09-16 12:19:55,340] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:55,677] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:19:55,702] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:19:55,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:19:55,717] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 12:19:55,791] {scheduler_job.py:146} INFO - Started process (PID=29642) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:00,799] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:00,800] {logging_mixin.py:95} INFO - [2019-09-16 12:20:00,800] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:01,143] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:01,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:01,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:01,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 12:20:01,250] {scheduler_job.py:146} INFO - Started process (PID=29644) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:06,258] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:06,259] {logging_mixin.py:95} INFO - [2019-09-16 12:20:06,259] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:06,600] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:06,625] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:06,634] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:06,639] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 12:20:06,711] {scheduler_job.py:146} INFO - Started process (PID=29650) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:11,717] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:11,718] {logging_mixin.py:95} INFO - [2019-09-16 12:20:11,717] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:12,073] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:12,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:12,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:12,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 12:20:12,167] {scheduler_job.py:146} INFO - Started process (PID=29653) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:17,181] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:17,182] {logging_mixin.py:95} INFO - [2019-09-16 12:20:17,182] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:17,533] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:17,557] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:17,566] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:17,571] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 12:20:17,628] {scheduler_job.py:146} INFO - Started process (PID=29658) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:22,637] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:22,638] {logging_mixin.py:95} INFO - [2019-09-16 12:20:22,638] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:22,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:23,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:23,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:23,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 12:20:23,089] {scheduler_job.py:146} INFO - Started process (PID=29659) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:28,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:28,101] {logging_mixin.py:95} INFO - [2019-09-16 12:20:28,101] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:28,451] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:28,475] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:28,485] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:28,490] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:20:28,549] {scheduler_job.py:146} INFO - Started process (PID=29661) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:33,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:33,557] {logging_mixin.py:95} INFO - [2019-09-16 12:20:33,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:33,895] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:33,919] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:33,928] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:33,933] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 12:20:34,011] {scheduler_job.py:146} INFO - Started process (PID=29662) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:39,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:39,019] {logging_mixin.py:95} INFO - [2019-09-16 12:20:39,018] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:39,375] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:39,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:39,409] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:39,414] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 12:20:39,464] {scheduler_job.py:146} INFO - Started process (PID=29666) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:44,473] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:44,475] {logging_mixin.py:95} INFO - [2019-09-16 12:20:44,474] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:44,828] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:44,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:44,858] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:44,863] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 12:20:44,921] {scheduler_job.py:146} INFO - Started process (PID=29671) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:49,930] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:49,931] {logging_mixin.py:95} INFO - [2019-09-16 12:20:49,931] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:50,282] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:50,306] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:50,316] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:50,321] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:20:50,386] {scheduler_job.py:146} INFO - Started process (PID=29672) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:55,391] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:20:55,392] {logging_mixin.py:95} INFO - [2019-09-16 12:20:55,392] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:55,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:20:55,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:20:55,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:20:55,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.354 seconds
[2019-09-16 12:20:55,848] {scheduler_job.py:146} INFO - Started process (PID=29673) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:00,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:00,859] {logging_mixin.py:95} INFO - [2019-09-16 12:21:00,859] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:01,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:01,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:01,200] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:01,206] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.358 seconds
[2019-09-16 12:21:01,309] {scheduler_job.py:146} INFO - Started process (PID=29675) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:06,317] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:06,318] {logging_mixin.py:95} INFO - [2019-09-16 12:21:06,318] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:06,632] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:06,657] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:06,666] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:06,671] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.362 seconds
[2019-09-16 12:21:06,769] {scheduler_job.py:146} INFO - Started process (PID=29677) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:11,775] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:11,776] {logging_mixin.py:95} INFO - [2019-09-16 12:21:11,776] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:12,084] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:12,099] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:12,108] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:12,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.344 seconds
[2019-09-16 12:21:12,227] {scheduler_job.py:146} INFO - Started process (PID=29681) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:17,242] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:17,243] {logging_mixin.py:95} INFO - [2019-09-16 12:21:17,243] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:17,552] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:17,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:17,583] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:17,588] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.361 seconds
[2019-09-16 12:21:17,688] {scheduler_job.py:146} INFO - Started process (PID=29683) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:22,696] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:22,697] {logging_mixin.py:95} INFO - [2019-09-16 12:21:22,697] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:23,135] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:23,152] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:23,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:23,167] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.480 seconds
[2019-09-16 12:21:23,231] {scheduler_job.py:146} INFO - Started process (PID=29687) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:28,237] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:28,239] {logging_mixin.py:95} INFO - [2019-09-16 12:21:28,238] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:28,587] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:28,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:28,618] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:28,623] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 12:21:28,679] {scheduler_job.py:146} INFO - Started process (PID=29689) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:33,686] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:33,687] {logging_mixin.py:95} INFO - [2019-09-16 12:21:33,686] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:34,038] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:34,064] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:34,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:34,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 12:21:34,140] {scheduler_job.py:146} INFO - Started process (PID=29690) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:39,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:39,145] {logging_mixin.py:95} INFO - [2019-09-16 12:21:39,145] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:39,508] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:39,527] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 12:21:39,536] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 12:21:39,541] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 12:21:39,602] {scheduler_job.py:146} INFO - Started process (PID=29696) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 12:21:44,607] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 12:21:44,608] {logging_mixin.py:95} INFO - [2019-09-16 12:21:44,608] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:16,484] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:16,504] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:16,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:16,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 2496.927 seconds
[2019-09-16 13:03:16,637] {scheduler_job.py:146} INFO - Started process (PID=29703) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:16,643] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:16,644] {logging_mixin.py:95} INFO - [2019-09-16 13:03:16,644] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:17,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:17,285] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:17,302] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:17,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 0.681 seconds
[2019-09-16 13:03:17,350] {scheduler_job.py:146} INFO - Started process (PID=29704) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:22,358] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:22,360] {logging_mixin.py:95} INFO - [2019-09-16 13:03:22,359] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:22,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:22,739] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:22,749] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:22,755] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 13:03:22,868] {scheduler_job.py:146} INFO - Started process (PID=29715) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:27,873] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:27,874] {logging_mixin.py:95} INFO - [2019-09-16 13:03:27,873] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:28,346] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:28,381] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:28,391] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:28,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.529 seconds
[2019-09-16 13:03:28,418] {scheduler_job.py:146} INFO - Started process (PID=29718) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:33,424] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:33,425] {logging_mixin.py:95} INFO - [2019-09-16 13:03:33,424] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:33,782] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:33,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:33,815] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:33,822] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:03:33,865] {scheduler_job.py:146} INFO - Started process (PID=29720) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:38,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:38,871] {logging_mixin.py:95} INFO - [2019-09-16 13:03:38,871] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:39,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:39,257] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:39,269] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:39,275] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 13:03:39,308] {scheduler_job.py:146} INFO - Started process (PID=29725) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:44,313] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:44,315] {logging_mixin.py:95} INFO - [2019-09-16 13:03:44,314] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:44,660] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:44,682] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:44,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:44,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:03:44,755] {scheduler_job.py:146} INFO - Started process (PID=29727) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:49,765] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:49,767] {logging_mixin.py:95} INFO - [2019-09-16 13:03:49,766] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:50,163] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:50,190] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:50,202] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:50,209] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.453 seconds
[2019-09-16 13:03:50,303] {scheduler_job.py:146} INFO - Started process (PID=29731) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:55,312] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:03:55,314] {logging_mixin.py:95} INFO - [2019-09-16 13:03:55,313] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:55,673] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:03:55,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:03:55,709] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:03:55,715] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 13:03:55,751] {scheduler_job.py:146} INFO - Started process (PID=29732) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:00,762] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:00,763] {logging_mixin.py:95} INFO - [2019-09-16 13:04:00,763] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:01,115] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:01,139] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:01,149] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:01,154] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 13:04:01,197] {scheduler_job.py:146} INFO - Started process (PID=29734) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:06,205] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:06,206] {logging_mixin.py:95} INFO - [2019-09-16 13:04:06,206] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:06,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:06,586] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:06,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:06,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 13:04:06,643] {scheduler_job.py:146} INFO - Started process (PID=29738) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:11,649] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:11,650] {logging_mixin.py:95} INFO - [2019-09-16 13:04:11,650] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:12,022] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:12,045] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:12,057] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:12,064] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 13:04:12,091] {scheduler_job.py:146} INFO - Started process (PID=29739) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:17,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:17,099] {logging_mixin.py:95} INFO - [2019-09-16 13:04:17,099] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:17,477] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:17,503] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:17,514] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:17,520] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.430 seconds
[2019-09-16 13:04:17,546] {scheduler_job.py:146} INFO - Started process (PID=29741) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:22,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:22,556] {logging_mixin.py:95} INFO - [2019-09-16 13:04:22,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:22,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:23,001] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:23,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:23,019] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.473 seconds
[2019-09-16 13:04:23,093] {scheduler_job.py:146} INFO - Started process (PID=29742) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:28,100] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:28,103] {logging_mixin.py:95} INFO - [2019-09-16 13:04:28,103] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:28,491] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:28,519] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:28,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:28,539] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.446 seconds
[2019-09-16 13:04:28,646] {scheduler_job.py:146} INFO - Started process (PID=29748) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:33,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:33,659] {logging_mixin.py:95} INFO - [2019-09-16 13:04:33,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:33,996] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:34,016] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:34,027] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:34,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 13:04:34,098] {scheduler_job.py:146} INFO - Started process (PID=29749) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:39,107] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:39,108] {logging_mixin.py:95} INFO - [2019-09-16 13:04:39,108] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:39,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:39,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:39,495] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:39,500] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 13:04:39,551] {scheduler_job.py:146} INFO - Started process (PID=29751) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:44,559] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:44,561] {logging_mixin.py:95} INFO - [2019-09-16 13:04:44,560] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:44,931] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:44,954] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:44,964] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:44,970] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 13:04:45,003] {scheduler_job.py:146} INFO - Started process (PID=29753) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:50,010] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:50,011] {logging_mixin.py:95} INFO - [2019-09-16 13:04:50,011] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:50,401] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:50,425] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:50,436] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:50,442] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 13:04:50,550] {scheduler_job.py:146} INFO - Started process (PID=29757) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:55,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:04:55,556] {logging_mixin.py:95} INFO - [2019-09-16 13:04:55,556] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:55,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:04:55,947] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:04:55,956] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:04:55,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 13:04:55,999] {scheduler_job.py:146} INFO - Started process (PID=29758) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:01,009] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:01,010] {logging_mixin.py:95} INFO - [2019-09-16 13:05:01,009] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:01,363] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:01,387] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:01,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:01,402] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 13:05:01,452] {scheduler_job.py:146} INFO - Started process (PID=29763) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:06,457] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:06,458] {logging_mixin.py:95} INFO - [2019-09-16 13:05:06,457] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:06,865] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:06,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:06,905] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:06,911] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 13:05:06,999] {scheduler_job.py:146} INFO - Started process (PID=29764) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:12,008] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:12,009] {logging_mixin.py:95} INFO - [2019-09-16 13:05:12,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:12,361] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:12,386] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:12,396] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:12,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 13:05:12,451] {scheduler_job.py:146} INFO - Started process (PID=29765) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:17,460] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:17,461] {logging_mixin.py:95} INFO - [2019-09-16 13:05:17,461] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:17,828] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:17,852] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:17,862] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:17,867] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.417 seconds
[2019-09-16 13:05:17,896] {scheduler_job.py:146} INFO - Started process (PID=29767) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:22,902] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:22,903] {logging_mixin.py:95} INFO - [2019-09-16 13:05:22,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:23,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:23,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:23,286] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:23,292] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:05:23,343] {scheduler_job.py:146} INFO - Started process (PID=29771) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:28,353] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:28,363] {logging_mixin.py:95} INFO - [2019-09-16 13:05:28,362] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:28,717] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:28,742] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:28,751] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:28,757] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 13:05:28,794] {scheduler_job.py:146} INFO - Started process (PID=29773) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:33,805] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:33,806] {logging_mixin.py:95} INFO - [2019-09-16 13:05:33,806] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:34,154] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:34,177] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:34,188] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:34,194] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:05:34,251] {scheduler_job.py:146} INFO - Started process (PID=29774) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:39,257] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:39,258] {logging_mixin.py:95} INFO - [2019-09-16 13:05:39,258] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:39,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:39,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:39,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:39,685] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 13:05:39,708] {scheduler_job.py:146} INFO - Started process (PID=29779) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:44,715] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:44,716] {logging_mixin.py:95} INFO - [2019-09-16 13:05:44,715] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:45,058] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:45,083] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:45,092] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:45,097] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 13:05:45,163] {scheduler_job.py:146} INFO - Started process (PID=29781) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:50,170] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:50,171] {logging_mixin.py:95} INFO - [2019-09-16 13:05:50,171] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:50,523] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:50,546] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:50,555] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:50,560] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 13:05:50,622] {scheduler_job.py:146} INFO - Started process (PID=29785) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:55,629] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:05:55,630] {logging_mixin.py:95} INFO - [2019-09-16 13:05:55,629] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:55,984] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:05:56,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:05:56,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:05:56,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:05:56,075] {scheduler_job.py:146} INFO - Started process (PID=29786) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:01,082] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:01,083] {logging_mixin.py:95} INFO - [2019-09-16 13:06:01,082] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:01,433] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:01,458] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:01,467] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:01,472] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 13:06:01,532] {scheduler_job.py:146} INFO - Started process (PID=29791) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:06,539] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:06,540] {logging_mixin.py:95} INFO - [2019-09-16 13:06:06,540] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:06,883] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:06,908] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:06,917] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:06,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:06:06,985] {scheduler_job.py:146} INFO - Started process (PID=29792) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:11,995] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:11,996] {logging_mixin.py:95} INFO - [2019-09-16 13:06:11,995] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:12,354] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:12,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:12,386] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:12,391] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 13:06:12,427] {scheduler_job.py:146} INFO - Started process (PID=29793) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:17,434] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:17,435] {logging_mixin.py:95} INFO - [2019-09-16 13:06:17,435] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:17,890] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:17,915] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:17,926] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:17,936] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.509 seconds
[2019-09-16 13:06:17,979] {scheduler_job.py:146} INFO - Started process (PID=29800) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:22,987] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:22,988] {logging_mixin.py:95} INFO - [2019-09-16 13:06:22,988] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:23,392] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:23,418] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:23,431] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:23,438] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-16 13:06:23,520] {scheduler_job.py:146} INFO - Started process (PID=29803) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:28,528] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:28,529] {logging_mixin.py:95} INFO - [2019-09-16 13:06:28,529] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:28,910] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:28,933] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:28,942] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:28,947] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 13:06:29,057] {scheduler_job.py:146} INFO - Started process (PID=29806) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:34,067] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:34,068] {logging_mixin.py:95} INFO - [2019-09-16 13:06:34,068] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:34,458] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:34,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:34,493] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:34,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.443 seconds
[2019-09-16 13:06:34,609] {scheduler_job.py:146} INFO - Started process (PID=29807) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:39,613] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:39,615] {logging_mixin.py:95} INFO - [2019-09-16 13:06:39,614] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:40,036] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:40,058] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:40,072] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:40,079] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.471 seconds
[2019-09-16 13:06:40,163] {scheduler_job.py:146} INFO - Started process (PID=29812) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:45,169] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:45,170] {logging_mixin.py:95} INFO - [2019-09-16 13:06:45,170] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:45,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:45,540] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:45,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:45,555] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 13:06:45,613] {scheduler_job.py:146} INFO - Started process (PID=29814) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:50,620] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:50,622] {logging_mixin.py:95} INFO - [2019-09-16 13:06:50,621] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:50,980] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:51,003] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:51,013] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:51,018] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:06:51,070] {scheduler_job.py:146} INFO - Started process (PID=29815) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:56,079] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:06:56,081] {logging_mixin.py:95} INFO - [2019-09-16 13:06:56,080] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:56,442] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:06:56,468] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:06:56,480] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:06:56,485] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 13:06:56,525] {scheduler_job.py:146} INFO - Started process (PID=29819) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:01,531] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:01,533] {logging_mixin.py:95} INFO - [2019-09-16 13:07:01,532] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:01,873] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:01,898] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:01,907] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:01,912] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 13:07:01,982] {scheduler_job.py:146} INFO - Started process (PID=29821) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:06,991] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:06,992] {logging_mixin.py:95} INFO - [2019-09-16 13:07:06,991] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:07,361] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:07,385] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:07,395] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:07,401] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-16 13:07:07,439] {scheduler_job.py:146} INFO - Started process (PID=29825) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:12,446] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:12,447] {logging_mixin.py:95} INFO - [2019-09-16 13:07:12,447] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:12,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:12,832] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:12,841] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:12,847] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.408 seconds
[2019-09-16 13:07:12,897] {scheduler_job.py:146} INFO - Started process (PID=29826) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:17,907] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:17,908] {logging_mixin.py:95} INFO - [2019-09-16 13:07:17,907] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:18,254] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:18,278] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:18,287] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:18,293] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:07:18,346] {scheduler_job.py:146} INFO - Started process (PID=29828) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:23,352] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:23,354] {logging_mixin.py:95} INFO - [2019-09-16 13:07:23,353] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:23,754] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:23,776] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:23,787] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:23,793] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 13:07:23,899] {scheduler_job.py:146} INFO - Started process (PID=29829) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:28,905] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:28,906] {logging_mixin.py:95} INFO - [2019-09-16 13:07:28,906] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:29,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:29,272] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:29,283] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:29,289] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 13:07:29,344] {scheduler_job.py:146} INFO - Started process (PID=29834) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:34,350] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:34,351] {logging_mixin.py:95} INFO - [2019-09-16 13:07:34,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:34,697] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:34,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:34,731] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:34,736] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 13:07:34,802] {scheduler_job.py:146} INFO - Started process (PID=29835) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:39,811] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:39,811] {logging_mixin.py:95} INFO - [2019-09-16 13:07:39,811] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:40,167] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:40,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:40,201] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:40,207] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:07:40,267] {scheduler_job.py:146} INFO - Started process (PID=29840) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:45,275] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:45,276] {logging_mixin.py:95} INFO - [2019-09-16 13:07:45,276] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:45,623] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:45,647] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:45,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:45,662] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 13:07:45,728] {scheduler_job.py:146} INFO - Started process (PID=29842) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:50,738] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:50,739] {logging_mixin.py:95} INFO - [2019-09-16 13:07:50,738] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:51,083] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:51,107] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:51,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:51,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 13:07:51,187] {scheduler_job.py:146} INFO - Started process (PID=29843) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:56,197] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:07:56,198] {logging_mixin.py:95} INFO - [2019-09-16 13:07:56,198] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:56,563] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:07:56,588] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:07:56,600] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:07:56,607] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 13:07:56,650] {scheduler_job.py:146} INFO - Started process (PID=29844) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:01,662] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:01,663] {logging_mixin.py:95} INFO - [2019-09-16 13:08:01,663] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:02,006] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:02,029] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:02,038] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:02,044] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:08:02,097] {scheduler_job.py:146} INFO - Started process (PID=29849) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:07,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:07,107] {logging_mixin.py:95} INFO - [2019-09-16 13:08:07,106] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:07,500] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:07,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:07,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:07,538] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 13:08:07,648] {scheduler_job.py:146} INFO - Started process (PID=29853) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:12,658] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:12,659] {logging_mixin.py:95} INFO - [2019-09-16 13:08:12,659] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:13,007] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:13,030] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:13,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:13,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:08:13,101] {scheduler_job.py:146} INFO - Started process (PID=29854) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:18,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:18,107] {logging_mixin.py:95} INFO - [2019-09-16 13:08:18,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:18,463] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:18,484] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:18,494] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:18,499] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:08:18,560] {scheduler_job.py:146} INFO - Started process (PID=29856) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:23,568] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:23,569] {logging_mixin.py:95} INFO - [2019-09-16 13:08:23,569] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:23,961] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:23,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:23,995] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:24,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 13:08:24,103] {scheduler_job.py:146} INFO - Started process (PID=29860) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:29,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:29,109] {logging_mixin.py:95} INFO - [2019-09-16 13:08:29,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:29,467] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:29,493] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:29,503] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:29,509] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 13:08:29,549] {scheduler_job.py:146} INFO - Started process (PID=29862) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:34,556] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:34,557] {logging_mixin.py:95} INFO - [2019-09-16 13:08:34,557] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:34,903] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:34,924] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:34,933] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:34,939] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:08:35,002] {scheduler_job.py:146} INFO - Started process (PID=29863) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:40,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:40,009] {logging_mixin.py:95} INFO - [2019-09-16 13:08:40,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:40,410] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:40,428] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:40,445] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:40,454] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.452 seconds
[2019-09-16 13:08:40,550] {scheduler_job.py:146} INFO - Started process (PID=29868) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:45,555] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:45,556] {logging_mixin.py:95} INFO - [2019-09-16 13:08:45,555] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:45,916] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:45,939] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:45,951] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:45,957] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 13:08:45,991] {scheduler_job.py:146} INFO - Started process (PID=29870) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:50,997] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:50,998] {logging_mixin.py:95} INFO - [2019-09-16 13:08:50,997] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:51,430] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:51,453] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:51,464] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:51,470] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.479 seconds
[2019-09-16 13:08:51,539] {scheduler_job.py:146} INFO - Started process (PID=29871) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:56,550] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:08:56,551] {logging_mixin.py:95} INFO - [2019-09-16 13:08:56,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:56,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:08:56,935] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:08:56,946] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:08:56,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.413 seconds
[2019-09-16 13:08:56,992] {scheduler_job.py:146} INFO - Started process (PID=29875) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:02,002] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:02,003] {logging_mixin.py:95} INFO - [2019-09-16 13:09:02,002] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:02,353] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:02,378] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:02,388] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:02,394] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 13:09:02,446] {scheduler_job.py:146} INFO - Started process (PID=29877) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:07,452] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:07,453] {logging_mixin.py:95} INFO - [2019-09-16 13:09:07,453] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:07,812] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:07,834] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:07,843] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:07,849] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 13:09:07,904] {scheduler_job.py:146} INFO - Started process (PID=29878) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:12,911] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:12,912] {logging_mixin.py:95} INFO - [2019-09-16 13:09:12,912] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:13,279] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:13,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:13,313] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:13,319] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 13:09:13,359] {scheduler_job.py:146} INFO - Started process (PID=29882) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:18,370] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:18,371] {logging_mixin.py:95} INFO - [2019-09-16 13:09:18,370] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:18,734] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:18,758] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:18,769] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:18,774] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 13:09:18,815] {scheduler_job.py:146} INFO - Started process (PID=29885) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:23,822] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:23,823] {logging_mixin.py:95} INFO - [2019-09-16 13:09:23,822] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:24,177] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:24,201] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:24,213] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:24,218] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 13:09:24,270] {scheduler_job.py:146} INFO - Started process (PID=29886) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:29,276] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:29,278] {logging_mixin.py:95} INFO - [2019-09-16 13:09:29,278] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:29,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:29,679] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:29,690] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:29,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 13:09:29,723] {scheduler_job.py:146} INFO - Started process (PID=29888) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:34,733] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:34,734] {logging_mixin.py:95} INFO - [2019-09-16 13:09:34,734] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:35,097] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:35,116] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:35,127] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:35,133] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 13:09:35,174] {scheduler_job.py:146} INFO - Started process (PID=29893) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:40,183] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:40,184] {logging_mixin.py:95} INFO - [2019-09-16 13:09:40,184] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:40,536] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:40,560] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:40,569] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:40,574] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:09:40,627] {scheduler_job.py:146} INFO - Started process (PID=29894) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:45,636] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:45,637] {logging_mixin.py:95} INFO - [2019-09-16 13:09:45,637] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:46,070] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:46,107] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:46,124] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:46,135] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.507 seconds
[2019-09-16 13:09:46,182] {scheduler_job.py:146} INFO - Started process (PID=29899) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:51,188] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:51,189] {logging_mixin.py:95} INFO - [2019-09-16 13:09:51,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:51,565] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:51,587] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:51,597] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:51,603] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 13:09:51,632] {scheduler_job.py:146} INFO - Started process (PID=29900) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:56,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:09:56,639] {logging_mixin.py:95} INFO - [2019-09-16 13:09:56,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:56,978] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:09:57,002] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:09:57,011] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:09:57,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 13:09:57,089] {scheduler_job.py:146} INFO - Started process (PID=29901) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:02,098] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:02,099] {logging_mixin.py:95} INFO - [2019-09-16 13:10:02,098] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:02,447] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:02,472] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:02,481] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:02,487] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 13:10:02,544] {scheduler_job.py:146} INFO - Started process (PID=29903) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:07,549] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:07,550] {logging_mixin.py:95} INFO - [2019-09-16 13:10:07,550] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:07,898] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:07,913] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:07,923] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:07,928] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.384 seconds
[2019-09-16 13:10:07,999] {scheduler_job.py:146} INFO - Started process (PID=29907) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:13,007] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:13,009] {logging_mixin.py:95} INFO - [2019-09-16 13:10:13,008] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:13,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:13,450] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:13,463] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:13,470] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 13:10:13,554] {scheduler_job.py:146} INFO - Started process (PID=29908) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:18,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:18,562] {logging_mixin.py:95} INFO - [2019-09-16 13:10:18,561] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:18,909] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:18,936] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:18,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:18,953] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:10:19,006] {scheduler_job.py:146} INFO - Started process (PID=29913) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:24,012] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:24,013] {logging_mixin.py:95} INFO - [2019-09-16 13:10:24,012] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:24,355] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:24,376] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:24,387] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:24,392] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 13:10:24,450] {scheduler_job.py:146} INFO - Started process (PID=29914) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:29,455] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:29,456] {logging_mixin.py:95} INFO - [2019-09-16 13:10:29,456] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:29,784] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:29,805] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:29,814] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:29,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-16 13:10:29,904] {scheduler_job.py:146} INFO - Started process (PID=29916) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:34,913] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:34,914] {logging_mixin.py:95} INFO - [2019-09-16 13:10:34,913] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:35,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:35,356] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:35,369] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:35,376] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.472 seconds
[2019-09-16 13:10:35,457] {scheduler_job.py:146} INFO - Started process (PID=29918) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:40,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:40,470] {logging_mixin.py:95} INFO - [2019-09-16 13:10:40,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:40,808] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:40,833] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:40,842] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:40,848] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:10:40,909] {scheduler_job.py:146} INFO - Started process (PID=29922) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:45,915] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:45,916] {logging_mixin.py:95} INFO - [2019-09-16 13:10:45,916] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:46,269] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:46,294] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:46,304] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:46,309] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:10:46,371] {scheduler_job.py:146} INFO - Started process (PID=29924) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:51,381] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:51,382] {logging_mixin.py:95} INFO - [2019-09-16 13:10:51,382] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:51,723] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:51,748] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:51,757] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:51,762] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 13:10:51,827] {scheduler_job.py:146} INFO - Started process (PID=29928) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:56,833] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:10:56,834] {logging_mixin.py:95} INFO - [2019-09-16 13:10:56,834] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:57,179] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:10:57,203] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:10:57,214] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:10:57,219] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 13:10:57,294] {scheduler_job.py:146} INFO - Started process (PID=29929) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:02,305] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:02,306] {logging_mixin.py:95} INFO - [2019-09-16 13:11:02,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:02,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:02,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:02,681] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:02,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 13:11:02,757] {scheduler_job.py:146} INFO - Started process (PID=29931) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:07,763] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:07,764] {logging_mixin.py:95} INFO - [2019-09-16 13:11:07,764] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:08,138] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:08,162] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:08,172] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:08,178] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 13:11:08,214] {scheduler_job.py:146} INFO - Started process (PID=29935) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:13,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:13,221] {logging_mixin.py:95} INFO - [2019-09-16 13:11:13,221] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:13,572] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:13,594] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:13,603] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:13,608] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 13:11:13,662] {scheduler_job.py:146} INFO - Started process (PID=29936) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:18,672] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:18,673] {logging_mixin.py:95} INFO - [2019-09-16 13:11:18,672] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:19,039] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:19,061] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:19,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:19,082] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.420 seconds
[2019-09-16 13:11:19,111] {scheduler_job.py:146} INFO - Started process (PID=29941) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:24,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:24,120] {logging_mixin.py:95} INFO - [2019-09-16 13:11:24,120] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:24,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:24,494] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:24,505] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:24,510] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:11:24,555] {scheduler_job.py:146} INFO - Started process (PID=29942) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:29,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:29,562] {logging_mixin.py:95} INFO - [2019-09-16 13:11:29,562] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:29,959] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:29,985] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:29,999] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:30,005] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 13:11:30,117] {scheduler_job.py:146} INFO - Started process (PID=29944) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:35,126] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:35,128] {logging_mixin.py:95} INFO - [2019-09-16 13:11:35,127] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:35,487] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:35,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:35,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:35,524] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 13:11:35,565] {scheduler_job.py:146} INFO - Started process (PID=29949) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:40,573] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:40,574] {logging_mixin.py:95} INFO - [2019-09-16 13:11:40,573] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:40,920] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:40,944] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:40,954] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:40,959] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 13:11:41,019] {scheduler_job.py:146} INFO - Started process (PID=29950) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:46,026] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:46,027] {logging_mixin.py:95} INFO - [2019-09-16 13:11:46,027] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:46,382] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:46,406] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:46,416] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:46,421] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 13:11:46,474] {scheduler_job.py:146} INFO - Started process (PID=29952) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:51,481] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:51,482] {logging_mixin.py:95} INFO - [2019-09-16 13:11:51,482] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:51,825] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:51,850] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:51,859] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:51,864] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:11:51,929] {scheduler_job.py:146} INFO - Started process (PID=29953) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:56,936] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:11:56,937] {logging_mixin.py:95} INFO - [2019-09-16 13:11:56,936] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:57,284] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:11:57,303] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:11:57,312] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:11:57,318] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 13:11:57,388] {scheduler_job.py:146} INFO - Started process (PID=29957) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:02,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:02,399] {logging_mixin.py:95} INFO - [2019-09-16 13:12:02,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:02,746] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:02,769] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:02,778] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:02,783] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:12:02,847] {scheduler_job.py:146} INFO - Started process (PID=29959) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:07,858] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:07,859] {logging_mixin.py:95} INFO - [2019-09-16 13:12:07,858] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:08,214] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:08,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:08,247] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:08,252] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 13:12:08,298] {scheduler_job.py:146} INFO - Started process (PID=29960) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:13,304] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:13,306] {logging_mixin.py:95} INFO - [2019-09-16 13:12:13,305] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:13,656] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:13,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:13,701] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:13,709] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.410 seconds
[2019-09-16 13:12:13,753] {scheduler_job.py:146} INFO - Started process (PID=29971) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:18,759] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:18,761] {logging_mixin.py:95} INFO - [2019-09-16 13:12:18,760] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:19,135] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:19,160] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:19,171] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:19,177] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 13:12:19,202] {scheduler_job.py:146} INFO - Started process (PID=29973) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:24,209] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:24,210] {logging_mixin.py:95} INFO - [2019-09-16 13:12:24,209] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:24,622] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:24,646] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:24,657] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:24,664] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.462 seconds
[2019-09-16 13:12:24,748] {scheduler_job.py:146} INFO - Started process (PID=29977) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:29,754] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:29,755] {logging_mixin.py:95} INFO - [2019-09-16 13:12:29,754] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:30,127] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:30,151] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:30,165] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:30,172] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.424 seconds
[2019-09-16 13:12:30,198] {scheduler_job.py:146} INFO - Started process (PID=29979) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:35,208] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:35,209] {logging_mixin.py:95} INFO - [2019-09-16 13:12:35,208] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:35,573] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:35,596] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:35,606] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:35,612] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 13:12:35,642] {scheduler_job.py:146} INFO - Started process (PID=29981) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:40,652] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:40,653] {logging_mixin.py:95} INFO - [2019-09-16 13:12:40,652] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:40,997] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:41,019] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:41,029] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:41,034] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.392 seconds
[2019-09-16 13:12:41,098] {scheduler_job.py:146} INFO - Started process (PID=29982) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:46,104] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:46,105] {logging_mixin.py:95} INFO - [2019-09-16 13:12:46,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:46,450] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:46,474] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:46,483] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:46,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:12:46,558] {scheduler_job.py:146} INFO - Started process (PID=29987) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:51,564] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:51,565] {logging_mixin.py:95} INFO - [2019-09-16 13:12:51,565] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:51,906] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:51,929] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:51,938] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:51,944] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.386 seconds
[2019-09-16 13:12:52,014] {scheduler_job.py:146} INFO - Started process (PID=29988) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:57,020] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:12:57,021] {logging_mixin.py:95} INFO - [2019-09-16 13:12:57,021] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:57,368] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:12:57,392] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:12:57,401] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:12:57,406] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:12:57,476] {scheduler_job.py:146} INFO - Started process (PID=29989) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:02,486] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:02,487] {logging_mixin.py:95} INFO - [2019-09-16 13:13:02,487] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:02,830] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:02,854] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:02,863] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:02,869] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:13:02,936] {scheduler_job.py:146} INFO - Started process (PID=29992) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:07,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:07,943] {logging_mixin.py:95} INFO - [2019-09-16 13:13:07,943] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:08,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:08,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:08,324] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:08,329] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 13:13:08,400] {scheduler_job.py:146} INFO - Started process (PID=29995) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:13,407] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:13,408] {logging_mixin.py:95} INFO - [2019-09-16 13:13:13,407] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:13,757] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:13,781] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:13,790] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:13,795] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 13:13:13,859] {scheduler_job.py:146} INFO - Started process (PID=29999) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:18,870] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:18,871] {logging_mixin.py:95} INFO - [2019-09-16 13:13:18,870] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:19,225] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:19,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:19,259] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:19,265] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 13:13:19,326] {scheduler_job.py:146} INFO - Started process (PID=30001) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:24,333] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:24,334] {logging_mixin.py:95} INFO - [2019-09-16 13:13:24,334] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:24,674] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:24,698] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:24,708] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:24,713] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 13:13:24,788] {scheduler_job.py:146} INFO - Started process (PID=30002) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:29,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:29,795] {logging_mixin.py:95} INFO - [2019-09-16 13:13:29,794] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:30,141] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:30,165] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:30,175] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:30,180] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:13:30,247] {scheduler_job.py:146} INFO - Started process (PID=30004) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:35,253] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:35,254] {logging_mixin.py:95} INFO - [2019-09-16 13:13:35,254] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:35,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:35,650] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:35,660] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:35,665] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.418 seconds
[2019-09-16 13:13:35,696] {scheduler_job.py:146} INFO - Started process (PID=30009) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:40,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:40,708] {logging_mixin.py:95} INFO - [2019-09-16 13:13:40,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:41,050] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:41,074] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:41,084] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:41,089] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:13:41,154] {scheduler_job.py:146} INFO - Started process (PID=30010) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:46,161] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:46,163] {logging_mixin.py:95} INFO - [2019-09-16 13:13:46,162] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:46,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:46,539] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:46,549] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:46,554] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.400 seconds
[2019-09-16 13:13:46,614] {scheduler_job.py:146} INFO - Started process (PID=30012) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:51,624] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:51,625] {logging_mixin.py:95} INFO - [2019-09-16 13:13:51,624] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:51,976] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:51,998] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:52,010] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:52,016] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.402 seconds
[2019-09-16 13:13:52,069] {scheduler_job.py:146} INFO - Started process (PID=30016) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:57,075] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:13:57,076] {logging_mixin.py:95} INFO - [2019-09-16 13:13:57,076] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:57,425] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:13:57,448] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:13:57,457] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:13:57,462] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:13:57,520] {scheduler_job.py:146} INFO - Started process (PID=30017) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:02,527] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:02,528] {logging_mixin.py:95} INFO - [2019-09-16 13:14:02,528] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:02,878] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:02,902] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:02,912] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:02,917] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 13:14:02,977] {scheduler_job.py:146} INFO - Started process (PID=30022) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:07,984] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:07,985] {logging_mixin.py:95} INFO - [2019-09-16 13:14:07,985] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:08,343] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:08,366] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:08,376] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:08,381] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:14:08,432] {scheduler_job.py:146} INFO - Started process (PID=30023) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:13,441] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:13,442] {logging_mixin.py:95} INFO - [2019-09-16 13:14:13,442] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:13,805] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:13,828] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:13,838] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:13,843] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 13:14:13,885] {scheduler_job.py:146} INFO - Started process (PID=30024) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:18,894] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:18,895] {logging_mixin.py:95} INFO - [2019-09-16 13:14:18,895] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:19,259] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:19,282] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:19,292] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:19,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 13:14:19,339] {scheduler_job.py:146} INFO - Started process (PID=30029) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:24,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:24,350] {logging_mixin.py:95} INFO - [2019-09-16 13:14:24,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:24,701] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:24,725] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:24,735] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:24,740] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 13:14:24,797] {scheduler_job.py:146} INFO - Started process (PID=30030) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:29,802] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:29,803] {logging_mixin.py:95} INFO - [2019-09-16 13:14:29,803] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:30,198] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:30,224] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:30,245] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:30,256] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.458 seconds
[2019-09-16 13:14:30,354] {scheduler_job.py:146} INFO - Started process (PID=30035) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:35,359] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:35,360] {logging_mixin.py:95} INFO - [2019-09-16 13:14:35,360] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:35,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:35,726] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:35,736] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:35,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 13:14:35,794] {scheduler_job.py:146} INFO - Started process (PID=30043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:40,801] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:40,802] {logging_mixin.py:95} INFO - [2019-09-16 13:14:40,802] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:41,213] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:41,237] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:41,248] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:41,254] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.460 seconds
[2019-09-16 13:14:41,340] {scheduler_job.py:146} INFO - Started process (PID=30046) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:46,348] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:46,349] {logging_mixin.py:95} INFO - [2019-09-16 13:14:46,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:46,707] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:46,728] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:46,738] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:46,743] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.403 seconds
[2019-09-16 13:14:46,787] {scheduler_job.py:146} INFO - Started process (PID=30048) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:51,794] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:51,795] {logging_mixin.py:95} INFO - [2019-09-16 13:14:51,795] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:52,149] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:52,176] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:52,187] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:52,193] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.406 seconds
[2019-09-16 13:14:52,246] {scheduler_job.py:146} INFO - Started process (PID=30052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:57,252] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:14:57,253] {logging_mixin.py:95} INFO - [2019-09-16 13:14:57,252] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:57,657] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:14:57,681] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:14:57,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:14:57,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.454 seconds
[2019-09-16 13:14:57,791] {scheduler_job.py:146} INFO - Started process (PID=30053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:02,797] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:02,798] {logging_mixin.py:95} INFO - [2019-09-16 13:15:02,797] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:03,246] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:03,277] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:03,295] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:03,303] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.512 seconds
[2019-09-16 13:15:03,340] {scheduler_job.py:146} INFO - Started process (PID=30055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:08,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:08,350] {logging_mixin.py:95} INFO - [2019-09-16 13:15:08,349] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:08,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:08,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:08,733] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:08,739] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:15:08,785] {scheduler_job.py:146} INFO - Started process (PID=30059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:13,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:13,792] {logging_mixin.py:95} INFO - [2019-09-16 13:15:13,792] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:14,173] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:14,198] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:14,208] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:14,213] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 13:15:14,235] {scheduler_job.py:146} INFO - Started process (PID=30061) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:19,241] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:19,242] {logging_mixin.py:95} INFO - [2019-09-16 13:15:19,242] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:19,630] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:19,655] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:19,664] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:19,669] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 13:15:19,784] {scheduler_job.py:146} INFO - Started process (PID=30062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:24,791] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:24,792] {logging_mixin.py:95} INFO - [2019-09-16 13:15:24,791] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:25,205] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:25,232] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:25,243] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:25,249] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.465 seconds
[2019-09-16 13:15:25,334] {scheduler_job.py:146} INFO - Started process (PID=30066) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:30,341] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:30,342] {logging_mixin.py:95} INFO - [2019-09-16 13:15:30,341] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:30,704] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:30,729] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:30,741] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:30,748] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 13:15:30,780] {scheduler_job.py:146} INFO - Started process (PID=30068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:35,789] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:35,790] {logging_mixin.py:95} INFO - [2019-09-16 13:15:35,789] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:36,129] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:36,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:36,162] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:36,169] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 13:15:36,230] {scheduler_job.py:146} INFO - Started process (PID=30073) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:41,240] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:41,241] {logging_mixin.py:95} INFO - [2019-09-16 13:15:41,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:41,586] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:41,607] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:41,617] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:41,622] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:15:41,676] {scheduler_job.py:146} INFO - Started process (PID=30074) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:46,682] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:46,683] {logging_mixin.py:95} INFO - [2019-09-16 13:15:46,683] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:47,032] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:47,049] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:47,060] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:47,065] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.389 seconds
[2019-09-16 13:15:47,124] {scheduler_job.py:146} INFO - Started process (PID=30076) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:52,130] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:52,131] {logging_mixin.py:95} INFO - [2019-09-16 13:15:52,130] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:52,490] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:52,514] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:52,524] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:52,529] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 13:15:52,574] {scheduler_job.py:146} INFO - Started process (PID=30080) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:57,583] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:15:57,584] {logging_mixin.py:95} INFO - [2019-09-16 13:15:57,583] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:57,981] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:15:58,004] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:15:58,015] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:15:58,021] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 13:15:58,121] {scheduler_job.py:146} INFO - Started process (PID=30081) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:03,131] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:03,132] {logging_mixin.py:95} INFO - [2019-09-16 13:16:03,131] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:03,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:03,564] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:03,574] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:03,580] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.459 seconds
[2019-09-16 13:16:03,669] {scheduler_job.py:146} INFO - Started process (PID=30084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:08,676] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:08,677] {logging_mixin.py:95} INFO - [2019-09-16 13:16:08,677] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:09,041] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:09,065] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:09,074] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:09,080] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 13:16:09,114] {scheduler_job.py:146} INFO - Started process (PID=30085) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:14,120] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:14,121] {logging_mixin.py:95} INFO - [2019-09-16 13:16:14,121] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:14,497] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:14,521] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:14,531] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:14,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 13:16:14,562] {scheduler_job.py:146} INFO - Started process (PID=30090) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:19,567] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:19,568] {logging_mixin.py:95} INFO - [2019-09-16 13:16:19,568] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:19,913] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:19,937] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:19,947] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:19,952] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:16:20,008] {scheduler_job.py:146} INFO - Started process (PID=30091) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:25,017] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:25,018] {logging_mixin.py:95} INFO - [2019-09-16 13:16:25,017] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:25,420] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:25,443] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:25,453] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:25,459] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 13:16:25,562] {scheduler_job.py:146} INFO - Started process (PID=30095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:30,572] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:30,583] {logging_mixin.py:95} INFO - [2019-09-16 13:16:30,583] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:30,954] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:30,978] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:30,988] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:30,993] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.431 seconds
[2019-09-16 13:16:31,014] {scheduler_job.py:146} INFO - Started process (PID=30099) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:36,022] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:36,023] {logging_mixin.py:95} INFO - [2019-09-16 13:16:36,023] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:36,364] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:36,388] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:36,398] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:36,405] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:16:36,470] {scheduler_job.py:146} INFO - Started process (PID=30101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:41,475] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:41,476] {logging_mixin.py:95} INFO - [2019-09-16 13:16:41,476] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:41,818] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:41,842] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:41,852] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:41,858] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.388 seconds
[2019-09-16 13:16:41,918] {scheduler_job.py:146} INFO - Started process (PID=30102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:46,924] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:46,925] {logging_mixin.py:95} INFO - [2019-09-16 13:16:46,924] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:47,302] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:47,327] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:47,339] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:47,346] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.428 seconds
[2019-09-16 13:16:47,369] {scheduler_job.py:146} INFO - Started process (PID=30107) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:52,376] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:52,377] {logging_mixin.py:95} INFO - [2019-09-16 13:16:52,377] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:52,725] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:52,747] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:52,756] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:52,761] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.393 seconds
[2019-09-16 13:16:52,826] {scheduler_job.py:146} INFO - Started process (PID=30108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:57,834] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:16:57,835] {logging_mixin.py:95} INFO - [2019-09-16 13:16:57,835] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:58,227] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:16:58,249] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:16:58,260] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:16:58,266] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.440 seconds
[2019-09-16 13:16:58,289] {scheduler_job.py:146} INFO - Started process (PID=30109) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:03,295] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:03,296] {logging_mixin.py:95} INFO - [2019-09-16 13:17:03,296] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:03,644] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:03,668] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:03,680] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:03,686] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 13:17:03,744] {scheduler_job.py:146} INFO - Started process (PID=30114) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:08,753] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:08,754] {logging_mixin.py:95} INFO - [2019-09-16 13:17:08,753] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:09,157] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:09,181] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:09,192] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:09,199] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.455 seconds
[2019-09-16 13:17:09,295] {scheduler_job.py:146} INFO - Started process (PID=30115) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:14,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:14,301] {logging_mixin.py:95} INFO - [2019-09-16 13:17:14,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:14,696] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:14,721] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:14,734] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:14,742] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.447 seconds
[2019-09-16 13:17:14,845] {scheduler_job.py:146} INFO - Started process (PID=30120) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:19,852] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:19,853] {logging_mixin.py:95} INFO - [2019-09-16 13:17:19,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:20,204] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:20,228] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:20,237] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:20,243] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 13:17:20,286] {scheduler_job.py:146} INFO - Started process (PID=30121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:25,291] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:25,292] {logging_mixin.py:95} INFO - [2019-09-16 13:17:25,291] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:25,637] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:25,661] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:25,670] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:25,676] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.390 seconds
[2019-09-16 13:17:25,735] {scheduler_job.py:146} INFO - Started process (PID=30122) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:30,742] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:30,743] {logging_mixin.py:95} INFO - [2019-09-16 13:17:30,743] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:31,100] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:31,124] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:31,134] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:31,140] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:17:31,187] {scheduler_job.py:146} INFO - Started process (PID=30124) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:36,193] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:36,194] {logging_mixin.py:95} INFO - [2019-09-16 13:17:36,194] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:36,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:36,619] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:36,631] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:36,637] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 13:17:36,739] {scheduler_job.py:146} INFO - Started process (PID=30129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:41,748] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:41,749] {logging_mixin.py:95} INFO - [2019-09-16 13:17:41,749] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:42,101] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:42,126] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:42,137] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:42,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.404 seconds
[2019-09-16 13:17:42,191] {scheduler_job.py:146} INFO - Started process (PID=30130) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:47,198] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:47,199] {logging_mixin.py:95} INFO - [2019-09-16 13:17:47,199] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:47,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:47,570] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:47,581] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:47,587] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:17:47,640] {scheduler_job.py:146} INFO - Started process (PID=30135) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:52,650] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:52,651] {logging_mixin.py:95} INFO - [2019-09-16 13:17:52,651] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:53,008] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:53,032] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:53,041] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:53,047] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.407 seconds
[2019-09-16 13:17:53,100] {scheduler_job.py:146} INFO - Started process (PID=30136) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:58,106] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:17:58,107] {logging_mixin.py:95} INFO - [2019-09-16 13:17:58,107] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:58,476] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:17:58,508] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:17:58,518] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:17:58,523] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.423 seconds
[2019-09-16 13:17:58,556] {scheduler_job.py:146} INFO - Started process (PID=30137) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:03,566] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:03,567] {logging_mixin.py:95} INFO - [2019-09-16 13:18:03,566] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:03,902] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:03,926] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:03,936] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:03,941] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 13:18:04,024] {scheduler_job.py:146} INFO - Started process (PID=30139) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:09,030] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:09,031] {logging_mixin.py:95} INFO - [2019-09-16 13:18:09,031] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:09,380] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:09,404] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:09,414] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:09,419] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:18:09,487] {scheduler_job.py:146} INFO - Started process (PID=30143) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:14,493] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:14,494] {logging_mixin.py:95} INFO - [2019-09-16 13:18:14,494] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:14,835] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:14,859] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:14,869] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:14,874] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.387 seconds
[2019-09-16 13:18:14,946] {scheduler_job.py:146} INFO - Started process (PID=30145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:19,952] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:19,953] {logging_mixin.py:95} INFO - [2019-09-16 13:18:19,953] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:20,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:20,400] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:20,412] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:20,420] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.474 seconds
[2019-09-16 13:18:20,511] {scheduler_job.py:146} INFO - Started process (PID=30149) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:25,521] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:25,522] {logging_mixin.py:95} INFO - [2019-09-16 13:18:25,522] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:25,868] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:25,892] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:25,902] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:25,907] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.396 seconds
[2019-09-16 13:18:25,965] {scheduler_job.py:146} INFO - Started process (PID=30150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:30,971] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:30,972] {logging_mixin.py:95} INFO - [2019-09-16 13:18:30,972] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:31,323] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:31,346] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:31,356] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:31,362] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.398 seconds
[2019-09-16 13:18:31,415] {scheduler_job.py:146} INFO - Started process (PID=30152) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:36,422] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:36,423] {logging_mixin.py:95} INFO - [2019-09-16 13:18:36,422] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:36,785] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:36,810] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:36,820] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:36,826] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 13:18:36,873] {scheduler_job.py:146} INFO - Started process (PID=30157) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:41,881] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:41,882] {logging_mixin.py:95} INFO - [2019-09-16 13:18:41,881] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:42,241] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:42,263] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:42,272] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:42,278] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.405 seconds
[2019-09-16 13:18:42,330] {scheduler_job.py:146} INFO - Started process (PID=30158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:47,335] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:47,337] {logging_mixin.py:95} INFO - [2019-09-16 13:18:47,335] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:47,712] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:47,735] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:47,744] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:47,749] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.419 seconds
[2019-09-16 13:18:47,785] {scheduler_job.py:146} INFO - Started process (PID=30160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:52,795] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:52,796] {logging_mixin.py:95} INFO - [2019-09-16 13:18:52,796] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:53,134] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:53,150] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:53,160] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:53,166] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.381 seconds
[2019-09-16 13:18:53,222] {scheduler_job.py:146} INFO - Started process (PID=31021) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:58,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:18:58,241] {logging_mixin.py:95} INFO - [2019-09-16 13:18:58,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:58,679] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:18:58,699] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:18:58,712] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:18:58,722] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.500 seconds
[2019-09-16 13:18:58,764] {scheduler_job.py:146} INFO - Started process (PID=31043) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:03,772] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:03,773] {logging_mixin.py:95} INFO - [2019-09-16 13:19:03,772] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:04,145] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:04,169] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:04,179] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:04,184] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.421 seconds
[2019-09-16 13:19:04,208] {scheduler_job.py:146} INFO - Started process (PID=31052) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:09,218] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:09,219] {logging_mixin.py:95} INFO - [2019-09-16 13:19:09,218] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:09,538] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:09,563] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:09,573] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:09,578] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.370 seconds
[2019-09-16 13:19:09,658] {scheduler_job.py:146} INFO - Started process (PID=31053) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:14,670] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:14,671] {logging_mixin.py:95} INFO - [2019-09-16 13:19:14,670] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:15,020] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:15,043] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:15,053] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:15,059] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.401 seconds
[2019-09-16 13:19:15,113] {scheduler_job.py:146} INFO - Started process (PID=31055) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:20,123] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:20,124] {logging_mixin.py:95} INFO - [2019-09-16 13:19:20,124] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:20,485] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:20,510] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:20,520] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:20,525] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.412 seconds
[2019-09-16 13:19:20,567] {scheduler_job.py:146} INFO - Started process (PID=31059) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:25,579] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:25,580] {logging_mixin.py:95} INFO - [2019-09-16 13:19:25,580] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:25,924] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:25,949] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:25,958] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:25,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 13:19:26,024] {scheduler_job.py:146} INFO - Started process (PID=31060) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:31,036] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:31,037] {logging_mixin.py:95} INFO - [2019-09-16 13:19:31,036] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:31,385] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:31,409] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:31,419] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:31,424] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:19:31,482] {scheduler_job.py:146} INFO - Started process (PID=31062) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:36,490] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:36,491] {logging_mixin.py:95} INFO - [2019-09-16 13:19:36,491] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:36,863] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:36,879] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:36,891] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:36,897] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.415 seconds
[2019-09-16 13:19:36,933] {scheduler_job.py:146} INFO - Started process (PID=31067) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:41,942] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:41,943] {logging_mixin.py:95} INFO - [2019-09-16 13:19:41,942] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:42,291] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:42,312] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:42,323] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:42,328] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 13:19:42,386] {scheduler_job.py:146} INFO - Started process (PID=31068) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:47,398] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:47,399] {logging_mixin.py:95} INFO - [2019-09-16 13:19:47,399] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:47,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:47,766] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:47,776] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:47,781] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.395 seconds
[2019-09-16 13:19:47,834] {scheduler_job.py:146} INFO - Started process (PID=31070) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:52,844] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:52,845] {logging_mixin.py:95} INFO - [2019-09-16 13:19:52,845] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:53,244] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:53,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:53,278] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:53,284] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.450 seconds
[2019-09-16 13:19:53,386] {scheduler_job.py:146} INFO - Started process (PID=31071) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:58,395] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:19:58,402] {logging_mixin.py:95} INFO - [2019-09-16 13:19:58,402] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:58,742] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:19:58,765] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:19:58,774] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:19:58,780] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 13:19:58,840] {scheduler_job.py:146} INFO - Started process (PID=31075) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:03,852] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:03,853] {logging_mixin.py:95} INFO - [2019-09-16 13:20:03,853] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:04,255] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:04,274] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:04,285] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:04,291] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.451 seconds
[2019-09-16 13:20:04,401] {scheduler_job.py:146} INFO - Started process (PID=31077) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:09,408] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:09,409] {logging_mixin.py:95} INFO - [2019-09-16 13:20:09,409] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:09,761] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:09,785] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:09,794] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:09,800] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.399 seconds
[2019-09-16 13:20:09,855] {scheduler_job.py:146} INFO - Started process (PID=31078) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:14,865] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:14,866] {logging_mixin.py:95} INFO - [2019-09-16 13:20:14,866] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:15,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:15,250] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:15,261] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:15,271] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.416 seconds
[2019-09-16 13:20:15,315] {scheduler_job.py:146} INFO - Started process (PID=31083) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:20,325] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:20,326] {logging_mixin.py:95} INFO - [2019-09-16 13:20:20,326] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:20,676] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:20,697] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:20,706] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:20,712] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.397 seconds
[2019-09-16 13:20:20,769] {scheduler_job.py:146} INFO - Started process (PID=31084) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:25,777] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:25,778] {logging_mixin.py:95} INFO - [2019-09-16 13:20:25,778] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:26,171] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:26,187] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:26,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:26,202] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.433 seconds
[2019-09-16 13:20:26,223] {scheduler_job.py:146} INFO - Started process (PID=31088) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:31,231] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:31,233] {logging_mixin.py:95} INFO - [2019-09-16 13:20:31,232] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:31,618] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:31,639] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:31,650] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:31,658] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.434 seconds
[2019-09-16 13:20:31,683] {scheduler_job.py:146} INFO - Started process (PID=31092) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:36,692] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:36,694] {logging_mixin.py:95} INFO - [2019-09-16 13:20:36,693] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:37,087] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:37,105] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:37,116] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:37,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.439 seconds
[2019-09-16 13:20:37,231] {scheduler_job.py:146} INFO - Started process (PID=31095) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:42,239] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:42,240] {logging_mixin.py:95} INFO - [2019-09-16 13:20:42,240] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:42,606] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:42,630] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:42,640] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:42,645] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.414 seconds
[2019-09-16 13:20:42,695] {scheduler_job.py:146} INFO - Started process (PID=31096) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:47,707] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:47,708] {logging_mixin.py:95} INFO - [2019-09-16 13:20:47,708] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:48,068] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:48,090] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:48,100] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:48,106] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.411 seconds
[2019-09-16 13:20:48,143] {scheduler_job.py:146} INFO - Started process (PID=31101) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:53,153] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:53,154] {logging_mixin.py:95} INFO - [2019-09-16 13:20:53,154] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:53,506] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:53,523] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:53,532] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:53,537] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.394 seconds
[2019-09-16 13:20:53,592] {scheduler_job.py:146} INFO - Started process (PID=31102) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:58,603] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:20:58,604] {logging_mixin.py:95} INFO - [2019-09-16 13:20:58,604] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:58,990] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:20:59,008] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:20:59,018] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:20:59,024] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.432 seconds
[2019-09-16 13:20:59,047] {scheduler_job.py:146} INFO - Started process (PID=31103) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:04,055] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:04,057] {logging_mixin.py:95} INFO - [2019-09-16 13:21:04,056] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:04,416] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:04,440] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:04,464] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:04,466] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:04,498] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:04,501] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:04,511] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.464 seconds
[2019-09-16 13:21:04,611] {scheduler_job.py:146} INFO - Started process (PID=31108) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:09,623] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:09,630] {logging_mixin.py:95} INFO - [2019-09-16 13:21:09,630] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:09,983] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:10,006] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:10,034] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:10,039] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:10,047] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:10,101] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:10,103] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:10,113] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.502 seconds
[2019-09-16 13:21:10,153] {scheduler_job.py:146} INFO - Started process (PID=31110) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:15,160] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:15,161] {logging_mixin.py:95} INFO - [2019-09-16 13:21:15,160] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:15,548] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:15,568] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:15,587] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:15,589] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:15,595] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:15,601] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:15,682] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:15,685] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:15,695] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.542 seconds
[2019-09-16 13:21:15,806] {scheduler_job.py:146} INFO - Started process (PID=31116) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:20,819] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:20,820] {logging_mixin.py:95} INFO - [2019-09-16 13:21:20,819] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:21,235] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:21,253] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:21,273] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:21,275] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:21,281] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:21,288] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:21,295] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:21,408] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:21,412] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:21,422] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.616 seconds
[2019-09-16 13:21:21,461] {scheduler_job.py:146} INFO - Started process (PID=31119) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:26,469] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:26,470] {logging_mixin.py:95} INFO - [2019-09-16 13:21:26,469] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:26,822] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:26,840] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:26,862] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:26,864] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:26,870] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:26,876] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:26,882] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:26,888] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:27,064] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:27,068] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:27,083] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.622 seconds
[2019-09-16 13:21:27,118] {scheduler_job.py:146} INFO - Started process (PID=31121) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:32,124] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:32,125] {logging_mixin.py:95} INFO - [2019-09-16 13:21:32,125] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:32,516] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:32,535] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:32,558] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,560] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,567] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,573] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,579] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,586] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,592] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:32,801] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:32,804] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:32,819] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.702 seconds
[2019-09-16 13:21:32,880] {scheduler_job.py:146} INFO - Started process (PID=31126) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:37,888] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:37,889] {logging_mixin.py:95} INFO - [2019-09-16 13:21:37,889] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:38,251] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:38,268] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:38,289] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,292] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,300] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,305] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,311] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,318] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,327] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,333] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:38,559] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:38,562] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,565] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,567] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,570] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,572] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,575] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:38,582] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.701 seconds
[2019-09-16 13:21:38,629] {scheduler_job.py:146} INFO - Started process (PID=31129) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:43,638] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:43,639] {logging_mixin.py:95} INFO - [2019-09-16 13:21:43,639] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:44,002] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:44,026] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:44,053] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,056] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,066] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,073] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,080] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,087] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,093] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,100] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,106] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:44,378] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:44,381] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:44,395] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.766 seconds
[2019-09-16 13:21:44,482] {scheduler_job.py:146} INFO - Started process (PID=31131) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:49,499] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:49,500] {logging_mixin.py:95} INFO - [2019-09-16 13:21:49,500] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:49,858] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:49,877] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:49,898] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,900] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,908] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,914] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,920] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,926] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,932] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,938] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,944] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:49,951] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:50,230] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:50,233] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:50,250] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.767 seconds
[2019-09-16 13:21:50,331] {scheduler_job.py:146} INFO - Started process (PID=31141) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:55,337] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:21:55,338] {logging_mixin.py:95} INFO - [2019-09-16 13:21:55,338] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:55,743] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:21:55,759] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:21:55,781] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,783] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,795] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,803] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,811] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,818] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,825] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,831] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,837] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,844] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:55,850] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:21:56,218] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:21:56,224] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:21:56,238] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.907 seconds
[2019-09-16 13:21:56,289] {scheduler_job.py:146} INFO - Started process (PID=31145) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:01,300] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:01,301] {logging_mixin.py:95} INFO - [2019-09-16 13:22:01,301] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:01,654] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:01,680] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:01,702] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,705] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,714] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,720] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,727] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,733] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,739] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,746] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,753] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,760] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,765] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:01,772] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:02,091] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:02,095] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:02,105] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.816 seconds
[2019-09-16 13:22:02,136] {scheduler_job.py:146} INFO - Started process (PID=31150) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:07,145] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:07,146] {logging_mixin.py:95} INFO - [2019-09-16 13:22:07,146] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:07,554] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:07,572] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:07,592] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,595] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,602] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,610] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,616] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,622] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,628] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,634] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,645] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,651] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,657] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,662] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:07,980] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:07,983] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:07,985] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:07,988] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:07,990] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:07,992] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:07,994] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:08,006] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.870 seconds
[2019-09-16 13:22:08,096] {scheduler_job.py:146} INFO - Started process (PID=31151) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:13,103] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:13,104] {logging_mixin.py:95} INFO - [2019-09-16 13:22:13,104] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:13,481] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:13,505] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:13,529] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,532] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,541] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,551] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,558] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,565] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,571] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,578] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,584] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,591] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,597] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,604] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,610] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,616] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:13,968] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:13,971] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:13,978] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.883 seconds
[2019-09-16 13:22:14,056] {scheduler_job.py:146} INFO - Started process (PID=31153) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:19,063] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:19,064] {logging_mixin.py:95} INFO - [2019-09-16 13:22:19,064] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:19,441] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:19,466] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:19,489] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-17T17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,491] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,501] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,510] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,517] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,523] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,530] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,536] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,542] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,548] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,554] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,560] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,565] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,571] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,577] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:19,943] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:19,946] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:19,962] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.906 seconds
[2019-09-16 13:22:20,013] {scheduler_job.py:146} INFO - Started process (PID=31158) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:25,021] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:25,022] {logging_mixin.py:95} INFO - [2019-09-16 13:22:25,022] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:25,376] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:25,393] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:25,416] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-17T18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,419] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,428] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,437] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,443] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,449] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,456] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,463] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,469] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,476] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,482] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,488] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,495] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,502] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,509] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,516] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:25,909] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:25,912] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:25,926] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.913 seconds
[2019-09-16 13:22:25,970] {scheduler_job.py:146} INFO - Started process (PID=31160) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:30,981] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:30,982] {logging_mixin.py:95} INFO - [2019-09-16 13:22:30,981] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:31,330] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:31,347] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:31,371] {scheduler_job.py:1238} INFO - Created <DagRun stock_data @ 2019-01-17T19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,373] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,382] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,391] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,397] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,403] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,409] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,415] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,421] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,427] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,434] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,440] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,446] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,451] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,457] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,462] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,468] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:31,866] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:31,869] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.start 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:31,885] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.915 seconds
[2019-09-16 13:22:31,933] {scheduler_job.py:146} INFO - Started process (PID=31165) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:36,945] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:36,946] {logging_mixin.py:95} INFO - [2019-09-16 13:22:36,946] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:37,312] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:37,329] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:37,335] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,344] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,352] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,358] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,364] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,369] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,375] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,380] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,386] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,391] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,397] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,402] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,407] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,413] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,418] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,424] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:37,821] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:37,825] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.893 seconds
[2019-09-16 13:22:37,891] {scheduler_job.py:146} INFO - Started process (PID=31170) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:42,900] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:42,901] {logging_mixin.py:95} INFO - [2019-09-16 13:22:42,901] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:43,238] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:43,259] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:43,265] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,275] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,283] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,291] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,296] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,302] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,307] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,313] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,319] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,325] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,331] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,337] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,343] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,348] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,354] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,360] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:43,791] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:43,794] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:43,796] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:43,798] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:43,800] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:43,802] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-03 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:22:43,818] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.927 seconds
[2019-09-16 13:22:43,846] {scheduler_job.py:146} INFO - Started process (PID=31174) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:48,852] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:22:48,853] {logging_mixin.py:95} INFO - [2019-09-16 13:22:48,852] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:49,200] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:22:49,217] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:22:49,224] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,234] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,242] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,251] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,257] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,263] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,271] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,278] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,284] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,291] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,297] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,303] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,309] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,315] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,321] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,329] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:22:49,746] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:22:49,751] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.905 seconds
[2019-09-16 13:24:19,222] {scheduler_job.py:146} INFO - Started process (PID=31216) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:24,232] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:24,233] {logging_mixin.py:95} INFO - [2019-09-16 13:24:24,233] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:24,579] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:24,602] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:24,607] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,616] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,624] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,632] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,649] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,657] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,663] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,669] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,675] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,680] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,686] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,691] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,697] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,702] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:24,708] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:25,102] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:25,105] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,108] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,110] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,112] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,115] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-04 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,117] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,119] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,121] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,124] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,126] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-07 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,128] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,130] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,133] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,135] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,138] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-08 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:25,156] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.934 seconds
[2019-09-16 13:24:25,180] {scheduler_job.py:146} INFO - Started process (PID=31221) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:30,189] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:30,190] {logging_mixin.py:95} INFO - [2019-09-16 13:24:30,189] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:30,562] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:30,585] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:30,590] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,600] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,609] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,617] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,626] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,638] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,648] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,655] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,662] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,668] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,675] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,681] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,687] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,694] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,700] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:30,706] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:31,081] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:31,086] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.906 seconds
[2019-09-16 13:24:31,137] {scheduler_job.py:146} INFO - Started process (PID=31223) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:36,147] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:36,148] {logging_mixin.py:95} INFO - [2019-09-16 13:24:36,148] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:36,601] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:36,621] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:36,628] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,653] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,668] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,680] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,693] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,708] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,716] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,726] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,735] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,744] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,753] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,761] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,771] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,777] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:36,786] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:37,197] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:37,203] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.067 seconds
[2019-09-16 13:24:37,290] {scheduler_job.py:146} INFO - Started process (PID=31227) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:42,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:42,299] {logging_mixin.py:95} INFO - [2019-09-16 13:24:42,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:42,647] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:42,671] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:42,676] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,686] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,694] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,702] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,711] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,720] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,728] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,734] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,740] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,746] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,752] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,758] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,764] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,771] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,777] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:42,783] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:43,177] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:43,183] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.893 seconds
[2019-09-16 13:24:43,245] {scheduler_job.py:146} INFO - Started process (PID=31231) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:48,255] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:48,256] {logging_mixin.py:95} INFO - [2019-09-16 13:24:48,256] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:48,594] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:48,617] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:48,622] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,631] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,639] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,647] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,655] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,662] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,669] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,677] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,683] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,688] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,693] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,699] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,705] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,710] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,715] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:48,721] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:49,093] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:49,096] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:49,099] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:49,101] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:49,104] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:49,106] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-09 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:24:49,122] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.876 seconds
[2019-09-16 13:24:49,208] {scheduler_job.py:146} INFO - Started process (PID=31233) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:54,220] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:24:54,221] {logging_mixin.py:95} INFO - [2019-09-16 13:24:54,220] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:54,580] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:24:54,604] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:24:54,610] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,619] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,627] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,635] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,643] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,650] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,658] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,666] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,672] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,678] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,684] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,690] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,696] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,701] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,708] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:54,714] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:24:55,088] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:24:55,092] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.885 seconds
[2019-09-16 13:24:55,167] {scheduler_job.py:146} INFO - Started process (PID=31235) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:00,174] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:00,175] {logging_mixin.py:95} INFO - [2019-09-16 13:25:00,175] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:00,531] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:00,551] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:00,556] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,567] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,583] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,593] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,603] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,614] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,625] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,634] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,646] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,653] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,659] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,667] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,676] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,685] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:00,693] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:01,138] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:01,143] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.976 seconds
[2019-09-16 13:25:01,231] {scheduler_job.py:146} INFO - Started process (PID=31237) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:06,238] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:06,239] {logging_mixin.py:95} INFO - [2019-09-16 13:25:06,239] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:06,584] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:06,608] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:06,613] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,622] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,630] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,638] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,646] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,654] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,661] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,669] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,674] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,680] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,685] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,691] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,696] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,702] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,707] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:06,713] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:07,097] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:07,102] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.871 seconds
[2019-09-16 13:25:07,192] {scheduler_job.py:146} INFO - Started process (PID=31242) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:12,203] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:12,204] {logging_mixin.py:95} INFO - [2019-09-16 13:25:12,203] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:12,550] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:12,574] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:12,579] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,589] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,597] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,605] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,612] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,620] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,627] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,634] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,645] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,650] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,656] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,662] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,667] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,673] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:12,679] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:13,046] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:13,051] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.859 seconds
[2019-09-16 13:25:13,155] {scheduler_job.py:146} INFO - Started process (PID=31244) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:18,163] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:18,164] {logging_mixin.py:95} INFO - [2019-09-16 13:25:18,164] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:18,517] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:18,541] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:18,546] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,556] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,564] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,571] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,579] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,586] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,594] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,601] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,607] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,612] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,618] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,624] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,630] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,635] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,641] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:18,647] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:19,012] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:19,017] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.861 seconds
[2019-09-16 13:25:19,112] {scheduler_job.py:146} INFO - Started process (PID=31249) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:24,119] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:24,120] {logging_mixin.py:95} INFO - [2019-09-16 13:25:24,119] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:24,482] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:24,497] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:24,503] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,512] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,521] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,529] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,537] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,545] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,553] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,562] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,570] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,576] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,582] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,589] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,595] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,601] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,607] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,613] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:24,987] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:24,990] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:25:24,993] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:25:24,995] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:25:24,997] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:25:25,000] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-10 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:25:25,015] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.903 seconds
[2019-09-16 13:25:25,065] {scheduler_job.py:146} INFO - Started process (PID=31251) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:30,074] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:30,075] {logging_mixin.py:95} INFO - [2019-09-16 13:25:30,075] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:30,422] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:30,446] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:30,451] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,460] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,468] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,476] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,484] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,491] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,499] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,507] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,515] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,521] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,527] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,533] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,539] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,544] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,550] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,555] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:30,900] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:30,904] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.840 seconds
[2019-09-16 13:25:30,924] {scheduler_job.py:146} INFO - Started process (PID=31256) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:35,934] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:25:35,935] {logging_mixin.py:95} INFO - [2019-09-16 13:25:35,934] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:36,286] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:25:36,310] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:25:36,315] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,324] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,332] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,342] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,350] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,358] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,365] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,373] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,380] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,386] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,391] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,397] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,402] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,408] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,414] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,419] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:25:36,765] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:25:36,770] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.846 seconds
[2019-09-16 13:33:11,292] {scheduler_job.py:146} INFO - Started process (PID=31457) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:16,298] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:16,299] {logging_mixin.py:95} INFO - [2019-09-16 13:33:16,299] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:16,662] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:16,687] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:33:16,692] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,701] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,709] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,717] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,725] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,732] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,739] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,747] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,755] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,762] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,770] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,779] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,787] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,794] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,801] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:16,809] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:17,170] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:33:17,173] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_amzn_to_s3 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,175] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_msft_to_s3 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,178] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_fb_to_s3 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,180] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_aapl_to_s3 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,182] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_googl_to_s3 2019-01-01 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,184] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_amzn_to_s3 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,187] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,189] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,191] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,193] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,195] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-11 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,197] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,199] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,201] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,204] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,206] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-14 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,208] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,210] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,212] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,214] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,216] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-15 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,218] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,220] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,223] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,225] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,227] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-16 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,229] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,231] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,233] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,236] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,239] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-17 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,243] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,245] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,247] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,250] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,254] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-17 17:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,257] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,259] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,262] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,264] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,267] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-17 18:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,269] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_amzn_stock_data 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,272] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_msft_stock_data 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,274] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_fb_stock_data 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,276] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_aapl_stock_data 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,278] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.get_googl_stock_data 2019-01-17 19:10:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:17,297] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 6.005 seconds
[2019-09-16 13:33:17,343] {scheduler_job.py:146} INFO - Started process (PID=31460) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:22,349] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:22,350] {logging_mixin.py:95} INFO - [2019-09-16 13:33:22,350] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:22,700] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:22,724] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:33:22,729] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,738] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,746] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,754] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,762] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,770] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,778] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,785] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,792] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,801] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,809] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,817] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,824] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,832] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,839] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:22,846] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:23,120] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:33:23,125] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.783 seconds
[2019-09-16 13:33:23,199] {scheduler_job.py:146} INFO - Started process (PID=31464) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:28,204] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:28,205] {logging_mixin.py:95} INFO - [2019-09-16 13:33:28,205] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:28,574] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:28,591] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:33:28,596] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,606] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,614] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,623] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,631] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,640] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,648] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,657] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,666] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,674] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,683] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,691] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,700] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,708] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,716] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,725] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:28,996] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:33:29,000] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.801 seconds
[2019-09-16 13:33:29,052] {scheduler_job.py:146} INFO - Started process (PID=31469) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:34,057] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:34,058] {logging_mixin.py:95} INFO - [2019-09-16 13:33:34,058] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:34,471] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:34,499] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:33:34,506] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,523] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,537] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,551] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,564] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,578] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,591] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,605] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,618] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,630] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,642] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,654] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,668] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,678] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,690] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:34,702] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:35,020] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:33:35,025] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.973 seconds
[2019-09-16 13:33:35,102] {scheduler_job.py:146} INFO - Started process (PID=31472) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:40,108] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:40,109] {logging_mixin.py:95} INFO - [2019-09-16 13:33:40,109] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:40,464] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:40,488] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.385 seconds
[2019-09-16 13:33:40,557] {scheduler_job.py:146} INFO - Started process (PID=31474) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:45,561] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:45,562] {logging_mixin.py:95} INFO - [2019-09-16 13:33:45,562] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:45,907] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:45,922] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.365 seconds
[2019-09-16 13:33:46,006] {scheduler_job.py:146} INFO - Started process (PID=31477) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:51,015] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:51,016] {logging_mixin.py:95} INFO - [2019-09-16 13:33:51,016] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:51,373] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:51,397] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.391 seconds
[2019-09-16 13:33:51,453] {scheduler_job.py:146} INFO - Started process (PID=31481) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:56,463] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:33:56,464] {logging_mixin.py:95} INFO - [2019-09-16 13:33:56,463] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:56,824] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:33:56,849] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:33:56,854] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,863] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,871] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,879] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,888] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,896] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,905] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,913] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,921] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,928] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,936] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,945] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,952] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,961] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,968] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:56,976] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:33:57,274] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:33:57,279] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_msft_to_s3 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:33:57,295] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.842 seconds
[2019-09-16 13:33:57,404] {scheduler_job.py:146} INFO - Started process (PID=31482) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:02,412] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:02,414] {logging_mixin.py:95} INFO - [2019-09-16 13:34:02,413] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:02,753] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:02,778] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:02,783] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,793] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,801] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,808] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,816] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,823] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,830] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,838] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,846] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,853] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,860] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,868] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,876] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,883] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,890] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:02,897] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:03,166] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:03,170] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.766 seconds
[2019-09-16 13:34:03,263] {scheduler_job.py:146} INFO - Started process (PID=31485) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:08,269] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:08,270] {logging_mixin.py:95} INFO - [2019-09-16 13:34:08,269] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:08,628] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:08,644] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:08,649] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,658] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,666] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,674] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,682] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,689] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,696] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,704] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,712] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,720] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,728] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,736] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,743] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,751] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,759] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:08,767] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:09,032] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:09,037] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.774 seconds
[2019-09-16 13:34:09,105] {scheduler_job.py:146} INFO - Started process (PID=31490) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:14,110] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:14,111] {logging_mixin.py:95} INFO - [2019-09-16 13:34:14,111] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:14,521] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:14,543] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:14,550] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,563] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,575] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,586] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,596] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,605] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,613] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,621] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,629] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,637] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,644] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,652] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,660] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,668] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,675] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,684] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:14,949] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:14,952] {scheduler_job.py:1569} INFO - Creating / updating <TaskInstance: stock_data.upload_fb_to_s3 2019-01-02 17:00:00+00:00 [scheduled]> in ORM
[2019-09-16 13:34:14,964] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.859 seconds
[2019-09-16 13:34:15,067] {scheduler_job.py:146} INFO - Started process (PID=31492) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:20,072] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:20,073] {logging_mixin.py:95} INFO - [2019-09-16 13:34:20,073] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:20,462] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:20,486] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:20,492] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,501] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,509] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,518] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,526] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,534] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,541] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,549] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,557] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,565] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,573] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,580] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,588] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,596] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,603] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,611] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:20,878] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:20,883] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.817 seconds
[2019-09-16 13:34:20,920] {scheduler_job.py:146} INFO - Started process (PID=31497) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:25,929] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:25,931] {logging_mixin.py:95} INFO - [2019-09-16 13:34:25,930] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:26,289] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:26,313] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:26,319] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,329] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,338] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,346] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,354] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,362] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,370] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,378] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,385] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,392] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,400] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,408] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,416] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,423] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,430] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,438] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:26,693] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:26,698] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.777 seconds
[2019-09-16 13:34:26,772] {scheduler_job.py:146} INFO - Started process (PID=31498) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:31,779] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:31,780] {logging_mixin.py:95} INFO - [2019-09-16 13:34:31,780] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:32,171] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:32,192] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:32,198] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,208] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,217] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,226] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,236] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,246] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,256] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,267] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,277] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,288] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,301] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,313] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,323] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,336] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,351] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,362] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:32,694] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:32,700] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.928 seconds
[2019-09-16 13:34:32,726] {scheduler_job.py:146} INFO - Started process (PID=31501) to work on /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:37,730] {scheduler_job.py:1493} INFO - Processing file /Users/hdeva/airflow/dags/hello_world_dag.py for tasks to queue
[2019-09-16 13:34:37,731] {logging_mixin.py:95} INFO - [2019-09-16 13:34:37,731] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:38,174] {scheduler_job.py:1505} INFO - DAG(s) dict_keys(['stock_data']) retrieved from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-16 13:34:38,209] {scheduler_job.py:1228} INFO - Processing stock_data
[2019-09-16 13:34:38,223] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-01 17:00:00+00:00: scheduled__2019-01-01T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,238] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-02 17:00:00+00:00: scheduled__2019-01-02T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,251] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-03 17:00:00+00:00: scheduled__2019-01-03T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,269] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-04 17:00:00+00:00: scheduled__2019-01-04T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,282] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-07 17:00:00+00:00: scheduled__2019-01-07T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,291] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-08 17:00:00+00:00: scheduled__2019-01-08T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,302] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-09 17:00:00+00:00: scheduled__2019-01-09T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,311] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-10 17:00:00+00:00: scheduled__2019-01-10T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,321] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-11 17:00:00+00:00: scheduled__2019-01-11T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,332] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-14 17:00:00+00:00: scheduled__2019-01-14T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,341] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-15 17:00:00+00:00: scheduled__2019-01-15T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,351] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-16 17:00:00+00:00: scheduled__2019-01-16T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,363] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:00:00+00:00: scheduled__2019-01-17T17:00:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,371] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 17:10:00+00:00: scheduled__2019-01-17T17:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,382] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 18:10:00+00:00: scheduled__2019-01-17T18:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,391] {scheduler_job.py:711} INFO - Examining DAG run <DagRun stock_data @ 2019-01-17 19:10:00+00:00: scheduled__2019-01-17T19:10:00+00:00, externally triggered: False>
[2019-09-16 13:34:38,692] {scheduler_job.py:413} INFO - Skipping SLA check for <DAG: stock_data> because no tasks in DAG have SLAs
[2019-09-16 13:34:38,699] {scheduler_job.py:152} INFO - Processing /Users/hdeva/airflow/dags/hello_world_dag.py took 5.973 seconds
