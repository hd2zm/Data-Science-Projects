[2019-09-01 18:46:56,445] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_googl_to_s3 2019-09-01T23:41:11.504322+00:00 [queued]>
[2019-09-01 18:46:56,452] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_googl_to_s3 2019-09-01T23:41:11.504322+00:00 [queued]>
[2019-09-01 18:46:56,452] {taskinstance.py:834} INFO - 
--------------------------------------------------------------------------------
[2019-09-01 18:46:56,452] {taskinstance.py:835} INFO - Starting attempt 1 of 2
[2019-09-01 18:46:56,452] {taskinstance.py:836} INFO - 
--------------------------------------------------------------------------------
[2019-09-01 18:46:56,464] {taskinstance.py:855} INFO - Executing <Task(PythonOperator): upload_googl_to_s3> on 2019-09-01T23:41:11.504322+00:00
[2019-09-01 18:46:56,465] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'stock_data', 'upload_googl_to_s3', '2019-09-01T23:41:11.504322+00:00', '--job_id', '62', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/hello_world_dag.py', '--cfg_path', '/var/folders/z6/sk1b92g1385cmsp5qvg672kr0000gn/T/tmpq6aelmgh']
[2019-09-01 18:46:57,284] {base_task_runner.py:115} INFO - Job 62: Subtask upload_googl_to_s3 [2019-09-01 18:46:57,283] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-09-01 18:46:57,644] {base_task_runner.py:115} INFO - Job 62: Subtask upload_googl_to_s3 [2019-09-01 18:46:57,643] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-01 18:47:02,945] {base_task_runner.py:115} INFO - Job 62: Subtask upload_googl_to_s3 [2019-09-01 18:47:02,944] {cli.py:516} INFO - Running <TaskInstance: stock_data.upload_googl_to_s3 2019-09-01T23:41:11.504322+00:00 [running]> on host Haris-MacBook-Pro.local
[2019-09-01 18:47:07,959] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=stock_data
AIRFLOW_CTX_TASK_ID=upload_googl_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2019-09-01T23:41:11.504322+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2019-09-01T23:41:11.504322+00:00
[2019-09-01 18:47:07,964] {logging_mixin.py:95} INFO - GOOGL_stock_df.csv
[2019-09-01 18:47:08,026] {logging_mixin.py:95} INFO - [[34m2019-09-01 18:47:08,026[0m] {[34mcredentials.py:[0m1182} INFO[0m - Found credentials in shared credentials file: [1m~/.aws/credentials[0m[0m
[2019-09-01 18:47:09,241] {python_operator.py:114} INFO - Done. Returned value was: None
[2019-09-01 18:47:11,530] {logging_mixin.py:95} INFO - [[34m2019-09-01 18:47:11,528[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 0[0m
