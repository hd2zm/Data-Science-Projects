[2019-09-12 17:28:25,723] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_googl_to_s3 2019-09-12T22:22:39.316294+00:00 [queued]>
[2019-09-12 17:28:25,730] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_googl_to_s3 2019-09-12T22:22:39.316294+00:00 [queued]>
[2019-09-12 17:28:25,730] {taskinstance.py:834} INFO - 
--------------------------------------------------------------------------------
[2019-09-12 17:28:25,730] {taskinstance.py:835} INFO - Starting attempt 1 of 2
[2019-09-12 17:28:25,730] {taskinstance.py:836} INFO - 
--------------------------------------------------------------------------------
[2019-09-12 17:28:25,742] {taskinstance.py:855} INFO - Executing <Task(PythonOperator): upload_googl_to_s3> on 2019-09-12T22:22:39.316294+00:00
[2019-09-12 17:28:25,742] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'stock_data', 'upload_googl_to_s3', '2019-09-12T22:22:39.316294+00:00', '--job_id', '75', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/hello_world_dag.py', '--cfg_path', '/var/folders/z6/sk1b92g1385cmsp5qvg672kr0000gn/T/tmpm7d5wxfj']
[2019-09-12 17:28:26,563] {base_task_runner.py:115} INFO - Job 75: Subtask upload_googl_to_s3 [2019-09-12 17:28:26,562] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-09-12 17:28:26,904] {base_task_runner.py:115} INFO - Job 75: Subtask upload_googl_to_s3 [2019-09-12 17:28:26,903] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-09-12 17:28:32,407] {base_task_runner.py:115} INFO - Job 75: Subtask upload_googl_to_s3 [2019-09-12 17:28:32,406] {cli.py:516} INFO - Running <TaskInstance: stock_data.upload_googl_to_s3 2019-09-12T22:22:39.316294+00:00 [running]> on host Haris-MacBook-Pro.local
[2019-09-12 17:28:37,422] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=stock_data
AIRFLOW_CTX_TASK_ID=upload_googl_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2019-09-12T22:22:39.316294+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2019-09-12T22:22:39.316294+00:00
[2019-09-12 17:28:37,440] {logging_mixin.py:95} INFO - GOOGL_stock_df.csv
[2019-09-12 17:28:37,518] {logging_mixin.py:95} INFO - [[34m2019-09-12 17:28:37,518[0m] {[34mcredentials.py:[0m1182} INFO[0m - Found credentials in shared credentials file: [1m~/.aws/credentials[0m[0m
[2019-09-12 17:28:37,837] {python_operator.py:114} INFO - Done. Returned value was: None
[2019-09-12 17:28:40,818] {logging_mixin.py:95} INFO - [[34m2019-09-12 17:28:40,816[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 0[0m
