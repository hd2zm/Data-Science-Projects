[2019-08-28 17:32:36,826] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_to_s3 2019-08-28T22:28:22.184591+00:00 [queued]>
[2019-08-28 17:32:36,833] {taskinstance.py:616} INFO - Dependencies all met for <TaskInstance: stock_data.upload_to_s3 2019-08-28T22:28:22.184591+00:00 [queued]>
[2019-08-28 17:32:36,833] {taskinstance.py:834} INFO - 
--------------------------------------------------------------------------------
[2019-08-28 17:32:36,833] {taskinstance.py:835} INFO - Starting attempt 2 of 2
[2019-08-28 17:32:36,833] {taskinstance.py:836} INFO - 
--------------------------------------------------------------------------------
[2019-08-28 17:32:36,846] {taskinstance.py:855} INFO - Executing <Task(PythonOperator): upload_to_s3> on 2019-08-28T22:28:22.184591+00:00
[2019-08-28 17:32:36,846] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'stock_data', 'upload_to_s3', '2019-08-28T22:28:22.184591+00:00', '--job_id', '41', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/hello_world_dag.py', '--cfg_path', '/var/folders/z6/sk1b92g1385cmsp5qvg672kr0000gn/T/tmpdm9hlyux']
[2019-08-28 17:32:37,617] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3 [2019-08-28 17:32:37,616] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-08-28 17:32:37,962] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3 [2019-08-28 17:32:37,961] {dagbag.py:90} INFO - Filling up the DagBag from /Users/hdeva/airflow/dags/hello_world_dag.py
[2019-08-28 17:32:43,256] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3 [2019-08-28 17:32:43,256] {cli.py:516} INFO - Running <TaskInstance: stock_data.upload_to_s3 2019-08-28T22:28:22.184591+00:00 [running]> on host Haris-MacBook-Pro.local
[2019-08-28 17:32:48,267] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=stock_data
AIRFLOW_CTX_TASK_ID=upload_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2019-08-28T22:28:22.184591+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2019-08-28T22:28:22.184591+00:00
[2019-08-28 17:32:48,277] {taskinstance.py:1047} ERROR - tuple indices must be integers or slices, not str
Traceback (most recent call last):
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 922, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 43, in upload_to_s3
    stock = df['symbol'][0]
TypeError: tuple indices must be integers or slices, not str
[2019-08-28 17:32:48,278] {taskinstance.py:1076} INFO - All retries failed; marking task as FAILED
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3 Traceback (most recent call last):
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/bin/airflow", line 32, in <module>
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     args.func(args)
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     return f(*args, **kwargs)
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/bin/cli.py", line 522, in run
[2019-08-28 17:32:48,294] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     _run(args, dag, ti)
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/bin/cli.py", line 440, in _run
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     pool=args.pool,
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     return func(*args, **kwargs)
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 922, in _run_raw_task
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     result = task_copy.execute(context=context)
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 113, in execute
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     return_value = self.execute_callable()
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/anaconda3/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     return self.python_callable(*self.op_args, **self.op_kwargs)
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3   File "/Users/hdeva/airflow/dags/hello_world_dag.py", line 43, in upload_to_s3
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3     stock = df['symbol'][0]
[2019-08-28 17:32:48,295] {base_task_runner.py:115} INFO - Job 41: Subtask upload_to_s3 TypeError: tuple indices must be integers or slices, not str
[2019-08-28 17:32:51,912] {logging_mixin.py:95} INFO - [[34m2019-08-28 17:32:51,911[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 1[0m
